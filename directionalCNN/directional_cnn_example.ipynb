{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('directional_cnns')\n",
    "import os\n",
    "os.environ[ 'NUMBA_CACHE_DIR' ] = '/tmp/'\n",
    "from directional_cnns.feature_extraction import *\n",
    "from directional_cnns.training import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = None\n",
    "audio_folder = 'giantsteps-tempo-dataset/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tempo_extractor(file):\n",
    "    return extract_tempo_features(file, window_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very slow, don't run if already generated"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "convert_audio_folder_to_joblib(\n",
    "  audio_folder, ground_truth,\n",
    "  join(audio_folder, 'tempo_features.joblib'), tempo_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./jobs/log-20220311-164800.txt\n",
      "Starting train and predict. 2022-03-11 16:48:00.715147\n",
      "\n",
      "WARNING:tensorflow:From /tf/directional_cnns/directional_cnns/training.py:60: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.\n",
      "\n",
      "Default GPU: /device:GPU:0\n",
      "Creating local copies, if necessary...\n",
      "Local copy for train.tsv not needed.\n",
      "Local copy for val.tsv not needed.\n",
      "Local copy for test.tsv not needed.\n",
      "Local copy for giantsteps-tempo-dataset/audio/tempo_features.joblib not needed.\n",
      "Loaded features for 664 files from ['giantsteps-tempo-dataset/audio/tempo_features.joblib'].\n",
      "We assume that we are estimating TEMPO. First feature shape: (40, 2584, 1)\n",
      "Loading ground truth...\n",
      "Loaded 398 training annotations from train.tsv.\n",
      "Loaded 132 validation annotations from val.tsv.\n",
      "Number of classes: 256\n",
      "Creating generators...\n",
      "Creating model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=9322\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 5.5248 - accuracy: 0.0078 - val_loss: 5.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5278 - accuracy: 0.0000e+00 - val_loss: 5.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.5387 - accuracy: 0.0156 - val_loss: 5.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.5149 - accuracy: 0.0000e+00 - val_loss: 5.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5536 - accuracy: 0.0078 - val_loss: 5.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.5548 - accuracy: 0.0000e+00 - val_loss: 5.5476 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5265 - accuracy: 0.0078 - val_loss: 5.5476 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.5413 - accuracy: 0.0000e+00 - val_loss: 5.5477 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5184 - accuracy: 0.0078 - val_loss: 5.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4610 - accuracy: 0.0078 - val_loss: 5.5476 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4996 - accuracy: 0.0078 - val_loss: 5.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4796 - accuracy: 0.0078 - val_loss: 5.5462 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4560 - accuracy: 0.0312 - val_loss: 5.5462 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4422 - accuracy: 0.0234 - val_loss: 5.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4895 - accuracy: 0.0156 - val_loss: 5.5454 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4813 - accuracy: 0.0000e+00 - val_loss: 5.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4221 - accuracy: 0.0078 - val_loss: 5.5432 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.4612 - accuracy: 0.0312 - val_loss: 5.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4665 - accuracy: 0.0000e+00 - val_loss: 5.5432 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4088 - accuracy: 0.0156 - val_loss: 5.5429 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4562 - accuracy: 0.0078 - val_loss: 5.5421 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4047 - accuracy: 0.0156 - val_loss: 5.5410 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4114 - accuracy: 0.0234 - val_loss: 5.5390 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.4485 - accuracy: 0.0078 - val_loss: 5.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3716 - accuracy: 0.0391 - val_loss: 5.5381 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3921 - accuracy: 0.0078 - val_loss: 5.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3841 - accuracy: 0.0312 - val_loss: 5.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4541 - accuracy: 0.0000e+00 - val_loss: 5.5336 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4344 - accuracy: 0.0078 - val_loss: 5.5320 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4261 - accuracy: 0.0078 - val_loss: 5.5305 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3337 - accuracy: 0.0391 - val_loss: 5.5284 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.4339 - accuracy: 0.0156 - val_loss: 5.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4226 - accuracy: 0.0234 - val_loss: 5.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3794 - accuracy: 0.0078 - val_loss: 5.5245 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3777 - accuracy: 0.0156 - val_loss: 5.5227 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3845 - accuracy: 0.0391 - val_loss: 5.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3630 - accuracy: 0.0156 - val_loss: 5.5211 - val_accuracy: 0.0078\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3297 - accuracy: 0.0234 - val_loss: 5.5184 - val_accuracy: 0.0156\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3853 - accuracy: 0.0312 - val_loss: 5.5152 - val_accuracy: 0.0234\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3105 - accuracy: 0.0625 - val_loss: 5.5099 - val_accuracy: 0.0234\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3662 - accuracy: 0.0078 - val_loss: 5.5082 - val_accuracy: 0.0234\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3278 - accuracy: 0.0312 - val_loss: 5.5075 - val_accuracy: 0.0234\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.3153 - accuracy: 0.0156 - val_loss: 5.5070 - val_accuracy: 0.0234\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3818 - accuracy: 0.0078 - val_loss: 5.5065 - val_accuracy: 0.0234\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3694 - accuracy: 0.0156 - val_loss: 5.5058 - val_accuracy: 0.0234\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.3297 - accuracy: 0.0078 - val_loss: 5.5048 - val_accuracy: 0.0234\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.3517 - accuracy: 0.0234 - val_loss: 5.5032 - val_accuracy: 0.0156\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3542 - accuracy: 0.0078 - val_loss: 5.5007 - val_accuracy: 0.0156\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2635 - accuracy: 0.0234 - val_loss: 5.4944 - val_accuracy: 0.0156\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2465 - accuracy: 0.0391 - val_loss: 5.4858 - val_accuracy: 0.0156\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3167 - accuracy: 0.0078 - val_loss: 5.4771 - val_accuracy: 0.0156\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3105 - accuracy: 0.0234 - val_loss: 5.4675 - val_accuracy: 0.0156\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3174 - accuracy: 0.0078 - val_loss: 5.4608 - val_accuracy: 0.0156\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2972 - accuracy: 0.0156 - val_loss: 5.4550 - val_accuracy: 0.0078\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3433 - accuracy: 0.0078 - val_loss: 5.4506 - val_accuracy: 0.0078\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2475 - accuracy: 0.0469 - val_loss: 5.4520 - val_accuracy: 0.0156\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2413 - accuracy: 0.0312 - val_loss: 5.4520 - val_accuracy: 0.0156\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2253 - accuracy: 0.0234 - val_loss: 5.4500 - val_accuracy: 0.0078\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3191 - accuracy: 0.0391 - val_loss: 5.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1925 - accuracy: 0.0625 - val_loss: 5.4441 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.2225 - accuracy: 0.0312 - val_loss: 5.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3051 - accuracy: 0.0234 - val_loss: 5.4390 - val_accuracy: 0.0078\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2644 - accuracy: 0.0391 - val_loss: 5.4363 - val_accuracy: 0.0156\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2818 - accuracy: 0.0078 - val_loss: 5.4327 - val_accuracy: 0.0156\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2819 - accuracy: 0.0391 - val_loss: 5.4308 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1783 - accuracy: 0.0078 - val_loss: 5.4299 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2163 - accuracy: 0.0156 - val_loss: 5.4287 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.1541 - accuracy: 0.0312 - val_loss: 5.4248 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2065 - accuracy: 0.0156 - val_loss: 5.4159 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1493 - accuracy: 0.0078 - val_loss: 5.4084 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2166 - accuracy: 0.0312 - val_loss: 5.3986 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1015 - accuracy: 0.0703 - val_loss: 5.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1837 - accuracy: 0.0078 - val_loss: 5.3788 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.0745 - accuracy: 0.0156 - val_loss: 5.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.0924 - accuracy: 0.0625 - val_loss: 5.3567 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1209 - accuracy: 0.0156 - val_loss: 5.3385 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1394 - accuracy: 0.0547 - val_loss: 5.3243 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2012 - accuracy: 0.0000e+00 - val_loss: 5.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0960 - accuracy: 0.0156 - val_loss: 5.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2814 - accuracy: 0.0156 - val_loss: 5.2982 - val_accuracy: 0.0078\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1944 - accuracy: 0.0156 - val_loss: 5.2868 - val_accuracy: 0.0078\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0591 - accuracy: 0.0625 - val_loss: 5.2786 - val_accuracy: 0.0078\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 5.1520 - accuracy: 0.0078 - val_loss: 5.2686 - val_accuracy: 0.0078\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0964 - accuracy: 0.0703 - val_loss: 5.2509 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0810 - accuracy: 0.0234 - val_loss: 5.2390 - val_accuracy: 0.0078\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1383 - accuracy: 0.0078 - val_loss: 5.2357 - val_accuracy: 0.0078\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.0878 - accuracy: 0.0703 - val_loss: 5.2288 - val_accuracy: 0.0078\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0317 - accuracy: 0.0078 - val_loss: 5.2222 - val_accuracy: 0.0078\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9673 - accuracy: 0.0234 - val_loss: 5.2130 - val_accuracy: 0.0078\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1273 - accuracy: 0.0391 - val_loss: 5.2022 - val_accuracy: 0.0078\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0711 - accuracy: 0.0156 - val_loss: 5.1938 - val_accuracy: 0.0078\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1128 - accuracy: 0.0312 - val_loss: 5.1915 - val_accuracy: 0.0078\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0384 - accuracy: 0.0547 - val_loss: 5.1917 - val_accuracy: 0.0078\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9542 - accuracy: 0.0469 - val_loss: 5.1913 - val_accuracy: 0.0078\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0626 - accuracy: 0.0234 - val_loss: 5.1795 - val_accuracy: 0.0078\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9620 - accuracy: 0.0000e+00 - val_loss: 5.1673 - val_accuracy: 0.0078\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0067 - accuracy: 0.0391 - val_loss: 5.1573 - val_accuracy: 0.0078\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9507 - accuracy: 0.0156 - val_loss: 5.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0460 - accuracy: 0.0000e+00 - val_loss: 5.1498 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0363 - accuracy: 0.0234 - val_loss: 5.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1799 - accuracy: 0.0000e+00 - val_loss: 5.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.0842 - accuracy: 0.0312 - val_loss: 5.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0501 - accuracy: 0.0234 - val_loss: 5.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9372 - accuracy: 0.0625 - val_loss: 5.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9282 - accuracy: 0.0156 - val_loss: 5.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9846 - accuracy: 0.0156 - val_loss: 5.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9438 - accuracy: 0.0781 - val_loss: 5.0968 - val_accuracy: 0.0078\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9569 - accuracy: 0.0312 - val_loss: 5.0802 - val_accuracy: 0.0156\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.0075 - accuracy: 0.0391 - val_loss: 5.0552 - val_accuracy: 0.0156\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9364 - accuracy: 0.0391 - val_loss: 5.0385 - val_accuracy: 0.0078\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9931 - accuracy: 0.0078 - val_loss: 5.0318 - val_accuracy: 0.0156\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8774 - accuracy: 0.0547 - val_loss: 5.0285 - val_accuracy: 0.0156\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9696 - accuracy: 0.0156 - val_loss: 5.0298 - val_accuracy: 0.0156\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8908 - accuracy: 0.0000e+00 - val_loss: 5.0254 - val_accuracy: 0.0156\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8613 - accuracy: 0.0391 - val_loss: 4.9809 - val_accuracy: 0.0156\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9945 - accuracy: 0.0234 - val_loss: 4.9385 - val_accuracy: 0.0547\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9521 - accuracy: 0.0625 - val_loss: 4.9049 - val_accuracy: 0.0781\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8114 - accuracy: 0.0469 - val_loss: 4.8845 - val_accuracy: 0.0781\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1219 - accuracy: 0.0312 - val_loss: 4.8778 - val_accuracy: 0.0703\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8509 - accuracy: 0.0391 - val_loss: 4.8778 - val_accuracy: 0.0781\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9962 - accuracy: 0.0391 - val_loss: 4.8820 - val_accuracy: 0.0938\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.7556 - accuracy: 0.0547 - val_loss: 4.8887 - val_accuracy: 0.1094\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8170 - accuracy: 0.0547 - val_loss: 4.9003 - val_accuracy: 0.1094\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7803 - accuracy: 0.0703 - val_loss: 4.8853 - val_accuracy: 0.1250\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8174 - accuracy: 0.0625 - val_loss: 4.8575 - val_accuracy: 0.1406\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0832 - accuracy: 0.0078 - val_loss: 4.8401 - val_accuracy: 0.1406\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7494 - accuracy: 0.0078 - val_loss: 4.8305 - val_accuracy: 0.1406\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9006 - accuracy: 0.0312 - val_loss: 4.8250 - val_accuracy: 0.1406\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.8522 - accuracy: 0.0859 - val_loss: 4.8123 - val_accuracy: 0.1406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6774 - accuracy: 0.1016 - val_loss: 4.7816 - val_accuracy: 0.1406\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8117 - accuracy: 0.0156 - val_loss: 4.7593 - val_accuracy: 0.1406\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9033 - accuracy: 0.0234 - val_loss: 4.7400 - val_accuracy: 0.1328\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7650 - accuracy: 0.0156 - val_loss: 4.7309 - val_accuracy: 0.1328\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9484 - accuracy: 0.0312 - val_loss: 4.7222 - val_accuracy: 0.1328\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0381 - accuracy: 0.0234 - val_loss: 4.7248 - val_accuracy: 0.1250\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9450 - accuracy: 0.0234 - val_loss: 4.7196 - val_accuracy: 0.1094\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7835 - accuracy: 0.0312 - val_loss: 4.7173 - val_accuracy: 0.1016\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8510 - accuracy: 0.0156 - val_loss: 4.7215 - val_accuracy: 0.0703\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8827 - accuracy: 0.0469 - val_loss: 4.7181 - val_accuracy: 0.0781\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9147 - accuracy: 0.0078 - val_loss: 4.6987 - val_accuracy: 0.0859\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9984 - accuracy: 0.0000e+00 - val_loss: 4.6744 - val_accuracy: 0.1016\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9502 - accuracy: 0.0234 - val_loss: 4.6625 - val_accuracy: 0.1016\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7874 - accuracy: 0.0469 - val_loss: 4.6465 - val_accuracy: 0.1172\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8889 - accuracy: 0.0703 - val_loss: 4.6351 - val_accuracy: 0.1172\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7829 - accuracy: 0.0078 - val_loss: 4.6253 - val_accuracy: 0.1250\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8920 - accuracy: 0.0469 - val_loss: 4.6272 - val_accuracy: 0.1328\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8326 - accuracy: 0.0312 - val_loss: 4.6328 - val_accuracy: 0.1172\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7693 - accuracy: 0.0547 - val_loss: 4.6421 - val_accuracy: 0.1016\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8782 - accuracy: 0.0234 - val_loss: 4.6550 - val_accuracy: 0.1094\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9201 - accuracy: 0.0078 - val_loss: 4.6648 - val_accuracy: 0.1094\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9162 - accuracy: 0.0469 - val_loss: 4.6844 - val_accuracy: 0.1094\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8094 - accuracy: 0.0234 - val_loss: 4.7087 - val_accuracy: 0.1016\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8735 - accuracy: 0.0469 - val_loss: 4.7235 - val_accuracy: 0.0859\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7213 - accuracy: 0.0391 - val_loss: 4.7411 - val_accuracy: 0.0703\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8074 - accuracy: 0.0469 - val_loss: 4.7451 - val_accuracy: 0.0859\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8635 - accuracy: 0.0234 - val_loss: 4.7408 - val_accuracy: 0.1016\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5888 - accuracy: 0.0703 - val_loss: 4.7361 - val_accuracy: 0.0859\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9738 - accuracy: 0.0000e+00 - val_loss: 4.7358 - val_accuracy: 0.0938\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8541 - accuracy: 0.0391 - val_loss: 4.7379 - val_accuracy: 0.0938\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0441 - accuracy: 0.0078 - val_loss: 4.7415 - val_accuracy: 0.1016\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7796 - accuracy: 0.0312 - val_loss: 4.7305 - val_accuracy: 0.1172\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7903 - accuracy: 0.0234 - val_loss: 4.7301 - val_accuracy: 0.1094\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7792 - accuracy: 0.0234 - val_loss: 4.7228 - val_accuracy: 0.0938\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7354 - accuracy: 0.0469 - val_loss: 4.7218 - val_accuracy: 0.1016\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8385 - accuracy: 0.0234 - val_loss: 4.7261 - val_accuracy: 0.1094\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1558 - accuracy: 0.0000e+00 - val_loss: 4.7340 - val_accuracy: 0.1016\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5738 - accuracy: 0.0156 - val_loss: 4.7488 - val_accuracy: 0.0625\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7386 - accuracy: 0.0312 - val_loss: 4.7619 - val_accuracy: 0.0469\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8519 - accuracy: 0.0312 - val_loss: 4.7635 - val_accuracy: 0.0312\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7978 - accuracy: 0.0156 - val_loss: 4.7563 - val_accuracy: 0.0234\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6643 - accuracy: 0.0469 - val_loss: 4.7477 - val_accuracy: 0.0312\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8694 - accuracy: 0.0469 - val_loss: 4.7357 - val_accuracy: 0.0312\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8975 - accuracy: 0.0391 - val_loss: 4.7343 - val_accuracy: 0.0312\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8215 - accuracy: 0.0469 - val_loss: 4.7396 - val_accuracy: 0.0234\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8686 - accuracy: 0.0469 - val_loss: 4.7519 - val_accuracy: 0.0156\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7958 - accuracy: 0.0625 - val_loss: 4.7634 - val_accuracy: 0.0078\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8529 - accuracy: 0.0234 - val_loss: 4.7704 - val_accuracy: 0.0078\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5855 - accuracy: 0.0391 - val_loss: 4.7711 - val_accuracy: 0.0078\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8117 - accuracy: 0.0000e+00 - val_loss: 4.7567 - val_accuracy: 0.0078\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8272 - accuracy: 0.0078 - val_loss: 4.7425 - val_accuracy: 0.0078\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7364 - accuracy: 0.0312 - val_loss: 4.7448 - val_accuracy: 0.0156\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8197 - accuracy: 0.0234 - val_loss: 4.7496 - val_accuracy: 0.0156\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6812 - accuracy: 0.0391 - val_loss: 4.7479 - val_accuracy: 0.0156\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8004 - accuracy: 0.0547 - val_loss: 4.7509 - val_accuracy: 0.0234\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6777 - accuracy: 0.0469 - val_loss: 4.7447 - val_accuracy: 0.0234\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6324 - accuracy: 0.0312 - val_loss: 4.7323 - val_accuracy: 0.0234\n",
      "Epoch 187/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8537 - accuracy: 0.0078 - val_loss: 4.7263 - val_accuracy: 0.0391\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8462 - accuracy: 0.0156 - val_loss: 4.7299 - val_accuracy: 0.0625\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7578 - accuracy: 0.0391 - val_loss: 4.7298 - val_accuracy: 0.0547\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7681 - accuracy: 0.0156 - val_loss: 4.7140 - val_accuracy: 0.0547\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7126 - accuracy: 0.0547 - val_loss: 4.7123 - val_accuracy: 0.0391\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5442 - accuracy: 0.0703 - val_loss: 4.7083 - val_accuracy: 0.0469\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8716 - accuracy: 0.0312 - val_loss: 4.7018 - val_accuracy: 0.0469\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6763 - accuracy: 0.0391 - val_loss: 4.7031 - val_accuracy: 0.0469\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9185 - accuracy: 0.0234 - val_loss: 4.6954 - val_accuracy: 0.0391\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8867 - accuracy: 0.0156 - val_loss: 4.6933 - val_accuracy: 0.0391\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7559 - accuracy: 0.0547 - val_loss: 4.7017 - val_accuracy: 0.0234\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5796 - accuracy: 0.0547 - val_loss: 4.7148 - val_accuracy: 0.0156\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9165 - accuracy: 0.0078 - val_loss: 4.7265 - val_accuracy: 0.0156\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8472 - accuracy: 0.0156 - val_loss: 4.7413 - val_accuracy: 0.0078\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7160 - accuracy: 0.0312 - val_loss: 4.7459 - val_accuracy: 0.0078\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7048 - accuracy: 0.0234 - val_loss: 4.7482 - val_accuracy: 0.0156\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7048 - accuracy: 0.0391 - val_loss: 4.7474 - val_accuracy: 0.0234\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6746 - accuracy: 0.0469 - val_loss: 4.7320 - val_accuracy: 0.0234\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8046 - accuracy: 0.0547 - val_loss: 4.7141 - val_accuracy: 0.0156\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8734 - accuracy: 0.0312 - val_loss: 4.7078 - val_accuracy: 0.0234\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6412 - accuracy: 0.0469 - val_loss: 4.7085 - val_accuracy: 0.0391\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8333 - accuracy: 0.0625 - val_loss: 4.7137 - val_accuracy: 0.0391\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8794 - accuracy: 0.0156 - val_loss: 4.7227 - val_accuracy: 0.0312\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7793 - accuracy: 0.0234 - val_loss: 4.7126 - val_accuracy: 0.0391\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8072 - accuracy: 0.0703 - val_loss: 4.7057 - val_accuracy: 0.0469\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6035 - accuracy: 0.0547 - val_loss: 4.7076 - val_accuracy: 0.0391\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7205 - accuracy: 0.0156 - val_loss: 4.7049 - val_accuracy: 0.0391\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6810 - accuracy: 0.0312 - val_loss: 4.7042 - val_accuracy: 0.0312\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6955 - accuracy: 0.0703 - val_loss: 4.7113 - val_accuracy: 0.0234\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8193 - accuracy: 0.0078 - val_loss: 4.7055 - val_accuracy: 0.0078\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.5898 - accuracy: 0.0625 - val_loss: 4.6847 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5914 - accuracy: 0.1016 - val_loss: 4.6801 - val_accuracy: 0.0078\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7534 - accuracy: 0.0547 - val_loss: 4.6703 - val_accuracy: 0.0078\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5254 - accuracy: 0.1250 - val_loss: 4.6544 - val_accuracy: 0.0078\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6298 - accuracy: 0.0703 - val_loss: 4.6461 - val_accuracy: 0.0078\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7603 - accuracy: 0.0156 - val_loss: 4.6439 - val_accuracy: 0.0078\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8579 - accuracy: 0.0078 - val_loss: 4.6478 - val_accuracy: 0.0078\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7166 - accuracy: 0.0078 - val_loss: 4.6381 - val_accuracy: 0.0078\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9109 - accuracy: 0.0156 - val_loss: 4.6324 - val_accuracy: 0.0078\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0051 - accuracy: 0.0000e+00 - val_loss: 4.6320 - val_accuracy: 0.0078\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9676 - accuracy: 0.0156 - val_loss: 4.6332 - val_accuracy: 0.0078\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.4595 - accuracy: 0.0391 - val_loss: 4.6029 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8363 - accuracy: 0.0156 - val_loss: 4.5861 - val_accuracy: 0.0078\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6879 - accuracy: 0.0625 - val_loss: 4.5818 - val_accuracy: 0.0078\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8451 - accuracy: 0.0000e+00 - val_loss: 4.5761 - val_accuracy: 0.0156\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8565 - accuracy: 0.0312 - val_loss: 4.5690 - val_accuracy: 0.0312\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8836 - accuracy: 0.0234 - val_loss: 4.5684 - val_accuracy: 0.0391\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9623 - accuracy: 0.0234 - val_loss: 4.5783 - val_accuracy: 0.0391\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7228 - accuracy: 0.0078 - val_loss: 4.5784 - val_accuracy: 0.0703\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8250 - accuracy: 0.0547 - val_loss: 4.5792 - val_accuracy: 0.0781\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7795 - accuracy: 0.0078 - val_loss: 4.5761 - val_accuracy: 0.0859\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7146 - accuracy: 0.0547 - val_loss: 4.5740 - val_accuracy: 0.0938\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7385 - accuracy: 0.0156 - val_loss: 4.5673 - val_accuracy: 0.0938\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7858 - accuracy: 0.0000e+00 - val_loss: 4.5682 - val_accuracy: 0.1016\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6300 - accuracy: 0.0391 - val_loss: 4.5735 - val_accuracy: 0.0938\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8201 - accuracy: 0.0312 - val_loss: 4.5858 - val_accuracy: 0.0781\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5998 - accuracy: 0.0547 - val_loss: 4.5951 - val_accuracy: 0.0547\n",
      "Epoch 244/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8506 - accuracy: 0.0234 - val_loss: 4.5861 - val_accuracy: 0.0312\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6827 - accuracy: 0.0234 - val_loss: 4.5765 - val_accuracy: 0.0312\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7079 - accuracy: 0.0312 - val_loss: 4.5477 - val_accuracy: 0.0469\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6635 - accuracy: 0.0078 - val_loss: 4.5185 - val_accuracy: 0.0469\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8095 - accuracy: 0.0234 - val_loss: 4.5001 - val_accuracy: 0.0469\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8734 - accuracy: 0.0000e+00 - val_loss: 4.4959 - val_accuracy: 0.0703\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6527 - accuracy: 0.0469 - val_loss: 4.4956 - val_accuracy: 0.0625\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6688 - accuracy: 0.0391 - val_loss: 4.4837 - val_accuracy: 0.0859\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.6279 - accuracy: 0.0234 - val_loss: 4.4586 - val_accuracy: 0.1016\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8363 - accuracy: 0.0156 - val_loss: 4.4509 - val_accuracy: 0.1016\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7252 - accuracy: 0.0078 - val_loss: 4.4427 - val_accuracy: 0.0938\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7516 - accuracy: 0.0156 - val_loss: 4.4430 - val_accuracy: 0.0859\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7689 - accuracy: 0.0156 - val_loss: 4.4567 - val_accuracy: 0.0547\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5807 - accuracy: 0.0547 - val_loss: 4.4524 - val_accuracy: 0.0625\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5310 - accuracy: 0.0469 - val_loss: 4.4344 - val_accuracy: 0.0859\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7621 - accuracy: 0.0391 - val_loss: 4.4207 - val_accuracy: 0.1016\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6608 - accuracy: 0.0391 - val_loss: 4.4104 - val_accuracy: 0.0938\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6816 - accuracy: 0.0391 - val_loss: 4.3921 - val_accuracy: 0.1094\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8319 - accuracy: 0.0312 - val_loss: 4.3855 - val_accuracy: 0.1094\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6524 - accuracy: 0.0625 - val_loss: 4.3789 - val_accuracy: 0.0938\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8374 - accuracy: 0.0156 - val_loss: 4.3653 - val_accuracy: 0.1094\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6464 - accuracy: 0.0156 - val_loss: 4.3606 - val_accuracy: 0.1250\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6139 - accuracy: 0.0547 - val_loss: 4.3627 - val_accuracy: 0.1172\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7042 - accuracy: 0.0234 - val_loss: 4.3687 - val_accuracy: 0.1250\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.5611 - accuracy: 0.0234 - val_loss: 4.3741 - val_accuracy: 0.1250\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.6352 - accuracy: 0.0625 - val_loss: 4.3571 - val_accuracy: 0.1250\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.6911 - accuracy: 0.0312 - val_loss: 4.3368 - val_accuracy: 0.1250\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7216 - accuracy: 0.0547 - val_loss: 4.3134 - val_accuracy: 0.1250\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6327 - accuracy: 0.0703 - val_loss: 4.3009 - val_accuracy: 0.1250\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7487 - accuracy: 0.0000e+00 - val_loss: 4.2936 - val_accuracy: 0.1250\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7874 - accuracy: 0.0156 - val_loss: 4.2892 - val_accuracy: 0.1172\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6327 - accuracy: 0.0469 - val_loss: 4.2850 - val_accuracy: 0.1094\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6226 - accuracy: 0.0547 - val_loss: 4.2729 - val_accuracy: 0.1172\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7605 - accuracy: 0.0469 - val_loss: 4.2586 - val_accuracy: 0.1172\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6090 - accuracy: 0.0234 - val_loss: 4.2555 - val_accuracy: 0.1172\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6035 - accuracy: 0.0156 - val_loss: 4.2608 - val_accuracy: 0.1172\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5338 - accuracy: 0.0625 - val_loss: 4.2723 - val_accuracy: 0.0859\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6664 - accuracy: 0.0469 - val_loss: 4.2874 - val_accuracy: 0.0312\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5268 - accuracy: 0.0469 - val_loss: 4.2861 - val_accuracy: 0.0312\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7039 - accuracy: 0.0391 - val_loss: 4.2771 - val_accuracy: 0.0391\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4665 - accuracy: 0.0703 - val_loss: 4.2697 - val_accuracy: 0.0234\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8030 - accuracy: 0.0156 - val_loss: 4.2686 - val_accuracy: 0.0234\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6961 - accuracy: 0.0312 - val_loss: 4.2676 - val_accuracy: 0.0234\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.6090 - accuracy: 0.0234 - val_loss: 4.2417 - val_accuracy: 0.0703\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5623 - accuracy: 0.0547 - val_loss: 4.2177 - val_accuracy: 0.1016\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8806 - accuracy: 0.0391 - val_loss: 4.2134 - val_accuracy: 0.1172\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9088 - accuracy: 0.0234 - val_loss: 4.2160 - val_accuracy: 0.1172\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7207 - accuracy: 0.0234 - val_loss: 4.2144 - val_accuracy: 0.1250\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8194 - accuracy: 0.0312 - val_loss: 4.2115 - val_accuracy: 0.1172\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.6325 - accuracy: 0.0625 - val_loss: 4.2064 - val_accuracy: 0.1484\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7112 - accuracy: 0.0234 - val_loss: 4.2161 - val_accuracy: 0.1328\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8896 - accuracy: 0.0000e+00 - val_loss: 4.2311 - val_accuracy: 0.1328\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6931 - accuracy: 0.0234 - val_loss: 4.2501 - val_accuracy: 0.1328\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6643 - accuracy: 0.0469 - val_loss: 4.2724 - val_accuracy: 0.1250\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8113 - accuracy: 0.0156 - val_loss: 4.2953 - val_accuracy: 0.1172\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8418 - accuracy: 0.0391 - val_loss: 4.3166 - val_accuracy: 0.1172\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5922 - accuracy: 0.0234 - val_loss: 4.3441 - val_accuracy: 0.1094\n",
      "Epoch 301/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6543 - accuracy: 0.0312 - val_loss: 4.3704 - val_accuracy: 0.0703\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7360 - accuracy: 0.0391 - val_loss: 4.3929 - val_accuracy: 0.0234\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5222 - accuracy: 0.0312 - val_loss: 4.3943 - val_accuracy: 0.0234\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6564 - accuracy: 0.0078 - val_loss: 4.3849 - val_accuracy: 0.0312\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6100 - accuracy: 0.0156 - val_loss: 4.3836 - val_accuracy: 0.0156\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6510 - accuracy: 0.0234 - val_loss: 4.3940 - val_accuracy: 0.0391\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6406 - accuracy: 0.0234 - val_loss: 4.3940 - val_accuracy: 0.0547\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6189 - accuracy: 0.0625 - val_loss: 4.3926 - val_accuracy: 0.0703\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.5333 - accuracy: 0.0703 - val_loss: 4.3888 - val_accuracy: 0.0781\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7081 - accuracy: 0.0312 - val_loss: 4.3787 - val_accuracy: 0.0781\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8043 - accuracy: 0.0234 - val_loss: 4.3769 - val_accuracy: 0.0781\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5202 - accuracy: 0.0391 - val_loss: 4.3852 - val_accuracy: 0.0625\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7975 - accuracy: 0.0312 - val_loss: 4.3990 - val_accuracy: 0.0312\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7802 - accuracy: 0.0391 - val_loss: 4.4159 - val_accuracy: 0.0234\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6061 - accuracy: 0.0625 - val_loss: 4.4172 - val_accuracy: 0.0156\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6679 - accuracy: 0.0859 - val_loss: 4.4256 - val_accuracy: 0.0156\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.5284 - accuracy: 0.0156 - val_loss: 4.4413 - val_accuracy: 0.0156\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4275 - accuracy: 0.0703 - val_loss: 4.4511 - val_accuracy: 0.0156\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8822 - accuracy: 0.0078 - val_loss: 4.4607 - val_accuracy: 0.0156\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7970 - accuracy: 0.0234 - val_loss: 4.4789 - val_accuracy: 0.0156\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6392 - accuracy: 0.0703 - val_loss: 4.5021 - val_accuracy: 0.0156\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5253 - accuracy: 0.0312 - val_loss: 4.5278 - val_accuracy: 0.0156\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5563 - accuracy: 0.0312 - val_loss: 4.5457 - val_accuracy: 0.0156\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5954 - accuracy: 0.0234 - val_loss: 4.5564 - val_accuracy: 0.0156\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5503 - accuracy: 0.0469 - val_loss: 4.5595 - val_accuracy: 0.0156\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6132 - accuracy: 0.0078 - val_loss: 4.5659 - val_accuracy: 0.0156\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7236 - accuracy: 0.0469 - val_loss: 4.5701 - val_accuracy: 0.0156\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6066 - accuracy: 0.0156 - val_loss: 4.5587 - val_accuracy: 0.0156\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6966 - accuracy: 0.0391 - val_loss: 4.5577 - val_accuracy: 0.0156\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6715 - accuracy: 0.0625 - val_loss: 4.5459 - val_accuracy: 0.0234\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5175 - accuracy: 0.0469 - val_loss: 4.5252 - val_accuracy: 0.0234\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5853 - accuracy: 0.0547 - val_loss: 4.5107 - val_accuracy: 0.0234\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6549 - accuracy: 0.0703 - val_loss: 4.4999 - val_accuracy: 0.0156\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8523 - accuracy: 0.0312 - val_loss: 4.5017 - val_accuracy: 0.0078\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6462 - accuracy: 0.0625 - val_loss: 4.5009 - val_accuracy: 0.0078\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6308 - accuracy: 0.0312 - val_loss: 4.4980 - val_accuracy: 0.0078\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6403 - accuracy: 0.0703 - val_loss: 4.4904 - val_accuracy: 0.0078\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6514 - accuracy: 0.0859 - val_loss: 4.4925 - val_accuracy: 0.0078\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7975 - accuracy: 0.0000e+00 - val_loss: 4.5004 - val_accuracy: 0.0078\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7458 - accuracy: 0.0000e+00 - val_loss: 4.5110 - val_accuracy: 0.0078\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6837 - accuracy: 0.0156 - val_loss: 4.5185 - val_accuracy: 0.0078\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8638 - accuracy: 0.0703 - val_loss: 4.5295 - val_accuracy: 0.0078\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6981 - accuracy: 0.0156 - val_loss: 4.5383 - val_accuracy: 0.0078\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.6505 - accuracy: 0.0859 - val_loss: 4.5364 - val_accuracy: 0.0078\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5297 - accuracy: 0.0469 - val_loss: 4.5179 - val_accuracy: 0.0078\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6770 - accuracy: 0.0312 - val_loss: 4.5057 - val_accuracy: 0.0078\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7814 - accuracy: 0.0391 - val_loss: 4.5124 - val_accuracy: 0.0078\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4725 - accuracy: 0.0469 - val_loss: 4.5276 - val_accuracy: 0.0078\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6516 - accuracy: 0.0469 - val_loss: 4.5387 - val_accuracy: 0.0078\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7915 - accuracy: 0.0391 - val_loss: 4.5287 - val_accuracy: 0.0078\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5359 - accuracy: 0.0312 - val_loss: 4.5242 - val_accuracy: 0.0078\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7645 - accuracy: 0.0781 - val_loss: 4.5286 - val_accuracy: 0.0078\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4952 - accuracy: 0.0625 - val_loss: 4.5425 - val_accuracy: 0.0078\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6587 - accuracy: 0.0547 - val_loss: 4.5391 - val_accuracy: 0.0078\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7243 - accuracy: 0.0000e+00 - val_loss: 4.5410 - val_accuracy: 0.0078\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7881 - accuracy: 0.0234 - val_loss: 4.5395 - val_accuracy: 0.0078\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6468 - accuracy: 0.0703 - val_loss: 4.5264 - val_accuracy: 0.0078\n",
      "Epoch 358/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6882 - accuracy: 0.0312 - val_loss: 4.5239 - val_accuracy: 0.0078\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5573 - accuracy: 0.1094 - val_loss: 4.5343 - val_accuracy: 0.0078\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5212 - accuracy: 0.0078 - val_loss: 4.5516 - val_accuracy: 0.0078\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8235 - accuracy: 0.0156 - val_loss: 4.5661 - val_accuracy: 0.0078\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6224 - accuracy: 0.0703 - val_loss: 4.5790 - val_accuracy: 0.0078\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5575 - accuracy: 0.0625 - val_loss: 4.5935 - val_accuracy: 0.0078\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6477 - accuracy: 0.0234 - val_loss: 4.5935 - val_accuracy: 0.0156\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6860 - accuracy: 0.0156 - val_loss: 4.5963 - val_accuracy: 0.0156\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8514 - accuracy: 0.0234 - val_loss: 4.5943 - val_accuracy: 0.0156\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4470 - accuracy: 0.0469 - val_loss: 4.6000 - val_accuracy: 0.0156\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5805 - accuracy: 0.0312 - val_loss: 4.6045 - val_accuracy: 0.0156\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7221 - accuracy: 0.0312 - val_loss: 4.6052 - val_accuracy: 0.0156\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7643 - accuracy: 0.0234 - val_loss: 4.6100 - val_accuracy: 0.0156\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6397 - accuracy: 0.1094 - val_loss: 4.6245 - val_accuracy: 0.0156\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6552 - accuracy: 0.0156 - val_loss: 4.6281 - val_accuracy: 0.0156\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6689 - accuracy: 0.0234 - val_loss: 4.6175 - val_accuracy: 0.0156\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6108 - accuracy: 0.0781 - val_loss: 4.6241 - val_accuracy: 0.0078\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9147 - accuracy: 0.0234 - val_loss: 4.6259 - val_accuracy: 0.0078\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7285 - accuracy: 0.0469 - val_loss: 4.6166 - val_accuracy: 0.0078\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5144 - accuracy: 0.0078 - val_loss: 4.6169 - val_accuracy: 0.0078\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3484 - accuracy: 0.0859 - val_loss: 4.6249 - val_accuracy: 0.0078\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5555 - accuracy: 0.0156 - val_loss: 4.6340 - val_accuracy: 0.0078\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5934 - accuracy: 0.0156 - val_loss: 4.6403 - val_accuracy: 0.0078\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6903 - accuracy: 0.0391 - val_loss: 4.6286 - val_accuracy: 0.0078\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7343 - accuracy: 0.0625 - val_loss: 4.6224 - val_accuracy: 0.0078\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7436 - accuracy: 0.0469 - val_loss: 4.6230 - val_accuracy: 0.0078\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5613 - accuracy: 0.0000e+00 - val_loss: 4.6264 - val_accuracy: 0.0078\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6189 - accuracy: 0.0703 - val_loss: 4.6231 - val_accuracy: 0.0078\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5559 - accuracy: 0.0547 - val_loss: 4.6086 - val_accuracy: 0.0078\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6711 - accuracy: 0.0234 - val_loss: 4.5972 - val_accuracy: 0.0156\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8630 - accuracy: 0.0625 - val_loss: 4.5815 - val_accuracy: 0.0078\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5971 - accuracy: 0.0781 - val_loss: 4.5748 - val_accuracy: 0.0078\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8227 - accuracy: 0.0625 - val_loss: 4.5719 - val_accuracy: 0.0156\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7602 - accuracy: 0.0234 - val_loss: 4.5760 - val_accuracy: 0.0156\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6858 - accuracy: 0.0469 - val_loss: 4.5824 - val_accuracy: 0.0156\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6173 - accuracy: 0.0625 - val_loss: 4.5903 - val_accuracy: 0.0156\n",
      "Epoch 00393: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=9322\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 5.5321 - accuracy: 0.0078 - val_loss: 5.5456 - val_accuracy: 0.0078\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.5708 - accuracy: 0.0000e+00 - val_loss: 5.5466 - val_accuracy: 0.0078\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.5330 - accuracy: 0.0156 - val_loss: 5.5470 - val_accuracy: 0.0078\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.5338 - accuracy: 0.0000e+00 - val_loss: 5.5473 - val_accuracy: 0.0078\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.5046 - accuracy: 0.0234 - val_loss: 5.5477 - val_accuracy: 0.0078\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.5222 - accuracy: 0.0000e+00 - val_loss: 5.5474 - val_accuracy: 0.0078\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.5243 - accuracy: 0.0078 - val_loss: 5.5466 - val_accuracy: 0.0078\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.5276 - accuracy: 0.0000e+00 - val_loss: 5.5456 - val_accuracy: 0.0078\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4825 - accuracy: 0.0156 - val_loss: 5.5447 - val_accuracy: 0.0078\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4945 - accuracy: 0.0000e+00 - val_loss: 5.5438 - val_accuracy: 0.0078\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.5127 - accuracy: 0.0156 - val_loss: 5.5425 - val_accuracy: 0.0078\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4798 - accuracy: 0.0000e+00 - val_loss: 5.5414 - val_accuracy: 0.0078\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4585 - accuracy: 0.0234 - val_loss: 5.5407 - val_accuracy: 0.0078\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4738 - accuracy: 0.0312 - val_loss: 5.5400 - val_accuracy: 0.0078\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4609 - accuracy: 0.0312 - val_loss: 5.5394 - val_accuracy: 0.0078\n",
      "Epoch 16/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4728 - accuracy: 0.0078 - val_loss: 5.5384 - val_accuracy: 0.0078\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4468 - accuracy: 0.0078 - val_loss: 5.5382 - val_accuracy: 0.0078\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4755 - accuracy: 0.0078 - val_loss: 5.5385 - val_accuracy: 0.0078\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4908 - accuracy: 0.0078 - val_loss: 5.5383 - val_accuracy: 0.0078\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4302 - accuracy: 0.0156 - val_loss: 5.5384 - val_accuracy: 0.0078\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4509 - accuracy: 0.0234 - val_loss: 5.5383 - val_accuracy: 0.0078\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4288 - accuracy: 0.0234 - val_loss: 5.5382 - val_accuracy: 0.0078\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.4729 - accuracy: 0.0156 - val_loss: 5.5381 - val_accuracy: 0.0078\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4236 - accuracy: 0.0078 - val_loss: 5.5376 - val_accuracy: 0.0078\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4150 - accuracy: 0.0156 - val_loss: 5.5387 - val_accuracy: 0.0078\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.4266 - accuracy: 0.0078 - val_loss: 5.5390 - val_accuracy: 0.0078\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3902 - accuracy: 0.0078 - val_loss: 5.5368 - val_accuracy: 0.0078\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4102 - accuracy: 0.0156 - val_loss: 5.5349 - val_accuracy: 0.0078\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.4274 - accuracy: 0.0156 - val_loss: 5.5340 - val_accuracy: 0.0078\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.4248 - accuracy: 0.0156 - val_loss: 5.5315 - val_accuracy: 0.0078\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4412 - accuracy: 0.0156 - val_loss: 5.5288 - val_accuracy: 0.0078\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4259 - accuracy: 0.0078 - val_loss: 5.5253 - val_accuracy: 0.0078\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4150 - accuracy: 0.0000e+00 - val_loss: 5.5206 - val_accuracy: 0.0078\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3847 - accuracy: 0.0234 - val_loss: 5.5150 - val_accuracy: 0.0078\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3977 - accuracy: 0.0391 - val_loss: 5.5109 - val_accuracy: 0.0078\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3845 - accuracy: 0.0391 - val_loss: 5.5066 - val_accuracy: 0.0078\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4470 - accuracy: 0.0234 - val_loss: 5.5042 - val_accuracy: 0.0078\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3728 - accuracy: 0.0234 - val_loss: 5.5031 - val_accuracy: 0.0078\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3352 - accuracy: 0.0547 - val_loss: 5.4989 - val_accuracy: 0.0078\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3178 - accuracy: 0.0391 - val_loss: 5.4881 - val_accuracy: 0.0078\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3952 - accuracy: 0.0234 - val_loss: 5.4760 - val_accuracy: 0.0078\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3602 - accuracy: 0.0234 - val_loss: 5.4650 - val_accuracy: 0.0078\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3431 - accuracy: 0.0469 - val_loss: 5.4549 - val_accuracy: 0.0078\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4181 - accuracy: 0.0156 - val_loss: 5.4478 - val_accuracy: 0.0078\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3985 - accuracy: 0.0078 - val_loss: 5.4428 - val_accuracy: 0.0078\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3933 - accuracy: 0.0078 - val_loss: 5.4400 - val_accuracy: 0.0078\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.3315 - accuracy: 0.0312 - val_loss: 5.4337 - val_accuracy: 0.0078\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3780 - accuracy: 0.0391 - val_loss: 5.4253 - val_accuracy: 0.0078\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3361 - accuracy: 0.0312 - val_loss: 5.4200 - val_accuracy: 0.0078\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3363 - accuracy: 0.0078 - val_loss: 5.4167 - val_accuracy: 0.0078\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3616 - accuracy: 0.0000e+00 - val_loss: 5.4126 - val_accuracy: 0.0078\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3597 - accuracy: 0.0234 - val_loss: 5.4068 - val_accuracy: 0.0078\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4185 - accuracy: 0.0000e+00 - val_loss: 5.3999 - val_accuracy: 0.0078\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3715 - accuracy: 0.0078 - val_loss: 5.3960 - val_accuracy: 0.0078\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3043 - accuracy: 0.0391 - val_loss: 5.3946 - val_accuracy: 0.0078\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3727 - accuracy: 0.0156 - val_loss: 5.3912 - val_accuracy: 0.0078\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.3763 - accuracy: 0.0156 - val_loss: 5.3891 - val_accuracy: 0.0078\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2698 - accuracy: 0.0000e+00 - val_loss: 5.3853 - val_accuracy: 0.0078\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.4064 - accuracy: 0.0078 - val_loss: 5.3801 - val_accuracy: 0.0078\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3548 - accuracy: 0.0234 - val_loss: 5.3794 - val_accuracy: 0.0078\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2809 - accuracy: 0.0234 - val_loss: 5.3810 - val_accuracy: 0.0078\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2811 - accuracy: 0.0547 - val_loss: 5.3777 - val_accuracy: 0.0078\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2346 - accuracy: 0.0391 - val_loss: 5.3707 - val_accuracy: 0.0078\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3126 - accuracy: 0.0156 - val_loss: 5.3649 - val_accuracy: 0.0078\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2234 - accuracy: 0.0469 - val_loss: 5.3578 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2530 - accuracy: 0.0234 - val_loss: 5.3504 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2555 - accuracy: 0.0078 - val_loss: 5.3464 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2680 - accuracy: 0.0078 - val_loss: 5.3455 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.2920 - accuracy: 0.0078 - val_loss: 5.3460 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2391 - accuracy: 0.0156 - val_loss: 5.3460 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2354 - accuracy: 0.0469 - val_loss: 5.3463 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2454 - accuracy: 0.0469 - val_loss: 5.3455 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.2246 - accuracy: 0.0234 - val_loss: 5.3433 - val_accuracy: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1503 - accuracy: 0.0625 - val_loss: 5.3333 - val_accuracy: 0.0078\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2240 - accuracy: 0.0469 - val_loss: 5.3200 - val_accuracy: 0.0078\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2791 - accuracy: 0.0234 - val_loss: 5.3053 - val_accuracy: 0.0078\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1554 - accuracy: 0.0547 - val_loss: 5.2931 - val_accuracy: 0.0078\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2308 - accuracy: 0.0156 - val_loss: 5.2853 - val_accuracy: 0.0078\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.1432 - accuracy: 0.0703 - val_loss: 5.2715 - val_accuracy: 0.0078\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.1286 - accuracy: 0.0469 - val_loss: 5.2585 - val_accuracy: 0.0078\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2979 - accuracy: 0.0234 - val_loss: 5.2469 - val_accuracy: 0.0078\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.2024 - accuracy: 0.0547 - val_loss: 5.2360 - val_accuracy: 0.0078\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2414 - accuracy: 0.0234 - val_loss: 5.2330 - val_accuracy: 0.0078\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1714 - accuracy: 0.0547 - val_loss: 5.2338 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2102 - accuracy: 0.0000e+00 - val_loss: 5.2289 - val_accuracy: 0.0078\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0654 - accuracy: 0.0234 - val_loss: 5.2300 - val_accuracy: 0.0078\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1705 - accuracy: 0.0234 - val_loss: 5.2329 - val_accuracy: 0.0078\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0714 - accuracy: 0.0469 - val_loss: 5.2354 - val_accuracy: 0.0078\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1154 - accuracy: 0.0078 - val_loss: 5.2379 - val_accuracy: 0.0078\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1428 - accuracy: 0.0312 - val_loss: 5.2430 - val_accuracy: 0.0078\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0929 - accuracy: 0.0234 - val_loss: 5.2492 - val_accuracy: 0.0078\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0904 - accuracy: 0.0625 - val_loss: 5.2540 - val_accuracy: 0.0078\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2085 - accuracy: 0.0234 - val_loss: 5.2562 - val_accuracy: 0.0078\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0657 - accuracy: 0.0391 - val_loss: 5.2520 - val_accuracy: 0.0078\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0770 - accuracy: 0.0156 - val_loss: 5.2478 - val_accuracy: 0.0078\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1304 - accuracy: 0.0234 - val_loss: 5.2494 - val_accuracy: 0.0078\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0776 - accuracy: 0.0625 - val_loss: 5.2517 - val_accuracy: 0.0078\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9915 - accuracy: 0.0859 - val_loss: 5.2589 - val_accuracy: 0.0078\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1496 - accuracy: 0.0469 - val_loss: 5.2686 - val_accuracy: 0.0078\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0110 - accuracy: 0.0469 - val_loss: 5.2648 - val_accuracy: 0.0078\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0049 - accuracy: 0.0391 - val_loss: 5.2620 - val_accuracy: 0.0078\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9275 - accuracy: 0.0156 - val_loss: 5.2621 - val_accuracy: 0.0078\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0904 - accuracy: 0.0469 - val_loss: 5.2553 - val_accuracy: 0.0078\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0932 - accuracy: 0.0625 - val_loss: 5.2491 - val_accuracy: 0.0078\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9360 - accuracy: 0.0234 - val_loss: 5.2421 - val_accuracy: 0.0078\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9922 - accuracy: 0.0156 - val_loss: 5.2326 - val_accuracy: 0.0234\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9758 - accuracy: 0.0078 - val_loss: 5.2279 - val_accuracy: 0.0391\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0946 - accuracy: 0.0234 - val_loss: 5.2286 - val_accuracy: 0.0703\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1221 - accuracy: 0.0391 - val_loss: 5.2200 - val_accuracy: 0.0938\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0671 - accuracy: 0.0156 - val_loss: 5.2188 - val_accuracy: 0.1172\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8736 - accuracy: 0.0391 - val_loss: 5.2218 - val_accuracy: 0.1406\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0661 - accuracy: 0.0000e+00 - val_loss: 5.2259 - val_accuracy: 0.1406\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1024 - accuracy: 0.0234 - val_loss: 5.2317 - val_accuracy: 0.1406\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9574 - accuracy: 0.0234 - val_loss: 5.2441 - val_accuracy: 0.1328\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8495 - accuracy: 0.0469 - val_loss: 5.2547 - val_accuracy: 0.0859\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1405 - accuracy: 0.0312 - val_loss: 5.2571 - val_accuracy: 0.0781\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0815 - accuracy: 0.0234 - val_loss: 5.2511 - val_accuracy: 0.0547\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0042 - accuracy: 0.0312 - val_loss: 5.2534 - val_accuracy: 0.0391\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9048 - accuracy: 0.0156 - val_loss: 5.2629 - val_accuracy: 0.0234\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1123 - accuracy: 0.0078 - val_loss: 5.2684 - val_accuracy: 0.0156\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9326 - accuracy: 0.0469 - val_loss: 5.2752 - val_accuracy: 0.0234\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9717 - accuracy: 0.0156 - val_loss: 5.2862 - val_accuracy: 0.0156\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0514 - accuracy: 0.0234 - val_loss: 5.2916 - val_accuracy: 0.0078\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.8556 - accuracy: 0.0312 - val_loss: 5.2971 - val_accuracy: 0.0078\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9103 - accuracy: 0.0078 - val_loss: 5.3038 - val_accuracy: 0.0078\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9307 - accuracy: 0.0312 - val_loss: 5.3097 - val_accuracy: 0.0078\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7814 - accuracy: 0.0234 - val_loss: 5.3156 - val_accuracy: 0.0078\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9881 - accuracy: 0.0234 - val_loss: 5.3196 - val_accuracy: 0.0078\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8455 - accuracy: 0.0547 - val_loss: 5.3242 - val_accuracy: 0.0156\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0007 - accuracy: 0.0078 - val_loss: 5.3157 - val_accuracy: 0.0078\n",
      "Epoch 131/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9952 - accuracy: 0.0469 - val_loss: 5.3019 - val_accuracy: 0.0078\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8591 - accuracy: 0.0156 - val_loss: 5.3000 - val_accuracy: 0.0078\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9783 - accuracy: 0.0078 - val_loss: 5.3039 - val_accuracy: 0.0078\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9140 - accuracy: 0.0547 - val_loss: 5.3103 - val_accuracy: 0.0078\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9106 - accuracy: 0.0312 - val_loss: 5.3099 - val_accuracy: 0.0078\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8987 - accuracy: 0.0078 - val_loss: 5.3062 - val_accuracy: 0.0078\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8331 - accuracy: 0.0312 - val_loss: 5.2918 - val_accuracy: 0.0078\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8799 - accuracy: 0.0156 - val_loss: 5.2815 - val_accuracy: 0.0078\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0227 - accuracy: 0.0156 - val_loss: 5.2716 - val_accuracy: 0.0078\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9726 - accuracy: 0.0234 - val_loss: 5.2604 - val_accuracy: 0.0078\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0132 - accuracy: 0.0234 - val_loss: 5.2455 - val_accuracy: 0.0078\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0857 - accuracy: 0.0312 - val_loss: 5.2331 - val_accuracy: 0.0078\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8718 - accuracy: 0.0391 - val_loss: 5.2251 - val_accuracy: 0.0078\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8449 - accuracy: 0.0234 - val_loss: 5.2240 - val_accuracy: 0.0078\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7497 - accuracy: 0.0234 - val_loss: 5.2258 - val_accuracy: 0.0078\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9208 - accuracy: 0.0312 - val_loss: 5.2146 - val_accuracy: 0.0078\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8151 - accuracy: 0.0234 - val_loss: 5.1889 - val_accuracy: 0.0078\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1198 - accuracy: 0.0234 - val_loss: 5.1788 - val_accuracy: 0.0078\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8668 - accuracy: 0.0156 - val_loss: 5.1748 - val_accuracy: 0.0078\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8657 - accuracy: 0.0078 - val_loss: 5.1718 - val_accuracy: 0.0078\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8328 - accuracy: 0.0234 - val_loss: 5.1719 - val_accuracy: 0.0078\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9144 - accuracy: 0.0391 - val_loss: 5.1719 - val_accuracy: 0.0078\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0782 - accuracy: 0.0000e+00 - val_loss: 5.1705 - val_accuracy: 0.0078\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0272 - accuracy: 0.0000e+00 - val_loss: 5.1661 - val_accuracy: 0.0156\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8199 - accuracy: 0.0391 - val_loss: 5.1702 - val_accuracy: 0.0078\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8415 - accuracy: 0.0234 - val_loss: 5.1743 - val_accuracy: 0.0078\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9035 - accuracy: 0.0234 - val_loss: 5.1736 - val_accuracy: 0.0078\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0530 - accuracy: 0.0156 - val_loss: 5.1718 - val_accuracy: 0.0078\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8654 - accuracy: 0.0234 - val_loss: 5.1661 - val_accuracy: 0.0078\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9837 - accuracy: 0.0391 - val_loss: 5.1607 - val_accuracy: 0.0078\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7370 - accuracy: 0.0156 - val_loss: 5.1521 - val_accuracy: 0.0078\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8220 - accuracy: 0.0312 - val_loss: 5.1360 - val_accuracy: 0.0078\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8657 - accuracy: 0.0234 - val_loss: 5.1155 - val_accuracy: 0.0078\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7972 - accuracy: 0.0234 - val_loss: 5.0989 - val_accuracy: 0.0078\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0445 - accuracy: 0.0156 - val_loss: 5.0667 - val_accuracy: 0.0156\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8695 - accuracy: 0.0391 - val_loss: 5.0144 - val_accuracy: 0.0469\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6732 - accuracy: 0.0391 - val_loss: 4.9817 - val_accuracy: 0.0469\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7935 - accuracy: 0.0156 - val_loss: 4.9692 - val_accuracy: 0.0469\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9779 - accuracy: 0.0391 - val_loss: 4.9659 - val_accuracy: 0.0469\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0203 - accuracy: 0.0156 - val_loss: 4.9708 - val_accuracy: 0.0391\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0165 - accuracy: 0.0234 - val_loss: 4.9620 - val_accuracy: 0.0234\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7884 - accuracy: 0.0391 - val_loss: 4.9482 - val_accuracy: 0.0234\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7999 - accuracy: 0.0156 - val_loss: 4.9486 - val_accuracy: 0.0078\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9974 - accuracy: 0.0312 - val_loss: 4.9503 - val_accuracy: 0.0078\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7843 - accuracy: 0.0391 - val_loss: 4.9568 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9352 - accuracy: 0.0469 - val_loss: 4.9572 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8308 - accuracy: 0.0391 - val_loss: 4.9555 - val_accuracy: 0.0078\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8108 - accuracy: 0.0469 - val_loss: 4.9555 - val_accuracy: 0.0078\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8142 - accuracy: 0.0156 - val_loss: 4.9523 - val_accuracy: 0.0078\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8364 - accuracy: 0.0469 - val_loss: 4.9493 - val_accuracy: 0.0078\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9386 - accuracy: 0.0391 - val_loss: 4.9351 - val_accuracy: 0.0078\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9513 - accuracy: 0.0469 - val_loss: 4.9247 - val_accuracy: 0.0078\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9215 - accuracy: 0.0312 - val_loss: 4.9181 - val_accuracy: 0.0078\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0397 - accuracy: 0.0234 - val_loss: 4.9190 - val_accuracy: 0.0078\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8726 - accuracy: 0.0234 - val_loss: 4.9134 - val_accuracy: 0.0078\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9143 - accuracy: 0.0078 - val_loss: 4.8935 - val_accuracy: 0.0078\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9981 - accuracy: 0.0312 - val_loss: 4.8816 - val_accuracy: 0.0078\n",
      "Epoch 188/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7592 - accuracy: 0.0469 - val_loss: 4.8750 - val_accuracy: 0.0078\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.0037 - accuracy: 0.0312 - val_loss: 4.8631 - val_accuracy: 0.0078\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8271 - accuracy: 0.0078 - val_loss: 4.8628 - val_accuracy: 0.0078\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9061 - accuracy: 0.0312 - val_loss: 4.8653 - val_accuracy: 0.0078\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8159 - accuracy: 0.0391 - val_loss: 4.8741 - val_accuracy: 0.0078\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8349 - accuracy: 0.0156 - val_loss: 4.8801 - val_accuracy: 0.0078\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8434 - accuracy: 0.0078 - val_loss: 4.8838 - val_accuracy: 0.0078\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7891 - accuracy: 0.0469 - val_loss: 4.8931 - val_accuracy: 0.0078\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9929 - accuracy: 0.0078 - val_loss: 4.9013 - val_accuracy: 0.0078\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.8587 - accuracy: 0.0312 - val_loss: 4.8864 - val_accuracy: 0.0078\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9598 - accuracy: 0.0156 - val_loss: 4.8709 - val_accuracy: 0.0078\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8213 - accuracy: 0.0469 - val_loss: 4.8563 - val_accuracy: 0.0078\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7717 - accuracy: 0.0078 - val_loss: 4.8533 - val_accuracy: 0.0078\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7987 - accuracy: 0.0234 - val_loss: 4.8320 - val_accuracy: 0.0078\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9895 - accuracy: 0.0156 - val_loss: 4.8018 - val_accuracy: 0.0078\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8226 - accuracy: 0.0391 - val_loss: 4.7869 - val_accuracy: 0.0078\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9846 - accuracy: 0.0469 - val_loss: 4.7783 - val_accuracy: 0.0078\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7738 - accuracy: 0.0156 - val_loss: 4.7739 - val_accuracy: 0.0078\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6962 - accuracy: 0.0469 - val_loss: 4.7751 - val_accuracy: 0.0078\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7879 - accuracy: 0.0391 - val_loss: 4.7818 - val_accuracy: 0.0078\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8327 - accuracy: 0.0312 - val_loss: 4.7904 - val_accuracy: 0.0078\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7168 - accuracy: 0.0391 - val_loss: 4.7944 - val_accuracy: 0.0078\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8273 - accuracy: 0.0391 - val_loss: 4.7749 - val_accuracy: 0.0078\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8241 - accuracy: 0.0234 - val_loss: 4.7538 - val_accuracy: 0.0078\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9395 - accuracy: 0.0000e+00 - val_loss: 4.7406 - val_accuracy: 0.0078\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7198 - accuracy: 0.0156 - val_loss: 4.7375 - val_accuracy: 0.0078\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9327 - accuracy: 0.0000e+00 - val_loss: 4.7393 - val_accuracy: 0.0078\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7347 - accuracy: 0.0469 - val_loss: 4.7299 - val_accuracy: 0.0156\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9572 - accuracy: 0.0391 - val_loss: 4.7041 - val_accuracy: 0.0156\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0248 - accuracy: 0.0312 - val_loss: 4.6882 - val_accuracy: 0.0391\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9703 - accuracy: 0.0312 - val_loss: 4.6816 - val_accuracy: 0.0156\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6212 - accuracy: 0.0312 - val_loss: 4.6790 - val_accuracy: 0.0469\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9327 - accuracy: 0.0312 - val_loss: 4.6827 - val_accuracy: 0.0703\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8507 - accuracy: 0.0078 - val_loss: 4.6962 - val_accuracy: 0.0703\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9253 - accuracy: 0.0234 - val_loss: 4.7132 - val_accuracy: 0.0859\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6250 - accuracy: 0.0547 - val_loss: 4.7292 - val_accuracy: 0.1016\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8109 - accuracy: 0.0078 - val_loss: 4.7454 - val_accuracy: 0.0781\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9139 - accuracy: 0.0312 - val_loss: 4.7599 - val_accuracy: 0.0625\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0199 - accuracy: 0.0234 - val_loss: 4.7704 - val_accuracy: 0.0156\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8891 - accuracy: 0.0234 - val_loss: 4.7817 - val_accuracy: 0.0156\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9284 - accuracy: 0.0469 - val_loss: 4.7969 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7593 - accuracy: 0.0000e+00 - val_loss: 4.8082 - val_accuracy: 0.0078\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8883 - accuracy: 0.0469 - val_loss: 4.7978 - val_accuracy: 0.0078\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7794 - accuracy: 0.0547 - val_loss: 4.7995 - val_accuracy: 0.0078\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8588 - accuracy: 0.0078 - val_loss: 4.7921 - val_accuracy: 0.0078\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8521 - accuracy: 0.0156 - val_loss: 4.7924 - val_accuracy: 0.0078\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7798 - accuracy: 0.0156 - val_loss: 4.7871 - val_accuracy: 0.0078\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7774 - accuracy: 0.0469 - val_loss: 4.7859 - val_accuracy: 0.0078\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7450 - accuracy: 0.0234 - val_loss: 4.7931 - val_accuracy: 0.0078\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8646 - accuracy: 0.0469 - val_loss: 4.7861 - val_accuracy: 0.0078\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9336 - accuracy: 0.0547 - val_loss: 4.7713 - val_accuracy: 0.0078\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8261 - accuracy: 0.0078 - val_loss: 4.7704 - val_accuracy: 0.0078\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.7127 - accuracy: 0.0469 - val_loss: 4.7467 - val_accuracy: 0.0078\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6095 - accuracy: 0.0312 - val_loss: 4.7276 - val_accuracy: 0.0078\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7068 - accuracy: 0.0234 - val_loss: 4.7197 - val_accuracy: 0.0156\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9146 - accuracy: 0.0078 - val_loss: 4.7195 - val_accuracy: 0.0156\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7489 - accuracy: 0.0625 - val_loss: 4.7138 - val_accuracy: 0.0078\n",
      "Epoch 245/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8534 - accuracy: 0.0234 - val_loss: 4.7051 - val_accuracy: 0.0078\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6827 - accuracy: 0.0625 - val_loss: 4.7020 - val_accuracy: 0.0078\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6362 - accuracy: 0.0078 - val_loss: 4.6815 - val_accuracy: 0.0078\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8582 - accuracy: 0.0078 - val_loss: 4.6680 - val_accuracy: 0.0078\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6776 - accuracy: 0.0312 - val_loss: 4.6394 - val_accuracy: 0.0078\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7122 - accuracy: 0.0625 - val_loss: 4.6072 - val_accuracy: 0.0156\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7800 - accuracy: 0.0234 - val_loss: 4.5847 - val_accuracy: 0.0156\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5970 - accuracy: 0.0625 - val_loss: 4.5722 - val_accuracy: 0.0312\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6151 - accuracy: 0.0469 - val_loss: 4.5679 - val_accuracy: 0.0547\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 4.7030 - accuracy: 0.0859 - val_loss: 4.5239 - val_accuracy: 0.1328\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8682 - accuracy: 0.0234 - val_loss: 4.4813 - val_accuracy: 0.1562\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7197 - accuracy: 0.0312 - val_loss: 4.4566 - val_accuracy: 0.1562\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9526 - accuracy: 0.0234 - val_loss: 4.4412 - val_accuracy: 0.1641\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.6844 - accuracy: 0.0547 - val_loss: 4.4264 - val_accuracy: 0.1641\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7284 - accuracy: 0.0156 - val_loss: 4.4106 - val_accuracy: 0.1641\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9146 - accuracy: 0.0000e+00 - val_loss: 4.4082 - val_accuracy: 0.1641\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7366 - accuracy: 0.0078 - val_loss: 4.4187 - val_accuracy: 0.1484\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7034 - accuracy: 0.0859 - val_loss: 4.4086 - val_accuracy: 0.1562\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8808 - accuracy: 0.0312 - val_loss: 4.4037 - val_accuracy: 0.1562\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8786 - accuracy: 0.0234 - val_loss: 4.4103 - val_accuracy: 0.1250\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8798 - accuracy: 0.0156 - val_loss: 4.4182 - val_accuracy: 0.1094\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9287 - accuracy: 0.0078 - val_loss: 4.4280 - val_accuracy: 0.0781\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7959 - accuracy: 0.0078 - val_loss: 4.4457 - val_accuracy: 0.0625\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7495 - accuracy: 0.0234 - val_loss: 4.4641 - val_accuracy: 0.0391\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6773 - accuracy: 0.0156 - val_loss: 4.4777 - val_accuracy: 0.0234\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6949 - accuracy: 0.0391 - val_loss: 4.4825 - val_accuracy: 0.0156\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7880 - accuracy: 0.0078 - val_loss: 4.4719 - val_accuracy: 0.0391\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7829 - accuracy: 0.0547 - val_loss: 4.4683 - val_accuracy: 0.0391\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8999 - accuracy: 0.0234 - val_loss: 4.4724 - val_accuracy: 0.0312\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6558 - accuracy: 0.0625 - val_loss: 4.4742 - val_accuracy: 0.0391\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6440 - accuracy: 0.0625 - val_loss: 4.4755 - val_accuracy: 0.0938\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6908 - accuracy: 0.0234 - val_loss: 4.4721 - val_accuracy: 0.1172\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7295 - accuracy: 0.0000e+00 - val_loss: 4.4789 - val_accuracy: 0.1172\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6745 - accuracy: 0.0547 - val_loss: 4.4893 - val_accuracy: 0.1172\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.5834 - accuracy: 0.0625 - val_loss: 4.4830 - val_accuracy: 0.1250\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6298 - accuracy: 0.0391 - val_loss: 4.4799 - val_accuracy: 0.1250\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9987 - accuracy: 0.0078 - val_loss: 4.4802 - val_accuracy: 0.1250\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8998 - accuracy: 0.0000e+00 - val_loss: 4.4880 - val_accuracy: 0.1172\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8416 - accuracy: 0.0234 - val_loss: 4.5041 - val_accuracy: 0.1172\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7614 - accuracy: 0.0859 - val_loss: 4.5199 - val_accuracy: 0.1172\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8805 - accuracy: 0.0078 - val_loss: 4.5404 - val_accuracy: 0.0859\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7301 - accuracy: 0.0469 - val_loss: 4.5536 - val_accuracy: 0.0859\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5664 - accuracy: 0.0469 - val_loss: 4.5705 - val_accuracy: 0.0234\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6472 - accuracy: 0.0312 - val_loss: 4.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7089 - accuracy: 0.0391 - val_loss: 4.5822 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8230 - accuracy: 0.0156 - val_loss: 4.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8684 - accuracy: 0.0078 - val_loss: 4.5599 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5497 - accuracy: 0.0391 - val_loss: 4.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6722 - accuracy: 0.0469 - val_loss: 4.5423 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.6769 - accuracy: 0.0156 - val_loss: 4.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9228 - accuracy: 0.0234 - val_loss: 4.5153 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9984 - accuracy: 0.0234 - val_loss: 4.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8502 - accuracy: 0.0312 - val_loss: 4.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7519 - accuracy: 0.0234 - val_loss: 4.4957 - val_accuracy: 0.0078\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7002 - accuracy: 0.0312 - val_loss: 4.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8339 - accuracy: 0.0469 - val_loss: 4.4694 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9196 - accuracy: 0.0391 - val_loss: 4.4697 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7984 - accuracy: 0.0234 - val_loss: 4.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7264 - accuracy: 0.0000e+00 - val_loss: 4.4852 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7172 - accuracy: 0.0000e+00 - val_loss: 4.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6084 - accuracy: 0.0312 - val_loss: 4.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8955 - accuracy: 0.0391 - val_loss: 4.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6520 - accuracy: 0.0391 - val_loss: 4.4992 - val_accuracy: 0.0078\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7668 - accuracy: 0.0156 - val_loss: 4.5045 - val_accuracy: 0.0078\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5402 - accuracy: 0.0234 - val_loss: 4.5057 - val_accuracy: 0.0312\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8369 - accuracy: 0.0156 - val_loss: 4.5050 - val_accuracy: 0.1094\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8366 - accuracy: 0.0156 - val_loss: 4.5097 - val_accuracy: 0.1094\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7260 - accuracy: 0.0312 - val_loss: 4.5214 - val_accuracy: 0.1016\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8098 - accuracy: 0.0078 - val_loss: 4.5397 - val_accuracy: 0.0781\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5805 - accuracy: 0.0312 - val_loss: 4.5587 - val_accuracy: 0.0469\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8149 - accuracy: 0.0234 - val_loss: 4.5755 - val_accuracy: 0.0078\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8970 - accuracy: 0.0156 - val_loss: 4.5854 - val_accuracy: 0.0078\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6318 - accuracy: 0.0156 - val_loss: 4.5960 - val_accuracy: 0.0078\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7826 - accuracy: 0.0391 - val_loss: 4.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6974 - accuracy: 0.0312 - val_loss: 4.6188 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7626 - accuracy: 0.0000e+00 - val_loss: 4.6077 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8219 - accuracy: 0.0312 - val_loss: 4.5932 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9074 - accuracy: 0.0234 - val_loss: 4.5791 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7152 - accuracy: 0.0312 - val_loss: 4.5656 - val_accuracy: 0.0078\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8971 - accuracy: 0.0391 - val_loss: 4.5551 - val_accuracy: 0.0078\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7583 - accuracy: 0.0547 - val_loss: 4.5551 - val_accuracy: 0.0078\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7510 - accuracy: 0.0391 - val_loss: 4.5551 - val_accuracy: 0.0078\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7123 - accuracy: 0.0312 - val_loss: 4.5455 - val_accuracy: 0.0078\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6229 - accuracy: 0.0469 - val_loss: 4.5448 - val_accuracy: 0.0078\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6173 - accuracy: 0.0625 - val_loss: 4.5366 - val_accuracy: 0.0078\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6698 - accuracy: 0.0547 - val_loss: 4.5304 - val_accuracy: 0.0078\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.6649 - accuracy: 0.0234 - val_loss: 4.5251 - val_accuracy: 0.0078\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7990 - accuracy: 0.0391 - val_loss: 4.5203 - val_accuracy: 0.0078\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5585 - accuracy: 0.0625 - val_loss: 4.5232 - val_accuracy: 0.0078\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7501 - accuracy: 0.0234 - val_loss: 4.5334 - val_accuracy: 0.0078\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6926 - accuracy: 0.0391 - val_loss: 4.5469 - val_accuracy: 0.0078\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6550 - accuracy: 0.0391 - val_loss: 4.5631 - val_accuracy: 0.0078\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8600 - accuracy: 0.0234 - val_loss: 4.5811 - val_accuracy: 0.0078\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7814 - accuracy: 0.0391 - val_loss: 4.5946 - val_accuracy: 0.0078\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6815 - accuracy: 0.0234 - val_loss: 4.5811 - val_accuracy: 0.0078\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7954 - accuracy: 0.0312 - val_loss: 4.5669 - val_accuracy: 0.0078\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8015 - accuracy: 0.0312 - val_loss: 4.5600 - val_accuracy: 0.0078\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7042 - accuracy: 0.0391 - val_loss: 4.5520 - val_accuracy: 0.0156\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8044 - accuracy: 0.0078 - val_loss: 4.5473 - val_accuracy: 0.0156\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6730 - accuracy: 0.0078 - val_loss: 4.5516 - val_accuracy: 0.0312\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7479 - accuracy: 0.0234 - val_loss: 4.5631 - val_accuracy: 0.0234\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8060 - accuracy: 0.0156 - val_loss: 4.5771 - val_accuracy: 0.0234\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7031 - accuracy: 0.0703 - val_loss: 4.5795 - val_accuracy: 0.0234\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9315 - accuracy: 0.0078 - val_loss: 4.5822 - val_accuracy: 0.0234\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6862 - accuracy: 0.0469 - val_loss: 4.5956 - val_accuracy: 0.0156\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8569 - accuracy: 0.0156 - val_loss: 4.5942 - val_accuracy: 0.0156\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8113 - accuracy: 0.0547 - val_loss: 4.5932 - val_accuracy: 0.0234\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7816 - accuracy: 0.0234 - val_loss: 4.5773 - val_accuracy: 0.0234\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8429 - accuracy: 0.0234 - val_loss: 4.5600 - val_accuracy: 0.0312\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8296 - accuracy: 0.0469 - val_loss: 4.5520 - val_accuracy: 0.0391\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6371 - accuracy: 0.0312 - val_loss: 4.5513 - val_accuracy: 0.0391\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7919 - accuracy: 0.0391 - val_loss: 4.5558 - val_accuracy: 0.0312\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6475 - accuracy: 0.0391 - val_loss: 4.5636 - val_accuracy: 0.0234\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7686 - accuracy: 0.0391 - val_loss: 4.5653 - val_accuracy: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7711 - accuracy: 0.0234 - val_loss: 4.5678 - val_accuracy: 0.0078\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7352 - accuracy: 0.0547 - val_loss: 4.5722 - val_accuracy: 0.0078\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7276 - accuracy: 0.0547 - val_loss: 4.5790 - val_accuracy: 0.0156\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7828 - accuracy: 0.0312 - val_loss: 4.5910 - val_accuracy: 0.0078\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7185 - accuracy: 0.0547 - val_loss: 4.5993 - val_accuracy: 0.0078\n",
      "Epoch 00363: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=9322\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=9322\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 5.5567 - accuracy: 0.0000e+00 - val_loss: 5.5435 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 5.5669 - accuracy: 0.0234 - val_loss: 5.5415 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.5538 - accuracy: 0.0000e+00 - val_loss: 5.5398 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5459 - accuracy: 0.0000e+00 - val_loss: 5.5388 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.5384 - accuracy: 0.0078 - val_loss: 5.5383 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.5332 - accuracy: 0.0000e+00 - val_loss: 5.5382 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5302 - accuracy: 0.0000e+00 - val_loss: 5.5375 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5256 - accuracy: 0.0078 - val_loss: 5.5373 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.4944 - accuracy: 0.0078 - val_loss: 5.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5081 - accuracy: 0.0078 - val_loss: 5.5365 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.5117 - accuracy: 0.0000e+00 - val_loss: 5.5367 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5246 - accuracy: 0.0234 - val_loss: 5.5363 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4314 - accuracy: 0.0312 - val_loss: 5.5347 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.4850 - accuracy: 0.0156 - val_loss: 5.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4514 - accuracy: 0.0156 - val_loss: 5.5320 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4266 - accuracy: 0.0078 - val_loss: 5.5311 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4717 - accuracy: 0.0156 - val_loss: 5.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4863 - accuracy: 0.0156 - val_loss: 5.5290 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4617 - accuracy: 0.0312 - val_loss: 5.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4482 - accuracy: 0.0234 - val_loss: 5.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4334 - accuracy: 0.0156 - val_loss: 5.5252 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4555 - accuracy: 0.0000e+00 - val_loss: 5.5241 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4638 - accuracy: 0.0078 - val_loss: 5.5230 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4585 - accuracy: 0.0000e+00 - val_loss: 5.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.4473 - accuracy: 0.0234 - val_loss: 5.5195 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4910 - accuracy: 0.0000e+00 - val_loss: 5.5179 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4472 - accuracy: 0.0078 - val_loss: 5.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4862 - accuracy: 0.0078 - val_loss: 5.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4273 - accuracy: 0.0156 - val_loss: 5.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3866 - accuracy: 0.0078 - val_loss: 5.5115 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4531 - accuracy: 0.0078 - val_loss: 5.5090 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4146 - accuracy: 0.0156 - val_loss: 5.5076 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4557 - accuracy: 0.0078 - val_loss: 5.5057 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4629 - accuracy: 0.0234 - val_loss: 5.5033 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4604 - accuracy: 0.0234 - val_loss: 5.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4541 - accuracy: 0.0156 - val_loss: 5.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4513 - accuracy: 0.0078 - val_loss: 5.4942 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4243 - accuracy: 0.0312 - val_loss: 5.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3888 - accuracy: 0.0156 - val_loss: 5.4866 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4212 - accuracy: 0.0156 - val_loss: 5.4848 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3712 - accuracy: 0.0312 - val_loss: 5.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4380 - accuracy: 0.0156 - val_loss: 5.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3920 - accuracy: 0.0234 - val_loss: 5.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4103 - accuracy: 0.0234 - val_loss: 5.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3876 - accuracy: 0.0078 - val_loss: 5.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3856 - accuracy: 0.0312 - val_loss: 5.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4006 - accuracy: 0.0078 - val_loss: 5.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3624 - accuracy: 0.0391 - val_loss: 5.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.4180 - accuracy: 0.0000e+00 - val_loss: 5.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4241 - accuracy: 0.0234 - val_loss: 5.4716 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3243 - accuracy: 0.0547 - val_loss: 5.4700 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.3354 - accuracy: 0.0391 - val_loss: 5.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3224 - accuracy: 0.0078 - val_loss: 5.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3660 - accuracy: 0.0156 - val_loss: 5.4547 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3416 - accuracy: 0.0312 - val_loss: 5.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.3413 - accuracy: 0.0078 - val_loss: 5.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4051 - accuracy: 0.0234 - val_loss: 5.4410 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3748 - accuracy: 0.0156 - val_loss: 5.4384 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3637 - accuracy: 0.0078 - val_loss: 5.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.3378 - accuracy: 0.0234 - val_loss: 5.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3300 - accuracy: 0.0312 - val_loss: 5.4335 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3771 - accuracy: 0.0234 - val_loss: 5.4292 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2769 - accuracy: 0.0469 - val_loss: 5.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3182 - accuracy: 0.0312 - val_loss: 5.4188 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3189 - accuracy: 0.0312 - val_loss: 5.4124 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3467 - accuracy: 0.0156 - val_loss: 5.4073 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2925 - accuracy: 0.0312 - val_loss: 5.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.3307 - accuracy: 0.0234 - val_loss: 5.3924 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3308 - accuracy: 0.0234 - val_loss: 5.3903 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2711 - accuracy: 0.0625 - val_loss: 5.3878 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3380 - accuracy: 0.0234 - val_loss: 5.3874 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3578 - accuracy: 0.0156 - val_loss: 5.3874 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2938 - accuracy: 0.0078 - val_loss: 5.3863 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3774 - accuracy: 0.0234 - val_loss: 5.3836 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3625 - accuracy: 0.0078 - val_loss: 5.3785 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3038 - accuracy: 0.0312 - val_loss: 5.3713 - val_accuracy: 0.0156\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.2854 - accuracy: 0.0312 - val_loss: 5.3607 - val_accuracy: 0.0234\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.2421 - accuracy: 0.0234 - val_loss: 5.3475 - val_accuracy: 0.0312\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3058 - accuracy: 0.0312 - val_loss: 5.3387 - val_accuracy: 0.0469\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3298 - accuracy: 0.0234 - val_loss: 5.3247 - val_accuracy: 0.0625\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3180 - accuracy: 0.0156 - val_loss: 5.3166 - val_accuracy: 0.0703\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2076 - accuracy: 0.0469 - val_loss: 5.2985 - val_accuracy: 0.1094\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2651 - accuracy: 0.0000e+00 - val_loss: 5.2773 - val_accuracy: 0.1641\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2777 - accuracy: 0.0312 - val_loss: 5.2631 - val_accuracy: 0.1641\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2451 - accuracy: 0.0234 - val_loss: 5.2525 - val_accuracy: 0.1641\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1506 - accuracy: 0.0547 - val_loss: 5.2358 - val_accuracy: 0.1641\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.2590 - accuracy: 0.0156 - val_loss: 5.2238 - val_accuracy: 0.1641\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2621 - accuracy: 0.0234 - val_loss: 5.2122 - val_accuracy: 0.1641\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1913 - accuracy: 0.0156 - val_loss: 5.1959 - val_accuracy: 0.1641\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1460 - accuracy: 0.0703 - val_loss: 5.1762 - val_accuracy: 0.1641\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2646 - accuracy: 0.0391 - val_loss: 5.1633 - val_accuracy: 0.1641\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1787 - accuracy: 0.0391 - val_loss: 5.1461 - val_accuracy: 0.1641\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2166 - accuracy: 0.0234 - val_loss: 5.1368 - val_accuracy: 0.1641\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2763 - accuracy: 0.0391 - val_loss: 5.1329 - val_accuracy: 0.1641\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1796 - accuracy: 0.0156 - val_loss: 5.1315 - val_accuracy: 0.1641\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2901 - accuracy: 0.0156 - val_loss: 5.1333 - val_accuracy: 0.1641\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1888 - accuracy: 0.0312 - val_loss: 5.1316 - val_accuracy: 0.1641\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1754 - accuracy: 0.0234 - val_loss: 5.1267 - val_accuracy: 0.1641\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1803 - accuracy: 0.0625 - val_loss: 5.1234 - val_accuracy: 0.1484\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2024 - accuracy: 0.0156 - val_loss: 5.1219 - val_accuracy: 0.0625\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2072 - accuracy: 0.0234 - val_loss: 5.1249 - val_accuracy: 0.0234\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1589 - accuracy: 0.0391 - val_loss: 5.1305 - val_accuracy: 0.0078\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1784 - accuracy: 0.0469 - val_loss: 5.1329 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1708 - accuracy: 0.0391 - val_loss: 5.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.2086 - accuracy: 0.0312 - val_loss: 5.1385 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1808 - accuracy: 0.0234 - val_loss: 5.1338 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 5.1077 - accuracy: 0.0312 - val_loss: 5.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0492 - accuracy: 0.0234 - val_loss: 5.0975 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2235 - accuracy: 0.0312 - val_loss: 5.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2022 - accuracy: 0.0234 - val_loss: 5.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2373 - accuracy: 0.0078 - val_loss: 5.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1061 - accuracy: 0.0391 - val_loss: 5.0372 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1742 - accuracy: 0.0234 - val_loss: 5.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1589 - accuracy: 0.0156 - val_loss: 5.0264 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2167 - accuracy: 0.0078 - val_loss: 5.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1744 - accuracy: 0.0078 - val_loss: 5.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2392 - accuracy: 0.0156 - val_loss: 5.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1554 - accuracy: 0.0391 - val_loss: 5.0026 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1665 - accuracy: 0.0078 - val_loss: 5.0052 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1886 - accuracy: 0.0234 - val_loss: 5.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0545 - accuracy: 0.0625 - val_loss: 5.0039 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1113 - accuracy: 0.0156 - val_loss: 4.9995 - val_accuracy: 0.0078\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1089 - accuracy: 0.0391 - val_loss: 4.9972 - val_accuracy: 0.0078\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0092 - accuracy: 0.0234 - val_loss: 4.9889 - val_accuracy: 0.0312\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9548 - accuracy: 0.0547 - val_loss: 4.9684 - val_accuracy: 0.0625\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0285 - accuracy: 0.0156 - val_loss: 4.9478 - val_accuracy: 0.1562\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9986 - accuracy: 0.0234 - val_loss: 4.9319 - val_accuracy: 0.1562\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1138 - accuracy: 0.0312 - val_loss: 4.9198 - val_accuracy: 0.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0286 - accuracy: 0.0547 - val_loss: 4.9033 - val_accuracy: 0.1562\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2019 - accuracy: 0.0156 - val_loss: 4.8999 - val_accuracy: 0.1641\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0500 - accuracy: 0.0469 - val_loss: 4.9058 - val_accuracy: 0.1641\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0843 - accuracy: 0.0391 - val_loss: 4.9151 - val_accuracy: 0.1641\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2062 - accuracy: 0.0078 - val_loss: 4.9214 - val_accuracy: 0.1641\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2029 - accuracy: 0.0078 - val_loss: 4.9375 - val_accuracy: 0.1641\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1361 - accuracy: 0.0156 - val_loss: 4.9592 - val_accuracy: 0.1641\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0664 - accuracy: 0.0000e+00 - val_loss: 4.9781 - val_accuracy: 0.1641\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0578 - accuracy: 0.0312 - val_loss: 4.9871 - val_accuracy: 0.1641\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1225 - accuracy: 0.0078 - val_loss: 4.9938 - val_accuracy: 0.1562\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0588 - accuracy: 0.0234 - val_loss: 4.9936 - val_accuracy: 0.1562\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0439 - accuracy: 0.0000e+00 - val_loss: 4.9650 - val_accuracy: 0.1641\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1094 - accuracy: 0.0547 - val_loss: 4.9414 - val_accuracy: 0.1641\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0120 - accuracy: 0.0000e+00 - val_loss: 4.9232 - val_accuracy: 0.1641\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0484 - accuracy: 0.0391 - val_loss: 4.9098 - val_accuracy: 0.1641\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9724 - accuracy: 0.0469 - val_loss: 4.9027 - val_accuracy: 0.1641\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0896 - accuracy: 0.0234 - val_loss: 4.9090 - val_accuracy: 0.1641\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0309 - accuracy: 0.0391 - val_loss: 4.9152 - val_accuracy: 0.1562\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0642 - accuracy: 0.0156 - val_loss: 4.9248 - val_accuracy: 0.1250\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0422 - accuracy: 0.0391 - val_loss: 4.9261 - val_accuracy: 0.1172\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9551 - accuracy: 0.0391 - val_loss: 4.9264 - val_accuracy: 0.1016\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9730 - accuracy: 0.0312 - val_loss: 4.9296 - val_accuracy: 0.0859\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0845 - accuracy: 0.0547 - val_loss: 4.9402 - val_accuracy: 0.0703\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.9021 - accuracy: 0.0625 - val_loss: 4.9426 - val_accuracy: 0.1094\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0181 - accuracy: 0.0156 - val_loss: 4.9358 - val_accuracy: 0.1328\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.1148 - accuracy: 0.0000e+00 - val_loss: 4.9378 - val_accuracy: 0.1484\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9161 - accuracy: 0.0234 - val_loss: 4.9420 - val_accuracy: 0.1562\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0067 - accuracy: 0.0469 - val_loss: 4.9487 - val_accuracy: 0.1641\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9589 - accuracy: 0.0391 - val_loss: 4.9506 - val_accuracy: 0.1562\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.8019 - accuracy: 0.0469 - val_loss: 4.9607 - val_accuracy: 0.1406\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0155 - accuracy: 0.0234 - val_loss: 4.9729 - val_accuracy: 0.1016\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8762 - accuracy: 0.0312 - val_loss: 4.9867 - val_accuracy: 0.0781\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9695 - accuracy: 0.0078 - val_loss: 5.0004 - val_accuracy: 0.0312\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9857 - accuracy: 0.0391 - val_loss: 4.9905 - val_accuracy: 0.0391\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8934 - accuracy: 0.0312 - val_loss: 4.9803 - val_accuracy: 0.0859\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9406 - accuracy: 0.0469 - val_loss: 4.9641 - val_accuracy: 0.1172\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0355 - accuracy: 0.0156 - val_loss: 4.9370 - val_accuracy: 0.1250\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0411 - accuracy: 0.0625 - val_loss: 4.9260 - val_accuracy: 0.1406\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9869 - accuracy: 0.0078 - val_loss: 4.9171 - val_accuracy: 0.1406\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0396 - accuracy: 0.0391 - val_loss: 4.9158 - val_accuracy: 0.1406\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8531 - accuracy: 0.0391 - val_loss: 4.9156 - val_accuracy: 0.1484\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0648 - accuracy: 0.0156 - val_loss: 4.8975 - val_accuracy: 0.1562\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9615 - accuracy: 0.0312 - val_loss: 4.8738 - val_accuracy: 0.1641\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8810 - accuracy: 0.0547 - val_loss: 4.8537 - val_accuracy: 0.1641\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9017 - accuracy: 0.0234 - val_loss: 4.8209 - val_accuracy: 0.1641\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8975 - accuracy: 0.0391 - val_loss: 4.7796 - val_accuracy: 0.1562\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8597 - accuracy: 0.0156 - val_loss: 4.7458 - val_accuracy: 0.1484\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9310 - accuracy: 0.0469 - val_loss: 4.7206 - val_accuracy: 0.1484\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9386 - accuracy: 0.0234 - val_loss: 4.7091 - val_accuracy: 0.1641\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9662 - accuracy: 0.0234 - val_loss: 4.7115 - val_accuracy: 0.1484\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9293 - accuracy: 0.0078 - val_loss: 4.7183 - val_accuracy: 0.1562\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0037 - accuracy: 0.0312 - val_loss: 4.7244 - val_accuracy: 0.1562\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0152 - accuracy: 0.0391 - val_loss: 4.7354 - val_accuracy: 0.1562\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0026 - accuracy: 0.0156 - val_loss: 4.7466 - val_accuracy: 0.1406\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8816 - accuracy: 0.0469 - val_loss: 4.7532 - val_accuracy: 0.1172\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0446 - accuracy: 0.0234 - val_loss: 4.7612 - val_accuracy: 0.1172\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9755 - accuracy: 0.0234 - val_loss: 4.7651 - val_accuracy: 0.1094\n",
      "Epoch 186/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 50ms/step - loss: 4.8116 - accuracy: 0.0156 - val_loss: 4.7588 - val_accuracy: 0.1094\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9010 - accuracy: 0.0469 - val_loss: 4.7449 - val_accuracy: 0.1172\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.1001 - accuracy: 0.0234 - val_loss: 4.7358 - val_accuracy: 0.1328\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9814 - accuracy: 0.0391 - val_loss: 4.7338 - val_accuracy: 0.1328\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.0095 - accuracy: 0.0000e+00 - val_loss: 4.7336 - val_accuracy: 0.1406\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8443 - accuracy: 0.0156 - val_loss: 4.7258 - val_accuracy: 0.1562\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8858 - accuracy: 0.0312 - val_loss: 4.7199 - val_accuracy: 0.1641\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0976 - accuracy: 0.0156 - val_loss: 4.7168 - val_accuracy: 0.1641\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9363 - accuracy: 0.0391 - val_loss: 4.7155 - val_accuracy: 0.1641\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6884 - accuracy: 0.0547 - val_loss: 4.7187 - val_accuracy: 0.1641\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0685 - accuracy: 0.0312 - val_loss: 4.7248 - val_accuracy: 0.1562\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8585 - accuracy: 0.0469 - val_loss: 4.7340 - val_accuracy: 0.1562\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0059 - accuracy: 0.0156 - val_loss: 4.7393 - val_accuracy: 0.1406\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8532 - accuracy: 0.0312 - val_loss: 4.7459 - val_accuracy: 0.1250\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9435 - accuracy: 0.0000e+00 - val_loss: 4.7522 - val_accuracy: 0.1016\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9000 - accuracy: 0.0469 - val_loss: 4.7649 - val_accuracy: 0.0156\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9587 - accuracy: 0.0234 - val_loss: 4.7838 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9223 - accuracy: 0.0312 - val_loss: 4.8036 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6486 - accuracy: 0.0469 - val_loss: 4.8239 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9620 - accuracy: 0.0234 - val_loss: 4.8424 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9478 - accuracy: 0.0234 - val_loss: 4.8526 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0231 - accuracy: 0.0234 - val_loss: 4.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0464 - accuracy: 0.0234 - val_loss: 4.8863 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9097 - accuracy: 0.0078 - val_loss: 4.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9678 - accuracy: 0.0312 - val_loss: 4.8943 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9268 - accuracy: 0.0000e+00 - val_loss: 4.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8440 - accuracy: 0.0078 - val_loss: 4.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0029 - accuracy: 0.0078 - val_loss: 4.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9524 - accuracy: 0.0234 - val_loss: 4.9048 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9488 - accuracy: 0.0312 - val_loss: 4.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8706 - accuracy: 0.0312 - val_loss: 4.8780 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9025 - accuracy: 0.0234 - val_loss: 4.8713 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8179 - accuracy: 0.0078 - val_loss: 4.8660 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9669 - accuracy: 0.0078 - val_loss: 4.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8958 - accuracy: 0.0234 - val_loss: 4.8644 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8262 - accuracy: 0.0234 - val_loss: 4.8630 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0305 - accuracy: 0.0078 - val_loss: 4.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9523 - accuracy: 0.0469 - val_loss: 4.8560 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8801 - accuracy: 0.0078 - val_loss: 4.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8068 - accuracy: 0.0469 - val_loss: 4.8430 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8921 - accuracy: 0.0547 - val_loss: 4.8409 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9020 - accuracy: 0.0234 - val_loss: 4.8454 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8305 - accuracy: 0.0391 - val_loss: 4.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9830 - accuracy: 0.0234 - val_loss: 4.8347 - val_accuracy: 0.0156\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6776 - accuracy: 0.0391 - val_loss: 4.8084 - val_accuracy: 0.0781\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8504 - accuracy: 0.0156 - val_loss: 4.7866 - val_accuracy: 0.1406\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7780 - accuracy: 0.0312 - val_loss: 4.7677 - val_accuracy: 0.1641\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8524 - accuracy: 0.0156 - val_loss: 4.7483 - val_accuracy: 0.1641\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8298 - accuracy: 0.0312 - val_loss: 4.7340 - val_accuracy: 0.1641\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8237 - accuracy: 0.0078 - val_loss: 4.7197 - val_accuracy: 0.1641\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8762 - accuracy: 0.0391 - val_loss: 4.7142 - val_accuracy: 0.1641\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8430 - accuracy: 0.0234 - val_loss: 4.7135 - val_accuracy: 0.1641\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8795 - accuracy: 0.0547 - val_loss: 4.7025 - val_accuracy: 0.1641\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9465 - accuracy: 0.0391 - val_loss: 4.6926 - val_accuracy: 0.1641\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9540 - accuracy: 0.0391 - val_loss: 4.6821 - val_accuracy: 0.1641\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9341 - accuracy: 0.0547 - val_loss: 4.6814 - val_accuracy: 0.1641\n",
      "Epoch 242/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8152 - accuracy: 0.0156 - val_loss: 4.6877 - val_accuracy: 0.1641\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9548 - accuracy: 0.0156 - val_loss: 4.6988 - val_accuracy: 0.1641\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8192 - accuracy: 0.0156 - val_loss: 4.7138 - val_accuracy: 0.1641\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7326 - accuracy: 0.0312 - val_loss: 4.7321 - val_accuracy: 0.1641\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8770 - accuracy: 0.0234 - val_loss: 4.7453 - val_accuracy: 0.1641\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9153 - accuracy: 0.0156 - val_loss: 4.7550 - val_accuracy: 0.1641\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6646 - accuracy: 0.0156 - val_loss: 4.7640 - val_accuracy: 0.1641\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6902 - accuracy: 0.0547 - val_loss: 4.7689 - val_accuracy: 0.1641\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0199 - accuracy: 0.0078 - val_loss: 4.7700 - val_accuracy: 0.1641\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7957 - accuracy: 0.0156 - val_loss: 4.7813 - val_accuracy: 0.1641\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8537 - accuracy: 0.0547 - val_loss: 4.7935 - val_accuracy: 0.1641\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.6647 - accuracy: 0.0234 - val_loss: 4.8057 - val_accuracy: 0.1250\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9021 - accuracy: 0.0078 - val_loss: 4.8182 - val_accuracy: 0.1016\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8113 - accuracy: 0.0234 - val_loss: 4.8301 - val_accuracy: 0.0391\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8247 - accuracy: 0.0625 - val_loss: 4.8379 - val_accuracy: 0.0234\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9463 - accuracy: 0.0078 - val_loss: 4.8420 - val_accuracy: 0.0156\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7582 - accuracy: 0.0078 - val_loss: 4.8467 - val_accuracy: 0.0156\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8658 - accuracy: 0.0156 - val_loss: 4.8544 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1309 - accuracy: 0.0234 - val_loss: 4.8549 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9024 - accuracy: 0.0156 - val_loss: 4.8517 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7070 - accuracy: 0.0469 - val_loss: 4.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8653 - accuracy: 0.0234 - val_loss: 4.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9314 - accuracy: 0.0156 - val_loss: 4.8187 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6710 - accuracy: 0.0781 - val_loss: 4.8163 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9478 - accuracy: 0.0156 - val_loss: 4.8034 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7243 - accuracy: 0.0391 - val_loss: 4.7802 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7431 - accuracy: 0.0312 - val_loss: 4.7464 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9634 - accuracy: 0.0078 - val_loss: 4.7121 - val_accuracy: 0.0312\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8753 - accuracy: 0.0312 - val_loss: 4.6907 - val_accuracy: 0.0625\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8849 - accuracy: 0.0156 - val_loss: 4.6877 - val_accuracy: 0.1094\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8358 - accuracy: 0.0000e+00 - val_loss: 4.6922 - val_accuracy: 0.0859\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8293 - accuracy: 0.0312 - val_loss: 4.7021 - val_accuracy: 0.0391\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8573 - accuracy: 0.0078 - val_loss: 4.6986 - val_accuracy: 0.0234\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8430 - accuracy: 0.0234 - val_loss: 4.6981 - val_accuracy: 0.0234\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6993 - accuracy: 0.0312 - val_loss: 4.7045 - val_accuracy: 0.0156\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9011 - accuracy: 0.0391 - val_loss: 4.7153 - val_accuracy: 0.0156\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8180 - accuracy: 0.0078 - val_loss: 4.7251 - val_accuracy: 0.0156\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7294 - accuracy: 0.0469 - val_loss: 4.7338 - val_accuracy: 0.0078\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8551 - accuracy: 0.0391 - val_loss: 4.7332 - val_accuracy: 0.0078\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6574 - accuracy: 0.0312 - val_loss: 4.7284 - val_accuracy: 0.0078\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8408 - accuracy: 0.0234 - val_loss: 4.7120 - val_accuracy: 0.0391\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8115 - accuracy: 0.0156 - val_loss: 4.6942 - val_accuracy: 0.0938\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7157 - accuracy: 0.0391 - val_loss: 4.6824 - val_accuracy: 0.1094\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9215 - accuracy: 0.0469 - val_loss: 4.6785 - val_accuracy: 0.1094\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7195 - accuracy: 0.0078 - val_loss: 4.6817 - val_accuracy: 0.1016\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9742 - accuracy: 0.0078 - val_loss: 4.6880 - val_accuracy: 0.1016\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8246 - accuracy: 0.0234 - val_loss: 4.6970 - val_accuracy: 0.0859\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7042 - accuracy: 0.0469 - val_loss: 4.7058 - val_accuracy: 0.0547\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9239 - accuracy: 0.0391 - val_loss: 4.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.6869 - accuracy: 0.0078 - val_loss: 4.7212 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8837 - accuracy: 0.0312 - val_loss: 4.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8731 - accuracy: 0.0156 - val_loss: 4.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8732 - accuracy: 0.0625 - val_loss: 4.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7572 - accuracy: 0.0156 - val_loss: 4.7464 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8641 - accuracy: 0.0000e+00 - val_loss: 4.7551 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7811 - accuracy: 0.0391 - val_loss: 4.7649 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6743 - accuracy: 0.0625 - val_loss: 4.7768 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6892 - accuracy: 0.0078 - val_loss: 4.7921 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9539 - accuracy: 0.0234 - val_loss: 4.8030 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8464 - accuracy: 0.0234 - val_loss: 4.8114 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7547 - accuracy: 0.0547 - val_loss: 4.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8183 - accuracy: 0.0234 - val_loss: 4.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7708 - accuracy: 0.0156 - val_loss: 4.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6330 - accuracy: 0.0391 - val_loss: 4.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7675 - accuracy: 0.0234 - val_loss: 4.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8821 - accuracy: 0.0156 - val_loss: 4.8620 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7422 - accuracy: 0.0234 - val_loss: 4.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9637 - accuracy: 0.0078 - val_loss: 4.8697 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7612 - accuracy: 0.0234 - val_loss: 4.8524 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5721 - accuracy: 0.0781 - val_loss: 4.8429 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8173 - accuracy: 0.0703 - val_loss: 4.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8269 - accuracy: 0.0469 - val_loss: 4.8444 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6863 - accuracy: 0.0234 - val_loss: 4.8466 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8368 - accuracy: 0.0078 - val_loss: 4.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8225 - accuracy: 0.0547 - val_loss: 4.8586 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9622 - accuracy: 0.0156 - val_loss: 4.8598 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8277 - accuracy: 0.0234 - val_loss: 4.8536 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7101 - accuracy: 0.0469 - val_loss: 4.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7895 - accuracy: 0.0078 - val_loss: 4.8551 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8429 - accuracy: 0.0234 - val_loss: 4.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8700 - accuracy: 0.0312 - val_loss: 4.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8190 - accuracy: 0.0391 - val_loss: 4.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0411 - accuracy: 0.0000e+00 - val_loss: 4.8153 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9342 - accuracy: 0.0391 - val_loss: 4.8135 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7753 - accuracy: 0.0078 - val_loss: 4.8135 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8957 - accuracy: 0.0078 - val_loss: 4.8059 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8244 - accuracy: 0.0234 - val_loss: 4.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9468 - accuracy: 0.0391 - val_loss: 4.7966 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7798 - accuracy: 0.0156 - val_loss: 4.7798 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8209 - accuracy: 0.0391 - val_loss: 4.7684 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8079 - accuracy: 0.0078 - val_loss: 4.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8302 - accuracy: 0.0391 - val_loss: 4.7220 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9503 - accuracy: 0.0234 - val_loss: 4.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7669 - accuracy: 0.0312 - val_loss: 4.6799 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7588 - accuracy: 0.0156 - val_loss: 4.6691 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7092 - accuracy: 0.0312 - val_loss: 4.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7733 - accuracy: 0.0469 - val_loss: 4.6626 - val_accuracy: 0.0234\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8484 - accuracy: 0.0078 - val_loss: 4.6646 - val_accuracy: 0.0078\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8231 - accuracy: 0.0000e+00 - val_loss: 4.6709 - val_accuracy: 0.0312\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8386 - accuracy: 0.0078 - val_loss: 4.6792 - val_accuracy: 0.0156\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7121 - accuracy: 0.0391 - val_loss: 4.6898 - val_accuracy: 0.0078\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5300 - accuracy: 0.0625 - val_loss: 4.7001 - val_accuracy: 0.0078\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7637 - accuracy: 0.0078 - val_loss: 4.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7198 - accuracy: 0.0391 - val_loss: 4.7186 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7002 - accuracy: 0.0469 - val_loss: 4.7239 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9319 - accuracy: 0.0234 - val_loss: 4.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7740 - accuracy: 0.0156 - val_loss: 4.7322 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8111 - accuracy: 0.0078 - val_loss: 4.7338 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9201 - accuracy: 0.0078 - val_loss: 4.7324 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7808 - accuracy: 0.0078 - val_loss: 4.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7112 - accuracy: 0.0078 - val_loss: 4.7128 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6463 - accuracy: 0.0312 - val_loss: 4.6995 - val_accuracy: 0.0234\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7174 - accuracy: 0.0469 - val_loss: 4.6866 - val_accuracy: 0.0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7907 - accuracy: 0.0078 - val_loss: 4.6764 - val_accuracy: 0.0859\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7491 - accuracy: 0.0234 - val_loss: 4.6694 - val_accuracy: 0.0391\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8412 - accuracy: 0.0469 - val_loss: 4.6704 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7165 - accuracy: 0.0312 - val_loss: 4.6779 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8389 - accuracy: 0.0156 - val_loss: 4.6887 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7216 - accuracy: 0.0547 - val_loss: 4.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6160 - accuracy: 0.0391 - val_loss: 4.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7823 - accuracy: 0.0000e+00 - val_loss: 4.7216 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6040 - accuracy: 0.0469 - val_loss: 4.7423 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9195 - accuracy: 0.0156 - val_loss: 4.7596 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7598 - accuracy: 0.0547 - val_loss: 4.7764 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5964 - accuracy: 0.0234 - val_loss: 4.7891 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9062 - accuracy: 0.0234 - val_loss: 4.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9561 - accuracy: 0.0156 - val_loss: 4.8137 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9036 - accuracy: 0.0234 - val_loss: 4.8235 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6979 - accuracy: 0.0391 - val_loss: 4.8392 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8983 - accuracy: 0.0000e+00 - val_loss: 4.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9865 - accuracy: 0.0078 - val_loss: 4.8535 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7624 - accuracy: 0.0547 - val_loss: 4.8625 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.4529 - accuracy: 0.0625 - val_loss: 4.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8087 - accuracy: 0.0234 - val_loss: 4.8562 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7320 - accuracy: 0.0234 - val_loss: 4.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6763 - accuracy: 0.0234 - val_loss: 4.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7914 - accuracy: 0.0078 - val_loss: 4.8274 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8353 - accuracy: 0.0391 - val_loss: 4.8292 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7927 - accuracy: 0.0156 - val_loss: 4.8225 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6971 - accuracy: 0.0234 - val_loss: 4.8117 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7550 - accuracy: 0.0156 - val_loss: 4.7936 - val_accuracy: 0.0078\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9369 - accuracy: 0.0156 - val_loss: 4.7816 - val_accuracy: 0.0078\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6376 - accuracy: 0.0234 - val_loss: 4.7746 - val_accuracy: 0.0078\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6142 - accuracy: 0.0234 - val_loss: 4.7600 - val_accuracy: 0.0078\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7626 - accuracy: 0.0078 - val_loss: 4.7356 - val_accuracy: 0.0078\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9914 - accuracy: 0.0391 - val_loss: 4.7173 - val_accuracy: 0.0078\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7815 - accuracy: 0.0625 - val_loss: 4.7031 - val_accuracy: 0.0078\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8629 - accuracy: 0.0312 - val_loss: 4.6962 - val_accuracy: 0.0078\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6610 - accuracy: 0.0078 - val_loss: 4.6891 - val_accuracy: 0.0078\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6157 - accuracy: 0.0469 - val_loss: 4.6796 - val_accuracy: 0.0234\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6830 - accuracy: 0.0156 - val_loss: 4.6672 - val_accuracy: 0.0312\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7761 - accuracy: 0.0312 - val_loss: 4.6658 - val_accuracy: 0.0234\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6907 - accuracy: 0.0781 - val_loss: 4.6661 - val_accuracy: 0.0234\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8997 - accuracy: 0.0391 - val_loss: 4.6703 - val_accuracy: 0.0234\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8799 - accuracy: 0.0312 - val_loss: 4.6659 - val_accuracy: 0.0781\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7382 - accuracy: 0.0547 - val_loss: 4.6636 - val_accuracy: 0.1406\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8448 - accuracy: 0.0469 - val_loss: 4.6551 - val_accuracy: 0.1641\n",
      "Epoch 399/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8547 - accuracy: 0.0000e+00 - val_loss: 4.6453 - val_accuracy: 0.1641\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6991 - accuracy: 0.0156 - val_loss: 4.6387 - val_accuracy: 0.1641\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7729 - accuracy: 0.0547 - val_loss: 4.6361 - val_accuracy: 0.1484\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6966 - accuracy: 0.0391 - val_loss: 4.6435 - val_accuracy: 0.1328\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6728 - accuracy: 0.0234 - val_loss: 4.6526 - val_accuracy: 0.0859\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6895 - accuracy: 0.0078 - val_loss: 4.6672 - val_accuracy: 0.0781\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6594 - accuracy: 0.0312 - val_loss: 4.6763 - val_accuracy: 0.0547\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7768 - accuracy: 0.0625 - val_loss: 4.6822 - val_accuracy: 0.0469\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7712 - accuracy: 0.0078 - val_loss: 4.6836 - val_accuracy: 0.0547\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7144 - accuracy: 0.0391 - val_loss: 4.6906 - val_accuracy: 0.0703\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9210 - accuracy: 0.0312 - val_loss: 4.6969 - val_accuracy: 0.0781\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.6360 - accuracy: 0.0234 - val_loss: 4.6926 - val_accuracy: 0.0859\n",
      "Epoch 411/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8163 - accuracy: 0.0469 - val_loss: 4.6857 - val_accuracy: 0.1016\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7416 - accuracy: 0.0234 - val_loss: 4.6822 - val_accuracy: 0.0078\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7258 - accuracy: 0.0469 - val_loss: 4.6846 - val_accuracy: 0.0078\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6391 - accuracy: 0.0000e+00 - val_loss: 4.6887 - val_accuracy: 0.0078\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7021 - accuracy: 0.0312 - val_loss: 4.7009 - val_accuracy: 0.0078\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8351 - accuracy: 0.0078 - val_loss: 4.7190 - val_accuracy: 0.0078\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8478 - accuracy: 0.0156 - val_loss: 4.7291 - val_accuracy: 0.0078\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.6648 - accuracy: 0.0000e+00 - val_loss: 4.7304 - val_accuracy: 0.0078\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8538 - accuracy: 0.0078 - val_loss: 4.7272 - val_accuracy: 0.0312\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7957 - accuracy: 0.0312 - val_loss: 4.7360 - val_accuracy: 0.0938\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6578 - accuracy: 0.0078 - val_loss: 4.7469 - val_accuracy: 0.1172\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5799 - accuracy: 0.0781 - val_loss: 4.7534 - val_accuracy: 0.1016\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6110 - accuracy: 0.0000e+00 - val_loss: 4.7396 - val_accuracy: 0.1172\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6431 - accuracy: 0.0234 - val_loss: 4.7318 - val_accuracy: 0.1250\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7636 - accuracy: 0.0312 - val_loss: 4.7312 - val_accuracy: 0.1250\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7926 - accuracy: 0.0000e+00 - val_loss: 4.7338 - val_accuracy: 0.1250\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9463 - accuracy: 0.0312 - val_loss: 4.7500 - val_accuracy: 0.0938\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7974 - accuracy: 0.0078 - val_loss: 4.7657 - val_accuracy: 0.0859\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7982 - accuracy: 0.0000e+00 - val_loss: 4.7797 - val_accuracy: 0.0469\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.6108 - accuracy: 0.0547 - val_loss: 4.7752 - val_accuracy: 0.0781\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7102 - accuracy: 0.0312 - val_loss: 4.7656 - val_accuracy: 0.1406\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6742 - accuracy: 0.0859 - val_loss: 4.7492 - val_accuracy: 0.1641\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8009 - accuracy: 0.0703 - val_loss: 4.7352 - val_accuracy: 0.1641\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6675 - accuracy: 0.0000e+00 - val_loss: 4.7395 - val_accuracy: 0.1641\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7914 - accuracy: 0.0156 - val_loss: 4.7577 - val_accuracy: 0.1641\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6526 - accuracy: 0.0469 - val_loss: 4.7716 - val_accuracy: 0.1641\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7878 - accuracy: 0.0234 - val_loss: 4.7819 - val_accuracy: 0.1641\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8751 - accuracy: 0.0234 - val_loss: 4.8021 - val_accuracy: 0.1641\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6920 - accuracy: 0.0234 - val_loss: 4.8257 - val_accuracy: 0.1641\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6775 - accuracy: 0.0391 - val_loss: 4.8402 - val_accuracy: 0.1641\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9393 - accuracy: 0.0156 - val_loss: 4.8475 - val_accuracy: 0.1641\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8158 - accuracy: 0.0469 - val_loss: 4.8455 - val_accuracy: 0.1641\n",
      "Epoch 443/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6274 - accuracy: 0.0312 - val_loss: 4.8419 - val_accuracy: 0.1562\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7556 - accuracy: 0.0312 - val_loss: 4.8376 - val_accuracy: 0.1406\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7367 - accuracy: 0.0469 - val_loss: 4.8338 - val_accuracy: 0.1328\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6723 - accuracy: 0.0234 - val_loss: 4.8369 - val_accuracy: 0.0781\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8195 - accuracy: 0.0156 - val_loss: 4.8445 - val_accuracy: 0.0312\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7885 - accuracy: 0.0078 - val_loss: 4.8431 - val_accuracy: 0.0156\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6606 - accuracy: 0.0078 - val_loss: 4.8456 - val_accuracy: 0.0078\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6977 - accuracy: 0.0391 - val_loss: 4.8501 - val_accuracy: 0.0078\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6403 - accuracy: 0.0312 - val_loss: 4.8529 - val_accuracy: 0.0078\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7138 - accuracy: 0.0234 - val_loss: 4.8520 - val_accuracy: 0.0078\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7766 - accuracy: 0.0469 - val_loss: 4.8502 - val_accuracy: 0.0156\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7103 - accuracy: 0.0469 - val_loss: 4.8516 - val_accuracy: 0.0156\n",
      "Epoch 455/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6810 - accuracy: 0.0391 - val_loss: 4.8482 - val_accuracy: 0.0156\n",
      "Epoch 456/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6048 - accuracy: 0.0625 - val_loss: 4.8312 - val_accuracy: 0.0156\n",
      "Epoch 457/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6298 - accuracy: 0.0234 - val_loss: 4.8165 - val_accuracy: 0.0078\n",
      "Epoch 458/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7359 - accuracy: 0.0312 - val_loss: 4.8012 - val_accuracy: 0.0078\n",
      "Epoch 459/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9345 - accuracy: 0.0234 - val_loss: 4.8007 - val_accuracy: 0.0078\n",
      "Epoch 460/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6991 - accuracy: 0.0547 - val_loss: 4.8062 - val_accuracy: 0.0234\n",
      "Epoch 461/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7099 - accuracy: 0.0234 - val_loss: 4.8133 - val_accuracy: 0.0078\n",
      "Epoch 462/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7981 - accuracy: 0.0469 - val_loss: 4.8167 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8122 - accuracy: 0.0156 - val_loss: 4.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6747 - accuracy: 0.0703 - val_loss: 4.8279 - val_accuracy: 0.0078\n",
      "Epoch 465/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5987 - accuracy: 0.0391 - val_loss: 4.8340 - val_accuracy: 0.0078\n",
      "Epoch 466/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8677 - accuracy: 0.0234 - val_loss: 4.8330 - val_accuracy: 0.0078\n",
      "Epoch 467/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8039 - accuracy: 0.0391 - val_loss: 4.8425 - val_accuracy: 0.0078\n",
      "Epoch 468/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8414 - accuracy: 0.0391 - val_loss: 4.8462 - val_accuracy: 0.0078\n",
      "Epoch 469/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8325 - accuracy: 0.0234 - val_loss: 4.8409 - val_accuracy: 0.0078\n",
      "Epoch 470/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8661 - accuracy: 0.0781 - val_loss: 4.8374 - val_accuracy: 0.0078\n",
      "Epoch 471/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5228 - accuracy: 0.0625 - val_loss: 4.8273 - val_accuracy: 0.0078\n",
      "Epoch 472/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5131 - accuracy: 0.1641 - val_loss: 4.8203 - val_accuracy: 0.0078\n",
      "Epoch 473/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6068 - accuracy: 0.0234 - val_loss: 4.8168 - val_accuracy: 0.0078\n",
      "Epoch 474/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6140 - accuracy: 0.0000e+00 - val_loss: 4.8185 - val_accuracy: 0.0078\n",
      "Epoch 475/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8925 - accuracy: 0.0234 - val_loss: 4.8233 - val_accuracy: 0.0078\n",
      "Epoch 476/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6762 - accuracy: 0.0312 - val_loss: 4.8268 - val_accuracy: 0.0078\n",
      "Epoch 477/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7005 - accuracy: 0.0000e+00 - val_loss: 4.8322 - val_accuracy: 0.0078\n",
      "Epoch 478/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7434 - accuracy: 0.0000e+00 - val_loss: 4.8307 - val_accuracy: 0.0078\n",
      "Epoch 479/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7373 - accuracy: 0.0000e+00 - val_loss: 4.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7439 - accuracy: 0.0469 - val_loss: 4.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6066 - accuracy: 0.0391 - val_loss: 4.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8526 - accuracy: 0.0078 - val_loss: 4.8262 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7325 - accuracy: 0.0156 - val_loss: 4.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8100 - accuracy: 0.0078 - val_loss: 4.7988 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6743 - accuracy: 0.0547 - val_loss: 4.7881 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7387 - accuracy: 0.0547 - val_loss: 4.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8646 - accuracy: 0.0234 - val_loss: 4.7976 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5554 - accuracy: 0.0312 - val_loss: 4.8057 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8140 - accuracy: 0.0156 - val_loss: 4.8139 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6073 - accuracy: 0.0078 - val_loss: 4.8146 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7139 - accuracy: 0.0312 - val_loss: 4.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8070 - accuracy: 0.0156 - val_loss: 4.8268 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5141 - accuracy: 0.0391 - val_loss: 4.8481 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5582 - accuracy: 0.0547 - val_loss: 4.8566 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8603 - accuracy: 0.0078 - val_loss: 4.8650 - val_accuracy: 0.0156\n",
      "Epoch 496/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9201 - accuracy: 0.0156 - val_loss: 4.8673 - val_accuracy: 0.0078\n",
      "Epoch 497/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8553 - accuracy: 0.0391 - val_loss: 4.8658 - val_accuracy: 0.0312\n",
      "Epoch 498/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4552 - accuracy: 0.0469 - val_loss: 4.8663 - val_accuracy: 0.0391\n",
      "Epoch 499/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7871 - accuracy: 0.0156 - val_loss: 4.8658 - val_accuracy: 0.0391\n",
      "Epoch 500/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7202 - accuracy: 0.0391 - val_loss: 4.8726 - val_accuracy: 0.0234\n",
      "Epoch 501/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8435 - accuracy: 0.0156 - val_loss: 4.8693 - val_accuracy: 0.0234\n",
      "Epoch 00501: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 2)       12        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 2)       14        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 2)       8         \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 2)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 4)       44        \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 4)       52        \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 4)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 8)       168       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 8)       200       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 8)        0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 8)        328       \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 8)        200       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 8)        32        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 8)        0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 16)       656       \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 16)       784       \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 16)       1296      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 16)       784       \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 16)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      4352      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,322\n",
      "Trainable params: 9,106\n",
      "Non-trainable params: 216\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=27228\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 5.5931 - accuracy: 0.0078 - val_loss: 5.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.5192 - accuracy: 0.0156 - val_loss: 5.5391 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.5461 - accuracy: 0.0078 - val_loss: 5.5359 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.5049 - accuracy: 0.0234 - val_loss: 5.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.5124 - accuracy: 0.0078 - val_loss: 5.5259 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.5191 - accuracy: 0.0078 - val_loss: 5.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.4867 - accuracy: 0.0078 - val_loss: 5.5071 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4708 - accuracy: 0.0078 - val_loss: 5.4957 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.4297 - accuracy: 0.0312 - val_loss: 5.4858 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.4398 - accuracy: 0.0156 - val_loss: 5.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4513 - accuracy: 0.0391 - val_loss: 5.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4581 - accuracy: 0.0156 - val_loss: 5.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4391 - accuracy: 0.0000e+00 - val_loss: 5.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4140 - accuracy: 0.0234 - val_loss: 5.4454 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4321 - accuracy: 0.0156 - val_loss: 5.4393 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3901 - accuracy: 0.0234 - val_loss: 5.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3922 - accuracy: 0.0234 - val_loss: 5.4325 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4333 - accuracy: 0.0156 - val_loss: 5.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3864 - accuracy: 0.0312 - val_loss: 5.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3612 - accuracy: 0.0234 - val_loss: 5.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3120 - accuracy: 0.0625 - val_loss: 5.3881 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3734 - accuracy: 0.0000e+00 - val_loss: 5.3730 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4067 - accuracy: 0.0078 - val_loss: 5.3602 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3653 - accuracy: 0.0469 - val_loss: 5.3439 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3162 - accuracy: 0.0312 - val_loss: 5.3254 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2269 - accuracy: 0.0625 - val_loss: 5.3172 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3742 - accuracy: 0.0000e+00 - val_loss: 5.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2034 - accuracy: 0.0859 - val_loss: 5.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1656 - accuracy: 0.0547 - val_loss: 5.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3691 - accuracy: 0.0078 - val_loss: 5.2937 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.3910 - accuracy: 0.0156 - val_loss: 5.2913 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3218 - accuracy: 0.0078 - val_loss: 5.2863 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3063 - accuracy: 0.0156 - val_loss: 5.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3338 - accuracy: 0.0234 - val_loss: 5.2942 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4063 - accuracy: 0.0078 - val_loss: 5.3017 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4165 - accuracy: 0.0000e+00 - val_loss: 5.3122 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1534 - accuracy: 0.0625 - val_loss: 5.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2815 - accuracy: 0.0469 - val_loss: 5.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3298 - accuracy: 0.0078 - val_loss: 5.2687 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1420 - accuracy: 0.0547 - val_loss: 5.2425 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1354 - accuracy: 0.0547 - val_loss: 5.2055 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2039 - accuracy: 0.0391 - val_loss: 5.1704 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2440 - accuracy: 0.0312 - val_loss: 5.1254 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2576 - accuracy: 0.0234 - val_loss: 5.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2784 - accuracy: 0.0234 - val_loss: 5.0870 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1281 - accuracy: 0.0312 - val_loss: 5.0861 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0664 - accuracy: 0.0234 - val_loss: 5.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2600 - accuracy: 0.0078 - val_loss: 5.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1499 - accuracy: 0.0234 - val_loss: 5.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2316 - accuracy: 0.0000e+00 - val_loss: 5.0389 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0875 - accuracy: 0.0234 - val_loss: 5.0259 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2309 - accuracy: 0.0000e+00 - val_loss: 5.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1208 - accuracy: 0.0469 - val_loss: 5.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0434 - accuracy: 0.0312 - val_loss: 5.0345 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3546 - accuracy: 0.0078 - val_loss: 5.0392 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1712 - accuracy: 0.0078 - val_loss: 5.0318 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1350 - accuracy: 0.0469 - val_loss: 5.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1600 - accuracy: 0.0391 - val_loss: 5.0424 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9657 - accuracy: 0.0547 - val_loss: 5.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2292 - accuracy: 0.0312 - val_loss: 4.9915 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0963 - accuracy: 0.0547 - val_loss: 4.9585 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0741 - accuracy: 0.0547 - val_loss: 4.9378 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9554 - accuracy: 0.0781 - val_loss: 4.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2044 - accuracy: 0.0156 - val_loss: 4.8851 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1529 - accuracy: 0.0234 - val_loss: 4.8732 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2045 - accuracy: 0.0234 - val_loss: 4.8496 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0391 - accuracy: 0.0234 - val_loss: 4.8541 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2026 - accuracy: 0.0078 - val_loss: 4.8651 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1681 - accuracy: 0.0156 - val_loss: 4.8415 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0686 - accuracy: 0.0391 - val_loss: 4.8217 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.0244 - accuracy: 0.0156 - val_loss: 4.7944 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9326 - accuracy: 0.0234 - val_loss: 4.7396 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9634 - accuracy: 0.0312 - val_loss: 4.7032 - val_accuracy: 0.0156\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9132 - accuracy: 0.0625 - val_loss: 4.6634 - val_accuracy: 0.0156\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8070 - accuracy: 0.0859 - val_loss: 4.6306 - val_accuracy: 0.0156\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9442 - accuracy: 0.0156 - val_loss: 4.5798 - val_accuracy: 0.0078\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9283 - accuracy: 0.0547 - val_loss: 4.5319 - val_accuracy: 0.0156\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0815 - accuracy: 0.0156 - val_loss: 4.5299 - val_accuracy: 0.0234\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8683 - accuracy: 0.0469 - val_loss: 4.5517 - val_accuracy: 0.0391\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9876 - accuracy: 0.0078 - val_loss: 4.6052 - val_accuracy: 0.0547\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0598 - accuracy: 0.0078 - val_loss: 4.6274 - val_accuracy: 0.0625\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1292 - accuracy: 0.0312 - val_loss: 4.6524 - val_accuracy: 0.0547\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2103 - accuracy: 0.0078 - val_loss: 4.6605 - val_accuracy: 0.0625\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9751 - accuracy: 0.0312 - val_loss: 4.6428 - val_accuracy: 0.0703\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8064 - accuracy: 0.0781 - val_loss: 4.6408 - val_accuracy: 0.0469\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8403 - accuracy: 0.0625 - val_loss: 4.6703 - val_accuracy: 0.0234\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0296 - accuracy: 0.0000e+00 - val_loss: 4.6948 - val_accuracy: 0.0234\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9816 - accuracy: 0.0234 - val_loss: 4.6998 - val_accuracy: 0.0234\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0102 - accuracy: 0.0000e+00 - val_loss: 4.7154 - val_accuracy: 0.0078\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7841 - accuracy: 0.0312 - val_loss: 4.7127 - val_accuracy: 0.0078\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9735 - accuracy: 0.0234 - val_loss: 4.7118 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0030 - accuracy: 0.0547 - val_loss: 4.6925 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9506 - accuracy: 0.0156 - val_loss: 4.6522 - val_accuracy: 0.0078\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9660 - accuracy: 0.0547 - val_loss: 4.6361 - val_accuracy: 0.0156\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9075 - accuracy: 0.0312 - val_loss: 4.5971 - val_accuracy: 0.0312\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9209 - accuracy: 0.0547 - val_loss: 4.5777 - val_accuracy: 0.0469\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8801 - accuracy: 0.0469 - val_loss: 4.5871 - val_accuracy: 0.0469\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9144 - accuracy: 0.0625 - val_loss: 4.6132 - val_accuracy: 0.0547\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8982 - accuracy: 0.0781 - val_loss: 4.6252 - val_accuracy: 0.0781\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0929 - accuracy: 0.0469 - val_loss: 4.6222 - val_accuracy: 0.0703\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8619 - accuracy: 0.0391 - val_loss: 4.6289 - val_accuracy: 0.0625\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9827 - accuracy: 0.0391 - val_loss: 4.6290 - val_accuracy: 0.0625\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0527 - accuracy: 0.0078 - val_loss: 4.6147 - val_accuracy: 0.0703\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7340 - accuracy: 0.0703 - val_loss: 4.5933 - val_accuracy: 0.0781\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6188 - accuracy: 0.1250 - val_loss: 4.5604 - val_accuracy: 0.0859\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5838 - accuracy: 0.0781 - val_loss: 4.5248 - val_accuracy: 0.0938\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7398 - accuracy: 0.0469 - val_loss: 4.5031 - val_accuracy: 0.1016\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8991 - accuracy: 0.0156 - val_loss: 4.4863 - val_accuracy: 0.1016\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9342 - accuracy: 0.0234 - val_loss: 4.4806 - val_accuracy: 0.1094\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7480 - accuracy: 0.0625 - val_loss: 4.4652 - val_accuracy: 0.1094\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8914 - accuracy: 0.0156 - val_loss: 4.4636 - val_accuracy: 0.1094\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8811 - accuracy: 0.0625 - val_loss: 4.4623 - val_accuracy: 0.1016\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7360 - accuracy: 0.0312 - val_loss: 4.4458 - val_accuracy: 0.0938\n",
      "Epoch 114/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6438 - accuracy: 0.1172 - val_loss: 4.4343 - val_accuracy: 0.0938\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7887 - accuracy: 0.0312 - val_loss: 4.4416 - val_accuracy: 0.0938\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.8376 - accuracy: 0.0156 - val_loss: 4.4525 - val_accuracy: 0.0781\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9611 - accuracy: 0.0000e+00 - val_loss: 4.4797 - val_accuracy: 0.0625\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9152 - accuracy: 0.0156 - val_loss: 4.4913 - val_accuracy: 0.0625\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9942 - accuracy: 0.0312 - val_loss: 4.4893 - val_accuracy: 0.0625\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9111 - accuracy: 0.0078 - val_loss: 4.4840 - val_accuracy: 0.0703\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.0430 - accuracy: 0.0234 - val_loss: 4.4845 - val_accuracy: 0.0703\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8869 - accuracy: 0.0234 - val_loss: 4.4778 - val_accuracy: 0.0625\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7863 - accuracy: 0.0469 - val_loss: 4.4779 - val_accuracy: 0.0625\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9323 - accuracy: 0.0000e+00 - val_loss: 4.4785 - val_accuracy: 0.0625\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8406 - accuracy: 0.0312 - val_loss: 4.5026 - val_accuracy: 0.0625\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.5784 - accuracy: 0.0625 - val_loss: 4.5400 - val_accuracy: 0.0469\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8019 - accuracy: 0.0391 - val_loss: 4.5719 - val_accuracy: 0.0469\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5692 - accuracy: 0.0469 - val_loss: 4.5980 - val_accuracy: 0.0391\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7720 - accuracy: 0.0234 - val_loss: 4.6211 - val_accuracy: 0.0391\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7990 - accuracy: 0.0625 - val_loss: 4.6484 - val_accuracy: 0.0312\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7062 - accuracy: 0.0078 - val_loss: 4.6652 - val_accuracy: 0.0234\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8251 - accuracy: 0.0156 - val_loss: 4.6887 - val_accuracy: 0.0156\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8667 - accuracy: 0.0156 - val_loss: 4.7097 - val_accuracy: 0.0078\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9724 - accuracy: 0.0156 - val_loss: 4.7011 - val_accuracy: 0.0078\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8575 - accuracy: 0.0312 - val_loss: 4.6964 - val_accuracy: 0.0078\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7188 - accuracy: 0.0234 - val_loss: 4.6963 - val_accuracy: 0.0156\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9395 - accuracy: 0.0312 - val_loss: 4.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6429 - accuracy: 0.0469 - val_loss: 4.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8001 - accuracy: 0.0156 - val_loss: 4.7900 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6823 - accuracy: 0.0234 - val_loss: 4.8281 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9146 - accuracy: 0.0859 - val_loss: 4.8006 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7481 - accuracy: 0.0234 - val_loss: 4.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6607 - accuracy: 0.0781 - val_loss: 4.6905 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6920 - accuracy: 0.0625 - val_loss: 4.6715 - val_accuracy: 0.0078\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8276 - accuracy: 0.0547 - val_loss: 4.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6773 - accuracy: 0.0312 - val_loss: 4.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7670 - accuracy: 0.0234 - val_loss: 4.7031 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9041 - accuracy: 0.0000e+00 - val_loss: 4.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9140 - accuracy: 0.0469 - val_loss: 4.7139 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9822 - accuracy: 0.0312 - val_loss: 4.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6432 - accuracy: 0.1016 - val_loss: 4.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7407 - accuracy: 0.0312 - val_loss: 4.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5839 - accuracy: 0.0703 - val_loss: 4.7157 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6716 - accuracy: 0.0234 - val_loss: 4.7383 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8496 - accuracy: 0.0547 - val_loss: 4.7456 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9173 - accuracy: 0.0312 - val_loss: 4.7369 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7477 - accuracy: 0.0234 - val_loss: 4.7152 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6546 - accuracy: 0.0234 - val_loss: 4.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6819 - accuracy: 0.0469 - val_loss: 4.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7277 - accuracy: 0.0781 - val_loss: 4.6084 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7963 - accuracy: 0.0078 - val_loss: 4.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8421 - accuracy: 0.0000e+00 - val_loss: 4.5720 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6951 - accuracy: 0.0391 - val_loss: 4.5635 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8639 - accuracy: 0.0234 - val_loss: 4.5524 - val_accuracy: 0.0234\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7428 - accuracy: 0.0625 - val_loss: 4.5519 - val_accuracy: 0.0391\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7036 - accuracy: 0.0547 - val_loss: 4.5512 - val_accuracy: 0.0391\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6971 - accuracy: 0.0469 - val_loss: 4.5573 - val_accuracy: 0.0547\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6459 - accuracy: 0.0469 - val_loss: 4.5880 - val_accuracy: 0.0547\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7566 - accuracy: 0.0234 - val_loss: 4.6212 - val_accuracy: 0.0391\n",
      "Epoch 170/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7859 - accuracy: 0.0391 - val_loss: 4.6385 - val_accuracy: 0.0312\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8020 - accuracy: 0.0312 - val_loss: 4.6397 - val_accuracy: 0.0312\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.7978 - accuracy: 0.0469 - val_loss: 4.5999 - val_accuracy: 0.0547\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6672 - accuracy: 0.0391 - val_loss: 4.5835 - val_accuracy: 0.0547\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8595 - accuracy: 0.0156 - val_loss: 4.5440 - val_accuracy: 0.0625\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6335 - accuracy: 0.0469 - val_loss: 4.5155 - val_accuracy: 0.1094\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6623 - accuracy: 0.0391 - val_loss: 4.4991 - val_accuracy: 0.1250\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8304 - accuracy: 0.0391 - val_loss: 4.4974 - val_accuracy: 0.1406\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7327 - accuracy: 0.0312 - val_loss: 4.5237 - val_accuracy: 0.1406\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7588 - accuracy: 0.0391 - val_loss: 4.5285 - val_accuracy: 0.1406\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6301 - accuracy: 0.0234 - val_loss: 4.5194 - val_accuracy: 0.1484\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8789 - accuracy: 0.0234 - val_loss: 4.4945 - val_accuracy: 0.1562\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6466 - accuracy: 0.0312 - val_loss: 4.5079 - val_accuracy: 0.1641\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6414 - accuracy: 0.0234 - val_loss: 4.5323 - val_accuracy: 0.1562\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8860 - accuracy: 0.0000e+00 - val_loss: 4.5667 - val_accuracy: 0.1562\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6951 - accuracy: 0.0938 - val_loss: 4.5490 - val_accuracy: 0.1484\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8272 - accuracy: 0.0234 - val_loss: 4.5181 - val_accuracy: 0.1484\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7131 - accuracy: 0.0234 - val_loss: 4.4595 - val_accuracy: 0.1328\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6245 - accuracy: 0.0469 - val_loss: 4.4044 - val_accuracy: 0.1328\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6908 - accuracy: 0.0312 - val_loss: 4.3700 - val_accuracy: 0.1328\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7603 - accuracy: 0.0078 - val_loss: 4.3711 - val_accuracy: 0.1250\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8534 - accuracy: 0.0781 - val_loss: 4.3828 - val_accuracy: 0.1172\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5058 - accuracy: 0.0234 - val_loss: 4.3962 - val_accuracy: 0.1250\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6836 - accuracy: 0.0391 - val_loss: 4.3987 - val_accuracy: 0.1094\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7209 - accuracy: 0.0547 - val_loss: 4.3894 - val_accuracy: 0.1172\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6641 - accuracy: 0.0625 - val_loss: 4.3799 - val_accuracy: 0.1328\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5873 - accuracy: 0.0391 - val_loss: 4.3462 - val_accuracy: 0.1250\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9047 - accuracy: 0.0547 - val_loss: 4.2977 - val_accuracy: 0.1250\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8162 - accuracy: 0.0312 - val_loss: 4.2665 - val_accuracy: 0.1250\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6223 - accuracy: 0.0547 - val_loss: 4.2682 - val_accuracy: 0.1016\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7411 - accuracy: 0.0078 - val_loss: 4.2939 - val_accuracy: 0.0938\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7076 - accuracy: 0.0703 - val_loss: 4.3252 - val_accuracy: 0.1016\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9351 - accuracy: 0.0078 - val_loss: 4.3568 - val_accuracy: 0.0859\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4947 - accuracy: 0.0781 - val_loss: 4.3897 - val_accuracy: 0.0781\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8370 - accuracy: 0.0781 - val_loss: 4.4000 - val_accuracy: 0.0625\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7650 - accuracy: 0.0312 - val_loss: 4.4077 - val_accuracy: 0.0625\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5979 - accuracy: 0.0625 - val_loss: 4.4162 - val_accuracy: 0.0703\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8433 - accuracy: 0.0391 - val_loss: 4.4209 - val_accuracy: 0.0703\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7528 - accuracy: 0.0469 - val_loss: 4.4251 - val_accuracy: 0.0547\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6457 - accuracy: 0.0703 - val_loss: 4.4449 - val_accuracy: 0.0625\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5736 - accuracy: 0.0312 - val_loss: 4.4685 - val_accuracy: 0.0547\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6602 - accuracy: 0.0859 - val_loss: 4.4795 - val_accuracy: 0.0547\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6640 - accuracy: 0.0469 - val_loss: 4.4852 - val_accuracy: 0.0391\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5907 - accuracy: 0.1094 - val_loss: 4.4604 - val_accuracy: 0.0469\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8249 - accuracy: 0.0312 - val_loss: 4.4481 - val_accuracy: 0.0703\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7113 - accuracy: 0.0000e+00 - val_loss: 4.4478 - val_accuracy: 0.0859\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6414 - accuracy: 0.0703 - val_loss: 4.4598 - val_accuracy: 0.0938\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8196 - accuracy: 0.0312 - val_loss: 4.4795 - val_accuracy: 0.0938\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5920 - accuracy: 0.0938 - val_loss: 4.4708 - val_accuracy: 0.0781\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5799 - accuracy: 0.0312 - val_loss: 4.4800 - val_accuracy: 0.0547\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6155 - accuracy: 0.0625 - val_loss: 4.4711 - val_accuracy: 0.0391\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6996 - accuracy: 0.0078 - val_loss: 4.4412 - val_accuracy: 0.0625\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6043 - accuracy: 0.0391 - val_loss: 4.4285 - val_accuracy: 0.0781\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4918 - accuracy: 0.0938 - val_loss: 4.4258 - val_accuracy: 0.0781\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7438 - accuracy: 0.0312 - val_loss: 4.4537 - val_accuracy: 0.0703\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5526 - accuracy: 0.0391 - val_loss: 4.5192 - val_accuracy: 0.0781\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4579 - accuracy: 0.0547 - val_loss: 4.5758 - val_accuracy: 0.0469\n",
      "Epoch 227/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 55ms/step - loss: 4.5714 - accuracy: 0.0859 - val_loss: 4.5727 - val_accuracy: 0.0391\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6766 - accuracy: 0.0156 - val_loss: 4.5390 - val_accuracy: 0.0156\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5169 - accuracy: 0.0391 - val_loss: 4.4824 - val_accuracy: 0.0156\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5782 - accuracy: 0.0625 - val_loss: 4.4761 - val_accuracy: 0.0078\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7133 - accuracy: 0.0156 - val_loss: 4.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6735 - accuracy: 0.0078 - val_loss: 4.5116 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6992 - accuracy: 0.0469 - val_loss: 4.5064 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4344 - accuracy: 0.0469 - val_loss: 4.4887 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4493 - accuracy: 0.0625 - val_loss: 4.4741 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6280 - accuracy: 0.0234 - val_loss: 4.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5322 - accuracy: 0.0469 - val_loss: 4.4891 - val_accuracy: 0.0078\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5829 - accuracy: 0.0312 - val_loss: 4.4801 - val_accuracy: 0.0078\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4270 - accuracy: 0.0391 - val_loss: 4.4523 - val_accuracy: 0.0078\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4450 - accuracy: 0.0469 - val_loss: 4.4356 - val_accuracy: 0.0078\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5941 - accuracy: 0.0078 - val_loss: 4.4114 - val_accuracy: 0.0078\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7608 - accuracy: 0.0625 - val_loss: 4.4121 - val_accuracy: 0.0078\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6084 - accuracy: 0.0312 - val_loss: 4.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5953 - accuracy: 0.0547 - val_loss: 4.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.5823 - accuracy: 0.0547 - val_loss: 4.3794 - val_accuracy: 0.0156\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4238 - accuracy: 0.0469 - val_loss: 4.3921 - val_accuracy: 0.0078\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.4839 - accuracy: 0.0547 - val_loss: 4.3798 - val_accuracy: 0.0234\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.3301 - accuracy: 0.0781 - val_loss: 4.3649 - val_accuracy: 0.0391\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5696 - accuracy: 0.0391 - val_loss: 4.3721 - val_accuracy: 0.0547\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3920 - accuracy: 0.0547 - val_loss: 4.3866 - val_accuracy: 0.0703\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4455 - accuracy: 0.0625 - val_loss: 4.3983 - val_accuracy: 0.0781\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5380 - accuracy: 0.0391 - val_loss: 4.4003 - val_accuracy: 0.0703\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.4276 - accuracy: 0.0859 - val_loss: 4.4092 - val_accuracy: 0.0312\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.2677 - accuracy: 0.0469 - val_loss: 4.3775 - val_accuracy: 0.0547\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4088 - accuracy: 0.0547 - val_loss: 4.3659 - val_accuracy: 0.0703\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6041 - accuracy: 0.0547 - val_loss: 4.3607 - val_accuracy: 0.0938\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4692 - accuracy: 0.0547 - val_loss: 4.3654 - val_accuracy: 0.0938\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.3472 - accuracy: 0.0469 - val_loss: 4.3671 - val_accuracy: 0.0703\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6413 - accuracy: 0.0234 - val_loss: 4.3472 - val_accuracy: 0.0547\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4075 - accuracy: 0.0312 - val_loss: 4.3452 - val_accuracy: 0.0469\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.3654 - accuracy: 0.0625 - val_loss: 4.3195 - val_accuracy: 0.0469\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7173 - accuracy: 0.0547 - val_loss: 4.2802 - val_accuracy: 0.0156\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4711 - accuracy: 0.0156 - val_loss: 4.2367 - val_accuracy: 0.0234\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6795 - accuracy: 0.0312 - val_loss: 4.2271 - val_accuracy: 0.0312\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6241 - accuracy: 0.0391 - val_loss: 4.2461 - val_accuracy: 0.0234\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6151 - accuracy: 0.0391 - val_loss: 4.2476 - val_accuracy: 0.0078\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5950 - accuracy: 0.0391 - val_loss: 4.2381 - val_accuracy: 0.0156\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.3943 - accuracy: 0.0469 - val_loss: 4.2196 - val_accuracy: 0.0234\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5503 - accuracy: 0.0469 - val_loss: 4.2009 - val_accuracy: 0.0234\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4956 - accuracy: 0.0703 - val_loss: 4.2090 - val_accuracy: 0.0234\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5486 - accuracy: 0.0547 - val_loss: 4.2299 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3999 - accuracy: 0.0469 - val_loss: 4.2543 - val_accuracy: 0.0156\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6668 - accuracy: 0.0312 - val_loss: 4.2756 - val_accuracy: 0.0234\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5021 - accuracy: 0.0625 - val_loss: 4.3037 - val_accuracy: 0.0156\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5663 - accuracy: 0.0547 - val_loss: 4.3344 - val_accuracy: 0.0078\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3439 - accuracy: 0.0703 - val_loss: 4.3534 - val_accuracy: 0.0078\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.3816 - accuracy: 0.0859 - val_loss: 4.3405 - val_accuracy: 0.0078\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4455 - accuracy: 0.0234 - val_loss: 4.3293 - val_accuracy: 0.0078\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3224 - accuracy: 0.0625 - val_loss: 4.2788 - val_accuracy: 0.0156\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.2706 - accuracy: 0.0547 - val_loss: 4.2167 - val_accuracy: 0.0547\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3940 - accuracy: 0.0469 - val_loss: 4.1927 - val_accuracy: 0.0938\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6528 - accuracy: 0.0156 - val_loss: 4.1892 - val_accuracy: 0.0938\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5079 - accuracy: 0.0703 - val_loss: 4.2014 - val_accuracy: 0.0703\n",
      "Epoch 284/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5483 - accuracy: 0.0078 - val_loss: 4.2118 - val_accuracy: 0.0781\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4379 - accuracy: 0.0312 - val_loss: 4.2141 - val_accuracy: 0.0703\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5206 - accuracy: 0.0859 - val_loss: 4.2374 - val_accuracy: 0.0547\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4696 - accuracy: 0.0938 - val_loss: 4.2524 - val_accuracy: 0.0391\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5712 - accuracy: 0.0547 - val_loss: 4.2626 - val_accuracy: 0.0312\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4178 - accuracy: 0.0781 - val_loss: 4.2881 - val_accuracy: 0.0312\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.2245 - accuracy: 0.0938 - val_loss: 4.2997 - val_accuracy: 0.0234\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5765 - accuracy: 0.0625 - val_loss: 4.3173 - val_accuracy: 0.0234\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.3378 - accuracy: 0.0469 - val_loss: 4.3007 - val_accuracy: 0.0234\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4201 - accuracy: 0.0625 - val_loss: 4.2939 - val_accuracy: 0.0312\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.4031 - accuracy: 0.0547 - val_loss: 4.3160 - val_accuracy: 0.0312\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3603 - accuracy: 0.0547 - val_loss: 4.3345 - val_accuracy: 0.0312\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.3282 - accuracy: 0.0859 - val_loss: 4.3506 - val_accuracy: 0.0156\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3448 - accuracy: 0.0469 - val_loss: 4.3798 - val_accuracy: 0.0156\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.4792 - accuracy: 0.0703 - val_loss: 4.3917 - val_accuracy: 0.0156\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5569 - accuracy: 0.0391 - val_loss: 4.3730 - val_accuracy: 0.0156\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3756 - accuracy: 0.0703 - val_loss: 4.3912 - val_accuracy: 0.0078\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4751 - accuracy: 0.0234 - val_loss: 4.4285 - val_accuracy: 0.0078\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.5413 - accuracy: 0.0469 - val_loss: 4.4611 - val_accuracy: 0.0078\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5203 - accuracy: 0.0156 - val_loss: 4.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5329 - accuracy: 0.0547 - val_loss: 4.4883 - val_accuracy: 0.0078\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3400 - accuracy: 0.0781 - val_loss: 4.4270 - val_accuracy: 0.0078\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.5880 - accuracy: 0.0625 - val_loss: 4.3149 - val_accuracy: 0.0156\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2261 - accuracy: 0.0391 - val_loss: 4.2188 - val_accuracy: 0.0078\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.2726 - accuracy: 0.0625 - val_loss: 4.1722 - val_accuracy: 0.0156\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.2641 - accuracy: 0.0469 - val_loss: 4.1118 - val_accuracy: 0.0547\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5561 - accuracy: 0.0469 - val_loss: 4.0768 - val_accuracy: 0.0781\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.4751 - accuracy: 0.0625 - val_loss: 4.0789 - val_accuracy: 0.0625\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.4706 - accuracy: 0.0312 - val_loss: 4.1133 - val_accuracy: 0.0547\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3154 - accuracy: 0.0703 - val_loss: 4.1082 - val_accuracy: 0.0625\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.3572 - accuracy: 0.0469 - val_loss: 4.1109 - val_accuracy: 0.0625\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3793 - accuracy: 0.1016 - val_loss: 4.0764 - val_accuracy: 0.0547\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1964 - accuracy: 0.1094 - val_loss: 4.0137 - val_accuracy: 0.1016\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.2537 - accuracy: 0.0547 - val_loss: 3.9569 - val_accuracy: 0.1172\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3094 - accuracy: 0.0625 - val_loss: 3.9300 - val_accuracy: 0.1641\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3249 - accuracy: 0.0859 - val_loss: 3.9266 - val_accuracy: 0.1719\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.3340 - accuracy: 0.0859 - val_loss: 3.9321 - val_accuracy: 0.1641\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2661 - accuracy: 0.0781 - val_loss: 3.9467 - val_accuracy: 0.1641\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2826 - accuracy: 0.0703 - val_loss: 3.9588 - val_accuracy: 0.1641\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.3782 - accuracy: 0.0547 - val_loss: 3.9774 - val_accuracy: 0.1562\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3572 - accuracy: 0.0625 - val_loss: 3.9762 - val_accuracy: 0.1484\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2111 - accuracy: 0.0938 - val_loss: 3.9547 - val_accuracy: 0.1484\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3920 - accuracy: 0.0234 - val_loss: 3.9807 - val_accuracy: 0.1328\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2697 - accuracy: 0.0703 - val_loss: 4.0159 - val_accuracy: 0.1328\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3114 - accuracy: 0.0703 - val_loss: 4.0659 - val_accuracy: 0.1250\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2493 - accuracy: 0.0547 - val_loss: 4.0819 - val_accuracy: 0.1250\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3165 - accuracy: 0.0625 - val_loss: 4.0345 - val_accuracy: 0.1172\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1942 - accuracy: 0.0781 - val_loss: 3.9589 - val_accuracy: 0.1094\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1447 - accuracy: 0.1094 - val_loss: 3.8912 - val_accuracy: 0.1250\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3789 - accuracy: 0.1016 - val_loss: 3.8580 - val_accuracy: 0.1406\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.3484 - accuracy: 0.0938 - val_loss: 3.8478 - val_accuracy: 0.1328\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1709 - accuracy: 0.0625 - val_loss: 3.8728 - val_accuracy: 0.1484\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.4225 - accuracy: 0.0078 - val_loss: 3.9213 - val_accuracy: 0.1406\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.1500 - accuracy: 0.1328 - val_loss: 3.9083 - val_accuracy: 0.1641\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.3178 - accuracy: 0.0312 - val_loss: 3.9306 - val_accuracy: 0.1562\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.2357 - accuracy: 0.0703 - val_loss: 3.9121 - val_accuracy: 0.1406\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3906 - accuracy: 0.0938 - val_loss: 3.8740 - val_accuracy: 0.1562\n",
      "Epoch 341/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step - loss: 4.2239 - accuracy: 0.0938 - val_loss: 3.9028 - val_accuracy: 0.1641\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.3137 - accuracy: 0.0859 - val_loss: 3.9425 - val_accuracy: 0.1797\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1169 - accuracy: 0.0859 - val_loss: 3.9278 - val_accuracy: 0.1797\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5098 - accuracy: 0.0391 - val_loss: 3.9459 - val_accuracy: 0.1797\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0968 - accuracy: 0.0859 - val_loss: 4.0071 - val_accuracy: 0.1562\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3440 - accuracy: 0.0625 - val_loss: 4.0189 - val_accuracy: 0.1406\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4042 - accuracy: 0.0703 - val_loss: 4.0228 - val_accuracy: 0.1406\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4737 - accuracy: 0.0234 - val_loss: 4.0939 - val_accuracy: 0.1250\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0756 - accuracy: 0.1484 - val_loss: 4.2128 - val_accuracy: 0.1250\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.1468 - accuracy: 0.0938 - val_loss: 4.2836 - val_accuracy: 0.1250\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1591 - accuracy: 0.0859 - val_loss: 4.2186 - val_accuracy: 0.1328\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2568 - accuracy: 0.0781 - val_loss: 4.1649 - val_accuracy: 0.1172\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0989 - accuracy: 0.1016 - val_loss: 4.0918 - val_accuracy: 0.1094\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4268 - accuracy: 0.0703 - val_loss: 4.1040 - val_accuracy: 0.1172\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4849 - accuracy: 0.0391 - val_loss: 4.1150 - val_accuracy: 0.0703\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2725 - accuracy: 0.0781 - val_loss: 4.1088 - val_accuracy: 0.0703\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1603 - accuracy: 0.0859 - val_loss: 4.1412 - val_accuracy: 0.0703\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.0208 - accuracy: 0.1172 - val_loss: 4.0995 - val_accuracy: 0.0781\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.3742 - accuracy: 0.0312 - val_loss: 4.0792 - val_accuracy: 0.0781\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2805 - accuracy: 0.0703 - val_loss: 4.1017 - val_accuracy: 0.0391\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1092 - accuracy: 0.1562 - val_loss: 4.0806 - val_accuracy: 0.0312\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.2659 - accuracy: 0.0938 - val_loss: 4.0720 - val_accuracy: 0.0312\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2973 - accuracy: 0.0625 - val_loss: 4.0458 - val_accuracy: 0.0234\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1201 - accuracy: 0.1406 - val_loss: 4.0171 - val_accuracy: 0.0156\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3934 - accuracy: 0.0312 - val_loss: 3.9948 - val_accuracy: 0.0156\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.1564 - accuracy: 0.0469 - val_loss: 3.9763 - val_accuracy: 0.0078\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.1581 - accuracy: 0.1016 - val_loss: 4.0052 - val_accuracy: 0.0156\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3530 - accuracy: 0.0391 - val_loss: 3.9664 - val_accuracy: 0.0234\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.0382 - accuracy: 0.0859 - val_loss: 3.8530 - val_accuracy: 0.0234\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8475 - accuracy: 0.0469 - val_loss: 3.7318 - val_accuracy: 0.0312\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.3939 - accuracy: 0.0703 - val_loss: 3.7111 - val_accuracy: 0.0703\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0793 - accuracy: 0.1094 - val_loss: 3.7769 - val_accuracy: 0.0859\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.2744 - accuracy: 0.0469 - val_loss: 3.7775 - val_accuracy: 0.0938\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.2929 - accuracy: 0.1484 - val_loss: 3.7298 - val_accuracy: 0.1172\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1443 - accuracy: 0.1484 - val_loss: 3.6283 - val_accuracy: 0.1094\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9078 - accuracy: 0.1562 - val_loss: 3.6055 - val_accuracy: 0.1094\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0085 - accuracy: 0.1875 - val_loss: 3.6257 - val_accuracy: 0.1172\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1318 - accuracy: 0.0703 - val_loss: 3.6164 - val_accuracy: 0.1328\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2312 - accuracy: 0.0938 - val_loss: 3.6388 - val_accuracy: 0.1328\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1709 - accuracy: 0.0547 - val_loss: 3.5766 - val_accuracy: 0.1328\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.3224 - accuracy: 0.0469 - val_loss: 3.5439 - val_accuracy: 0.1250\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.2402 - accuracy: 0.0078 - val_loss: 3.5595 - val_accuracy: 0.1250\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0355 - accuracy: 0.1094 - val_loss: 3.6014 - val_accuracy: 0.1250\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3619 - accuracy: 0.0625 - val_loss: 3.6235 - val_accuracy: 0.1094\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1788 - accuracy: 0.0547 - val_loss: 3.6590 - val_accuracy: 0.1172\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.2969 - accuracy: 0.1172 - val_loss: 3.6892 - val_accuracy: 0.1172\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0586 - accuracy: 0.0859 - val_loss: 3.7041 - val_accuracy: 0.1172\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1894 - accuracy: 0.0938 - val_loss: 3.7249 - val_accuracy: 0.1328\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.0589 - accuracy: 0.0938 - val_loss: 3.7148 - val_accuracy: 0.1094\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1718 - accuracy: 0.0625 - val_loss: 3.7222 - val_accuracy: 0.1016\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.1083 - accuracy: 0.0703 - val_loss: 3.7206 - val_accuracy: 0.0859\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9887 - accuracy: 0.0781 - val_loss: 3.7149 - val_accuracy: 0.0703\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2097 - accuracy: 0.1094 - val_loss: 3.7055 - val_accuracy: 0.0703\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3664 - accuracy: 0.0547 - val_loss: 3.7131 - val_accuracy: 0.0859\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1382 - accuracy: 0.0938 - val_loss: 3.7437 - val_accuracy: 0.0703\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0832 - accuracy: 0.0781 - val_loss: 3.8107 - val_accuracy: 0.0625\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0029 - accuracy: 0.1172 - val_loss: 3.8924 - val_accuracy: 0.0312\n",
      "Epoch 398/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 56ms/step - loss: 3.9179 - accuracy: 0.0859 - val_loss: 3.8923 - val_accuracy: 0.0391\n",
      "Epoch 399/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0222 - accuracy: 0.0391 - val_loss: 3.8560 - val_accuracy: 0.0547\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0512 - accuracy: 0.1094 - val_loss: 3.8444 - val_accuracy: 0.0391\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0144 - accuracy: 0.0859 - val_loss: 3.8779 - val_accuracy: 0.0625\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.2326 - accuracy: 0.0859 - val_loss: 3.9431 - val_accuracy: 0.0625\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.9729 - accuracy: 0.0781 - val_loss: 3.9868 - val_accuracy: 0.0625\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1587 - accuracy: 0.1172 - val_loss: 3.9648 - val_accuracy: 0.0547\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.8921 - accuracy: 0.1328 - val_loss: 3.9839 - val_accuracy: 0.0312\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0972 - accuracy: 0.1406 - val_loss: 3.9698 - val_accuracy: 0.0312\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.1602 - accuracy: 0.0938 - val_loss: 3.9552 - val_accuracy: 0.0312\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8906 - accuracy: 0.1719 - val_loss: 3.9214 - val_accuracy: 0.0391\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1444 - accuracy: 0.0781 - val_loss: 3.9323 - val_accuracy: 0.0312\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1765 - accuracy: 0.0547 - val_loss: 3.9674 - val_accuracy: 0.0312\n",
      "Epoch 411/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8963 - accuracy: 0.0938 - val_loss: 3.9889 - val_accuracy: 0.0156\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0737 - accuracy: 0.0938 - val_loss: 3.9340 - val_accuracy: 0.0234\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.0314 - accuracy: 0.1172 - val_loss: 3.9332 - val_accuracy: 0.0156\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2034 - accuracy: 0.0391 - val_loss: 3.9891 - val_accuracy: 0.0234\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9429 - accuracy: 0.1719 - val_loss: 3.9910 - val_accuracy: 0.0234\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.0906 - accuracy: 0.0703 - val_loss: 3.9893 - val_accuracy: 0.0156\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0557 - accuracy: 0.0938 - val_loss: 3.9474 - val_accuracy: 0.0234\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1372 - accuracy: 0.0312 - val_loss: 3.9427 - val_accuracy: 0.0469\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.0870 - accuracy: 0.0625 - val_loss: 3.9827 - val_accuracy: 0.0391\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.3009 - accuracy: 0.0312 - val_loss: 4.0482 - val_accuracy: 0.0391\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9577 - accuracy: 0.0781 - val_loss: 4.0938 - val_accuracy: 0.0234\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9094 - accuracy: 0.0938 - val_loss: 4.1022 - val_accuracy: 0.0312\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8694 - accuracy: 0.1172 - val_loss: 4.0948 - val_accuracy: 0.0391\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8596 - accuracy: 0.1094 - val_loss: 4.1141 - val_accuracy: 0.0391\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0818 - accuracy: 0.1094 - val_loss: 4.1094 - val_accuracy: 0.0312\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0774 - accuracy: 0.0781 - val_loss: 4.1361 - val_accuracy: 0.0312\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9963 - accuracy: 0.0703 - val_loss: 4.1316 - val_accuracy: 0.0312\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0596 - accuracy: 0.0781 - val_loss: 3.9974 - val_accuracy: 0.0312\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6707 - accuracy: 0.1406 - val_loss: 3.8650 - val_accuracy: 0.0469\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 3.9504 - accuracy: 0.0859 - val_loss: 3.7973 - val_accuracy: 0.0703\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1928 - accuracy: 0.1250 - val_loss: 3.8254 - val_accuracy: 0.0781\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9744 - accuracy: 0.1719 - val_loss: 3.9274 - val_accuracy: 0.0625\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.1733 - accuracy: 0.0938 - val_loss: 3.9511 - val_accuracy: 0.0625\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.1521 - accuracy: 0.0703 - val_loss: 3.8585 - val_accuracy: 0.0859\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9449 - accuracy: 0.0625 - val_loss: 3.7014 - val_accuracy: 0.0781\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.8136 - accuracy: 0.1562 - val_loss: 3.5908 - val_accuracy: 0.1328\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2456 - accuracy: 0.0859 - val_loss: 3.5247 - val_accuracy: 0.1719\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.0103 - accuracy: 0.0703 - val_loss: 3.4589 - val_accuracy: 0.1875\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9299 - accuracy: 0.0938 - val_loss: 3.4290 - val_accuracy: 0.1719\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1656 - accuracy: 0.1094 - val_loss: 3.4462 - val_accuracy: 0.2422\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.9548 - accuracy: 0.0781 - val_loss: 3.4652 - val_accuracy: 0.2812\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0063 - accuracy: 0.1094 - val_loss: 3.6056 - val_accuracy: 0.2344\n",
      "Epoch 443/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.0205 - accuracy: 0.0938 - val_loss: 3.7822 - val_accuracy: 0.1641\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.0194 - accuracy: 0.1328 - val_loss: 3.8893 - val_accuracy: 0.1250\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.9399 - accuracy: 0.1328 - val_loss: 3.9659 - val_accuracy: 0.0938\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0777 - accuracy: 0.0703 - val_loss: 4.0769 - val_accuracy: 0.0703\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.8906 - accuracy: 0.1406 - val_loss: 4.1642 - val_accuracy: 0.0547\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2002 - accuracy: 0.0938 - val_loss: 4.1590 - val_accuracy: 0.0781\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9372 - accuracy: 0.0625 - val_loss: 4.1553 - val_accuracy: 0.0859\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.0520 - accuracy: 0.0938 - val_loss: 4.0428 - val_accuracy: 0.1172\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9496 - accuracy: 0.1328 - val_loss: 3.9313 - val_accuracy: 0.1328\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9426 - accuracy: 0.1328 - val_loss: 3.7650 - val_accuracy: 0.1562\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9535 - accuracy: 0.1016 - val_loss: 3.7921 - val_accuracy: 0.1562\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9219 - accuracy: 0.0625 - val_loss: 3.8723 - val_accuracy: 0.1016\n",
      "Epoch 455/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8318 - accuracy: 0.1016 - val_loss: 4.0243 - val_accuracy: 0.0625\n",
      "Epoch 456/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8881 - accuracy: 0.0859 - val_loss: 4.2743 - val_accuracy: 0.0391\n",
      "Epoch 457/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8436 - accuracy: 0.0859 - val_loss: 4.2674 - val_accuracy: 0.0547\n",
      "Epoch 458/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.7490 - accuracy: 0.1250 - val_loss: 4.1532 - val_accuracy: 0.1172\n",
      "Epoch 459/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8589 - accuracy: 0.0781 - val_loss: 4.0806 - val_accuracy: 0.1328\n",
      "Epoch 460/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7457 - accuracy: 0.1094 - val_loss: 4.0232 - val_accuracy: 0.1094\n",
      "Epoch 461/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2361 - accuracy: 0.0625 - val_loss: 4.1345 - val_accuracy: 0.0938\n",
      "Epoch 462/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0602 - accuracy: 0.0859 - val_loss: 4.4308 - val_accuracy: 0.0781\n",
      "Epoch 463/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9207 - accuracy: 0.1250 - val_loss: 4.5878 - val_accuracy: 0.0781\n",
      "Epoch 464/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.0474 - accuracy: 0.1172 - val_loss: 4.6932 - val_accuracy: 0.0703\n",
      "Epoch 465/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9827 - accuracy: 0.1406 - val_loss: 4.5775 - val_accuracy: 0.0703\n",
      "Epoch 466/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7969 - accuracy: 0.1328 - val_loss: 4.5032 - val_accuracy: 0.0938\n",
      "Epoch 467/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9423 - accuracy: 0.0703 - val_loss: 4.4061 - val_accuracy: 0.0859\n",
      "Epoch 468/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0118 - accuracy: 0.0938 - val_loss: 4.2896 - val_accuracy: 0.1016\n",
      "Epoch 469/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.8729 - accuracy: 0.1328 - val_loss: 4.1720 - val_accuracy: 0.1016\n",
      "Epoch 470/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6646 - accuracy: 0.1641 - val_loss: 4.0539 - val_accuracy: 0.0938\n",
      "Epoch 471/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0397 - accuracy: 0.1406 - val_loss: 3.9138 - val_accuracy: 0.0781\n",
      "Epoch 472/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.6411 - accuracy: 0.1094 - val_loss: 3.7294 - val_accuracy: 0.1406\n",
      "Epoch 473/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.4363 - accuracy: 0.1719 - val_loss: 3.6189 - val_accuracy: 0.1797\n",
      "Epoch 474/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8852 - accuracy: 0.1328 - val_loss: 3.5551 - val_accuracy: 0.2188\n",
      "Epoch 475/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8333 - accuracy: 0.1406 - val_loss: 3.4865 - val_accuracy: 0.2422\n",
      "Epoch 476/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7482 - accuracy: 0.1719 - val_loss: 3.4167 - val_accuracy: 0.2344\n",
      "Epoch 477/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.1236 - accuracy: 0.0703 - val_loss: 3.4435 - val_accuracy: 0.1875\n",
      "Epoch 478/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.9634 - accuracy: 0.1484 - val_loss: 3.4774 - val_accuracy: 0.1953\n",
      "Epoch 479/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.0516 - accuracy: 0.0625 - val_loss: 3.5303 - val_accuracy: 0.2266\n",
      "Epoch 480/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3120 - accuracy: 0.0391 - val_loss: 3.7343 - val_accuracy: 0.1641\n",
      "Epoch 481/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.1395 - accuracy: 0.0859 - val_loss: 3.9867 - val_accuracy: 0.1172\n",
      "Epoch 482/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8820 - accuracy: 0.0781 - val_loss: 4.1529 - val_accuracy: 0.0781\n",
      "Epoch 483/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9950 - accuracy: 0.0469 - val_loss: 4.1849 - val_accuracy: 0.0625\n",
      "Epoch 484/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8409 - accuracy: 0.1016 - val_loss: 4.1404 - val_accuracy: 0.0703\n",
      "Epoch 485/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1884 - accuracy: 0.0312 - val_loss: 4.0600 - val_accuracy: 0.0859\n",
      "Epoch 486/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.1752 - accuracy: 0.0938 - val_loss: 3.9827 - val_accuracy: 0.1016\n",
      "Epoch 487/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8855 - accuracy: 0.1016 - val_loss: 3.8684 - val_accuracy: 0.1016\n",
      "Epoch 488/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.0320 - accuracy: 0.0625 - val_loss: 3.9486 - val_accuracy: 0.0938\n",
      "Epoch 489/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0300 - accuracy: 0.1016 - val_loss: 4.0038 - val_accuracy: 0.0938\n",
      "Epoch 490/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6835 - accuracy: 0.1641 - val_loss: 3.9265 - val_accuracy: 0.1250\n",
      "Epoch 491/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9804 - accuracy: 0.0781 - val_loss: 3.8278 - val_accuracy: 0.1406\n",
      "Epoch 492/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2103 - accuracy: 0.0781 - val_loss: 3.6335 - val_accuracy: 0.1484\n",
      "Epoch 493/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.7315 - accuracy: 0.1406 - val_loss: 3.5232 - val_accuracy: 0.2031\n",
      "Epoch 494/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0278 - accuracy: 0.1094 - val_loss: 3.4694 - val_accuracy: 0.2344\n",
      "Epoch 495/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5792 - accuracy: 0.1875 - val_loss: 3.4293 - val_accuracy: 0.2422\n",
      "Epoch 496/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6848 - accuracy: 0.2500 - val_loss: 3.4542 - val_accuracy: 0.2109\n",
      "Epoch 497/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8160 - accuracy: 0.1094 - val_loss: 3.5673 - val_accuracy: 0.1797\n",
      "Epoch 498/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.0130 - accuracy: 0.0781 - val_loss: 3.6778 - val_accuracy: 0.1250\n",
      "Epoch 499/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.7662 - accuracy: 0.1172 - val_loss: 3.7111 - val_accuracy: 0.1484\n",
      "Epoch 500/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9542 - accuracy: 0.0469 - val_loss: 3.7499 - val_accuracy: 0.1484\n",
      "Epoch 501/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.0405 - accuracy: 0.0703 - val_loss: 3.7136 - val_accuracy: 0.1172\n",
      "Epoch 502/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3230 - accuracy: 0.0469 - val_loss: 3.7419 - val_accuracy: 0.1094\n",
      "Epoch 503/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8623 - accuracy: 0.1641 - val_loss: 3.7224 - val_accuracy: 0.1094\n",
      "Epoch 504/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8713 - accuracy: 0.1562 - val_loss: 3.6818 - val_accuracy: 0.0938\n",
      "Epoch 505/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6079 - accuracy: 0.1797 - val_loss: 3.6080 - val_accuracy: 0.1016\n",
      "Epoch 506/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7981 - accuracy: 0.0938 - val_loss: 3.6198 - val_accuracy: 0.0781\n",
      "Epoch 507/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7995 - accuracy: 0.1328 - val_loss: 3.6622 - val_accuracy: 0.0703\n",
      "Epoch 508/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0044 - accuracy: 0.0938 - val_loss: 3.6763 - val_accuracy: 0.0938\n",
      "Epoch 509/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6966 - accuracy: 0.1406 - val_loss: 3.6492 - val_accuracy: 0.1406\n",
      "Epoch 510/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1250 - accuracy: 0.1016 - val_loss: 3.5550 - val_accuracy: 0.1719\n",
      "Epoch 511/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6573 - accuracy: 0.1406 - val_loss: 3.4752 - val_accuracy: 0.2031\n",
      "Epoch 512/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8880 - accuracy: 0.1719 - val_loss: 3.4288 - val_accuracy: 0.2109\n",
      "Epoch 513/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8513 - accuracy: 0.1172 - val_loss: 3.4049 - val_accuracy: 0.1797\n",
      "Epoch 514/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.9830 - accuracy: 0.0938 - val_loss: 3.4180 - val_accuracy: 0.1328\n",
      "Epoch 515/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9165 - accuracy: 0.0859 - val_loss: 3.4784 - val_accuracy: 0.1250\n",
      "Epoch 516/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6626 - accuracy: 0.1719 - val_loss: 3.5874 - val_accuracy: 0.1094\n",
      "Epoch 517/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8045 - accuracy: 0.1250 - val_loss: 3.6920 - val_accuracy: 0.0859\n",
      "Epoch 518/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.0564 - accuracy: 0.0938 - val_loss: 3.7442 - val_accuracy: 0.0859\n",
      "Epoch 519/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.1779 - accuracy: 0.0234 - val_loss: 3.7333 - val_accuracy: 0.0859\n",
      "Epoch 520/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.7914 - accuracy: 0.1250 - val_loss: 3.7156 - val_accuracy: 0.0625\n",
      "Epoch 521/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9222 - accuracy: 0.0703 - val_loss: 3.7004 - val_accuracy: 0.0938\n",
      "Epoch 522/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.9432 - accuracy: 0.0859 - val_loss: 3.6526 - val_accuracy: 0.1406\n",
      "Epoch 523/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9323 - accuracy: 0.1016 - val_loss: 3.6438 - val_accuracy: 0.0859\n",
      "Epoch 524/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9353 - accuracy: 0.1328 - val_loss: 3.6896 - val_accuracy: 0.0547\n",
      "Epoch 525/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.8079 - accuracy: 0.1484 - val_loss: 3.7562 - val_accuracy: 0.0547\n",
      "Epoch 526/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7928 - accuracy: 0.1250 - val_loss: 3.7756 - val_accuracy: 0.0547\n",
      "Epoch 527/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8618 - accuracy: 0.0625 - val_loss: 3.7497 - val_accuracy: 0.0781\n",
      "Epoch 528/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8170 - accuracy: 0.1406 - val_loss: 3.6841 - val_accuracy: 0.0781\n",
      "Epoch 529/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8560 - accuracy: 0.0469 - val_loss: 3.6483 - val_accuracy: 0.0938\n",
      "Epoch 530/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9332 - accuracy: 0.1484 - val_loss: 3.6694 - val_accuracy: 0.0703\n",
      "Epoch 531/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5778 - accuracy: 0.1953 - val_loss: 3.7221 - val_accuracy: 0.0781\n",
      "Epoch 532/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.6980 - accuracy: 0.1719 - val_loss: 3.6961 - val_accuracy: 0.0391\n",
      "Epoch 533/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7656 - accuracy: 0.0938 - val_loss: 3.7294 - val_accuracy: 0.0312\n",
      "Epoch 534/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9865 - accuracy: 0.0625 - val_loss: 3.8230 - val_accuracy: 0.0547\n",
      "Epoch 535/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9453 - accuracy: 0.1094 - val_loss: 3.8638 - val_accuracy: 0.0703\n",
      "Epoch 536/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9729 - accuracy: 0.0469 - val_loss: 3.8693 - val_accuracy: 0.0469\n",
      "Epoch 537/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9525 - accuracy: 0.0469 - val_loss: 3.8438 - val_accuracy: 0.0469\n",
      "Epoch 538/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.8145 - accuracy: 0.0781 - val_loss: 3.8118 - val_accuracy: 0.0469\n",
      "Epoch 539/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9427 - accuracy: 0.1016 - val_loss: 3.7277 - val_accuracy: 0.0859\n",
      "Epoch 540/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7198 - accuracy: 0.0938 - val_loss: 3.6506 - val_accuracy: 0.1094\n",
      "Epoch 541/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7994 - accuracy: 0.1719 - val_loss: 3.6591 - val_accuracy: 0.1484\n",
      "Epoch 542/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9070 - accuracy: 0.1641 - val_loss: 3.7670 - val_accuracy: 0.1250\n",
      "Epoch 543/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9800 - accuracy: 0.0938 - val_loss: 3.8014 - val_accuracy: 0.1172\n",
      "Epoch 544/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9569 - accuracy: 0.0547 - val_loss: 3.6637 - val_accuracy: 0.1172\n",
      "Epoch 545/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8242 - accuracy: 0.1406 - val_loss: 3.5430 - val_accuracy: 0.1094\n",
      "Epoch 546/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.7058 - accuracy: 0.0938 - val_loss: 3.4999 - val_accuracy: 0.1406\n",
      "Epoch 547/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5511 - accuracy: 0.1484 - val_loss: 3.5141 - val_accuracy: 0.1172\n",
      "Epoch 548/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6629 - accuracy: 0.1562 - val_loss: 3.5784 - val_accuracy: 0.1250\n",
      "Epoch 549/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.9125 - accuracy: 0.0781 - val_loss: 3.6571 - val_accuracy: 0.1094\n",
      "Epoch 550/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.8950 - accuracy: 0.0938 - val_loss: 3.7222 - val_accuracy: 0.0781\n",
      "Epoch 551/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7685 - accuracy: 0.1172 - val_loss: 3.7847 - val_accuracy: 0.0625\n",
      "Epoch 552/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.8528 - accuracy: 0.0703 - val_loss: 3.8256 - val_accuracy: 0.0312\n",
      "Epoch 553/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.8801 - accuracy: 0.0859 - val_loss: 3.8202 - val_accuracy: 0.0469\n",
      "Epoch 554/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.8534 - accuracy: 0.1094 - val_loss: 3.8080 - val_accuracy: 0.0703\n",
      "Epoch 555/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8306 - accuracy: 0.0938 - val_loss: 3.7506 - val_accuracy: 0.0703\n",
      "Epoch 556/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7970 - accuracy: 0.0859 - val_loss: 3.7436 - val_accuracy: 0.0156\n",
      "Epoch 557/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6554 - accuracy: 0.1406 - val_loss: 3.7822 - val_accuracy: 0.0156\n",
      "Epoch 558/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.0444 - accuracy: 0.0547 - val_loss: 3.7704 - val_accuracy: 0.0234\n",
      "Epoch 559/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8920 - accuracy: 0.1250 - val_loss: 3.7152 - val_accuracy: 0.0312\n",
      "Epoch 560/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7000 - accuracy: 0.1406 - val_loss: 3.6703 - val_accuracy: 0.0547\n",
      "Epoch 561/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5851 - accuracy: 0.2031 - val_loss: 3.6837 - val_accuracy: 0.0547\n",
      "Epoch 562/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.7827 - accuracy: 0.0625 - val_loss: 3.6653 - val_accuracy: 0.0703\n",
      "Epoch 563/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.8353 - accuracy: 0.0938 - val_loss: 3.6252 - val_accuracy: 0.0938\n",
      "Epoch 564/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8209 - accuracy: 0.0703 - val_loss: 3.6022 - val_accuracy: 0.1328\n",
      "Epoch 565/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.7274 - accuracy: 0.0938 - val_loss: 3.5633 - val_accuracy: 0.1719\n",
      "Epoch 566/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5350 - accuracy: 0.2734 - val_loss: 3.4403 - val_accuracy: 0.1953\n",
      "Epoch 567/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9267 - accuracy: 0.1172 - val_loss: 3.3981 - val_accuracy: 0.1562\n",
      "Epoch 568/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8630 - accuracy: 0.1016 - val_loss: 3.4423 - val_accuracy: 0.1094\n",
      "Epoch 569/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 59ms/step - loss: 3.8035 - accuracy: 0.0859 - val_loss: 3.4609 - val_accuracy: 0.0938\n",
      "Epoch 570/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7678 - accuracy: 0.1484 - val_loss: 3.4660 - val_accuracy: 0.1172\n",
      "Epoch 571/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9231 - accuracy: 0.1094 - val_loss: 3.4508 - val_accuracy: 0.1406\n",
      "Epoch 572/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.9384 - accuracy: 0.1484 - val_loss: 3.4487 - val_accuracy: 0.1328\n",
      "Epoch 573/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7032 - accuracy: 0.1484 - val_loss: 3.4652 - val_accuracy: 0.1797\n",
      "Epoch 574/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9277 - accuracy: 0.1172 - val_loss: 3.5507 - val_accuracy: 0.1875\n",
      "Epoch 575/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4364 - accuracy: 0.2109 - val_loss: 3.5308 - val_accuracy: 0.2188\n",
      "Epoch 576/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6604 - accuracy: 0.1250 - val_loss: 3.4613 - val_accuracy: 0.2812\n",
      "Epoch 577/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8459 - accuracy: 0.1094 - val_loss: 3.4238 - val_accuracy: 0.2734\n",
      "Epoch 578/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9084 - accuracy: 0.0781 - val_loss: 3.4075 - val_accuracy: 0.2812\n",
      "Epoch 579/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.7035 - accuracy: 0.1406 - val_loss: 3.4405 - val_accuracy: 0.2500\n",
      "Epoch 580/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8255 - accuracy: 0.0625 - val_loss: 3.5246 - val_accuracy: 0.1875\n",
      "Epoch 581/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5711 - accuracy: 0.1797 - val_loss: 3.6268 - val_accuracy: 0.1406\n",
      "Epoch 582/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7819 - accuracy: 0.0859 - val_loss: 3.6953 - val_accuracy: 0.1172\n",
      "Epoch 583/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8723 - accuracy: 0.1250 - val_loss: 3.7291 - val_accuracy: 0.0859\n",
      "Epoch 584/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7310 - accuracy: 0.1406 - val_loss: 3.7365 - val_accuracy: 0.0781\n",
      "Epoch 585/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5233 - accuracy: 0.1562 - val_loss: 3.6792 - val_accuracy: 0.1094\n",
      "Epoch 586/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6672 - accuracy: 0.1094 - val_loss: 3.6692 - val_accuracy: 0.0938\n",
      "Epoch 587/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7856 - accuracy: 0.0703 - val_loss: 3.6895 - val_accuracy: 0.0625\n",
      "Epoch 588/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.7394 - accuracy: 0.0391 - val_loss: 3.6263 - val_accuracy: 0.0625\n",
      "Epoch 589/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.7200 - accuracy: 0.1250 - val_loss: 3.5307 - val_accuracy: 0.0938\n",
      "Epoch 590/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8148 - accuracy: 0.1172 - val_loss: 3.4667 - val_accuracy: 0.1406\n",
      "Epoch 591/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9963 - accuracy: 0.0938 - val_loss: 3.5286 - val_accuracy: 0.1094\n",
      "Epoch 592/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7221 - accuracy: 0.1406 - val_loss: 3.6017 - val_accuracy: 0.0859\n",
      "Epoch 593/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8183 - accuracy: 0.1250 - val_loss: 3.6327 - val_accuracy: 0.0703\n",
      "Epoch 594/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7293 - accuracy: 0.0859 - val_loss: 3.6739 - val_accuracy: 0.0625\n",
      "Epoch 595/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9428 - accuracy: 0.1484 - val_loss: 3.7053 - val_accuracy: 0.0625\n",
      "Epoch 596/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.5982 - accuracy: 0.1953 - val_loss: 3.7078 - val_accuracy: 0.0859\n",
      "Epoch 597/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8659 - accuracy: 0.1328 - val_loss: 3.7271 - val_accuracy: 0.0781\n",
      "Epoch 598/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6897 - accuracy: 0.1484 - val_loss: 3.7389 - val_accuracy: 0.0938\n",
      "Epoch 599/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7363 - accuracy: 0.0859 - val_loss: 3.7956 - val_accuracy: 0.0938\n",
      "Epoch 600/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.5865 - accuracy: 0.1406 - val_loss: 3.7131 - val_accuracy: 0.1328\n",
      "Epoch 601/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7310 - accuracy: 0.1562 - val_loss: 3.6351 - val_accuracy: 0.1328\n",
      "Epoch 602/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9107 - accuracy: 0.1250 - val_loss: 3.6182 - val_accuracy: 0.1719\n",
      "Epoch 603/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.6127 - accuracy: 0.1094 - val_loss: 3.5536 - val_accuracy: 0.1875\n",
      "Epoch 604/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7354 - accuracy: 0.1250 - val_loss: 3.5907 - val_accuracy: 0.2109\n",
      "Epoch 605/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6676 - accuracy: 0.1484 - val_loss: 3.6176 - val_accuracy: 0.1875\n",
      "Epoch 606/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.4955 - accuracy: 0.1875 - val_loss: 3.6017 - val_accuracy: 0.1797\n",
      "Epoch 607/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8370 - accuracy: 0.0938 - val_loss: 3.5336 - val_accuracy: 0.2188\n",
      "Epoch 608/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9327 - accuracy: 0.1016 - val_loss: 3.4568 - val_accuracy: 0.2422\n",
      "Epoch 609/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7401 - accuracy: 0.1172 - val_loss: 3.4544 - val_accuracy: 0.2422\n",
      "Epoch 610/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8699 - accuracy: 0.1250 - val_loss: 3.5559 - val_accuracy: 0.1875\n",
      "Epoch 611/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6922 - accuracy: 0.1484 - val_loss: 3.6514 - val_accuracy: 0.1953\n",
      "Epoch 612/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4593 - accuracy: 0.1875 - val_loss: 3.7914 - val_accuracy: 0.1250\n",
      "Epoch 613/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5244 - accuracy: 0.1406 - val_loss: 3.8446 - val_accuracy: 0.1016\n",
      "Epoch 614/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6826 - accuracy: 0.1797 - val_loss: 3.8558 - val_accuracy: 0.1172\n",
      "Epoch 615/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9060 - accuracy: 0.0938 - val_loss: 3.7702 - val_accuracy: 0.1094\n",
      "Epoch 616/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8836 - accuracy: 0.1094 - val_loss: 3.6985 - val_accuracy: 0.1094\n",
      "Epoch 617/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.5048 - accuracy: 0.1875 - val_loss: 3.6668 - val_accuracy: 0.1094\n",
      "Epoch 618/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8114 - accuracy: 0.1172 - val_loss: 3.7431 - val_accuracy: 0.0938\n",
      "Epoch 619/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7929 - accuracy: 0.0703 - val_loss: 3.8170 - val_accuracy: 0.0859\n",
      "Epoch 620/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.8106 - accuracy: 0.1406 - val_loss: 3.8393 - val_accuracy: 0.1016\n",
      "Epoch 621/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.7195 - accuracy: 0.1250 - val_loss: 3.9232 - val_accuracy: 0.0625\n",
      "Epoch 622/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.5865 - accuracy: 0.1172 - val_loss: 4.0301 - val_accuracy: 0.0625\n",
      "Epoch 623/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5172 - accuracy: 0.0859 - val_loss: 3.9891 - val_accuracy: 0.0391\n",
      "Epoch 624/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7295 - accuracy: 0.1641 - val_loss: 3.9194 - val_accuracy: 0.0234\n",
      "Epoch 625/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9241 - accuracy: 0.0938 - val_loss: 3.9026 - val_accuracy: 0.0078\n",
      "Epoch 626/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5058 - accuracy: 0.1797 - val_loss: 3.9817 - val_accuracy: 0.0078\n",
      "Epoch 627/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8029 - accuracy: 0.0547 - val_loss: 3.9810 - val_accuracy: 0.0078\n",
      "Epoch 628/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7131 - accuracy: 0.0859 - val_loss: 3.9419 - val_accuracy: 0.0234\n",
      "Epoch 629/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7400 - accuracy: 0.1562 - val_loss: 3.8500 - val_accuracy: 0.0234\n",
      "Epoch 630/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6525 - accuracy: 0.1406 - val_loss: 3.9017 - val_accuracy: 0.0234\n",
      "Epoch 631/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6169 - accuracy: 0.1172 - val_loss: 3.9903 - val_accuracy: 0.0234\n",
      "Epoch 632/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6692 - accuracy: 0.0938 - val_loss: 4.0800 - val_accuracy: 0.0156\n",
      "Epoch 633/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7225 - accuracy: 0.1797 - val_loss: 4.0419 - val_accuracy: 0.0234\n",
      "Epoch 634/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.8763 - accuracy: 0.1094 - val_loss: 3.9573 - val_accuracy: 0.0078\n",
      "Epoch 635/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.7709 - accuracy: 0.1484 - val_loss: 3.8673 - val_accuracy: 0.0156\n",
      "Epoch 636/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6731 - accuracy: 0.1172 - val_loss: 3.8574 - val_accuracy: 0.0078\n",
      "Epoch 637/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9241 - accuracy: 0.0859 - val_loss: 3.8147 - val_accuracy: 0.0078\n",
      "Epoch 638/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5243 - accuracy: 0.1406 - val_loss: 3.7516 - val_accuracy: 0.0234\n",
      "Epoch 639/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6174 - accuracy: 0.1484 - val_loss: 3.7569 - val_accuracy: 0.0234\n",
      "Epoch 640/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5478 - accuracy: 0.0938 - val_loss: 3.8773 - val_accuracy: 0.0469\n",
      "Epoch 641/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6274 - accuracy: 0.1406 - val_loss: 4.0551 - val_accuracy: 0.0391\n",
      "Epoch 642/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6564 - accuracy: 0.1328 - val_loss: 4.0720 - val_accuracy: 0.0625\n",
      "Epoch 643/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.5612 - accuracy: 0.2031 - val_loss: 4.0577 - val_accuracy: 0.0547\n",
      "Epoch 644/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8235 - accuracy: 0.0938 - val_loss: 4.0248 - val_accuracy: 0.0469\n",
      "Epoch 645/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4720 - accuracy: 0.1484 - val_loss: 3.8837 - val_accuracy: 0.0391\n",
      "Epoch 646/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3792 - accuracy: 0.1797 - val_loss: 3.7438 - val_accuracy: 0.0469\n",
      "Epoch 647/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.6429 - accuracy: 0.1484 - val_loss: 3.6104 - val_accuracy: 0.0703\n",
      "Epoch 648/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7837 - accuracy: 0.0938 - val_loss: 3.5903 - val_accuracy: 0.0703\n",
      "Epoch 649/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6630 - accuracy: 0.1406 - val_loss: 3.7682 - val_accuracy: 0.0547\n",
      "Epoch 650/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6271 - accuracy: 0.1797 - val_loss: 3.8805 - val_accuracy: 0.0391\n",
      "Epoch 651/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7308 - accuracy: 0.1797 - val_loss: 3.7878 - val_accuracy: 0.0547\n",
      "Epoch 652/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.7742 - accuracy: 0.1250 - val_loss: 3.7055 - val_accuracy: 0.1094\n",
      "Epoch 653/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.8700 - accuracy: 0.1250 - val_loss: 3.6599 - val_accuracy: 0.1328\n",
      "Epoch 654/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6320 - accuracy: 0.0469 - val_loss: 3.5660 - val_accuracy: 0.2031\n",
      "Epoch 655/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.6196 - accuracy: 0.0312 - val_loss: 3.4592 - val_accuracy: 0.2109\n",
      "Epoch 656/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.7622 - accuracy: 0.1172 - val_loss: 3.3512 - val_accuracy: 0.1953\n",
      "Epoch 657/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6576 - accuracy: 0.0859 - val_loss: 3.3252 - val_accuracy: 0.1719\n",
      "Epoch 658/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3720 - accuracy: 0.1797 - val_loss: 3.3359 - val_accuracy: 0.1562\n",
      "Epoch 659/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.4265 - accuracy: 0.2422 - val_loss: 3.3747 - val_accuracy: 0.1094\n",
      "Epoch 660/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.9320 - accuracy: 0.0781 - val_loss: 3.4604 - val_accuracy: 0.0703\n",
      "Epoch 661/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.0458 - accuracy: 0.0703 - val_loss: 3.5360 - val_accuracy: 0.0469\n",
      "Epoch 662/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.8218 - accuracy: 0.1250 - val_loss: 3.5276 - val_accuracy: 0.0938\n",
      "Epoch 663/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6067 - accuracy: 0.1328 - val_loss: 3.5694 - val_accuracy: 0.1328\n",
      "Epoch 664/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6879 - accuracy: 0.1484 - val_loss: 3.5796 - val_accuracy: 0.1328\n",
      "Epoch 665/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.7250 - accuracy: 0.0859 - val_loss: 3.6054 - val_accuracy: 0.1250\n",
      "Epoch 666/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6620 - accuracy: 0.0938 - val_loss: 3.6163 - val_accuracy: 0.1094\n",
      "Epoch 667/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6272 - accuracy: 0.1406 - val_loss: 3.6016 - val_accuracy: 0.0781\n",
      "Epoch 668/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.6141 - accuracy: 0.1562 - val_loss: 3.6690 - val_accuracy: 0.0703\n",
      "Epoch 669/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.7340 - accuracy: 0.1328 - val_loss: 3.6465 - val_accuracy: 0.0859\n",
      "Epoch 670/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0066 - accuracy: 0.0781 - val_loss: 3.6174 - val_accuracy: 0.1250\n",
      "Epoch 671/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5701 - accuracy: 0.1875 - val_loss: 3.6766 - val_accuracy: 0.1328\n",
      "Epoch 672/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5480 - accuracy: 0.0781 - val_loss: 3.7738 - val_accuracy: 0.1328\n",
      "Epoch 673/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6748 - accuracy: 0.1484 - val_loss: 3.8037 - val_accuracy: 0.1328\n",
      "Epoch 674/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6192 - accuracy: 0.1562 - val_loss: 3.7890 - val_accuracy: 0.1484\n",
      "Epoch 675/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4572 - accuracy: 0.1797 - val_loss: 3.7069 - val_accuracy: 0.1562\n",
      "Epoch 676/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5992 - accuracy: 0.1250 - val_loss: 3.7351 - val_accuracy: 0.1719\n",
      "Epoch 677/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5352 - accuracy: 0.1562 - val_loss: 3.6517 - val_accuracy: 0.1953\n",
      "Epoch 678/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4979 - accuracy: 0.0703 - val_loss: 3.5528 - val_accuracy: 0.1953\n",
      "Epoch 679/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8580 - accuracy: 0.1016 - val_loss: 3.4590 - val_accuracy: 0.2188\n",
      "Epoch 680/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7139 - accuracy: 0.1094 - val_loss: 3.3216 - val_accuracy: 0.2422\n",
      "Epoch 681/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6198 - accuracy: 0.1875 - val_loss: 3.2129 - val_accuracy: 0.3125\n",
      "Epoch 682/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.5270 - accuracy: 0.1016 - val_loss: 3.0751 - val_accuracy: 0.3438\n",
      "Epoch 683/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5801 - accuracy: 0.1250 - val_loss: 3.0158 - val_accuracy: 0.3672\n",
      "Epoch 684/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7352 - accuracy: 0.1250 - val_loss: 3.0281 - val_accuracy: 0.3672\n",
      "Epoch 685/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.5025 - accuracy: 0.1172 - val_loss: 3.1062 - val_accuracy: 0.3281\n",
      "Epoch 686/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6509 - accuracy: 0.1875 - val_loss: 3.1251 - val_accuracy: 0.2891\n",
      "Epoch 687/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5007 - accuracy: 0.1797 - val_loss: 3.1367 - val_accuracy: 0.2578\n",
      "Epoch 688/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.7608 - accuracy: 0.1328 - val_loss: 3.1594 - val_accuracy: 0.1953\n",
      "Epoch 689/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5762 - accuracy: 0.1562 - val_loss: 3.1730 - val_accuracy: 0.1875\n",
      "Epoch 690/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.6813 - accuracy: 0.1172 - val_loss: 3.2179 - val_accuracy: 0.1719\n",
      "Epoch 691/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.3775 - accuracy: 0.1484 - val_loss: 3.2221 - val_accuracy: 0.2266\n",
      "Epoch 692/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.8476 - accuracy: 0.0859 - val_loss: 3.2425 - val_accuracy: 0.2422\n",
      "Epoch 693/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.8926 - accuracy: 0.1172 - val_loss: 3.2263 - val_accuracy: 0.2734\n",
      "Epoch 694/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4400 - accuracy: 0.1562 - val_loss: 3.2093 - val_accuracy: 0.2578\n",
      "Epoch 695/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5738 - accuracy: 0.2422 - val_loss: 3.2477 - val_accuracy: 0.2031\n",
      "Epoch 696/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7239 - accuracy: 0.1562 - val_loss: 3.3260 - val_accuracy: 0.1875\n",
      "Epoch 697/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6943 - accuracy: 0.1172 - val_loss: 3.3719 - val_accuracy: 0.1875\n",
      "Epoch 698/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7558 - accuracy: 0.1250 - val_loss: 3.4073 - val_accuracy: 0.1719\n",
      "Epoch 699/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5009 - accuracy: 0.1719 - val_loss: 3.4420 - val_accuracy: 0.1562\n",
      "Epoch 700/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7064 - accuracy: 0.1328 - val_loss: 3.5076 - val_accuracy: 0.1484\n",
      "Epoch 701/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.4180 - accuracy: 0.1719 - val_loss: 3.6095 - val_accuracy: 0.1250\n",
      "Epoch 702/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5546 - accuracy: 0.1328 - val_loss: 3.6343 - val_accuracy: 0.0938\n",
      "Epoch 703/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5879 - accuracy: 0.1484 - val_loss: 3.5895 - val_accuracy: 0.1094\n",
      "Epoch 704/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6023 - accuracy: 0.1953 - val_loss: 3.6749 - val_accuracy: 0.0781\n",
      "Epoch 705/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5216 - accuracy: 0.1562 - val_loss: 3.6635 - val_accuracy: 0.1016\n",
      "Epoch 706/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5148 - accuracy: 0.1328 - val_loss: 3.5721 - val_accuracy: 0.0781\n",
      "Epoch 707/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2699 - accuracy: 0.2500 - val_loss: 3.5598 - val_accuracy: 0.0938\n",
      "Epoch 708/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5414 - accuracy: 0.1328 - val_loss: 3.6048 - val_accuracy: 0.0859\n",
      "Epoch 709/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5847 - accuracy: 0.1328 - val_loss: 3.7238 - val_accuracy: 0.0547\n",
      "Epoch 710/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.4417 - accuracy: 0.1016 - val_loss: 3.8180 - val_accuracy: 0.0625\n",
      "Epoch 711/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4686 - accuracy: 0.0859 - val_loss: 3.7613 - val_accuracy: 0.0781\n",
      "Epoch 712/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6205 - accuracy: 0.1250 - val_loss: 3.7626 - val_accuracy: 0.1016\n",
      "Epoch 713/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.4147 - accuracy: 0.2109 - val_loss: 3.7386 - val_accuracy: 0.0859\n",
      "Epoch 714/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5118 - accuracy: 0.1406 - val_loss: 3.7547 - val_accuracy: 0.0781\n",
      "Epoch 715/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.7419 - accuracy: 0.0391 - val_loss: 3.7743 - val_accuracy: 0.1172\n",
      "Epoch 716/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.6530 - accuracy: 0.1406 - val_loss: 3.8123 - val_accuracy: 0.1172\n",
      "Epoch 717/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6058 - accuracy: 0.1797 - val_loss: 3.8125 - val_accuracy: 0.1172\n",
      "Epoch 718/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.8846 - accuracy: 0.0859 - val_loss: 3.5894 - val_accuracy: 0.1641\n",
      "Epoch 719/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.5375 - accuracy: 0.1797 - val_loss: 3.3792 - val_accuracy: 0.1797\n",
      "Epoch 720/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5463 - accuracy: 0.1562 - val_loss: 3.2755 - val_accuracy: 0.2031\n",
      "Epoch 721/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3976 - accuracy: 0.2344 - val_loss: 3.2058 - val_accuracy: 0.2344\n",
      "Epoch 722/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5819 - accuracy: 0.1172 - val_loss: 3.1875 - val_accuracy: 0.2578\n",
      "Epoch 723/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6279 - accuracy: 0.1797 - val_loss: 3.1839 - val_accuracy: 0.2188\n",
      "Epoch 724/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5061 - accuracy: 0.1719 - val_loss: 3.2475 - val_accuracy: 0.1953\n",
      "Epoch 725/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.9424 - accuracy: 0.0703 - val_loss: 3.3769 - val_accuracy: 0.1875\n",
      "Epoch 726/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4601 - accuracy: 0.1094 - val_loss: 3.5216 - val_accuracy: 0.1250\n",
      "Epoch 727/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.6508 - accuracy: 0.1641 - val_loss: 3.5871 - val_accuracy: 0.1250\n",
      "Epoch 728/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7550 - accuracy: 0.0703 - val_loss: 3.5503 - val_accuracy: 0.1406\n",
      "Epoch 729/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3889 - accuracy: 0.1875 - val_loss: 3.5238 - val_accuracy: 0.1406\n",
      "Epoch 730/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6181 - accuracy: 0.1172 - val_loss: 3.5382 - val_accuracy: 0.1094\n",
      "Epoch 731/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4782 - accuracy: 0.1484 - val_loss: 3.6011 - val_accuracy: 0.1016\n",
      "Epoch 732/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6031 - accuracy: 0.1250 - val_loss: 3.6128 - val_accuracy: 0.1172\n",
      "Epoch 733/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.5200 - accuracy: 0.1094 - val_loss: 3.6074 - val_accuracy: 0.1094\n",
      "Epoch 734/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3374 - accuracy: 0.1484 - val_loss: 3.6562 - val_accuracy: 0.0781\n",
      "Epoch 735/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6779 - accuracy: 0.1719 - val_loss: 3.6964 - val_accuracy: 0.0703\n",
      "Epoch 736/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7222 - accuracy: 0.0859 - val_loss: 3.7492 - val_accuracy: 0.0781\n",
      "Epoch 737/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4526 - accuracy: 0.1875 - val_loss: 3.7784 - val_accuracy: 0.0859\n",
      "Epoch 738/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5672 - accuracy: 0.1875 - val_loss: 3.7159 - val_accuracy: 0.0703\n",
      "Epoch 739/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.3703 - accuracy: 0.2344 - val_loss: 3.6528 - val_accuracy: 0.0781\n",
      "Epoch 740/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5964 - accuracy: 0.1016 - val_loss: 3.5623 - val_accuracy: 0.1016\n",
      "Epoch 741/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.5014 - accuracy: 0.1562 - val_loss: 3.5197 - val_accuracy: 0.0938\n",
      "Epoch 742/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6768 - accuracy: 0.1172 - val_loss: 3.5388 - val_accuracy: 0.0859\n",
      "Epoch 743/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7127 - accuracy: 0.1484 - val_loss: 3.5425 - val_accuracy: 0.0938\n",
      "Epoch 744/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7136 - accuracy: 0.1094 - val_loss: 3.4637 - val_accuracy: 0.1250\n",
      "Epoch 745/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4939 - accuracy: 0.1328 - val_loss: 3.3815 - val_accuracy: 0.1641\n",
      "Epoch 746/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6637 - accuracy: 0.1016 - val_loss: 3.3775 - val_accuracy: 0.1641\n",
      "Epoch 747/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4022 - accuracy: 0.1875 - val_loss: 3.4306 - val_accuracy: 0.1641\n",
      "Epoch 748/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5838 - accuracy: 0.1797 - val_loss: 3.4341 - val_accuracy: 0.1406\n",
      "Epoch 749/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6525 - accuracy: 0.1328 - val_loss: 3.4801 - val_accuracy: 0.1328\n",
      "Epoch 750/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.4296 - accuracy: 0.1719 - val_loss: 3.4546 - val_accuracy: 0.1172\n",
      "Epoch 751/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5929 - accuracy: 0.1562 - val_loss: 3.4496 - val_accuracy: 0.1172\n",
      "Epoch 752/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.5050 - accuracy: 0.1406 - val_loss: 3.4538 - val_accuracy: 0.1250\n",
      "Epoch 753/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.4926 - accuracy: 0.1797 - val_loss: 3.4488 - val_accuracy: 0.1797\n",
      "Epoch 754/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5279 - accuracy: 0.1875 - val_loss: 3.5063 - val_accuracy: 0.1562\n",
      "Epoch 755/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.4355 - accuracy: 0.1953 - val_loss: 3.5706 - val_accuracy: 0.1641\n",
      "Epoch 756/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5658 - accuracy: 0.1562 - val_loss: 3.6657 - val_accuracy: 0.1562\n",
      "Epoch 757/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3706 - accuracy: 0.2422 - val_loss: 3.7801 - val_accuracy: 0.1328\n",
      "Epoch 758/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.3161 - accuracy: 0.2266 - val_loss: 3.8667 - val_accuracy: 0.1250\n",
      "Epoch 759/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5427 - accuracy: 0.1484 - val_loss: 3.8616 - val_accuracy: 0.1172\n",
      "Epoch 760/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.2562 - accuracy: 0.1719 - val_loss: 3.8164 - val_accuracy: 0.1250\n",
      "Epoch 761/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6325 - accuracy: 0.1406 - val_loss: 3.7443 - val_accuracy: 0.1406\n",
      "Epoch 762/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3852 - accuracy: 0.1328 - val_loss: 3.6966 - val_accuracy: 0.1094\n",
      "Epoch 763/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6517 - accuracy: 0.0859 - val_loss: 3.5903 - val_accuracy: 0.1016\n",
      "Epoch 764/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3683 - accuracy: 0.1328 - val_loss: 3.5534 - val_accuracy: 0.1250\n",
      "Epoch 765/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4737 - accuracy: 0.1797 - val_loss: 3.5118 - val_accuracy: 0.1484\n",
      "Epoch 766/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4246 - accuracy: 0.1641 - val_loss: 3.5416 - val_accuracy: 0.1406\n",
      "Epoch 767/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.4037 - accuracy: 0.1562 - val_loss: 3.5354 - val_accuracy: 0.1328\n",
      "Epoch 768/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6402 - accuracy: 0.1094 - val_loss: 3.5339 - val_accuracy: 0.1484\n",
      "Epoch 769/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5890 - accuracy: 0.1562 - val_loss: 3.5449 - val_accuracy: 0.1562\n",
      "Epoch 770/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5191 - accuracy: 0.1328 - val_loss: 3.5046 - val_accuracy: 0.1562\n",
      "Epoch 771/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.6643 - accuracy: 0.1406 - val_loss: 3.5205 - val_accuracy: 0.1875\n",
      "Epoch 772/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.6176 - accuracy: 0.1719 - val_loss: 3.5784 - val_accuracy: 0.1484\n",
      "Epoch 773/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4021 - accuracy: 0.1406 - val_loss: 3.6590 - val_accuracy: 0.1484\n",
      "Epoch 774/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.4809 - accuracy: 0.2031 - val_loss: 3.6604 - val_accuracy: 0.1328\n",
      "Epoch 775/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6983 - accuracy: 0.1250 - val_loss: 3.6175 - val_accuracy: 0.1562\n",
      "Epoch 776/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5676 - accuracy: 0.1016 - val_loss: 3.5226 - val_accuracy: 0.1797\n",
      "Epoch 777/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4194 - accuracy: 0.1641 - val_loss: 3.4665 - val_accuracy: 0.1641\n",
      "Epoch 778/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.5927 - accuracy: 0.2344 - val_loss: 3.5132 - val_accuracy: 0.1406\n",
      "Epoch 779/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6752 - accuracy: 0.1016 - val_loss: 3.5577 - val_accuracy: 0.1875\n",
      "Epoch 780/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.5824 - accuracy: 0.1484 - val_loss: 3.5295 - val_accuracy: 0.2031\n",
      "Epoch 781/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3830 - accuracy: 0.1719 - val_loss: 3.4769 - val_accuracy: 0.1797\n",
      "Epoch 782/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.4620 - accuracy: 0.1875 - val_loss: 3.4902 - val_accuracy: 0.1641\n",
      "Epoch 783/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4996 - accuracy: 0.1719 - val_loss: 3.4981 - val_accuracy: 0.1562\n",
      "Epoch 00783: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=27228\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=27228\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 5.5388 - accuracy: 0.0000e+00 - val_loss: 5.5429 - val_accuracy: 0.0469\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 5.5896 - accuracy: 0.0000e+00 - val_loss: 5.5382 - val_accuracy: 0.0859\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 5.5454 - accuracy: 0.0078 - val_loss: 5.5319 - val_accuracy: 0.1172\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.5529 - accuracy: 0.0078 - val_loss: 5.5243 - val_accuracy: 0.1641\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.5194 - accuracy: 0.0234 - val_loss: 5.5164 - val_accuracy: 0.1641\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4564 - accuracy: 0.0156 - val_loss: 5.5080 - val_accuracy: 0.1641\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4922 - accuracy: 0.0234 - val_loss: 5.5000 - val_accuracy: 0.1641\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4951 - accuracy: 0.0000e+00 - val_loss: 5.4932 - val_accuracy: 0.1641\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4678 - accuracy: 0.0078 - val_loss: 5.4866 - val_accuracy: 0.1641\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4787 - accuracy: 0.0078 - val_loss: 5.4814 - val_accuracy: 0.1641\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.4762 - accuracy: 0.0156 - val_loss: 5.4768 - val_accuracy: 0.1641\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4714 - accuracy: 0.0078 - val_loss: 5.4708 - val_accuracy: 0.1641\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4243 - accuracy: 0.0078 - val_loss: 5.4641 - val_accuracy: 0.1641\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4362 - accuracy: 0.0078 - val_loss: 5.4570 - val_accuracy: 0.1641\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4941 - accuracy: 0.0000e+00 - val_loss: 5.4498 - val_accuracy: 0.1641\n",
      "Epoch 16/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4323 - accuracy: 0.0234 - val_loss: 5.4424 - val_accuracy: 0.1641\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4037 - accuracy: 0.0312 - val_loss: 5.4356 - val_accuracy: 0.1641\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4001 - accuracy: 0.0234 - val_loss: 5.4285 - val_accuracy: 0.0156\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3204 - accuracy: 0.0469 - val_loss: 5.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4047 - accuracy: 0.0156 - val_loss: 5.4157 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3234 - accuracy: 0.0234 - val_loss: 5.4062 - val_accuracy: 0.1406\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3814 - accuracy: 0.0078 - val_loss: 5.3972 - val_accuracy: 0.1641\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.3364 - accuracy: 0.0391 - val_loss: 5.3881 - val_accuracy: 0.0547\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3185 - accuracy: 0.0312 - val_loss: 5.3793 - val_accuracy: 0.0547\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3008 - accuracy: 0.0156 - val_loss: 5.3710 - val_accuracy: 0.0547\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3225 - accuracy: 0.0234 - val_loss: 5.3612 - val_accuracy: 0.0703\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3718 - accuracy: 0.0234 - val_loss: 5.3488 - val_accuracy: 0.1562\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2973 - accuracy: 0.0234 - val_loss: 5.3282 - val_accuracy: 0.1641\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3119 - accuracy: 0.0391 - val_loss: 5.3034 - val_accuracy: 0.1641\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3539 - accuracy: 0.0312 - val_loss: 5.2844 - val_accuracy: 0.1641\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3309 - accuracy: 0.0391 - val_loss: 5.2665 - val_accuracy: 0.1641\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1962 - accuracy: 0.0859 - val_loss: 5.2493 - val_accuracy: 0.1641\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3487 - accuracy: 0.0156 - val_loss: 5.2281 - val_accuracy: 0.1641\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2639 - accuracy: 0.0312 - val_loss: 5.2081 - val_accuracy: 0.1641\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2522 - accuracy: 0.0391 - val_loss: 5.1962 - val_accuracy: 0.0078\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2376 - accuracy: 0.0391 - val_loss: 5.1906 - val_accuracy: 0.0078\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1798 - accuracy: 0.0703 - val_loss: 5.1852 - val_accuracy: 0.0078\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2823 - accuracy: 0.0156 - val_loss: 5.1832 - val_accuracy: 0.0078\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2191 - accuracy: 0.0625 - val_loss: 5.1868 - val_accuracy: 0.0078\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2644 - accuracy: 0.0234 - val_loss: 5.1967 - val_accuracy: 0.0078\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1999 - accuracy: 0.0469 - val_loss: 5.2025 - val_accuracy: 0.0078\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1706 - accuracy: 0.0703 - val_loss: 5.2049 - val_accuracy: 0.0078\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3217 - accuracy: 0.0156 - val_loss: 5.1982 - val_accuracy: 0.0078\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1934 - accuracy: 0.0234 - val_loss: 5.1919 - val_accuracy: 0.0078\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2886 - accuracy: 0.0000e+00 - val_loss: 5.1904 - val_accuracy: 0.0078\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2933 - accuracy: 0.0078 - val_loss: 5.1933 - val_accuracy: 0.0078\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1924 - accuracy: 0.0781 - val_loss: 5.1895 - val_accuracy: 0.0078\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2685 - accuracy: 0.0078 - val_loss: 5.1678 - val_accuracy: 0.0078\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0345 - accuracy: 0.0703 - val_loss: 5.1565 - val_accuracy: 0.0078\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2215 - accuracy: 0.0078 - val_loss: 5.1363 - val_accuracy: 0.0078\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1498 - accuracy: 0.0469 - val_loss: 5.1193 - val_accuracy: 0.0078\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9653 - accuracy: 0.0781 - val_loss: 5.1084 - val_accuracy: 0.0078\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2239 - accuracy: 0.0078 - val_loss: 5.0960 - val_accuracy: 0.0078\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.1482 - accuracy: 0.0156 - val_loss: 5.0800 - val_accuracy: 0.0078\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1610 - accuracy: 0.0781 - val_loss: 5.0672 - val_accuracy: 0.0078\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0749 - accuracy: 0.0234 - val_loss: 5.0584 - val_accuracy: 0.0078\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2538 - accuracy: 0.0078 - val_loss: 5.0456 - val_accuracy: 0.1250\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9490 - accuracy: 0.0469 - val_loss: 5.0335 - val_accuracy: 0.1250\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0794 - accuracy: 0.0156 - val_loss: 5.0314 - val_accuracy: 0.0859\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1616 - accuracy: 0.0391 - val_loss: 5.0329 - val_accuracy: 0.0781\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0587 - accuracy: 0.0547 - val_loss: 5.0354 - val_accuracy: 0.0078\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1916 - accuracy: 0.0078 - val_loss: 5.0395 - val_accuracy: 0.0078\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0814 - accuracy: 0.0469 - val_loss: 5.0407 - val_accuracy: 0.0078\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0571 - accuracy: 0.0078 - val_loss: 5.0500 - val_accuracy: 0.0078\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0823 - accuracy: 0.0156 - val_loss: 5.0623 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0617 - accuracy: 0.0391 - val_loss: 5.0745 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9960 - accuracy: 0.0625 - val_loss: 5.0955 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1045 - accuracy: 0.0312 - val_loss: 5.0961 - val_accuracy: 0.0156\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1156 - accuracy: 0.0391 - val_loss: 5.0865 - val_accuracy: 0.0156\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0167 - accuracy: 0.0312 - val_loss: 5.0791 - val_accuracy: 0.0156\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9668 - accuracy: 0.0469 - val_loss: 5.0631 - val_accuracy: 0.0156\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0366 - accuracy: 0.0312 - val_loss: 5.0623 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8981 - accuracy: 0.0859 - val_loss: 5.0627 - val_accuracy: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.0685 - accuracy: 0.0469 - val_loss: 5.0656 - val_accuracy: 0.0078\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9649 - accuracy: 0.0156 - val_loss: 5.0596 - val_accuracy: 0.0078\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0723 - accuracy: 0.0156 - val_loss: 5.0495 - val_accuracy: 0.0078\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0498 - accuracy: 0.0156 - val_loss: 5.0470 - val_accuracy: 0.0156\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9812 - accuracy: 0.0312 - val_loss: 5.0427 - val_accuracy: 0.0078\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0364 - accuracy: 0.0469 - val_loss: 5.0384 - val_accuracy: 0.0078\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0429 - accuracy: 0.0312 - val_loss: 5.0297 - val_accuracy: 0.0078\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1860 - accuracy: 0.0078 - val_loss: 5.0129 - val_accuracy: 0.0078\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1089 - accuracy: 0.0156 - val_loss: 5.0065 - val_accuracy: 0.0078\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9625 - accuracy: 0.0391 - val_loss: 5.0150 - val_accuracy: 0.0078\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9520 - accuracy: 0.0000e+00 - val_loss: 5.0248 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9192 - accuracy: 0.0234 - val_loss: 5.0230 - val_accuracy: 0.0078\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9612 - accuracy: 0.0234 - val_loss: 5.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8996 - accuracy: 0.0156 - val_loss: 5.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8429 - accuracy: 0.0391 - val_loss: 5.0001 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0171 - accuracy: 0.0391 - val_loss: 5.0180 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7486 - accuracy: 0.0312 - val_loss: 5.0159 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9190 - accuracy: 0.0312 - val_loss: 5.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9235 - accuracy: 0.0312 - val_loss: 4.9740 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8573 - accuracy: 0.0078 - val_loss: 4.9411 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7940 - accuracy: 0.0469 - val_loss: 4.9195 - val_accuracy: 0.0078\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9075 - accuracy: 0.0469 - val_loss: 4.9181 - val_accuracy: 0.0078\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8828 - accuracy: 0.0234 - val_loss: 4.9198 - val_accuracy: 0.0078\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0330 - accuracy: 0.0156 - val_loss: 4.9309 - val_accuracy: 0.0078\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9226 - accuracy: 0.0156 - val_loss: 4.9249 - val_accuracy: 0.0078\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9690 - accuracy: 0.0156 - val_loss: 4.9157 - val_accuracy: 0.0078\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8994 - accuracy: 0.0312 - val_loss: 4.9081 - val_accuracy: 0.0078\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9326 - accuracy: 0.0391 - val_loss: 4.9035 - val_accuracy: 0.0078\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8525 - accuracy: 0.0312 - val_loss: 4.8732 - val_accuracy: 0.0312\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9377 - accuracy: 0.0312 - val_loss: 4.8357 - val_accuracy: 0.1250\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8741 - accuracy: 0.0078 - val_loss: 4.8198 - val_accuracy: 0.1562\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9346 - accuracy: 0.0469 - val_loss: 4.8017 - val_accuracy: 0.1484\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8393 - accuracy: 0.0469 - val_loss: 4.7733 - val_accuracy: 0.1484\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0638 - accuracy: 0.0156 - val_loss: 4.7543 - val_accuracy: 0.1250\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8914 - accuracy: 0.0234 - val_loss: 4.7567 - val_accuracy: 0.0938\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8217 - accuracy: 0.0703 - val_loss: 4.7623 - val_accuracy: 0.0547\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8649 - accuracy: 0.0312 - val_loss: 4.7456 - val_accuracy: 0.0391\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7432 - accuracy: 0.0312 - val_loss: 4.7315 - val_accuracy: 0.0078\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7639 - accuracy: 0.0156 - val_loss: 4.7192 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0104 - accuracy: 0.0547 - val_loss: 4.6747 - val_accuracy: 0.0234\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8825 - accuracy: 0.0234 - val_loss: 4.6526 - val_accuracy: 0.0312\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8356 - accuracy: 0.0469 - val_loss: 4.6288 - val_accuracy: 0.0547\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7815 - accuracy: 0.0391 - val_loss: 4.6218 - val_accuracy: 0.1250\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7663 - accuracy: 0.0703 - val_loss: 4.6105 - val_accuracy: 0.1562\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8484 - accuracy: 0.0391 - val_loss: 4.5846 - val_accuracy: 0.1641\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8943 - accuracy: 0.0391 - val_loss: 4.5767 - val_accuracy: 0.1641\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0534 - accuracy: 0.0156 - val_loss: 4.5929 - val_accuracy: 0.1641\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9610 - accuracy: 0.0078 - val_loss: 4.6222 - val_accuracy: 0.1641\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8973 - accuracy: 0.0000e+00 - val_loss: 4.6534 - val_accuracy: 0.1641\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7672 - accuracy: 0.0312 - val_loss: 4.6584 - val_accuracy: 0.1641\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8336 - accuracy: 0.0234 - val_loss: 4.6623 - val_accuracy: 0.1484\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8796 - accuracy: 0.0156 - val_loss: 4.6739 - val_accuracy: 0.0703\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6727 - accuracy: 0.1172 - val_loss: 4.6408 - val_accuracy: 0.0781\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8280 - accuracy: 0.0312 - val_loss: 4.5893 - val_accuracy: 0.1094\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8823 - accuracy: 0.0234 - val_loss: 4.5624 - val_accuracy: 0.1250\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0302 - accuracy: 0.0156 - val_loss: 4.5472 - val_accuracy: 0.1484\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8586 - accuracy: 0.0000e+00 - val_loss: 4.5445 - val_accuracy: 0.1484\n",
      "Epoch 131/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6998 - accuracy: 0.0703 - val_loss: 4.5100 - val_accuracy: 0.1562\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6582 - accuracy: 0.0469 - val_loss: 4.4638 - val_accuracy: 0.1641\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7475 - accuracy: 0.0078 - val_loss: 4.4417 - val_accuracy: 0.1641\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9924 - accuracy: 0.0156 - val_loss: 4.4519 - val_accuracy: 0.1641\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9369 - accuracy: 0.0312 - val_loss: 4.4761 - val_accuracy: 0.1641\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6731 - accuracy: 0.0078 - val_loss: 4.4921 - val_accuracy: 0.1641\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9128 - accuracy: 0.0156 - val_loss: 4.5060 - val_accuracy: 0.1406\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8857 - accuracy: 0.0234 - val_loss: 4.5257 - val_accuracy: 0.1250\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7905 - accuracy: 0.0547 - val_loss: 4.5345 - val_accuracy: 0.1250\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9462 - accuracy: 0.0000e+00 - val_loss: 4.5543 - val_accuracy: 0.1172\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0251 - accuracy: 0.0312 - val_loss: 4.6026 - val_accuracy: 0.0859\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8410 - accuracy: 0.0234 - val_loss: 4.6489 - val_accuracy: 0.0547\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0962 - accuracy: 0.0625 - val_loss: 4.6931 - val_accuracy: 0.0234\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8034 - accuracy: 0.0312 - val_loss: 4.7200 - val_accuracy: 0.0156\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9071 - accuracy: 0.0078 - val_loss: 4.7222 - val_accuracy: 0.0156\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9488 - accuracy: 0.0234 - val_loss: 4.7186 - val_accuracy: 0.0234\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8252 - accuracy: 0.0156 - val_loss: 4.7133 - val_accuracy: 0.0234\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7446 - accuracy: 0.0391 - val_loss: 4.7040 - val_accuracy: 0.0234\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7367 - accuracy: 0.0703 - val_loss: 4.7008 - val_accuracy: 0.0234\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7082 - accuracy: 0.0156 - val_loss: 4.6932 - val_accuracy: 0.0547\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7422 - accuracy: 0.0469 - val_loss: 4.6725 - val_accuracy: 0.0938\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8525 - accuracy: 0.0156 - val_loss: 4.6554 - val_accuracy: 0.1094\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8790 - accuracy: 0.0156 - val_loss: 4.6554 - val_accuracy: 0.1328\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8439 - accuracy: 0.0391 - val_loss: 4.6644 - val_accuracy: 0.1250\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8136 - accuracy: 0.0547 - val_loss: 4.6558 - val_accuracy: 0.0859\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7530 - accuracy: 0.0234 - val_loss: 4.6436 - val_accuracy: 0.0625\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8521 - accuracy: 0.0469 - val_loss: 4.6396 - val_accuracy: 0.0312\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0017 - accuracy: 0.0312 - val_loss: 4.6489 - val_accuracy: 0.0234\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6503 - accuracy: 0.0391 - val_loss: 4.6450 - val_accuracy: 0.0078\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8134 - accuracy: 0.0391 - val_loss: 4.6494 - val_accuracy: 0.0078\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7126 - accuracy: 0.0391 - val_loss: 4.6406 - val_accuracy: 0.0312\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8097 - accuracy: 0.0000e+00 - val_loss: 4.6226 - val_accuracy: 0.0938\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9320 - accuracy: 0.0234 - val_loss: 4.6260 - val_accuracy: 0.1484\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7071 - accuracy: 0.0547 - val_loss: 4.6193 - val_accuracy: 0.1641\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6495 - accuracy: 0.0625 - val_loss: 4.6381 - val_accuracy: 0.1641\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8102 - accuracy: 0.0391 - val_loss: 4.6766 - val_accuracy: 0.1641\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7177 - accuracy: 0.0547 - val_loss: 4.7203 - val_accuracy: 0.1484\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7057 - accuracy: 0.0000e+00 - val_loss: 4.7651 - val_accuracy: 0.1406\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7603 - accuracy: 0.0234 - val_loss: 4.7631 - val_accuracy: 0.1406\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8073 - accuracy: 0.0312 - val_loss: 4.7459 - val_accuracy: 0.0469\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9575 - accuracy: 0.0156 - val_loss: 4.7026 - val_accuracy: 0.0078\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6641 - accuracy: 0.0469 - val_loss: 4.6991 - val_accuracy: 0.0078\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8885 - accuracy: 0.0234 - val_loss: 4.7180 - val_accuracy: 0.0078\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6202 - accuracy: 0.0156 - val_loss: 4.7495 - val_accuracy: 0.0078\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7326 - accuracy: 0.0391 - val_loss: 4.7921 - val_accuracy: 0.0078\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6919 - accuracy: 0.0156 - val_loss: 4.7812 - val_accuracy: 0.0078\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7344 - accuracy: 0.0312 - val_loss: 4.7527 - val_accuracy: 0.0078\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7303 - accuracy: 0.0078 - val_loss: 4.7181 - val_accuracy: 0.0078\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7023 - accuracy: 0.0469 - val_loss: 4.7028 - val_accuracy: 0.0156\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9421 - accuracy: 0.0234 - val_loss: 4.7265 - val_accuracy: 0.0156\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8611 - accuracy: 0.0312 - val_loss: 4.7739 - val_accuracy: 0.0156\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6318 - accuracy: 0.0156 - val_loss: 4.8050 - val_accuracy: 0.0156\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8929 - accuracy: 0.0391 - val_loss: 4.8222 - val_accuracy: 0.0234\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8831 - accuracy: 0.0078 - val_loss: 4.8539 - val_accuracy: 0.0156\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7032 - accuracy: 0.0469 - val_loss: 4.8753 - val_accuracy: 0.0078\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8028 - accuracy: 0.0156 - val_loss: 4.8634 - val_accuracy: 0.0234\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8403 - accuracy: 0.0312 - val_loss: 4.8781 - val_accuracy: 0.0078\n",
      "Epoch 188/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6701 - accuracy: 0.0391 - val_loss: 4.9259 - val_accuracy: 0.0078\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.8456 - accuracy: 0.0234 - val_loss: 4.9883 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7693 - accuracy: 0.0312 - val_loss: 5.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6991 - accuracy: 0.0156 - val_loss: 5.0298 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8846 - accuracy: 0.0078 - val_loss: 4.9800 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8667 - accuracy: 0.0234 - val_loss: 4.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7557 - accuracy: 0.0312 - val_loss: 4.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7712 - accuracy: 0.0078 - val_loss: 4.8117 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7292 - accuracy: 0.0234 - val_loss: 4.7886 - val_accuracy: 0.0078\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6196 - accuracy: 0.0625 - val_loss: 4.8025 - val_accuracy: 0.0078\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8459 - accuracy: 0.0234 - val_loss: 4.8359 - val_accuracy: 0.0078\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6435 - accuracy: 0.0156 - val_loss: 4.8759 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6978 - accuracy: 0.0391 - val_loss: 4.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7501 - accuracy: 0.0312 - val_loss: 5.0047 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7719 - accuracy: 0.0078 - val_loss: 5.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9612 - accuracy: 0.0000e+00 - val_loss: 4.9831 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6639 - accuracy: 0.0391 - val_loss: 4.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8270 - accuracy: 0.0234 - val_loss: 4.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9253 - accuracy: 0.0312 - val_loss: 4.8993 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7897 - accuracy: 0.0156 - val_loss: 4.8844 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5872 - accuracy: 0.0234 - val_loss: 4.8544 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6525 - accuracy: 0.0469 - val_loss: 4.8615 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6587 - accuracy: 0.0234 - val_loss: 4.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8895 - accuracy: 0.0312 - val_loss: 4.9420 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7502 - accuracy: 0.0703 - val_loss: 4.9588 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8190 - accuracy: 0.0156 - val_loss: 4.9394 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7639 - accuracy: 0.0391 - val_loss: 4.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7287 - accuracy: 0.0234 - val_loss: 4.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6713 - accuracy: 0.0234 - val_loss: 4.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6535 - accuracy: 0.0156 - val_loss: 4.8670 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8313 - accuracy: 0.0156 - val_loss: 4.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7003 - accuracy: 0.0156 - val_loss: 4.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7094 - accuracy: 0.0156 - val_loss: 4.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8702 - accuracy: 0.0156 - val_loss: 4.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6777 - accuracy: 0.0078 - val_loss: 4.9468 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8823 - accuracy: 0.0391 - val_loss: 4.9004 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7277 - accuracy: 0.0156 - val_loss: 4.8555 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7273 - accuracy: 0.0234 - val_loss: 4.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8106 - accuracy: 0.0469 - val_loss: 4.8156 - val_accuracy: 0.0078\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7260 - accuracy: 0.0234 - val_loss: 4.8126 - val_accuracy: 0.0078\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5599 - accuracy: 0.0547 - val_loss: 4.8335 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7321 - accuracy: 0.0312 - val_loss: 4.8864 - val_accuracy: 0.0078\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6878 - accuracy: 0.0000e+00 - val_loss: 4.9292 - val_accuracy: 0.0078\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8703 - accuracy: 0.0312 - val_loss: 4.9037 - val_accuracy: 0.0078\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8591 - accuracy: 0.0156 - val_loss: 4.8834 - val_accuracy: 0.0078\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9361 - accuracy: 0.0000e+00 - val_loss: 4.8717 - val_accuracy: 0.0078\n",
      "Epoch 00233: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=27228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=27228\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 504ms/step - loss: 5.6142 - accuracy: 0.0000e+00 - val_loss: 5.5436 - val_accuracy: 0.0625\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.5671 - accuracy: 0.0078 - val_loss: 5.5436 - val_accuracy: 0.0078\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.5882 - accuracy: 0.0000e+00 - val_loss: 5.5414 - val_accuracy: 0.0078\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.5155 - accuracy: 0.0234 - val_loss: 5.5377 - val_accuracy: 0.0078\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.5068 - accuracy: 0.0078 - val_loss: 5.5342 - val_accuracy: 0.0078\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.5427 - accuracy: 0.0156 - val_loss: 5.5312 - val_accuracy: 0.0078\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5165 - accuracy: 0.0156 - val_loss: 5.5287 - val_accuracy: 0.0078\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.5342 - accuracy: 0.0000e+00 - val_loss: 5.5250 - val_accuracy: 0.0078\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.4320 - accuracy: 0.0078 - val_loss: 5.5189 - val_accuracy: 0.0078\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.5019 - accuracy: 0.0078 - val_loss: 5.5128 - val_accuracy: 0.0078\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4572 - accuracy: 0.0391 - val_loss: 5.5082 - val_accuracy: 0.0078\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4517 - accuracy: 0.0234 - val_loss: 5.5045 - val_accuracy: 0.0078\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4791 - accuracy: 0.0078 - val_loss: 5.5007 - val_accuracy: 0.0078\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4477 - accuracy: 0.0156 - val_loss: 5.4967 - val_accuracy: 0.0078\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4216 - accuracy: 0.0078 - val_loss: 5.4934 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4076 - accuracy: 0.0234 - val_loss: 5.4904 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4032 - accuracy: 0.0078 - val_loss: 5.4860 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3751 - accuracy: 0.0078 - val_loss: 5.4799 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4384 - accuracy: 0.0234 - val_loss: 5.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4508 - accuracy: 0.0312 - val_loss: 5.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4053 - accuracy: 0.0000e+00 - val_loss: 5.4681 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3393 - accuracy: 0.0391 - val_loss: 5.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3963 - accuracy: 0.0312 - val_loss: 5.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4070 - accuracy: 0.0078 - val_loss: 5.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4592 - accuracy: 0.0000e+00 - val_loss: 5.4559 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.4002 - accuracy: 0.0078 - val_loss: 5.4536 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2931 - accuracy: 0.0391 - val_loss: 5.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.3769 - accuracy: 0.0156 - val_loss: 5.4461 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2974 - accuracy: 0.0312 - val_loss: 5.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3890 - accuracy: 0.0078 - val_loss: 5.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3044 - accuracy: 0.0312 - val_loss: 5.4288 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3703 - accuracy: 0.0078 - val_loss: 5.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3038 - accuracy: 0.0312 - val_loss: 5.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3437 - accuracy: 0.0312 - val_loss: 5.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3873 - accuracy: 0.0000e+00 - val_loss: 5.4307 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3060 - accuracy: 0.0234 - val_loss: 5.4304 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3587 - accuracy: 0.0078 - val_loss: 5.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2335 - accuracy: 0.0469 - val_loss: 5.4286 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3281 - accuracy: 0.0156 - val_loss: 5.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2501 - accuracy: 0.0312 - val_loss: 5.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2734 - accuracy: 0.0234 - val_loss: 5.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.3200 - accuracy: 0.0312 - val_loss: 5.4252 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3429 - accuracy: 0.0078 - val_loss: 5.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2387 - accuracy: 0.0312 - val_loss: 5.4079 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2222 - accuracy: 0.0703 - val_loss: 5.3959 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3408 - accuracy: 0.0078 - val_loss: 5.3886 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2992 - accuracy: 0.0234 - val_loss: 5.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.2049 - accuracy: 0.0312 - val_loss: 5.3945 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2240 - accuracy: 0.0234 - val_loss: 5.3899 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2462 - accuracy: 0.0078 - val_loss: 5.3873 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2450 - accuracy: 0.0312 - val_loss: 5.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2280 - accuracy: 0.0234 - val_loss: 5.3860 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1491 - accuracy: 0.0234 - val_loss: 5.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2205 - accuracy: 0.0312 - val_loss: 5.3753 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2329 - accuracy: 0.0078 - val_loss: 5.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1611 - accuracy: 0.0391 - val_loss: 5.3606 - val_accuracy: 0.0078\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1730 - accuracy: 0.0312 - val_loss: 5.3572 - val_accuracy: 0.0078\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2655 - accuracy: 0.0078 - val_loss: 5.3587 - val_accuracy: 0.0078\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1886 - accuracy: 0.0234 - val_loss: 5.3598 - val_accuracy: 0.0078\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1547 - accuracy: 0.0312 - val_loss: 5.3644 - val_accuracy: 0.0078\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2004 - accuracy: 0.0312 - val_loss: 5.3573 - val_accuracy: 0.0078\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2006 - accuracy: 0.0234 - val_loss: 5.3487 - val_accuracy: 0.0078\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1815 - accuracy: 0.0391 - val_loss: 5.3390 - val_accuracy: 0.0078\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.2909 - accuracy: 0.0234 - val_loss: 5.3260 - val_accuracy: 0.0078\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1522 - accuracy: 0.0312 - val_loss: 5.3120 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1780 - accuracy: 0.0156 - val_loss: 5.2929 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0088 - accuracy: 0.0312 - val_loss: 5.2707 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0911 - accuracy: 0.0156 - val_loss: 5.2427 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2162 - accuracy: 0.0312 - val_loss: 5.2209 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1045 - accuracy: 0.0234 - val_loss: 5.2076 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2390 - accuracy: 0.0312 - val_loss: 5.1977 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1619 - accuracy: 0.0156 - val_loss: 5.1931 - val_accuracy: 0.0625\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0554 - accuracy: 0.0234 - val_loss: 5.1931 - val_accuracy: 0.0703\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1214 - accuracy: 0.0781 - val_loss: 5.1880 - val_accuracy: 0.0781\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1785 - accuracy: 0.0312 - val_loss: 5.1641 - val_accuracy: 0.0859\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 101ms/step - loss: 5.0870 - accuracy: 0.0156 - val_loss: 5.1484 - val_accuracy: 0.1328\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2213 - accuracy: 0.0625 - val_loss: 5.1438 - val_accuracy: 0.1328\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9696 - accuracy: 0.0469 - val_loss: 5.1466 - val_accuracy: 0.1328\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1299 - accuracy: 0.0078 - val_loss: 5.1577 - val_accuracy: 0.1406\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1327 - accuracy: 0.0391 - val_loss: 5.1710 - val_accuracy: 0.1328\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.1814 - accuracy: 0.0156 - val_loss: 5.1801 - val_accuracy: 0.1094\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9559 - accuracy: 0.0625 - val_loss: 5.1846 - val_accuracy: 0.1172\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0663 - accuracy: 0.0547 - val_loss: 5.1731 - val_accuracy: 0.1172\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8799 - accuracy: 0.0859 - val_loss: 5.1693 - val_accuracy: 0.1250\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.1241 - accuracy: 0.0234 - val_loss: 5.1614 - val_accuracy: 0.0938\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0604 - accuracy: 0.0312 - val_loss: 5.1409 - val_accuracy: 0.0703\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9099 - accuracy: 0.0781 - val_loss: 5.1141 - val_accuracy: 0.0312\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1842 - accuracy: 0.0000e+00 - val_loss: 5.0944 - val_accuracy: 0.0312\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0279 - accuracy: 0.0391 - val_loss: 5.0772 - val_accuracy: 0.0469\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9791 - accuracy: 0.0156 - val_loss: 5.0696 - val_accuracy: 0.0625\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0292 - accuracy: 0.0547 - val_loss: 5.0724 - val_accuracy: 0.0469\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1190 - accuracy: 0.0078 - val_loss: 5.0803 - val_accuracy: 0.0469\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0008 - accuracy: 0.0156 - val_loss: 5.0892 - val_accuracy: 0.0469\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9614 - accuracy: 0.0703 - val_loss: 5.0945 - val_accuracy: 0.0859\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1315 - accuracy: 0.0156 - val_loss: 5.0919 - val_accuracy: 0.1172\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1866 - accuracy: 0.0234 - val_loss: 5.0965 - val_accuracy: 0.1328\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1119 - accuracy: 0.0391 - val_loss: 5.1067 - val_accuracy: 0.1172\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1100 - accuracy: 0.0312 - val_loss: 5.1158 - val_accuracy: 0.1094\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1580 - accuracy: 0.0234 - val_loss: 5.1202 - val_accuracy: 0.0625\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1809 - accuracy: 0.0156 - val_loss: 5.1162 - val_accuracy: 0.0625\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1052 - accuracy: 0.0078 - val_loss: 5.1127 - val_accuracy: 0.0625\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0058 - accuracy: 0.0547 - val_loss: 5.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.1488 - accuracy: 0.0391 - val_loss: 5.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0515 - accuracy: 0.0000e+00 - val_loss: 5.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9260 - accuracy: 0.0469 - val_loss: 5.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8515 - accuracy: 0.0469 - val_loss: 5.0300 - val_accuracy: 0.0391\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9938 - accuracy: 0.0312 - val_loss: 5.0028 - val_accuracy: 0.1328\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8890 - accuracy: 0.0469 - val_loss: 4.9782 - val_accuracy: 0.1484\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9192 - accuracy: 0.0156 - val_loss: 4.9623 - val_accuracy: 0.1484\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0446 - accuracy: 0.0234 - val_loss: 4.9689 - val_accuracy: 0.1406\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7905 - accuracy: 0.0391 - val_loss: 4.9774 - val_accuracy: 0.1172\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1440 - accuracy: 0.0234 - val_loss: 4.9802 - val_accuracy: 0.0547\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9469 - accuracy: 0.0312 - val_loss: 4.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8390 - accuracy: 0.0469 - val_loss: 4.9706 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.0596 - accuracy: 0.0312 - val_loss: 4.9702 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1167 - accuracy: 0.0547 - val_loss: 4.9767 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9455 - accuracy: 0.0078 - val_loss: 4.9929 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0156 - accuracy: 0.0078 - val_loss: 5.0083 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8871 - accuracy: 0.0781 - val_loss: 5.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0391 - accuracy: 0.0234 - val_loss: 5.0169 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9456 - accuracy: 0.0391 - val_loss: 5.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.0025 - accuracy: 0.0547 - val_loss: 5.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9578 - accuracy: 0.0391 - val_loss: 5.0145 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9670 - accuracy: 0.0234 - val_loss: 5.0177 - val_accuracy: 0.0078\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9031 - accuracy: 0.0312 - val_loss: 5.0109 - val_accuracy: 0.0078\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9944 - accuracy: 0.0391 - val_loss: 5.0080 - val_accuracy: 0.0078\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9329 - accuracy: 0.0078 - val_loss: 5.0053 - val_accuracy: 0.0078\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7725 - accuracy: 0.0469 - val_loss: 4.9982 - val_accuracy: 0.0078\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9212 - accuracy: 0.0469 - val_loss: 5.0043 - val_accuracy: 0.0078\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8598 - accuracy: 0.0547 - val_loss: 5.0081 - val_accuracy: 0.0078\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0449 - accuracy: 0.0156 - val_loss: 5.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9972 - accuracy: 0.0078 - val_loss: 5.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8382 - accuracy: 0.0469 - val_loss: 4.9986 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0246 - accuracy: 0.0312 - val_loss: 4.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0503 - accuracy: 0.0234 - val_loss: 4.9830 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0340 - accuracy: 0.0391 - val_loss: 4.9906 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1608 - accuracy: 0.0156 - val_loss: 5.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8418 - accuracy: 0.0391 - val_loss: 5.0269 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8331 - accuracy: 0.0234 - val_loss: 5.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0729 - accuracy: 0.0391 - val_loss: 5.0255 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8667 - accuracy: 0.0234 - val_loss: 5.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0267 - accuracy: 0.0000e+00 - val_loss: 4.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9440 - accuracy: 0.0234 - val_loss: 4.9936 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8967 - accuracy: 0.0078 - val_loss: 4.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0919 - accuracy: 0.0156 - val_loss: 4.9876 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0163 - accuracy: 0.0391 - val_loss: 4.9815 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8562 - accuracy: 0.0391 - val_loss: 4.9583 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8621 - accuracy: 0.0078 - val_loss: 4.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0373 - accuracy: 0.0156 - val_loss: 4.8986 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7984 - accuracy: 0.0234 - val_loss: 4.8762 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9207 - accuracy: 0.0391 - val_loss: 4.8542 - val_accuracy: 0.0078\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8243 - accuracy: 0.0547 - val_loss: 4.8331 - val_accuracy: 0.0078\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8357 - accuracy: 0.0625 - val_loss: 4.8109 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1873 - accuracy: 0.0000e+00 - val_loss: 4.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7264 - accuracy: 0.0391 - val_loss: 4.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9898 - accuracy: 0.0156 - val_loss: 4.7715 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0625 - accuracy: 0.0000e+00 - val_loss: 4.7671 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9941 - accuracy: 0.0234 - val_loss: 4.7641 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8542 - accuracy: 0.0156 - val_loss: 4.7703 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0342 - accuracy: 0.0469 - val_loss: 4.7564 - val_accuracy: 0.0078\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9361 - accuracy: 0.0156 - val_loss: 4.7267 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.9810 - accuracy: 0.0234 - val_loss: 4.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9281 - accuracy: 0.0312 - val_loss: 4.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8846 - accuracy: 0.0547 - val_loss: 4.7156 - val_accuracy: 0.0078\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1810 - accuracy: 0.0156 - val_loss: 4.7218 - val_accuracy: 0.0078\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7489 - accuracy: 0.0156 - val_loss: 4.7182 - val_accuracy: 0.0078\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9702 - accuracy: 0.0078 - val_loss: 4.7217 - val_accuracy: 0.0234\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9583 - accuracy: 0.0000e+00 - val_loss: 4.7405 - val_accuracy: 0.0312\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9679 - accuracy: 0.0000e+00 - val_loss: 4.7607 - val_accuracy: 0.0469\n",
      "Epoch 170/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9554 - accuracy: 0.0078 - val_loss: 4.7793 - val_accuracy: 0.0625\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8947 - accuracy: 0.0391 - val_loss: 4.8057 - val_accuracy: 0.0469\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8876 - accuracy: 0.0078 - val_loss: 4.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8822 - accuracy: 0.0312 - val_loss: 4.8381 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9120 - accuracy: 0.0391 - val_loss: 4.8337 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9735 - accuracy: 0.0391 - val_loss: 4.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8373 - accuracy: 0.0469 - val_loss: 4.8073 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1456 - accuracy: 0.0234 - val_loss: 4.7998 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8269 - accuracy: 0.0469 - val_loss: 4.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9305 - accuracy: 0.0234 - val_loss: 4.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9070 - accuracy: 0.0156 - val_loss: 4.7701 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9259 - accuracy: 0.0391 - val_loss: 4.7467 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9725 - accuracy: 0.0391 - val_loss: 4.7384 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9960 - accuracy: 0.0078 - val_loss: 4.7449 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8638 - accuracy: 0.0078 - val_loss: 4.7191 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9073 - accuracy: 0.0078 - val_loss: 4.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9411 - accuracy: 0.0234 - val_loss: 4.6975 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9094 - accuracy: 0.0234 - val_loss: 4.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9287 - accuracy: 0.0391 - val_loss: 4.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8863 - accuracy: 0.0078 - val_loss: 4.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9135 - accuracy: 0.0078 - val_loss: 4.6511 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9704 - accuracy: 0.0156 - val_loss: 4.6214 - val_accuracy: 0.0312\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7924 - accuracy: 0.0469 - val_loss: 4.6138 - val_accuracy: 0.0312\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9200 - accuracy: 0.0156 - val_loss: 4.6177 - val_accuracy: 0.0156\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8313 - accuracy: 0.0156 - val_loss: 4.6175 - val_accuracy: 0.0156\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8515 - accuracy: 0.0312 - val_loss: 4.6231 - val_accuracy: 0.0156\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0895 - accuracy: 0.0234 - val_loss: 4.6353 - val_accuracy: 0.0156\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9247 - accuracy: 0.0469 - val_loss: 4.6415 - val_accuracy: 0.0234\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8624 - accuracy: 0.0469 - val_loss: 4.6351 - val_accuracy: 0.0312\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9008 - accuracy: 0.0391 - val_loss: 4.6289 - val_accuracy: 0.0391\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6633 - accuracy: 0.0781 - val_loss: 4.6194 - val_accuracy: 0.0547\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8730 - accuracy: 0.0469 - val_loss: 4.6161 - val_accuracy: 0.0703\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8377 - accuracy: 0.0703 - val_loss: 4.6144 - val_accuracy: 0.1016\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7693 - accuracy: 0.0781 - val_loss: 4.5951 - val_accuracy: 0.1484\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1339 - accuracy: 0.0000e+00 - val_loss: 4.5886 - val_accuracy: 0.1484\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8308 - accuracy: 0.0312 - val_loss: 4.5950 - val_accuracy: 0.1328\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7955 - accuracy: 0.0078 - val_loss: 4.5947 - val_accuracy: 0.0859\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9444 - accuracy: 0.0156 - val_loss: 4.5970 - val_accuracy: 0.0234\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8413 - accuracy: 0.0156 - val_loss: 4.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8553 - accuracy: 0.0312 - val_loss: 4.6038 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9476 - accuracy: 0.0000e+00 - val_loss: 4.6140 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8313 - accuracy: 0.0234 - val_loss: 4.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8508 - accuracy: 0.0234 - val_loss: 4.6393 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7798 - accuracy: 0.0156 - val_loss: 4.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8084 - accuracy: 0.0469 - val_loss: 4.6232 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8729 - accuracy: 0.0156 - val_loss: 4.6056 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0162 - accuracy: 0.0156 - val_loss: 4.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7944 - accuracy: 0.0391 - val_loss: 4.6093 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8259 - accuracy: 0.0234 - val_loss: 4.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8645 - accuracy: 0.0078 - val_loss: 4.5960 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9299 - accuracy: 0.0625 - val_loss: 4.6035 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9641 - accuracy: 0.0156 - val_loss: 4.6114 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7649 - accuracy: 0.0391 - val_loss: 4.6210 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7717 - accuracy: 0.0156 - val_loss: 4.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8648 - accuracy: 0.0234 - val_loss: 4.6263 - val_accuracy: 0.0078\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6602 - accuracy: 0.0312 - val_loss: 4.6209 - val_accuracy: 0.0078\n",
      "Epoch 226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9864 - accuracy: 0.0234 - val_loss: 4.6145 - val_accuracy: 0.0078\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8874 - accuracy: 0.0391 - val_loss: 4.6230 - val_accuracy: 0.0078\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7543 - accuracy: 0.0312 - val_loss: 4.6212 - val_accuracy: 0.0156\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8490 - accuracy: 0.0156 - val_loss: 4.6186 - val_accuracy: 0.0312\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9119 - accuracy: 0.0312 - val_loss: 4.6287 - val_accuracy: 0.0391\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7362 - accuracy: 0.0625 - val_loss: 4.6493 - val_accuracy: 0.0312\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8257 - accuracy: 0.0391 - val_loss: 4.6694 - val_accuracy: 0.0312\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8365 - accuracy: 0.0312 - val_loss: 4.6598 - val_accuracy: 0.0234\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7005 - accuracy: 0.0156 - val_loss: 4.6534 - val_accuracy: 0.0234\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1063 - accuracy: 0.0156 - val_loss: 4.6457 - val_accuracy: 0.0234\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8450 - accuracy: 0.0391 - val_loss: 4.6537 - val_accuracy: 0.0156\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9093 - accuracy: 0.0312 - val_loss: 4.6466 - val_accuracy: 0.0156\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8757 - accuracy: 0.0078 - val_loss: 4.6427 - val_accuracy: 0.0078\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7000 - accuracy: 0.0312 - val_loss: 4.6417 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6926 - accuracy: 0.0703 - val_loss: 4.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8310 - accuracy: 0.0234 - val_loss: 4.6632 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6467 - accuracy: 0.1016 - val_loss: 4.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7572 - accuracy: 0.0234 - val_loss: 4.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7103 - accuracy: 0.0312 - val_loss: 4.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8670 - accuracy: 0.0391 - val_loss: 4.7191 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8555 - accuracy: 0.0547 - val_loss: 4.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6336 - accuracy: 0.0469 - val_loss: 4.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9285 - accuracy: 0.0469 - val_loss: 4.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6481 - accuracy: 0.0703 - val_loss: 4.7351 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7100 - accuracy: 0.0391 - val_loss: 4.7262 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9074 - accuracy: 0.0234 - val_loss: 4.7111 - val_accuracy: 0.0156\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7652 - accuracy: 0.0469 - val_loss: 4.7068 - val_accuracy: 0.0234\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8012 - accuracy: 0.0391 - val_loss: 4.6993 - val_accuracy: 0.0625\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9801 - accuracy: 0.0391 - val_loss: 4.6884 - val_accuracy: 0.0781\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8804 - accuracy: 0.0078 - val_loss: 4.6750 - val_accuracy: 0.0859\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7689 - accuracy: 0.0312 - val_loss: 4.6702 - val_accuracy: 0.0625\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6078 - accuracy: 0.0391 - val_loss: 4.6695 - val_accuracy: 0.0547\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9460 - accuracy: 0.0391 - val_loss: 4.6708 - val_accuracy: 0.0547\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8042 - accuracy: 0.0312 - val_loss: 4.6799 - val_accuracy: 0.0547\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9001 - accuracy: 0.0391 - val_loss: 4.6722 - val_accuracy: 0.0547\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8617 - accuracy: 0.0469 - val_loss: 4.6720 - val_accuracy: 0.0547\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9100 - accuracy: 0.0156 - val_loss: 4.6823 - val_accuracy: 0.0625\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8321 - accuracy: 0.0156 - val_loss: 4.7058 - val_accuracy: 0.0469\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8757 - accuracy: 0.0000e+00 - val_loss: 4.7143 - val_accuracy: 0.0469\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9065 - accuracy: 0.0078 - val_loss: 4.7009 - val_accuracy: 0.0156\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7839 - accuracy: 0.0312 - val_loss: 4.6981 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6873 - accuracy: 0.0469 - val_loss: 4.6840 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7861 - accuracy: 0.0234 - val_loss: 4.6516 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7282 - accuracy: 0.0234 - val_loss: 4.6141 - val_accuracy: 0.0781\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6578 - accuracy: 0.0156 - val_loss: 4.5833 - val_accuracy: 0.1562\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8494 - accuracy: 0.0078 - val_loss: 4.5670 - val_accuracy: 0.1641\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7160 - accuracy: 0.0234 - val_loss: 4.5508 - val_accuracy: 0.1641\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7467 - accuracy: 0.0391 - val_loss: 4.5476 - val_accuracy: 0.1641\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6916 - accuracy: 0.0234 - val_loss: 4.5493 - val_accuracy: 0.1641\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6898 - accuracy: 0.0547 - val_loss: 4.5609 - val_accuracy: 0.1641\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6511 - accuracy: 0.0469 - val_loss: 4.5691 - val_accuracy: 0.1641\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7198 - accuracy: 0.0312 - val_loss: 4.5705 - val_accuracy: 0.1484\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8611 - accuracy: 0.0312 - val_loss: 4.5477 - val_accuracy: 0.1562\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7217 - accuracy: 0.0469 - val_loss: 4.5366 - val_accuracy: 0.1250\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6348 - accuracy: 0.1094 - val_loss: 4.5356 - val_accuracy: 0.0234\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9597 - accuracy: 0.0312 - val_loss: 4.5418 - val_accuracy: 0.0078\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9508 - accuracy: 0.0391 - val_loss: 4.5519 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7819 - accuracy: 0.0000e+00 - val_loss: 4.5673 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7330 - accuracy: 0.0234 - val_loss: 4.5565 - val_accuracy: 0.0312\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8841 - accuracy: 0.0156 - val_loss: 4.5552 - val_accuracy: 0.0547\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6267 - accuracy: 0.0547 - val_loss: 4.5579 - val_accuracy: 0.0703\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8790 - accuracy: 0.0078 - val_loss: 4.5634 - val_accuracy: 0.1016\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7762 - accuracy: 0.0469 - val_loss: 4.5692 - val_accuracy: 0.1562\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8104 - accuracy: 0.0234 - val_loss: 4.5747 - val_accuracy: 0.1641\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6507 - accuracy: 0.0703 - val_loss: 4.5854 - val_accuracy: 0.1172\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8877 - accuracy: 0.0391 - val_loss: 4.5965 - val_accuracy: 0.0078\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8659 - accuracy: 0.0312 - val_loss: 4.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6602 - accuracy: 0.0312 - val_loss: 4.6246 - val_accuracy: 0.0078\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7551 - accuracy: 0.0312 - val_loss: 4.6416 - val_accuracy: 0.0234\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8106 - accuracy: 0.0000e+00 - val_loss: 4.6419 - val_accuracy: 0.0547\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7017 - accuracy: 0.0312 - val_loss: 4.6419 - val_accuracy: 0.0547\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9348 - accuracy: 0.0000e+00 - val_loss: 4.6227 - val_accuracy: 0.0703\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6452 - accuracy: 0.0547 - val_loss: 4.6094 - val_accuracy: 0.1094\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9429 - accuracy: 0.0078 - val_loss: 4.6020 - val_accuracy: 0.0938\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7772 - accuracy: 0.0000e+00 - val_loss: 4.5696 - val_accuracy: 0.1250\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7828 - accuracy: 0.0156 - val_loss: 4.5536 - val_accuracy: 0.1094\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0316 - accuracy: 0.0078 - val_loss: 4.5494 - val_accuracy: 0.1406\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8793 - accuracy: 0.0234 - val_loss: 4.5499 - val_accuracy: 0.1562\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8205 - accuracy: 0.0234 - val_loss: 4.5349 - val_accuracy: 0.1641\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6532 - accuracy: 0.0234 - val_loss: 4.5227 - val_accuracy: 0.1641\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6882 - accuracy: 0.0703 - val_loss: 4.5109 - val_accuracy: 0.1641\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8267 - accuracy: 0.0000e+00 - val_loss: 4.5092 - val_accuracy: 0.1250\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8194 - accuracy: 0.0234 - val_loss: 4.5083 - val_accuracy: 0.1094\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6793 - accuracy: 0.0234 - val_loss: 4.5002 - val_accuracy: 0.1328\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9731 - accuracy: 0.0156 - val_loss: 4.5032 - val_accuracy: 0.1328\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6949 - accuracy: 0.0625 - val_loss: 4.5115 - val_accuracy: 0.1328\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8046 - accuracy: 0.0234 - val_loss: 4.5211 - val_accuracy: 0.1250\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7335 - accuracy: 0.0156 - val_loss: 4.5272 - val_accuracy: 0.1406\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9036 - accuracy: 0.0078 - val_loss: 4.5289 - val_accuracy: 0.1406\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7906 - accuracy: 0.0156 - val_loss: 4.5364 - val_accuracy: 0.1406\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8172 - accuracy: 0.0703 - val_loss: 4.5485 - val_accuracy: 0.1406\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.9407 - accuracy: 0.0078 - val_loss: 4.5660 - val_accuracy: 0.1406\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7579 - accuracy: 0.0156 - val_loss: 4.5768 - val_accuracy: 0.1484\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8949 - accuracy: 0.0391 - val_loss: 4.5785 - val_accuracy: 0.1641\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7014 - accuracy: 0.0234 - val_loss: 4.5879 - val_accuracy: 0.1641\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8169 - accuracy: 0.0312 - val_loss: 4.5939 - val_accuracy: 0.1641\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7860 - accuracy: 0.0391 - val_loss: 4.5977 - val_accuracy: 0.1641\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7469 - accuracy: 0.0156 - val_loss: 4.6083 - val_accuracy: 0.1641\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7290 - accuracy: 0.0469 - val_loss: 4.6252 - val_accuracy: 0.1641\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9203 - accuracy: 0.0234 - val_loss: 4.6417 - val_accuracy: 0.1641\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7789 - accuracy: 0.0625 - val_loss: 4.6630 - val_accuracy: 0.1562\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8450 - accuracy: 0.0156 - val_loss: 4.6832 - val_accuracy: 0.1250\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8390 - accuracy: 0.0391 - val_loss: 4.6837 - val_accuracy: 0.1016\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8044 - accuracy: 0.0391 - val_loss: 4.6889 - val_accuracy: 0.0391\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8053 - accuracy: 0.0156 - val_loss: 4.6967 - val_accuracy: 0.0312\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7195 - accuracy: 0.0078 - val_loss: 4.6981 - val_accuracy: 0.0703\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9430 - accuracy: 0.0156 - val_loss: 4.6840 - val_accuracy: 0.1406\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7094 - accuracy: 0.0234 - val_loss: 4.6692 - val_accuracy: 0.1641\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8198 - accuracy: 0.0312 - val_loss: 4.6547 - val_accuracy: 0.1641\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8140 - accuracy: 0.0469 - val_loss: 4.6371 - val_accuracy: 0.1641\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7908 - accuracy: 0.0234 - val_loss: 4.6247 - val_accuracy: 0.1641\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6864 - accuracy: 0.0312 - val_loss: 4.6127 - val_accuracy: 0.1641\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7981 - accuracy: 0.0156 - val_loss: 4.6057 - val_accuracy: 0.1641\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7390 - accuracy: 0.0234 - val_loss: 4.5928 - val_accuracy: 0.1641\n",
      "Epoch 340/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8876 - accuracy: 0.0234 - val_loss: 4.5951 - val_accuracy: 0.1641\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8467 - accuracy: 0.0000e+00 - val_loss: 4.6057 - val_accuracy: 0.1641\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6414 - accuracy: 0.0312 - val_loss: 4.6115 - val_accuracy: 0.1641\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8592 - accuracy: 0.0234 - val_loss: 4.6076 - val_accuracy: 0.1641\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0047 - accuracy: 0.0391 - val_loss: 4.5766 - val_accuracy: 0.1641\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8176 - accuracy: 0.0391 - val_loss: 4.5558 - val_accuracy: 0.1641\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8913 - accuracy: 0.0156 - val_loss: 4.5424 - val_accuracy: 0.1641\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7899 - accuracy: 0.0234 - val_loss: 4.5403 - val_accuracy: 0.1641\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9401 - accuracy: 0.0156 - val_loss: 4.5481 - val_accuracy: 0.1641\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8214 - accuracy: 0.0234 - val_loss: 4.5582 - val_accuracy: 0.1641\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9175 - accuracy: 0.0312 - val_loss: 4.5717 - val_accuracy: 0.1641\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7131 - accuracy: 0.0547 - val_loss: 4.5815 - val_accuracy: 0.1641\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6872 - accuracy: 0.0625 - val_loss: 4.5714 - val_accuracy: 0.1641\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7194 - accuracy: 0.0156 - val_loss: 4.5633 - val_accuracy: 0.1641\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7893 - accuracy: 0.0234 - val_loss: 4.5634 - val_accuracy: 0.1641\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6852 - accuracy: 0.0625 - val_loss: 4.5755 - val_accuracy: 0.1641\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8161 - accuracy: 0.0469 - val_loss: 4.5918 - val_accuracy: 0.1641\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6460 - accuracy: 0.0391 - val_loss: 4.6049 - val_accuracy: 0.1641\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8308 - accuracy: 0.0234 - val_loss: 4.6239 - val_accuracy: 0.1641\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8359 - accuracy: 0.0156 - val_loss: 4.6479 - val_accuracy: 0.1562\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6011 - accuracy: 0.0938 - val_loss: 4.6751 - val_accuracy: 0.1406\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7573 - accuracy: 0.0000e+00 - val_loss: 4.6952 - val_accuracy: 0.1250\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.7526 - accuracy: 0.0469 - val_loss: 4.6919 - val_accuracy: 0.1406\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9122 - accuracy: 0.0000e+00 - val_loss: 4.6761 - val_accuracy: 0.1641\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6544 - accuracy: 0.0547 - val_loss: 4.6572 - val_accuracy: 0.1641\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7160 - accuracy: 0.0703 - val_loss: 4.6288 - val_accuracy: 0.1641\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6563 - accuracy: 0.0156 - val_loss: 4.5921 - val_accuracy: 0.1641\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6773 - accuracy: 0.0078 - val_loss: 4.5726 - val_accuracy: 0.1641\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6772 - accuracy: 0.0938 - val_loss: 4.5675 - val_accuracy: 0.1641\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8096 - accuracy: 0.0000e+00 - val_loss: 4.5700 - val_accuracy: 0.1641\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0015 - accuracy: 0.0078 - val_loss: 4.5755 - val_accuracy: 0.1641\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6833 - accuracy: 0.0234 - val_loss: 4.5724 - val_accuracy: 0.1641\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6825 - accuracy: 0.0312 - val_loss: 4.5633 - val_accuracy: 0.1641\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6322 - accuracy: 0.0547 - val_loss: 4.5454 - val_accuracy: 0.1641\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9481 - accuracy: 0.0156 - val_loss: 4.5410 - val_accuracy: 0.1641\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9910 - accuracy: 0.0078 - val_loss: 4.5472 - val_accuracy: 0.1641\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9321 - accuracy: 0.0000e+00 - val_loss: 4.5553 - val_accuracy: 0.1641\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8929 - accuracy: 0.0156 - val_loss: 4.5646 - val_accuracy: 0.1641\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7259 - accuracy: 0.0312 - val_loss: 4.5633 - val_accuracy: 0.1641\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8577 - accuracy: 0.0156 - val_loss: 4.5708 - val_accuracy: 0.1641\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7768 - accuracy: 0.0000e+00 - val_loss: 4.5875 - val_accuracy: 0.1641\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8250 - accuracy: 0.0156 - val_loss: 4.6076 - val_accuracy: 0.1641\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8756 - accuracy: 0.0156 - val_loss: 4.6232 - val_accuracy: 0.1641\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7582 - accuracy: 0.0156 - val_loss: 4.6258 - val_accuracy: 0.1641\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7303 - accuracy: 0.0156 - val_loss: 4.6339 - val_accuracy: 0.1641\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9118 - accuracy: 0.0156 - val_loss: 4.6487 - val_accuracy: 0.1562\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7450 - accuracy: 0.0156 - val_loss: 4.6612 - val_accuracy: 0.1484\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8570 - accuracy: 0.0234 - val_loss: 4.6727 - val_accuracy: 0.1406\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8634 - accuracy: 0.0469 - val_loss: 4.6871 - val_accuracy: 0.1484\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7747 - accuracy: 0.0234 - val_loss: 4.6984 - val_accuracy: 0.1406\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6324 - accuracy: 0.0234 - val_loss: 4.6885 - val_accuracy: 0.1562\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0083 - accuracy: 0.0312 - val_loss: 4.6827 - val_accuracy: 0.1562\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7945 - accuracy: 0.0312 - val_loss: 4.6708 - val_accuracy: 0.1562\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8189 - accuracy: 0.0469 - val_loss: 4.6649 - val_accuracy: 0.1562\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6234 - accuracy: 0.0234 - val_loss: 4.6578 - val_accuracy: 0.1094\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8001 - accuracy: 0.0312 - val_loss: 4.6556 - val_accuracy: 0.0547\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6877 - accuracy: 0.0156 - val_loss: 4.6576 - val_accuracy: 0.0391\n",
      "Epoch 397/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9905 - accuracy: 0.0234 - val_loss: 4.6698 - val_accuracy: 0.0312\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6352 - accuracy: 0.0391 - val_loss: 4.6924 - val_accuracy: 0.0234\n",
      "Epoch 399/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6294 - accuracy: 0.0234 - val_loss: 4.7152 - val_accuracy: 0.0078\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6395 - accuracy: 0.0156 - val_loss: 4.7340 - val_accuracy: 0.0078\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6894 - accuracy: 0.0000e+00 - val_loss: 4.7538 - val_accuracy: 0.0078\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8075 - accuracy: 0.0234 - val_loss: 4.7701 - val_accuracy: 0.0078\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8678 - accuracy: 0.0156 - val_loss: 4.7749 - val_accuracy: 0.0078\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7336 - accuracy: 0.0312 - val_loss: 4.7790 - val_accuracy: 0.0234\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7285 - accuracy: 0.0312 - val_loss: 4.7836 - val_accuracy: 0.0078\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7359 - accuracy: 0.0156 - val_loss: 4.7845 - val_accuracy: 0.0078\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7737 - accuracy: 0.0391 - val_loss: 4.7854 - val_accuracy: 0.0078\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7334 - accuracy: 0.0234 - val_loss: 4.7899 - val_accuracy: 0.0078\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8971 - accuracy: 0.0156 - val_loss: 4.8002 - val_accuracy: 0.0078\n",
      "Epoch 00409: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 4)       24        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 4)       52        \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 4)       16        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 4)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 8)       168       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 8)       200       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 8)       0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 16)      656       \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 16)      784       \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 16)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 16)       1296      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 16)       784       \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 16)       64        \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 16)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 32)       2592      \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 32)       3104      \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 32)       5152      \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 32)       3104      \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 32)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      8448      \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,228\n",
      "Trainable params: 26,796\n",
      "Non-trainable params: 432\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=27228\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=89560\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 5.5884 - accuracy: 0.0078 - val_loss: 5.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.5471 - accuracy: 0.0000e+00 - val_loss: 5.5409 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.5342 - accuracy: 0.0156 - val_loss: 5.5367 - val_accuracy: 0.0156\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.5451 - accuracy: 0.0000e+00 - val_loss: 5.5303 - val_accuracy: 0.0156\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4822 - accuracy: 0.0078 - val_loss: 5.5242 - val_accuracy: 0.0156\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.4559 - accuracy: 0.0000e+00 - val_loss: 5.5187 - val_accuracy: 0.0156\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.4620 - accuracy: 0.0234 - val_loss: 5.5147 - val_accuracy: 0.0156\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.4534 - accuracy: 0.0156 - val_loss: 5.5130 - val_accuracy: 0.0156\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4987 - accuracy: 0.0000e+00 - val_loss: 5.5122 - val_accuracy: 0.0156\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3714 - accuracy: 0.0234 - val_loss: 5.5135 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3317 - accuracy: 0.0234 - val_loss: 5.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4524 - accuracy: 0.0000e+00 - val_loss: 5.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3905 - accuracy: 0.0078 - val_loss: 5.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4177 - accuracy: 0.0156 - val_loss: 5.5035 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3456 - accuracy: 0.0156 - val_loss: 5.4954 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3312 - accuracy: 0.0234 - val_loss: 5.4877 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3268 - accuracy: 0.0469 - val_loss: 5.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.2792 - accuracy: 0.0312 - val_loss: 5.4754 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2248 - accuracy: 0.0547 - val_loss: 5.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2961 - accuracy: 0.0078 - val_loss: 5.4584 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3135 - accuracy: 0.0234 - val_loss: 5.4520 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2688 - accuracy: 0.0391 - val_loss: 5.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3090 - accuracy: 0.0234 - val_loss: 5.4395 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3283 - accuracy: 0.0234 - val_loss: 5.4352 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.3062 - accuracy: 0.0078 - val_loss: 5.4309 - val_accuracy: 0.0078\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3381 - accuracy: 0.0078 - val_loss: 5.4149 - val_accuracy: 0.0078\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.2359 - accuracy: 0.0469 - val_loss: 5.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.2578 - accuracy: 0.0234 - val_loss: 5.3819 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1359 - accuracy: 0.0312 - val_loss: 5.3513 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2813 - accuracy: 0.0391 - val_loss: 5.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1905 - accuracy: 0.0234 - val_loss: 5.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8802 - accuracy: 0.0938 - val_loss: 5.3399 - val_accuracy: 0.0078\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1730 - accuracy: 0.0703 - val_loss: 5.3529 - val_accuracy: 0.0078\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1017 - accuracy: 0.0156 - val_loss: 5.3316 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2431 - accuracy: 0.0078 - val_loss: 5.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2136 - accuracy: 0.0078 - val_loss: 5.3139 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0854 - accuracy: 0.0469 - val_loss: 5.3172 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1911 - accuracy: 0.0234 - val_loss: 5.3306 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.2553 - accuracy: 0.0234 - val_loss: 5.3551 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1875 - accuracy: 0.0234 - val_loss: 5.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1102 - accuracy: 0.0234 - val_loss: 5.4117 - val_accuracy: 0.0078\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1849 - accuracy: 0.0078 - val_loss: 5.4009 - val_accuracy: 0.0078\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0977 - accuracy: 0.0078 - val_loss: 5.3563 - val_accuracy: 0.0078\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.1379 - accuracy: 0.0391 - val_loss: 5.2937 - val_accuracy: 0.0078\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0015 - accuracy: 0.0469 - val_loss: 5.2825 - val_accuracy: 0.0078\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1484 - accuracy: 0.0469 - val_loss: 5.2764 - val_accuracy: 0.0078\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0574 - accuracy: 0.0391 - val_loss: 5.2581 - val_accuracy: 0.0078\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0703 - accuracy: 0.0625 - val_loss: 5.2447 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0199 - accuracy: 0.0078 - val_loss: 5.2255 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9844 - accuracy: 0.0625 - val_loss: 5.2196 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8615 - accuracy: 0.0234 - val_loss: 5.2023 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8436 - accuracy: 0.0312 - val_loss: 5.1783 - val_accuracy: 0.0078\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0142 - accuracy: 0.0234 - val_loss: 5.0921 - val_accuracy: 0.0234\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9098 - accuracy: 0.0469 - val_loss: 5.0222 - val_accuracy: 0.0312\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9049 - accuracy: 0.0625 - val_loss: 4.9654 - val_accuracy: 0.0938\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9988 - accuracy: 0.0312 - val_loss: 4.9774 - val_accuracy: 0.0625\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9065 - accuracy: 0.0547 - val_loss: 5.0842 - val_accuracy: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0028 - accuracy: 0.0234 - val_loss: 5.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1090 - accuracy: 0.0312 - val_loss: 5.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9710 - accuracy: 0.0234 - val_loss: 5.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8222 - accuracy: 0.0547 - val_loss: 5.3404 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9204 - accuracy: 0.0391 - val_loss: 5.2754 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9612 - accuracy: 0.0312 - val_loss: 5.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8977 - accuracy: 0.0391 - val_loss: 5.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9747 - accuracy: 0.0156 - val_loss: 5.1563 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.1776 - accuracy: 0.0156 - val_loss: 5.0705 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9726 - accuracy: 0.0469 - val_loss: 4.9947 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7245 - accuracy: 0.0859 - val_loss: 5.0067 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7340 - accuracy: 0.0547 - val_loss: 5.0463 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9319 - accuracy: 0.0625 - val_loss: 5.0591 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8394 - accuracy: 0.0234 - val_loss: 5.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9978 - accuracy: 0.0625 - val_loss: 5.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8642 - accuracy: 0.0312 - val_loss: 5.1090 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.9374 - accuracy: 0.0391 - val_loss: 5.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0216 - accuracy: 0.0078 - val_loss: 5.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8382 - accuracy: 0.0312 - val_loss: 5.1496 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7625 - accuracy: 0.0703 - val_loss: 5.1736 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6832 - accuracy: 0.0234 - val_loss: 5.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8547 - accuracy: 0.0234 - val_loss: 5.0463 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9080 - accuracy: 0.0312 - val_loss: 4.9484 - val_accuracy: 0.0156\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7918 - accuracy: 0.0625 - val_loss: 4.8883 - val_accuracy: 0.0547\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7423 - accuracy: 0.0156 - val_loss: 4.8902 - val_accuracy: 0.0859\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7918 - accuracy: 0.0469 - val_loss: 4.9480 - val_accuracy: 0.0859\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7699 - accuracy: 0.0625 - val_loss: 5.0080 - val_accuracy: 0.0938\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8252 - accuracy: 0.0312 - val_loss: 5.1224 - val_accuracy: 0.1016\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9324 - accuracy: 0.0234 - val_loss: 5.2014 - val_accuracy: 0.1094\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8436 - accuracy: 0.0312 - val_loss: 5.1817 - val_accuracy: 0.1094\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8345 - accuracy: 0.0859 - val_loss: 5.1392 - val_accuracy: 0.0938\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7037 - accuracy: 0.0391 - val_loss: 5.1048 - val_accuracy: 0.0625\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9357 - accuracy: 0.0234 - val_loss: 5.0822 - val_accuracy: 0.1172\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9612 - accuracy: 0.0234 - val_loss: 5.1371 - val_accuracy: 0.1172\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7567 - accuracy: 0.0156 - val_loss: 5.2168 - val_accuracy: 0.1250\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7597 - accuracy: 0.0547 - val_loss: 5.2778 - val_accuracy: 0.1094\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7939 - accuracy: 0.0391 - val_loss: 5.3201 - val_accuracy: 0.0781\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 94ms/step - loss: 4.8530 - accuracy: 0.0703 - val_loss: 5.2582 - val_accuracy: 0.0938\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5906 - accuracy: 0.0625 - val_loss: 5.2229 - val_accuracy: 0.0156\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7769 - accuracy: 0.0547 - val_loss: 5.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7142 - accuracy: 0.0703 - val_loss: 5.2932 - val_accuracy: 0.0078\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7833 - accuracy: 0.0391 - val_loss: 5.3322 - val_accuracy: 0.0078\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5074 - accuracy: 0.0781 - val_loss: 5.3442 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5393 - accuracy: 0.0625 - val_loss: 5.3076 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6775 - accuracy: 0.0703 - val_loss: 5.3467 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7296 - accuracy: 0.0469 - val_loss: 5.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7108 - accuracy: 0.0312 - val_loss: 5.3763 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7540 - accuracy: 0.0156 - val_loss: 5.3038 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8001 - accuracy: 0.0391 - val_loss: 5.2363 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7751 - accuracy: 0.0625 - val_loss: 5.1871 - val_accuracy: 0.0156\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5097 - accuracy: 0.1172 - val_loss: 5.1691 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8552 - accuracy: 0.0703 - val_loss: 5.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5241 - accuracy: 0.0469 - val_loss: 5.3060 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7484 - accuracy: 0.0312 - val_loss: 5.4642 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6801 - accuracy: 0.0078 - val_loss: 5.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6000 - accuracy: 0.0703 - val_loss: 5.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9185 - accuracy: 0.0156 - val_loss: 6.0192 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5131 - accuracy: 0.1094 - val_loss: 5.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5077 - accuracy: 0.0938 - val_loss: 5.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6414 - accuracy: 0.0312 - val_loss: 5.5144 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9316 - accuracy: 0.0078 - val_loss: 5.1496 - val_accuracy: 0.0156\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6885 - accuracy: 0.0703 - val_loss: 4.9832 - val_accuracy: 0.0234\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8067 - accuracy: 0.0312 - val_loss: 4.9620 - val_accuracy: 0.0234\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5607 - accuracy: 0.0234 - val_loss: 4.9846 - val_accuracy: 0.0156\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6043 - accuracy: 0.0469 - val_loss: 5.1656 - val_accuracy: 0.0391\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5488 - accuracy: 0.0781 - val_loss: 5.3032 - val_accuracy: 0.0312\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6895 - accuracy: 0.0234 - val_loss: 5.2777 - val_accuracy: 0.0391\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.4204 - accuracy: 0.0625 - val_loss: 5.1096 - val_accuracy: 0.0781\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6631 - accuracy: 0.0391 - val_loss: 5.0212 - val_accuracy: 0.0312\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.2953 - accuracy: 0.1328 - val_loss: 5.0355 - val_accuracy: 0.0234\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5029 - accuracy: 0.0391 - val_loss: 5.2928 - val_accuracy: 0.0859\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6662 - accuracy: 0.0312 - val_loss: 5.6265 - val_accuracy: 0.0859\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5473 - accuracy: 0.0859 - val_loss: 5.8299 - val_accuracy: 0.0938\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3260 - accuracy: 0.0703 - val_loss: 5.6112 - val_accuracy: 0.1016\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.4436 - accuracy: 0.0781 - val_loss: 5.5338 - val_accuracy: 0.0859\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6411 - accuracy: 0.0703 - val_loss: 5.4129 - val_accuracy: 0.0547\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5147 - accuracy: 0.0625 - val_loss: 5.4478 - val_accuracy: 0.0391\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.3763 - accuracy: 0.0391 - val_loss: 5.5009 - val_accuracy: 0.0156\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.6179 - accuracy: 0.0391 - val_loss: 5.6006 - val_accuracy: 0.0156\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8017 - accuracy: 0.0156 - val_loss: 5.7362 - val_accuracy: 0.0078\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6578 - accuracy: 0.0625 - val_loss: 5.7917 - val_accuracy: 0.0078\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4566 - accuracy: 0.0469 - val_loss: 5.9339 - val_accuracy: 0.0078\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5260 - accuracy: 0.0078 - val_loss: 5.7091 - val_accuracy: 0.0078\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5280 - accuracy: 0.0078 - val_loss: 5.4201 - val_accuracy: 0.0156\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4982 - accuracy: 0.0469 - val_loss: 5.3112 - val_accuracy: 0.0234\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2630 - accuracy: 0.0938 - val_loss: 5.2034 - val_accuracy: 0.0078\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.2903 - accuracy: 0.1016 - val_loss: 5.2394 - val_accuracy: 0.0234\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.4090 - accuracy: 0.0859 - val_loss: 5.4392 - val_accuracy: 0.0156\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4366 - accuracy: 0.0312 - val_loss: 5.5764 - val_accuracy: 0.0234\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4616 - accuracy: 0.0547 - val_loss: 5.6943 - val_accuracy: 0.0156\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.5825 - accuracy: 0.0234 - val_loss: 5.7482 - val_accuracy: 0.0156\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3170 - accuracy: 0.1562 - val_loss: 5.7405 - val_accuracy: 0.0234\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4743 - accuracy: 0.0625 - val_loss: 5.7869 - val_accuracy: 0.0312\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1014 - accuracy: 0.1016 - val_loss: 5.8103 - val_accuracy: 0.0312\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4867 - accuracy: 0.0547 - val_loss: 5.8711 - val_accuracy: 0.0312\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3141 - accuracy: 0.1016 - val_loss: 5.8887 - val_accuracy: 0.0312\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7522 - accuracy: 0.0391 - val_loss: 5.9733 - val_accuracy: 0.0078\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5855 - accuracy: 0.0234 - val_loss: 5.9814 - val_accuracy: 0.0078\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7914 - accuracy: 0.0156 - val_loss: 6.0329 - val_accuracy: 0.0078\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.5176 - accuracy: 0.0312 - val_loss: 5.8849 - val_accuracy: 0.0078\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.7314 - accuracy: 0.0234 - val_loss: 5.7353 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1900 - accuracy: 0.0781 - val_loss: 5.6021 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2822 - accuracy: 0.0625 - val_loss: 5.5186 - val_accuracy: 0.0234\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3311 - accuracy: 0.0625 - val_loss: 5.4908 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.3270 - accuracy: 0.0625 - val_loss: 5.3500 - val_accuracy: 0.0312\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6207 - accuracy: 0.0469 - val_loss: 5.3008 - val_accuracy: 0.0391\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3257 - accuracy: 0.0547 - val_loss: 5.4041 - val_accuracy: 0.0391\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5490 - accuracy: 0.0703 - val_loss: 5.4204 - val_accuracy: 0.0625\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6910 - accuracy: 0.0547 - val_loss: 5.4111 - val_accuracy: 0.0312\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4921 - accuracy: 0.0391 - val_loss: 5.2445 - val_accuracy: 0.0547\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5196 - accuracy: 0.0625 - val_loss: 5.1174 - val_accuracy: 0.0469\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.2585 - accuracy: 0.0391 - val_loss: 4.9008 - val_accuracy: 0.0859\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6229 - accuracy: 0.0703 - val_loss: 4.6904 - val_accuracy: 0.1094\n",
      "Epoch 171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4872 - accuracy: 0.0469 - val_loss: 4.5688 - val_accuracy: 0.1094\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3485 - accuracy: 0.0703 - val_loss: 4.5897 - val_accuracy: 0.1016\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.2658 - accuracy: 0.0703 - val_loss: 4.7532 - val_accuracy: 0.0625\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4331 - accuracy: 0.0781 - val_loss: 4.8252 - val_accuracy: 0.0312\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3355 - accuracy: 0.0469 - val_loss: 4.8438 - val_accuracy: 0.0312\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3722 - accuracy: 0.0312 - val_loss: 4.7717 - val_accuracy: 0.0391\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.5611 - accuracy: 0.0469 - val_loss: 4.6389 - val_accuracy: 0.0312\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0724 - accuracy: 0.1406 - val_loss: 4.6284 - val_accuracy: 0.0469\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.2984 - accuracy: 0.0703 - val_loss: 4.6162 - val_accuracy: 0.0625\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.4408 - accuracy: 0.0547 - val_loss: 4.5128 - val_accuracy: 0.0859\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4236 - accuracy: 0.0391 - val_loss: 4.5408 - val_accuracy: 0.1016\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.3522 - accuracy: 0.0625 - val_loss: 4.5720 - val_accuracy: 0.1172\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1733 - accuracy: 0.0469 - val_loss: 4.8356 - val_accuracy: 0.1094\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.1846 - accuracy: 0.1016 - val_loss: 4.9595 - val_accuracy: 0.1328\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.2993 - accuracy: 0.0234 - val_loss: 4.9459 - val_accuracy: 0.1406\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0553 - accuracy: 0.1172 - val_loss: 4.9007 - val_accuracy: 0.1406\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.1558 - accuracy: 0.0703 - val_loss: 4.6772 - val_accuracy: 0.1094\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4708 - accuracy: 0.0938 - val_loss: 4.6498 - val_accuracy: 0.1250\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2587 - accuracy: 0.0781 - val_loss: 4.8300 - val_accuracy: 0.1016\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2801 - accuracy: 0.0469 - val_loss: 4.9515 - val_accuracy: 0.0859\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3911 - accuracy: 0.0547 - val_loss: 5.0154 - val_accuracy: 0.0547\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3440 - accuracy: 0.1172 - val_loss: 5.0333 - val_accuracy: 0.0312\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.4275 - accuracy: 0.0469 - val_loss: 4.9378 - val_accuracy: 0.0391\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.3949 - accuracy: 0.0078 - val_loss: 4.9196 - val_accuracy: 0.0391\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.2602 - accuracy: 0.0938 - val_loss: 4.9537 - val_accuracy: 0.0625\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4662 - accuracy: 0.0078 - val_loss: 5.0171 - val_accuracy: 0.1016\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.1102 - accuracy: 0.0625 - val_loss: 5.0629 - val_accuracy: 0.1172\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4216 - accuracy: 0.1250 - val_loss: 5.2242 - val_accuracy: 0.1016\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.4951 - accuracy: 0.0312 - val_loss: 5.1540 - val_accuracy: 0.0938\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.2566 - accuracy: 0.0469 - val_loss: 4.9123 - val_accuracy: 0.0703\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1690 - accuracy: 0.0625 - val_loss: 4.7059 - val_accuracy: 0.0469\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3499 - accuracy: 0.0391 - val_loss: 4.5662 - val_accuracy: 0.0469\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2357 - accuracy: 0.0938 - val_loss: 4.4939 - val_accuracy: 0.0469\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.3688 - accuracy: 0.0547 - val_loss: 4.5038 - val_accuracy: 0.0625\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1584 - accuracy: 0.0469 - val_loss: 4.5990 - val_accuracy: 0.0625\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4474 - accuracy: 0.0547 - val_loss: 4.6045 - val_accuracy: 0.0625\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0107 - accuracy: 0.0781 - val_loss: 4.4504 - val_accuracy: 0.1172\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3264 - accuracy: 0.0547 - val_loss: 4.3681 - val_accuracy: 0.1016\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0323 - accuracy: 0.0938 - val_loss: 4.3647 - val_accuracy: 0.1328\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9270 - accuracy: 0.1562 - val_loss: 4.2882 - val_accuracy: 0.1250\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.3503 - accuracy: 0.0391 - val_loss: 4.2632 - val_accuracy: 0.1172\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.8684 - accuracy: 0.1250 - val_loss: 4.1564 - val_accuracy: 0.1172\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.3619 - accuracy: 0.0703 - val_loss: 4.2209 - val_accuracy: 0.1172\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.2873 - accuracy: 0.0938 - val_loss: 4.4304 - val_accuracy: 0.0859\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3583 - accuracy: 0.0938 - val_loss: 4.5768 - val_accuracy: 0.1172\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4049 - accuracy: 0.0625 - val_loss: 4.7023 - val_accuracy: 0.1250\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.2626 - accuracy: 0.1016 - val_loss: 4.7714 - val_accuracy: 0.1406\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.4377 - accuracy: 0.0156 - val_loss: 5.0594 - val_accuracy: 0.1172\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1938 - accuracy: 0.0625 - val_loss: 5.2642 - val_accuracy: 0.0781\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2696 - accuracy: 0.0312 - val_loss: 5.1694 - val_accuracy: 0.0312\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.1173 - accuracy: 0.1328 - val_loss: 4.9955 - val_accuracy: 0.0156\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1298 - accuracy: 0.0625 - val_loss: 4.6512 - val_accuracy: 0.0312\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2613 - accuracy: 0.0469 - val_loss: 4.5201 - val_accuracy: 0.0391\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3244 - accuracy: 0.0234 - val_loss: 4.4450 - val_accuracy: 0.0312\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1837 - accuracy: 0.0547 - val_loss: 4.3392 - val_accuracy: 0.0469\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1524 - accuracy: 0.1016 - val_loss: 4.2089 - val_accuracy: 0.0938\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2054 - accuracy: 0.0703 - val_loss: 4.1489 - val_accuracy: 0.1484\n",
      "Epoch 228/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 4.1293 - accuracy: 0.0391 - val_loss: 4.1497 - val_accuracy: 0.1641\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1551 - accuracy: 0.0703 - val_loss: 4.2028 - val_accuracy: 0.1562\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.2673 - accuracy: 0.0312 - val_loss: 4.2612 - val_accuracy: 0.1797\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0627 - accuracy: 0.0781 - val_loss: 4.3646 - val_accuracy: 0.1719\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.0488 - accuracy: 0.1094 - val_loss: 4.5762 - val_accuracy: 0.1797\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.0221 - accuracy: 0.0703 - val_loss: 4.7295 - val_accuracy: 0.1328\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0865 - accuracy: 0.1406 - val_loss: 4.6907 - val_accuracy: 0.1406\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.1692 - accuracy: 0.0781 - val_loss: 4.5654 - val_accuracy: 0.1406\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2763 - accuracy: 0.0391 - val_loss: 4.1882 - val_accuracy: 0.0703\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1848 - accuracy: 0.0391 - val_loss: 4.3535 - val_accuracy: 0.0312\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.3755 - accuracy: 0.0781 - val_loss: 4.8682 - val_accuracy: 0.0547\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.2613 - accuracy: 0.0938 - val_loss: 4.7257 - val_accuracy: 0.0781\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.3732 - accuracy: 0.0156 - val_loss: 4.2319 - val_accuracy: 0.1172\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.3071 - accuracy: 0.0547 - val_loss: 3.9582 - val_accuracy: 0.1250\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0498 - accuracy: 0.0547 - val_loss: 3.8497 - val_accuracy: 0.1016\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1607 - accuracy: 0.1250 - val_loss: 3.9858 - val_accuracy: 0.0547\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7809 - accuracy: 0.1250 - val_loss: 4.0272 - val_accuracy: 0.0547\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9905 - accuracy: 0.1641 - val_loss: 3.8696 - val_accuracy: 0.1172\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0755 - accuracy: 0.0938 - val_loss: 3.8884 - val_accuracy: 0.0703\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.1260 - accuracy: 0.0547 - val_loss: 3.8152 - val_accuracy: 0.0859\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.3347 - accuracy: 0.0625 - val_loss: 3.8102 - val_accuracy: 0.0938\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.0281 - accuracy: 0.0625 - val_loss: 3.9939 - val_accuracy: 0.0703\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.2962 - accuracy: 0.0312 - val_loss: 4.3427 - val_accuracy: 0.0625\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.2270 - accuracy: 0.0781 - val_loss: 4.6973 - val_accuracy: 0.0078\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2092 - accuracy: 0.0703 - val_loss: 4.8821 - val_accuracy: 0.0312\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0594 - accuracy: 0.0625 - val_loss: 4.7942 - val_accuracy: 0.0469\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.0292 - accuracy: 0.0625 - val_loss: 4.5701 - val_accuracy: 0.0469\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.0303 - accuracy: 0.0391 - val_loss: 4.4147 - val_accuracy: 0.0938\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3447 - accuracy: 0.0391 - val_loss: 4.2111 - val_accuracy: 0.0859\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3505 - accuracy: 0.0156 - val_loss: 4.2094 - val_accuracy: 0.0781\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9956 - accuracy: 0.0938 - val_loss: 4.1856 - val_accuracy: 0.0938\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0347 - accuracy: 0.0703 - val_loss: 4.2602 - val_accuracy: 0.0859\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9610 - accuracy: 0.1328 - val_loss: 4.5447 - val_accuracy: 0.0625\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9541 - accuracy: 0.0312 - val_loss: 4.7454 - val_accuracy: 0.0234\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.0140 - accuracy: 0.0625 - val_loss: 4.8675 - val_accuracy: 0.0234\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.0201 - accuracy: 0.0938 - val_loss: 4.8573 - val_accuracy: 0.0234\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2231 - accuracy: 0.0781 - val_loss: 4.7151 - val_accuracy: 0.0156\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9478 - accuracy: 0.1172 - val_loss: 4.8610 - val_accuracy: 0.0078\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.0700 - accuracy: 0.0547 - val_loss: 5.1390 - val_accuracy: 0.0078\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.1204 - accuracy: 0.0781 - val_loss: 5.2645 - val_accuracy: 0.0078\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9991 - accuracy: 0.0938 - val_loss: 5.2383 - val_accuracy: 0.0078\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.9308 - accuracy: 0.1406 - val_loss: 5.1641 - val_accuracy: 0.0078\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.9720 - accuracy: 0.1250 - val_loss: 5.0189 - val_accuracy: 0.0078\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0157 - accuracy: 0.0781 - val_loss: 4.8348 - val_accuracy: 0.0078\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.9229 - accuracy: 0.1094 - val_loss: 4.7793 - val_accuracy: 0.0078\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.2499 - accuracy: 0.0312 - val_loss: 4.9183 - val_accuracy: 0.0078\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1463 - accuracy: 0.0859 - val_loss: 4.9388 - val_accuracy: 0.0156\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.0849 - accuracy: 0.0781 - val_loss: 4.7806 - val_accuracy: 0.0312\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0224 - accuracy: 0.0938 - val_loss: 4.6164 - val_accuracy: 0.0156\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0946 - accuracy: 0.0781 - val_loss: 4.4118 - val_accuracy: 0.0156\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0070 - accuracy: 0.0859 - val_loss: 4.2734 - val_accuracy: 0.0234\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1251 - accuracy: 0.0859 - val_loss: 4.3557 - val_accuracy: 0.0703\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.9174 - accuracy: 0.1094 - val_loss: 4.3766 - val_accuracy: 0.0547\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1533 - accuracy: 0.1016 - val_loss: 4.5687 - val_accuracy: 0.0312\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9151 - accuracy: 0.0938 - val_loss: 4.7551 - val_accuracy: 0.0078\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9189 - accuracy: 0.0625 - val_loss: 4.7559 - val_accuracy: 0.0156\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0850 - accuracy: 0.1094 - val_loss: 4.6576 - val_accuracy: 0.0234\n",
      "Epoch 285/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0672 - accuracy: 0.0625 - val_loss: 4.6056 - val_accuracy: 0.0234\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6473 - accuracy: 0.1719 - val_loss: 4.5539 - val_accuracy: 0.0391\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.0712 - accuracy: 0.1172 - val_loss: 4.7156 - val_accuracy: 0.0312\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8566 - accuracy: 0.1016 - val_loss: 4.8375 - val_accuracy: 0.0078\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9761 - accuracy: 0.0625 - val_loss: 4.7735 - val_accuracy: 0.0078\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7939 - accuracy: 0.1172 - val_loss: 4.5844 - val_accuracy: 0.0156\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9590 - accuracy: 0.1172 - val_loss: 4.4274 - val_accuracy: 0.0312\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.0933 - accuracy: 0.0625 - val_loss: 4.2620 - val_accuracy: 0.0312\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1356 - accuracy: 0.0859 - val_loss: 4.2028 - val_accuracy: 0.0234\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0528 - accuracy: 0.0703 - val_loss: 4.2798 - val_accuracy: 0.0312\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0361 - accuracy: 0.1328 - val_loss: 4.1853 - val_accuracy: 0.0312\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9553 - accuracy: 0.1250 - val_loss: 4.1548 - val_accuracy: 0.0391\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8964 - accuracy: 0.1172 - val_loss: 4.2196 - val_accuracy: 0.0234\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8720 - accuracy: 0.1484 - val_loss: 4.3035 - val_accuracy: 0.0391\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0038 - accuracy: 0.0938 - val_loss: 4.3742 - val_accuracy: 0.0312\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7078 - accuracy: 0.1406 - val_loss: 4.1582 - val_accuracy: 0.0547\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8082 - accuracy: 0.1016 - val_loss: 4.0497 - val_accuracy: 0.0859\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.1421 - accuracy: 0.1016 - val_loss: 4.1454 - val_accuracy: 0.1250\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.1069 - accuracy: 0.0781 - val_loss: 4.2160 - val_accuracy: 0.1250\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7885 - accuracy: 0.0938 - val_loss: 4.2526 - val_accuracy: 0.1094\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8697 - accuracy: 0.0547 - val_loss: 4.1729 - val_accuracy: 0.0703\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.9956 - accuracy: 0.1172 - val_loss: 4.1545 - val_accuracy: 0.0391\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7711 - accuracy: 0.0781 - val_loss: 4.1563 - val_accuracy: 0.0391\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.9167 - accuracy: 0.1016 - val_loss: 4.1824 - val_accuracy: 0.0312\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9067 - accuracy: 0.1406 - val_loss: 4.3463 - val_accuracy: 0.0391\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9595 - accuracy: 0.1016 - val_loss: 4.3141 - val_accuracy: 0.0312\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.8720 - accuracy: 0.1094 - val_loss: 4.0082 - val_accuracy: 0.0703\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8704 - accuracy: 0.0938 - val_loss: 3.9438 - val_accuracy: 0.0469\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.0362 - accuracy: 0.0391 - val_loss: 4.0781 - val_accuracy: 0.0547\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9774 - accuracy: 0.1016 - val_loss: 4.2364 - val_accuracy: 0.0391\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8069 - accuracy: 0.1406 - val_loss: 4.2836 - val_accuracy: 0.0469\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.0239 - accuracy: 0.0781 - val_loss: 4.2611 - val_accuracy: 0.0234\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8903 - accuracy: 0.1641 - val_loss: 4.1873 - val_accuracy: 0.0234\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8996 - accuracy: 0.1016 - val_loss: 4.1283 - val_accuracy: 0.0234\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.6802 - accuracy: 0.0938 - val_loss: 4.0532 - val_accuracy: 0.0469\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8103 - accuracy: 0.1328 - val_loss: 4.0673 - val_accuracy: 0.0234\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7261 - accuracy: 0.1406 - val_loss: 4.1773 - val_accuracy: 0.0156\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.1566 - accuracy: 0.0547 - val_loss: 4.1718 - val_accuracy: 0.0156\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.7901 - accuracy: 0.1406 - val_loss: 4.1407 - val_accuracy: 0.0078\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9146 - accuracy: 0.1328 - val_loss: 3.9194 - val_accuracy: 0.0469\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.8901 - accuracy: 0.0938 - val_loss: 3.8564 - val_accuracy: 0.0547\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.7031 - accuracy: 0.0859 - val_loss: 3.8619 - val_accuracy: 0.0547\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5543 - accuracy: 0.1875 - val_loss: 3.8970 - val_accuracy: 0.0625\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8142 - accuracy: 0.1484 - val_loss: 3.9033 - val_accuracy: 0.0547\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0570 - accuracy: 0.0859 - val_loss: 3.9624 - val_accuracy: 0.0469\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0441 - accuracy: 0.0703 - val_loss: 3.9256 - val_accuracy: 0.0547\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8371 - accuracy: 0.0781 - val_loss: 3.9988 - val_accuracy: 0.0547\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.5716 - accuracy: 0.1953 - val_loss: 4.0768 - val_accuracy: 0.0391\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7853 - accuracy: 0.1328 - val_loss: 4.0547 - val_accuracy: 0.0625\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8645 - accuracy: 0.1172 - val_loss: 4.1479 - val_accuracy: 0.0859\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6184 - accuracy: 0.1641 - val_loss: 4.0237 - val_accuracy: 0.0938\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6193 - accuracy: 0.1406 - val_loss: 3.8456 - val_accuracy: 0.1094\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8072 - accuracy: 0.1406 - val_loss: 3.8138 - val_accuracy: 0.1094\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7908 - accuracy: 0.1172 - val_loss: 3.7443 - val_accuracy: 0.1172\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8970 - accuracy: 0.0625 - val_loss: 3.6965 - val_accuracy: 0.1172\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.7911 - accuracy: 0.1328 - val_loss: 3.8181 - val_accuracy: 0.0625\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8497 - accuracy: 0.0938 - val_loss: 3.9404 - val_accuracy: 0.0703\n",
      "Epoch 342/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8434 - accuracy: 0.0859 - val_loss: 4.2282 - val_accuracy: 0.0703\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6524 - accuracy: 0.1641 - val_loss: 4.1924 - val_accuracy: 0.0703\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7159 - accuracy: 0.1172 - val_loss: 4.1906 - val_accuracy: 0.0391\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.8562 - accuracy: 0.1172 - val_loss: 4.2203 - val_accuracy: 0.0469\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8934 - accuracy: 0.0703 - val_loss: 4.1775 - val_accuracy: 0.0625\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.7195 - accuracy: 0.1172 - val_loss: 4.1852 - val_accuracy: 0.0469\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7453 - accuracy: 0.1719 - val_loss: 4.3991 - val_accuracy: 0.0312\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8555 - accuracy: 0.0391 - val_loss: 4.5700 - val_accuracy: 0.0156\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0578 - accuracy: 0.1250 - val_loss: 4.6106 - val_accuracy: 0.0156\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5927 - accuracy: 0.1797 - val_loss: 4.5229 - val_accuracy: 0.0234\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6844 - accuracy: 0.1484 - val_loss: 4.4420 - val_accuracy: 0.0156\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8570 - accuracy: 0.0781 - val_loss: 4.4776 - val_accuracy: 0.0234\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.9250 - accuracy: 0.1406 - val_loss: 4.4138 - val_accuracy: 0.0156\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6653 - accuracy: 0.1562 - val_loss: 4.4215 - val_accuracy: 0.0156\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.7340 - accuracy: 0.1250 - val_loss: 4.4304 - val_accuracy: 0.0234\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5161 - accuracy: 0.1562 - val_loss: 4.5334 - val_accuracy: 0.0391\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6597 - accuracy: 0.1172 - val_loss: 4.6504 - val_accuracy: 0.0391\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.8240 - accuracy: 0.0547 - val_loss: 4.5933 - val_accuracy: 0.0234\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7326 - accuracy: 0.1797 - val_loss: 4.3471 - val_accuracy: 0.0234\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5834 - accuracy: 0.1250 - val_loss: 4.1190 - val_accuracy: 0.0078\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5342 - accuracy: 0.1562 - val_loss: 4.3105 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4664 - accuracy: 0.1953 - val_loss: 4.5170 - val_accuracy: 0.0234\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.9326 - accuracy: 0.0938 - val_loss: 4.6188 - val_accuracy: 0.0156\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7534 - accuracy: 0.1719 - val_loss: 4.4862 - val_accuracy: 0.0156\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9424 - accuracy: 0.0391 - val_loss: 4.3238 - val_accuracy: 0.0156\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.1349 - accuracy: 0.0938 - val_loss: 4.1001 - val_accuracy: 0.0312\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.5436 - accuracy: 0.1328 - val_loss: 3.9465 - val_accuracy: 0.0625\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6193 - accuracy: 0.1797 - val_loss: 3.8994 - val_accuracy: 0.0938\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.4204 - accuracy: 0.1641 - val_loss: 3.7196 - val_accuracy: 0.0938\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7187 - accuracy: 0.1562 - val_loss: 3.5177 - val_accuracy: 0.1094\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7338 - accuracy: 0.1172 - val_loss: 3.5777 - val_accuracy: 0.0859\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3993 - accuracy: 0.2188 - val_loss: 3.6221 - val_accuracy: 0.0703\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.6265 - accuracy: 0.1172 - val_loss: 3.6466 - val_accuracy: 0.1094\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6605 - accuracy: 0.0938 - val_loss: 3.6759 - val_accuracy: 0.0703\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.4542 - accuracy: 0.1562 - val_loss: 3.6877 - val_accuracy: 0.0781\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.6663 - accuracy: 0.1172 - val_loss: 3.6311 - val_accuracy: 0.1016\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.6100 - accuracy: 0.1172 - val_loss: 3.6302 - val_accuracy: 0.1328\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6034 - accuracy: 0.1641 - val_loss: 3.5687 - val_accuracy: 0.1719\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.5862 - accuracy: 0.1328 - val_loss: 3.4609 - val_accuracy: 0.1719\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5123 - accuracy: 0.1562 - val_loss: 3.3966 - val_accuracy: 0.1641\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.7031 - accuracy: 0.1953 - val_loss: 3.5090 - val_accuracy: 0.1328\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4664 - accuracy: 0.1953 - val_loss: 3.6996 - val_accuracy: 0.1328\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.8173 - accuracy: 0.0859 - val_loss: 3.9345 - val_accuracy: 0.0703\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5280 - accuracy: 0.1172 - val_loss: 3.9116 - val_accuracy: 0.0312\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2808 - accuracy: 0.1797 - val_loss: 3.7336 - val_accuracy: 0.0391\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6850 - accuracy: 0.1172 - val_loss: 3.5934 - val_accuracy: 0.0781\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6096 - accuracy: 0.1875 - val_loss: 3.4574 - val_accuracy: 0.1094\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3199 - accuracy: 0.1875 - val_loss: 3.3922 - val_accuracy: 0.1016\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4734 - accuracy: 0.2031 - val_loss: 3.4735 - val_accuracy: 0.0859\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.5939 - accuracy: 0.1484 - val_loss: 3.6317 - val_accuracy: 0.0781\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5343 - accuracy: 0.1641 - val_loss: 3.6085 - val_accuracy: 0.0703\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.6387 - accuracy: 0.1875 - val_loss: 3.6074 - val_accuracy: 0.0547\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.4757 - accuracy: 0.1797 - val_loss: 3.6664 - val_accuracy: 0.0781\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5200 - accuracy: 0.2109 - val_loss: 3.7621 - val_accuracy: 0.0625\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.7622 - accuracy: 0.1406 - val_loss: 3.8322 - val_accuracy: 0.0547\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6078 - accuracy: 0.1172 - val_loss: 3.5479 - val_accuracy: 0.0781\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.5716 - accuracy: 0.1953 - val_loss: 3.4082 - val_accuracy: 0.1172\n",
      "Epoch 399/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6334 - accuracy: 0.0781 - val_loss: 3.3523 - val_accuracy: 0.1250\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6234 - accuracy: 0.0781 - val_loss: 3.3680 - val_accuracy: 0.1094\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5873 - accuracy: 0.1094 - val_loss: 3.3761 - val_accuracy: 0.1172\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7297 - accuracy: 0.0781 - val_loss: 3.4553 - val_accuracy: 0.1094\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.3768 - accuracy: 0.2031 - val_loss: 3.5831 - val_accuracy: 0.0938\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.6653 - accuracy: 0.1172 - val_loss: 3.4984 - val_accuracy: 0.1250\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7959 - accuracy: 0.0625 - val_loss: 3.5754 - val_accuracy: 0.1172\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5996 - accuracy: 0.1406 - val_loss: 3.7836 - val_accuracy: 0.0781\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.2342 - accuracy: 0.2812 - val_loss: 3.8961 - val_accuracy: 0.0547\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5863 - accuracy: 0.1406 - val_loss: 3.9043 - val_accuracy: 0.0547\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.4921 - accuracy: 0.2266 - val_loss: 3.7470 - val_accuracy: 0.0938\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7068 - accuracy: 0.0859 - val_loss: 3.6701 - val_accuracy: 0.0547\n",
      "Epoch 411/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2464 - accuracy: 0.2109 - val_loss: 3.5640 - val_accuracy: 0.0469\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7229 - accuracy: 0.1172 - val_loss: 3.4417 - val_accuracy: 0.0938\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4578 - accuracy: 0.1250 - val_loss: 3.4441 - val_accuracy: 0.1016\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.4980 - accuracy: 0.1016 - val_loss: 3.4808 - val_accuracy: 0.1094\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7702 - accuracy: 0.1250 - val_loss: 3.3997 - val_accuracy: 0.1094\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.4297 - accuracy: 0.2109 - val_loss: 3.3030 - val_accuracy: 0.1172\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3262 - accuracy: 0.2109 - val_loss: 3.2871 - val_accuracy: 0.1953\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5692 - accuracy: 0.1484 - val_loss: 3.5811 - val_accuracy: 0.1797\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7950 - accuracy: 0.0859 - val_loss: 3.6896 - val_accuracy: 0.1484\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4476 - accuracy: 0.1719 - val_loss: 3.6871 - val_accuracy: 0.1484\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.6713 - accuracy: 0.1016 - val_loss: 3.6828 - val_accuracy: 0.2031\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.4388 - accuracy: 0.1250 - val_loss: 3.7849 - val_accuracy: 0.2109\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3457 - accuracy: 0.1953 - val_loss: 3.6092 - val_accuracy: 0.2031\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6732 - accuracy: 0.0859 - val_loss: 3.5002 - val_accuracy: 0.1875\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2394 - accuracy: 0.2109 - val_loss: 3.5219 - val_accuracy: 0.1641\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6456 - accuracy: 0.1016 - val_loss: 3.5529 - val_accuracy: 0.1328\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3287 - accuracy: 0.1875 - val_loss: 3.5007 - val_accuracy: 0.1094\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.3586 - accuracy: 0.2109 - val_loss: 3.5342 - val_accuracy: 0.0469\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.4580 - accuracy: 0.0625 - val_loss: 3.4057 - val_accuracy: 0.0469\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5741 - accuracy: 0.1250 - val_loss: 3.2623 - val_accuracy: 0.0859\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6713 - accuracy: 0.1875 - val_loss: 3.1108 - val_accuracy: 0.1797\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3612 - accuracy: 0.2344 - val_loss: 3.0727 - val_accuracy: 0.2500\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.3223 - accuracy: 0.2656 - val_loss: 3.1359 - val_accuracy: 0.2422\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 3.1523 - accuracy: 0.2188 - val_loss: 2.8777 - val_accuracy: 0.3750\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.5734 - accuracy: 0.2188 - val_loss: 2.8764 - val_accuracy: 0.3750\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.6628 - accuracy: 0.1406 - val_loss: 2.9567 - val_accuracy: 0.3516\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.4324 - accuracy: 0.2266 - val_loss: 2.8803 - val_accuracy: 0.3438\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.3971 - accuracy: 0.2422 - val_loss: 2.9314 - val_accuracy: 0.3438\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 3.5367 - accuracy: 0.1328 - val_loss: 2.9000 - val_accuracy: 0.3203\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5540 - accuracy: 0.1016 - val_loss: 2.8363 - val_accuracy: 0.3359\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6061 - accuracy: 0.1406 - val_loss: 2.9196 - val_accuracy: 0.2656\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.2568 - accuracy: 0.2656 - val_loss: 3.0326 - val_accuracy: 0.2344\n",
      "Epoch 443/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6352 - accuracy: 0.1250 - val_loss: 3.0362 - val_accuracy: 0.2266\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9515 - accuracy: 0.0547 - val_loss: 3.0220 - val_accuracy: 0.2734\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3458 - accuracy: 0.1250 - val_loss: 3.0689 - val_accuracy: 0.2812\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2172 - accuracy: 0.2578 - val_loss: 3.2961 - val_accuracy: 0.1484\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2813 - accuracy: 0.1875 - val_loss: 3.4931 - val_accuracy: 0.0781\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.5586 - accuracy: 0.1250 - val_loss: 3.5912 - val_accuracy: 0.0703\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7019 - accuracy: 0.0781 - val_loss: 3.3863 - val_accuracy: 0.1328\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3149 - accuracy: 0.1484 - val_loss: 3.2788 - val_accuracy: 0.1797\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7515 - accuracy: 0.1641 - val_loss: 3.3555 - val_accuracy: 0.1406\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.3057 - accuracy: 0.1562 - val_loss: 3.3688 - val_accuracy: 0.1172\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.4617 - accuracy: 0.1484 - val_loss: 3.4949 - val_accuracy: 0.1328\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.4441 - accuracy: 0.1719 - val_loss: 3.4294 - val_accuracy: 0.0781\n",
      "Epoch 455/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4518 - accuracy: 0.1719 - val_loss: 3.3126 - val_accuracy: 0.1094\n",
      "Epoch 456/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4111 - accuracy: 0.1797 - val_loss: 3.2873 - val_accuracy: 0.1172\n",
      "Epoch 457/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.3007 - accuracy: 0.2188 - val_loss: 3.2127 - val_accuracy: 0.1406\n",
      "Epoch 458/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5182 - accuracy: 0.1172 - val_loss: 3.1744 - val_accuracy: 0.1719\n",
      "Epoch 459/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4045 - accuracy: 0.1797 - val_loss: 3.2100 - val_accuracy: 0.2188\n",
      "Epoch 460/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2832 - accuracy: 0.1328 - val_loss: 3.3399 - val_accuracy: 0.2188\n",
      "Epoch 461/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4941 - accuracy: 0.2500 - val_loss: 3.5540 - val_accuracy: 0.1641\n",
      "Epoch 462/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3719 - accuracy: 0.1641 - val_loss: 3.6965 - val_accuracy: 0.1328\n",
      "Epoch 463/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.4295 - accuracy: 0.0547 - val_loss: 3.7368 - val_accuracy: 0.1016\n",
      "Epoch 464/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.1940 - accuracy: 0.2578 - val_loss: 3.5089 - val_accuracy: 0.0859\n",
      "Epoch 465/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.5169 - accuracy: 0.2188 - val_loss: 3.4619 - val_accuracy: 0.0938\n",
      "Epoch 466/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.3104 - accuracy: 0.1406 - val_loss: 3.3462 - val_accuracy: 0.1250\n",
      "Epoch 467/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6281 - accuracy: 0.1094 - val_loss: 3.3455 - val_accuracy: 0.1328\n",
      "Epoch 468/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3757 - accuracy: 0.1953 - val_loss: 3.4128 - val_accuracy: 0.1562\n",
      "Epoch 469/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.6632 - accuracy: 0.1250 - val_loss: 3.4727 - val_accuracy: 0.0938\n",
      "Epoch 470/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.2848 - accuracy: 0.0938 - val_loss: 3.5426 - val_accuracy: 0.1094\n",
      "Epoch 471/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2555 - accuracy: 0.1797 - val_loss: 3.4981 - val_accuracy: 0.0703\n",
      "Epoch 472/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3545 - accuracy: 0.1797 - val_loss: 3.4077 - val_accuracy: 0.1016\n",
      "Epoch 473/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2002 - accuracy: 0.1875 - val_loss: 3.4864 - val_accuracy: 0.0547\n",
      "Epoch 474/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4645 - accuracy: 0.2188 - val_loss: 3.6696 - val_accuracy: 0.0312\n",
      "Epoch 475/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7474 - accuracy: 0.1094 - val_loss: 3.6014 - val_accuracy: 0.0312\n",
      "Epoch 476/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.4952 - accuracy: 0.1797 - val_loss: 3.5327 - val_accuracy: 0.0547\n",
      "Epoch 477/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.5491 - accuracy: 0.1641 - val_loss: 3.4718 - val_accuracy: 0.0703\n",
      "Epoch 478/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5069 - accuracy: 0.1797 - val_loss: 3.5231 - val_accuracy: 0.0781\n",
      "Epoch 479/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3591 - accuracy: 0.1328 - val_loss: 3.5439 - val_accuracy: 0.0625\n",
      "Epoch 480/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.6380 - accuracy: 0.1562 - val_loss: 3.5689 - val_accuracy: 0.0547\n",
      "Epoch 481/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1854 - accuracy: 0.2422 - val_loss: 3.7764 - val_accuracy: 0.0859\n",
      "Epoch 482/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3379 - accuracy: 0.1953 - val_loss: 3.7860 - val_accuracy: 0.1328\n",
      "Epoch 483/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.1123 - accuracy: 0.2734 - val_loss: 3.5194 - val_accuracy: 0.1562\n",
      "Epoch 484/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.2889 - accuracy: 0.2031 - val_loss: 3.5387 - val_accuracy: 0.0938\n",
      "Epoch 485/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.5357 - accuracy: 0.2266 - val_loss: 3.4451 - val_accuracy: 0.1172\n",
      "Epoch 486/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.3218 - accuracy: 0.1719 - val_loss: 3.4675 - val_accuracy: 0.1641\n",
      "Epoch 487/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3054 - accuracy: 0.2500 - val_loss: 3.2747 - val_accuracy: 0.2578\n",
      "Epoch 488/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2628 - accuracy: 0.1875 - val_loss: 3.0217 - val_accuracy: 0.3359\n",
      "Epoch 489/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9386 - accuracy: 0.3281 - val_loss: 3.0243 - val_accuracy: 0.3281\n",
      "Epoch 490/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.3463 - accuracy: 0.1875 - val_loss: 2.8891 - val_accuracy: 0.3281\n",
      "Epoch 491/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.3299 - accuracy: 0.2344 - val_loss: 2.9168 - val_accuracy: 0.2969\n",
      "Epoch 492/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.4331 - accuracy: 0.1406 - val_loss: 3.1387 - val_accuracy: 0.2969\n",
      "Epoch 493/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4038 - accuracy: 0.1328 - val_loss: 3.6160 - val_accuracy: 0.2812\n",
      "Epoch 494/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4752 - accuracy: 0.1172 - val_loss: 4.0141 - val_accuracy: 0.2188\n",
      "Epoch 495/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.1268 - accuracy: 0.2734 - val_loss: 3.9213 - val_accuracy: 0.1953\n",
      "Epoch 496/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4191 - accuracy: 0.1484 - val_loss: 3.6172 - val_accuracy: 0.1797\n",
      "Epoch 497/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.5050 - accuracy: 0.1094 - val_loss: 3.4044 - val_accuracy: 0.2344\n",
      "Epoch 498/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5501 - accuracy: 0.1641 - val_loss: 3.3083 - val_accuracy: 0.2109\n",
      "Epoch 499/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3847 - accuracy: 0.1797 - val_loss: 3.3423 - val_accuracy: 0.1562\n",
      "Epoch 500/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3577 - accuracy: 0.1875 - val_loss: 3.4400 - val_accuracy: 0.0938\n",
      "Epoch 501/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3410 - accuracy: 0.1562 - val_loss: 3.4331 - val_accuracy: 0.0703\n",
      "Epoch 502/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4092 - accuracy: 0.1328 - val_loss: 3.2884 - val_accuracy: 0.1094\n",
      "Epoch 503/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.2795 - accuracy: 0.1406 - val_loss: 3.3113 - val_accuracy: 0.1328\n",
      "Epoch 504/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5545 - accuracy: 0.1641 - val_loss: 3.2840 - val_accuracy: 0.1094\n",
      "Epoch 505/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.3882 - accuracy: 0.1719 - val_loss: 3.3238 - val_accuracy: 0.1094\n",
      "Epoch 506/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.5859 - accuracy: 0.1484 - val_loss: 3.5549 - val_accuracy: 0.0703\n",
      "Epoch 507/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.2353 - accuracy: 0.1953 - val_loss: 3.8174 - val_accuracy: 0.0391\n",
      "Epoch 508/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2067 - accuracy: 0.1953 - val_loss: 3.7764 - val_accuracy: 0.0547\n",
      "Epoch 509/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.2721 - accuracy: 0.1719 - val_loss: 3.8410 - val_accuracy: 0.0547\n",
      "Epoch 510/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5051 - accuracy: 0.1328 - val_loss: 3.8719 - val_accuracy: 0.0625\n",
      "Epoch 511/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 3.3385 - accuracy: 0.2188 - val_loss: 3.6642 - val_accuracy: 0.0859\n",
      "Epoch 512/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.1794 - accuracy: 0.2500 - val_loss: 3.5505 - val_accuracy: 0.0703\n",
      "Epoch 513/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3230 - accuracy: 0.1328 - val_loss: 3.4307 - val_accuracy: 0.0547\n",
      "Epoch 514/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.2844 - accuracy: 0.2109 - val_loss: 3.3584 - val_accuracy: 0.0938\n",
      "Epoch 515/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4694 - accuracy: 0.1641 - val_loss: 3.4793 - val_accuracy: 0.0703\n",
      "Epoch 516/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.1651 - accuracy: 0.1719 - val_loss: 3.4321 - val_accuracy: 0.0781\n",
      "Epoch 517/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.4959 - accuracy: 0.1875 - val_loss: 3.3807 - val_accuracy: 0.1016\n",
      "Epoch 518/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.3558 - accuracy: 0.1250 - val_loss: 3.4539 - val_accuracy: 0.0703\n",
      "Epoch 519/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.2879 - accuracy: 0.1797 - val_loss: 3.6870 - val_accuracy: 0.0547\n",
      "Epoch 520/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3579 - accuracy: 0.1875 - val_loss: 3.6578 - val_accuracy: 0.0703\n",
      "Epoch 521/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3926 - accuracy: 0.0859 - val_loss: 3.4618 - val_accuracy: 0.0859\n",
      "Epoch 522/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.6036 - accuracy: 0.1016 - val_loss: 3.3429 - val_accuracy: 0.0781\n",
      "Epoch 523/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3981 - accuracy: 0.1328 - val_loss: 3.3745 - val_accuracy: 0.0625\n",
      "Epoch 524/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.2722 - accuracy: 0.2500 - val_loss: 3.4443 - val_accuracy: 0.1172\n",
      "Epoch 525/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2300 - accuracy: 0.2109 - val_loss: 3.4365 - val_accuracy: 0.0781\n",
      "Epoch 526/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.2943 - accuracy: 0.1797 - val_loss: 3.4562 - val_accuracy: 0.0625\n",
      "Epoch 527/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.3899 - accuracy: 0.1328 - val_loss: 3.5545 - val_accuracy: 0.0625\n",
      "Epoch 528/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.2341 - accuracy: 0.2109 - val_loss: 3.8021 - val_accuracy: 0.0312\n",
      "Epoch 529/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.1475 - accuracy: 0.2656 - val_loss: 3.8093 - val_accuracy: 0.0234\n",
      "Epoch 530/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.4823 - accuracy: 0.1406 - val_loss: 3.8119 - val_accuracy: 0.0234\n",
      "Epoch 531/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.5143 - accuracy: 0.1406 - val_loss: 3.6485 - val_accuracy: 0.0312\n",
      "Epoch 532/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.3348 - accuracy: 0.2188 - val_loss: 3.5166 - val_accuracy: 0.0703\n",
      "Epoch 533/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 3.3092 - accuracy: 0.2266 - val_loss: 3.4762 - val_accuracy: 0.1328\n",
      "Epoch 534/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5313 - accuracy: 0.1172 - val_loss: 3.5518 - val_accuracy: 0.1172\n",
      "Epoch 535/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3698 - accuracy: 0.1875 - val_loss: 3.5523 - val_accuracy: 0.1250\n",
      "Epoch 536/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.3323 - accuracy: 0.2266 - val_loss: 3.6426 - val_accuracy: 0.0938\n",
      "Epoch 537/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3319 - accuracy: 0.1641 - val_loss: 3.6839 - val_accuracy: 0.1094\n",
      "Epoch 538/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.3709 - accuracy: 0.1797 - val_loss: 3.7021 - val_accuracy: 0.0938\n",
      "Epoch 539/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3065 - accuracy: 0.2422 - val_loss: 3.8161 - val_accuracy: 0.0703\n",
      "Epoch 540/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3289 - accuracy: 0.1484 - val_loss: 3.9667 - val_accuracy: 0.0469\n",
      "Epoch 00540: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=89560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=89560\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 5.5780 - accuracy: 0.0000e+00 - val_loss: 5.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.5608 - accuracy: 0.0156 - val_loss: 5.5425 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.5372 - accuracy: 0.0156 - val_loss: 5.5407 - val_accuracy: 0.0078\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4278 - accuracy: 0.0312 - val_loss: 5.5411 - val_accuracy: 0.0078\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5169 - accuracy: 0.0078 - val_loss: 5.5413 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.4662 - accuracy: 0.0078 - val_loss: 5.5411 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.4904 - accuracy: 0.0078 - val_loss: 5.5412 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3516 - accuracy: 0.0312 - val_loss: 5.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.4288 - accuracy: 0.0078 - val_loss: 5.5386 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.3652 - accuracy: 0.0312 - val_loss: 5.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4198 - accuracy: 0.0234 - val_loss: 5.5295 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3412 - accuracy: 0.0156 - val_loss: 5.5273 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3376 - accuracy: 0.0234 - val_loss: 5.5263 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2387 - accuracy: 0.0391 - val_loss: 5.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.3694 - accuracy: 0.0000e+00 - val_loss: 5.5336 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2997 - accuracy: 0.0312 - val_loss: 5.5326 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2559 - accuracy: 0.0312 - val_loss: 5.5317 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3571 - accuracy: 0.0234 - val_loss: 5.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2796 - accuracy: 0.0391 - val_loss: 5.5170 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3128 - accuracy: 0.0078 - val_loss: 5.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1461 - accuracy: 0.0547 - val_loss: 5.4926 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2986 - accuracy: 0.0000e+00 - val_loss: 5.4727 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3609 - accuracy: 0.0312 - val_loss: 5.4602 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1914 - accuracy: 0.0312 - val_loss: 5.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.1473 - accuracy: 0.0469 - val_loss: 5.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3297 - accuracy: 0.0000e+00 - val_loss: 5.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.2936 - accuracy: 0.0078 - val_loss: 5.3919 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.3458 - accuracy: 0.0156 - val_loss: 5.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0955 - accuracy: 0.0469 - val_loss: 5.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1916 - accuracy: 0.0234 - val_loss: 5.3875 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0583 - accuracy: 0.0469 - val_loss: 5.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3298 - accuracy: 0.0078 - val_loss: 5.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1031 - accuracy: 0.0625 - val_loss: 5.4028 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1730 - accuracy: 0.0312 - val_loss: 5.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.2620 - accuracy: 0.0156 - val_loss: 5.4118 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2133 - accuracy: 0.0078 - val_loss: 5.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.1824 - accuracy: 0.0156 - val_loss: 5.4480 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.2456 - accuracy: 0.0000e+00 - val_loss: 5.4582 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.2194 - accuracy: 0.0234 - val_loss: 5.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1316 - accuracy: 0.0234 - val_loss: 5.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1453 - accuracy: 0.0156 - val_loss: 5.4135 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1723 - accuracy: 0.0156 - val_loss: 5.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1207 - accuracy: 0.0078 - val_loss: 5.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0916 - accuracy: 0.0469 - val_loss: 5.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0396 - accuracy: 0.0078 - val_loss: 5.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9688 - accuracy: 0.0547 - val_loss: 5.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1535 - accuracy: 0.0469 - val_loss: 5.3625 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8787 - accuracy: 0.0312 - val_loss: 5.3712 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0687 - accuracy: 0.0391 - val_loss: 5.3805 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9920 - accuracy: 0.0391 - val_loss: 5.3771 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1293 - accuracy: 0.0234 - val_loss: 5.3649 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0582 - accuracy: 0.0625 - val_loss: 5.3729 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.0351 - accuracy: 0.0391 - val_loss: 5.3753 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2545 - accuracy: 0.0156 - val_loss: 5.3482 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9929 - accuracy: 0.0234 - val_loss: 5.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9344 - accuracy: 0.0234 - val_loss: 5.3056 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9864 - accuracy: 0.0156 - val_loss: 5.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0387 - accuracy: 0.0156 - val_loss: 5.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7940 - accuracy: 0.0469 - val_loss: 5.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0309 - accuracy: 0.0234 - val_loss: 5.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0042 - accuracy: 0.0234 - val_loss: 5.2203 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1134 - accuracy: 0.0312 - val_loss: 5.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8703 - accuracy: 0.0391 - val_loss: 5.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1141 - accuracy: 0.0469 - val_loss: 5.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.0813 - accuracy: 0.0078 - val_loss: 5.1137 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8227 - accuracy: 0.0156 - val_loss: 5.1368 - val_accuracy: 0.0391\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9959 - accuracy: 0.0312 - val_loss: 5.1742 - val_accuracy: 0.0703\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1473 - accuracy: 0.0078 - val_loss: 5.1982 - val_accuracy: 0.0234\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9117 - accuracy: 0.0469 - val_loss: 5.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8819 - accuracy: 0.0234 - val_loss: 5.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 5.0434 - accuracy: 0.0156 - val_loss: 5.1240 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8579 - accuracy: 0.0391 - val_loss: 5.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9213 - accuracy: 0.0625 - val_loss: 5.1902 - val_accuracy: 0.0078\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0895 - accuracy: 0.0156 - val_loss: 5.1478 - val_accuracy: 0.0469\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1940 - accuracy: 0.0312 - val_loss: 5.0844 - val_accuracy: 0.0312\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7730 - accuracy: 0.0469 - val_loss: 5.0606 - val_accuracy: 0.0547\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8453 - accuracy: 0.0703 - val_loss: 5.0375 - val_accuracy: 0.1250\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9541 - accuracy: 0.0391 - val_loss: 5.0235 - val_accuracy: 0.1328\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0399 - accuracy: 0.0391 - val_loss: 4.9862 - val_accuracy: 0.0938\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0371 - accuracy: 0.0000e+00 - val_loss: 4.9349 - val_accuracy: 0.0156\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9334 - accuracy: 0.0312 - val_loss: 4.8643 - val_accuracy: 0.0234\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9655 - accuracy: 0.0078 - val_loss: 4.8361 - val_accuracy: 0.0234\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8694 - accuracy: 0.0312 - val_loss: 4.8353 - val_accuracy: 0.0312\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0694 - accuracy: 0.0078 - val_loss: 4.8380 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8420 - accuracy: 0.0391 - val_loss: 4.8504 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8910 - accuracy: 0.0234 - val_loss: 4.8563 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0105 - accuracy: 0.0078 - val_loss: 4.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0421 - accuracy: 0.0156 - val_loss: 4.8983 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9982 - accuracy: 0.0547 - val_loss: 4.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.8466 - accuracy: 0.0312 - val_loss: 4.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8581 - accuracy: 0.0156 - val_loss: 4.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9904 - accuracy: 0.0078 - val_loss: 4.9730 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6525 - accuracy: 0.0391 - val_loss: 4.9868 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9272 - accuracy: 0.0391 - val_loss: 5.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8746 - accuracy: 0.0312 - val_loss: 4.9967 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9296 - accuracy: 0.0312 - val_loss: 5.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9456 - accuracy: 0.0156 - val_loss: 5.0443 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0351 - accuracy: 0.0312 - val_loss: 5.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7463 - accuracy: 0.0547 - val_loss: 5.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.1776 - accuracy: 0.0000e+00 - val_loss: 5.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0838 - accuracy: 0.0312 - val_loss: 5.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9220 - accuracy: 0.0156 - val_loss: 5.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9912 - accuracy: 0.0391 - val_loss: 5.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8307 - accuracy: 0.0156 - val_loss: 5.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9828 - accuracy: 0.0078 - val_loss: 5.1811 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9815 - accuracy: 0.0234 - val_loss: 5.1842 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8846 - accuracy: 0.0312 - val_loss: 5.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9456 - accuracy: 0.0391 - val_loss: 5.2155 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8578 - accuracy: 0.0234 - val_loss: 5.2546 - val_accuracy: 0.0078\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8205 - accuracy: 0.0391 - val_loss: 5.2695 - val_accuracy: 0.0078\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0781 - accuracy: 0.0312 - val_loss: 5.2698 - val_accuracy: 0.0078\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8940 - accuracy: 0.0078 - val_loss: 5.2746 - val_accuracy: 0.0078\n",
      "Epoch 113/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9686 - accuracy: 0.0391 - val_loss: 5.2617 - val_accuracy: 0.0078\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0348 - accuracy: 0.0391 - val_loss: 5.2334 - val_accuracy: 0.0078\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.9636 - accuracy: 0.0312 - val_loss: 5.2009 - val_accuracy: 0.0078\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9998 - accuracy: 0.0469 - val_loss: 5.1586 - val_accuracy: 0.0078\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5620 - accuracy: 0.0625 - val_loss: 5.1261 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9430 - accuracy: 0.0391 - val_loss: 5.1347 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0110 - accuracy: 0.0000e+00 - val_loss: 5.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0251 - accuracy: 0.0078 - val_loss: 5.1851 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0829 - accuracy: 0.0078 - val_loss: 5.2045 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6840 - accuracy: 0.0312 - val_loss: 5.1975 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8567 - accuracy: 0.0391 - val_loss: 5.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8872 - accuracy: 0.0312 - val_loss: 5.1553 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9017 - accuracy: 0.0469 - val_loss: 5.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8430 - accuracy: 0.0312 - val_loss: 5.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8381 - accuracy: 0.0234 - val_loss: 5.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8546 - accuracy: 0.0234 - val_loss: 5.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8257 - accuracy: 0.0156 - val_loss: 5.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9861 - accuracy: 0.0547 - val_loss: 5.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8234 - accuracy: 0.0156 - val_loss: 5.0626 - val_accuracy: 0.0078\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8427 - accuracy: 0.0391 - val_loss: 5.0515 - val_accuracy: 0.0078\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8976 - accuracy: 0.0156 - val_loss: 5.0183 - val_accuracy: 0.0078\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9382 - accuracy: 0.0156 - val_loss: 4.9907 - val_accuracy: 0.0078\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5900 - accuracy: 0.0391 - val_loss: 4.9702 - val_accuracy: 0.0078\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8872 - accuracy: 0.0312 - val_loss: 4.9530 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9125 - accuracy: 0.0312 - val_loss: 4.9267 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6902 - accuracy: 0.0469 - val_loss: 4.9023 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0629 - accuracy: 0.0312 - val_loss: 4.8686 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6913 - accuracy: 0.0547 - val_loss: 4.8324 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8835 - accuracy: 0.0000e+00 - val_loss: 4.8191 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8239 - accuracy: 0.0469 - val_loss: 4.7872 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8739 - accuracy: 0.0312 - val_loss: 4.7590 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9027 - accuracy: 0.0234 - val_loss: 4.7116 - val_accuracy: 0.0078\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7587 - accuracy: 0.0234 - val_loss: 4.6876 - val_accuracy: 0.0156\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7456 - accuracy: 0.0938 - val_loss: 4.6380 - val_accuracy: 0.0312\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8385 - accuracy: 0.0156 - val_loss: 4.6408 - val_accuracy: 0.0625\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8959 - accuracy: 0.0469 - val_loss: 4.6552 - val_accuracy: 0.0625\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8234 - accuracy: 0.0234 - val_loss: 4.6612 - val_accuracy: 0.0625\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7446 - accuracy: 0.0078 - val_loss: 4.6467 - val_accuracy: 0.0469\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6492 - accuracy: 0.0234 - val_loss: 4.5935 - val_accuracy: 0.0469\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7948 - accuracy: 0.0391 - val_loss: 4.5840 - val_accuracy: 0.0625\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8186 - accuracy: 0.0625 - val_loss: 4.5678 - val_accuracy: 0.0312\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7145 - accuracy: 0.0781 - val_loss: 4.5762 - val_accuracy: 0.0312\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8792 - accuracy: 0.0391 - val_loss: 4.5907 - val_accuracy: 0.0078\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8288 - accuracy: 0.0312 - val_loss: 4.6119 - val_accuracy: 0.0156\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9571 - accuracy: 0.0078 - val_loss: 4.6393 - val_accuracy: 0.0156\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9295 - accuracy: 0.0312 - val_loss: 4.6769 - val_accuracy: 0.0156\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8988 - accuracy: 0.0234 - val_loss: 4.7294 - val_accuracy: 0.0156\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8314 - accuracy: 0.0312 - val_loss: 4.7601 - val_accuracy: 0.0234\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.5858 - accuracy: 0.0391 - val_loss: 4.7498 - val_accuracy: 0.0156\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7166 - accuracy: 0.0312 - val_loss: 4.7392 - val_accuracy: 0.0156\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8528 - accuracy: 0.0391 - val_loss: 4.7467 - val_accuracy: 0.0234\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8159 - accuracy: 0.0156 - val_loss: 4.7509 - val_accuracy: 0.0234\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6507 - accuracy: 0.0547 - val_loss: 4.7307 - val_accuracy: 0.0234\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7687 - accuracy: 0.0234 - val_loss: 4.7320 - val_accuracy: 0.0234\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8960 - accuracy: 0.0234 - val_loss: 4.7372 - val_accuracy: 0.0234\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8268 - accuracy: 0.0234 - val_loss: 4.7310 - val_accuracy: 0.0234\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9161 - accuracy: 0.0312 - val_loss: 4.7436 - val_accuracy: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6718 - accuracy: 0.0547 - val_loss: 4.7431 - val_accuracy: 0.0234\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7595 - accuracy: 0.0156 - val_loss: 4.7360 - val_accuracy: 0.0234\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8688 - accuracy: 0.0156 - val_loss: 4.7395 - val_accuracy: 0.0234\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9352 - accuracy: 0.0078 - val_loss: 4.7502 - val_accuracy: 0.0156\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8248 - accuracy: 0.0312 - val_loss: 4.7304 - val_accuracy: 0.0156\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8654 - accuracy: 0.0547 - val_loss: 4.7338 - val_accuracy: 0.0156\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7443 - accuracy: 0.0547 - val_loss: 4.7762 - val_accuracy: 0.0156\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7074 - accuracy: 0.0234 - val_loss: 4.7915 - val_accuracy: 0.0156\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7253 - accuracy: 0.0234 - val_loss: 4.8149 - val_accuracy: 0.0078\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7664 - accuracy: 0.0234 - val_loss: 4.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7923 - accuracy: 0.0391 - val_loss: 4.8689 - val_accuracy: 0.0078\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9317 - accuracy: 0.0547 - val_loss: 4.8912 - val_accuracy: 0.0078\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6856 - accuracy: 0.0391 - val_loss: 4.8941 - val_accuracy: 0.0078\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7823 - accuracy: 0.0547 - val_loss: 4.9153 - val_accuracy: 0.0078\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8644 - accuracy: 0.0547 - val_loss: 4.9273 - val_accuracy: 0.0078\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9411 - accuracy: 0.0156 - val_loss: 4.9425 - val_accuracy: 0.0156\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7832 - accuracy: 0.0859 - val_loss: 4.9500 - val_accuracy: 0.0156\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8432 - accuracy: 0.0156 - val_loss: 4.9538 - val_accuracy: 0.0156\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8328 - accuracy: 0.0312 - val_loss: 4.9780 - val_accuracy: 0.0156\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.8237 - accuracy: 0.0078 - val_loss: 4.9877 - val_accuracy: 0.0156\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7567 - accuracy: 0.0234 - val_loss: 5.0136 - val_accuracy: 0.0156\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6581 - accuracy: 0.0156 - val_loss: 5.0336 - val_accuracy: 0.0156\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9462 - accuracy: 0.0078 - val_loss: 5.0467 - val_accuracy: 0.0156\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8752 - accuracy: 0.0078 - val_loss: 5.0706 - val_accuracy: 0.0156\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9215 - accuracy: 0.0156 - val_loss: 5.1016 - val_accuracy: 0.0156\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6351 - accuracy: 0.0469 - val_loss: 5.1367 - val_accuracy: 0.0156\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8505 - accuracy: 0.0547 - val_loss: 5.1615 - val_accuracy: 0.0234\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7602 - accuracy: 0.0078 - val_loss: 5.1622 - val_accuracy: 0.0234\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5705 - accuracy: 0.0625 - val_loss: 5.1496 - val_accuracy: 0.0234\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7037 - accuracy: 0.0703 - val_loss: 5.1388 - val_accuracy: 0.0234\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6955 - accuracy: 0.0391 - val_loss: 5.1241 - val_accuracy: 0.0234\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7382 - accuracy: 0.0859 - val_loss: 5.1286 - val_accuracy: 0.0156\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7579 - accuracy: 0.0547 - val_loss: 5.1527 - val_accuracy: 0.0156\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7921 - accuracy: 0.0234 - val_loss: 5.1573 - val_accuracy: 0.0156\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.9354 - accuracy: 0.0078 - val_loss: 5.1491 - val_accuracy: 0.0156\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7175 - accuracy: 0.0234 - val_loss: 5.1261 - val_accuracy: 0.0312\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 4.7044 - accuracy: 0.0625 - val_loss: 5.0702 - val_accuracy: 0.0312\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6121 - accuracy: 0.0703 - val_loss: 5.0628 - val_accuracy: 0.0234\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7511 - accuracy: 0.0469 - val_loss: 5.0229 - val_accuracy: 0.0234\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7972 - accuracy: 0.0156 - val_loss: 4.9630 - val_accuracy: 0.0234\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9978 - accuracy: 0.0000e+00 - val_loss: 4.9065 - val_accuracy: 0.0234\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7222 - accuracy: 0.0469 - val_loss: 4.8230 - val_accuracy: 0.0234\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9147 - accuracy: 0.0000e+00 - val_loss: 4.7984 - val_accuracy: 0.0234\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8432 - accuracy: 0.0078 - val_loss: 4.8002 - val_accuracy: 0.0234\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6699 - accuracy: 0.0469 - val_loss: 4.8005 - val_accuracy: 0.0234\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7708 - accuracy: 0.0156 - val_loss: 4.8356 - val_accuracy: 0.0156\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7491 - accuracy: 0.0625 - val_loss: 4.8409 - val_accuracy: 0.0078\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0025 - accuracy: 0.0234 - val_loss: 4.8568 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7191 - accuracy: 0.0312 - val_loss: 4.8457 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.6092 - accuracy: 0.0156 - val_loss: 4.8338 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7563 - accuracy: 0.0156 - val_loss: 4.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7492 - accuracy: 0.0469 - val_loss: 4.8195 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 4.6980 - accuracy: 0.0391 - val_loss: 4.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.6719 - accuracy: 0.0312 - val_loss: 4.8299 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7026 - accuracy: 0.0547 - val_loss: 4.8395 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8849 - accuracy: 0.0312 - val_loss: 4.8311 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7007 - accuracy: 0.0703 - val_loss: 4.8356 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6796 - accuracy: 0.0781 - val_loss: 4.8565 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6508 - accuracy: 0.0391 - val_loss: 4.8735 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7724 - accuracy: 0.0234 - val_loss: 4.8903 - val_accuracy: 0.0156\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8757 - accuracy: 0.0156 - val_loss: 4.9159 - val_accuracy: 0.0234\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9064 - accuracy: 0.0156 - val_loss: 4.9309 - val_accuracy: 0.0312\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7319 - accuracy: 0.0547 - val_loss: 4.8766 - val_accuracy: 0.0312\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6678 - accuracy: 0.0234 - val_loss: 4.8379 - val_accuracy: 0.0312\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7740 - accuracy: 0.0625 - val_loss: 4.8067 - val_accuracy: 0.0312\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7519 - accuracy: 0.0234 - val_loss: 4.7872 - val_accuracy: 0.0312\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6173 - accuracy: 0.0547 - val_loss: 4.7831 - val_accuracy: 0.0312\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6131 - accuracy: 0.0781 - val_loss: 4.7621 - val_accuracy: 0.0312\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6281 - accuracy: 0.1484 - val_loss: 4.7381 - val_accuracy: 0.0312\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7796 - accuracy: 0.0312 - val_loss: 4.6893 - val_accuracy: 0.0391\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6553 - accuracy: 0.0312 - val_loss: 4.6610 - val_accuracy: 0.0469\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9139 - accuracy: 0.0391 - val_loss: 4.6516 - val_accuracy: 0.0781\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7804 - accuracy: 0.0156 - val_loss: 4.6375 - val_accuracy: 0.1094\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7103 - accuracy: 0.0391 - val_loss: 4.6551 - val_accuracy: 0.1016\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8289 - accuracy: 0.0234 - val_loss: 4.7071 - val_accuracy: 0.0469\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7261 - accuracy: 0.0391 - val_loss: 4.7513 - val_accuracy: 0.0312\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7618 - accuracy: 0.0703 - val_loss: 4.7991 - val_accuracy: 0.0391\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.7933 - accuracy: 0.0391 - val_loss: 4.8127 - val_accuracy: 0.0312\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6898 - accuracy: 0.0312 - val_loss: 4.8315 - val_accuracy: 0.0312\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8186 - accuracy: 0.0234 - val_loss: 4.8485 - val_accuracy: 0.0156\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7394 - accuracy: 0.0000e+00 - val_loss: 4.8715 - val_accuracy: 0.0156\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7924 - accuracy: 0.0234 - val_loss: 4.9069 - val_accuracy: 0.0234\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7716 - accuracy: 0.0234 - val_loss: 4.9317 - val_accuracy: 0.0234\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4752 - accuracy: 0.0703 - val_loss: 4.9242 - val_accuracy: 0.0234\n",
      "Epoch 00253: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=89560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=89560\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 5.6319 - accuracy: 0.0000e+00 - val_loss: 5.5457 - val_accuracy: 0.0078\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5816 - accuracy: 0.0000e+00 - val_loss: 5.5455 - val_accuracy: 0.0078\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.5910 - accuracy: 0.0000e+00 - val_loss: 5.5441 - val_accuracy: 0.0078\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.5175 - accuracy: 0.0000e+00 - val_loss: 5.5417 - val_accuracy: 0.0078\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.5510 - accuracy: 0.0000e+00 - val_loss: 5.5393 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4533 - accuracy: 0.0156 - val_loss: 5.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.4841 - accuracy: 0.0078 - val_loss: 5.5327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4340 - accuracy: 0.0000e+00 - val_loss: 5.5303 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.4850 - accuracy: 0.0000e+00 - val_loss: 5.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.4631 - accuracy: 0.0078 - val_loss: 5.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.4860 - accuracy: 0.0156 - val_loss: 5.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4259 - accuracy: 0.0078 - val_loss: 5.5085 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3968 - accuracy: 0.0391 - val_loss: 5.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.4150 - accuracy: 0.0078 - val_loss: 5.4878 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4307 - accuracy: 0.0234 - val_loss: 5.4760 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3495 - accuracy: 0.0078 - val_loss: 5.4670 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3752 - accuracy: 0.0234 - val_loss: 5.4646 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3250 - accuracy: 0.0312 - val_loss: 5.4642 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.3763 - accuracy: 0.0234 - val_loss: 5.4707 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3875 - accuracy: 0.0078 - val_loss: 5.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3181 - accuracy: 0.0234 - val_loss: 5.4765 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3447 - accuracy: 0.0156 - val_loss: 5.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2828 - accuracy: 0.0234 - val_loss: 5.4439 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3176 - accuracy: 0.0156 - val_loss: 5.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3751 - accuracy: 0.0078 - val_loss: 5.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.2791 - accuracy: 0.0156 - val_loss: 5.3579 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3186 - accuracy: 0.0234 - val_loss: 5.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2470 - accuracy: 0.0469 - val_loss: 5.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3217 - accuracy: 0.0234 - val_loss: 5.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1820 - accuracy: 0.0391 - val_loss: 5.2870 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3227 - accuracy: 0.0000e+00 - val_loss: 5.2488 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.1867 - accuracy: 0.0391 - val_loss: 5.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2833 - accuracy: 0.0469 - val_loss: 5.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2193 - accuracy: 0.0391 - val_loss: 5.1677 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.2288 - accuracy: 0.0234 - val_loss: 5.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.2791 - accuracy: 0.0156 - val_loss: 5.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2558 - accuracy: 0.0234 - val_loss: 5.0759 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2751 - accuracy: 0.0078 - val_loss: 5.0638 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2122 - accuracy: 0.0391 - val_loss: 5.0549 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.2443 - accuracy: 0.0078 - val_loss: 5.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1992 - accuracy: 0.0391 - val_loss: 5.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 5.2866 - accuracy: 0.0234 - val_loss: 5.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1299 - accuracy: 0.0391 - val_loss: 5.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1597 - accuracy: 0.0234 - val_loss: 5.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.2113 - accuracy: 0.0391 - val_loss: 5.0606 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.1844 - accuracy: 0.0469 - val_loss: 5.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0878 - accuracy: 0.0156 - val_loss: 5.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3065 - accuracy: 0.0078 - val_loss: 5.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0246 - accuracy: 0.0156 - val_loss: 5.0837 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1254 - accuracy: 0.0156 - val_loss: 5.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1841 - accuracy: 0.0391 - val_loss: 5.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2394 - accuracy: 0.0078 - val_loss: 5.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1794 - accuracy: 0.0391 - val_loss: 5.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1164 - accuracy: 0.0156 - val_loss: 5.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0991 - accuracy: 0.0391 - val_loss: 5.1382 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0932 - accuracy: 0.0547 - val_loss: 5.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0911 - accuracy: 0.0312 - val_loss: 5.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8745 - accuracy: 0.0781 - val_loss: 5.1762 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0251 - accuracy: 0.0156 - val_loss: 5.1661 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0333 - accuracy: 0.0469 - val_loss: 5.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1426 - accuracy: 0.0156 - val_loss: 5.1504 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1120 - accuracy: 0.0156 - val_loss: 5.1712 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1873 - accuracy: 0.0234 - val_loss: 5.1957 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0803 - accuracy: 0.0156 - val_loss: 5.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9964 - accuracy: 0.0156 - val_loss: 5.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0946 - accuracy: 0.0547 - val_loss: 5.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9809 - accuracy: 0.0469 - val_loss: 5.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0659 - accuracy: 0.0312 - val_loss: 5.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.1406 - accuracy: 0.0234 - val_loss: 5.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1944 - accuracy: 0.0312 - val_loss: 5.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0579 - accuracy: 0.0547 - val_loss: 5.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8796 - accuracy: 0.0625 - val_loss: 5.0362 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0448 - accuracy: 0.0234 - val_loss: 5.0632 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1294 - accuracy: 0.0469 - val_loss: 5.1115 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1480 - accuracy: 0.0234 - val_loss: 5.1554 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0858 - accuracy: 0.0312 - val_loss: 5.1821 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0246 - accuracy: 0.0156 - val_loss: 5.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.1285 - accuracy: 0.0312 - val_loss: 5.1651 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1146 - accuracy: 0.0078 - val_loss: 5.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9852 - accuracy: 0.0078 - val_loss: 5.1283 - val_accuracy: 0.0078\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0852 - accuracy: 0.0234 - val_loss: 5.1071 - val_accuracy: 0.0078\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.1107 - accuracy: 0.0000e+00 - val_loss: 5.0930 - val_accuracy: 0.0078\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9127 - accuracy: 0.0156 - val_loss: 5.0824 - val_accuracy: 0.0078\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0414 - accuracy: 0.0391 - val_loss: 5.0963 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0537 - accuracy: 0.0156 - val_loss: 5.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8917 - accuracy: 0.0469 - val_loss: 5.0668 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0323 - accuracy: 0.0156 - val_loss: 5.0338 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9691 - accuracy: 0.0234 - val_loss: 4.9947 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0560 - accuracy: 0.0234 - val_loss: 4.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9897 - accuracy: 0.0391 - val_loss: 5.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9351 - accuracy: 0.0234 - val_loss: 5.0812 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9487 - accuracy: 0.0078 - val_loss: 5.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9140 - accuracy: 0.0469 - val_loss: 5.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9862 - accuracy: 0.0312 - val_loss: 5.1656 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 5.3535 - accuracy: 0.0156 - val_loss: 5.1632 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0842 - accuracy: 0.0234 - val_loss: 5.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0055 - accuracy: 0.0781 - val_loss: 5.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0748 - accuracy: 0.0234 - val_loss: 5.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0821 - accuracy: 0.0312 - val_loss: 5.0874 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1605 - accuracy: 0.0391 - val_loss: 5.0653 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1726 - accuracy: 0.0156 - val_loss: 5.0400 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.0979 - accuracy: 0.0156 - val_loss: 5.0071 - val_accuracy: 0.0078\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9511 - accuracy: 0.0234 - val_loss: 4.9981 - val_accuracy: 0.0078\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0164 - accuracy: 0.0312 - val_loss: 4.9980 - val_accuracy: 0.0078\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0327 - accuracy: 0.0547 - val_loss: 5.0140 - val_accuracy: 0.0078\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.0059 - accuracy: 0.0234 - val_loss: 5.0119 - val_accuracy: 0.0078\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0512 - accuracy: 0.0312 - val_loss: 5.0185 - val_accuracy: 0.0078\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8718 - accuracy: 0.0000e+00 - val_loss: 5.0220 - val_accuracy: 0.0078\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9080 - accuracy: 0.0547 - val_loss: 5.0408 - val_accuracy: 0.0078\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9998 - accuracy: 0.0312 - val_loss: 5.0728 - val_accuracy: 0.0078\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9104 - accuracy: 0.0312 - val_loss: 5.0979 - val_accuracy: 0.0078\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0721 - accuracy: 0.0156 - val_loss: 5.0762 - val_accuracy: 0.0078\n",
      "Epoch 113/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8882 - accuracy: 0.0391 - val_loss: 5.0469 - val_accuracy: 0.0078\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.0249 - accuracy: 0.0234 - val_loss: 5.0152 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0880 - accuracy: 0.0391 - val_loss: 5.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0334 - accuracy: 0.0234 - val_loss: 5.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9280 - accuracy: 0.0078 - val_loss: 5.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.0298 - accuracy: 0.0234 - val_loss: 5.0250 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9099 - accuracy: 0.0312 - val_loss: 5.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9140 - accuracy: 0.0312 - val_loss: 5.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9903 - accuracy: 0.0234 - val_loss: 4.9779 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9572 - accuracy: 0.0234 - val_loss: 4.9385 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9471 - accuracy: 0.0469 - val_loss: 4.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9827 - accuracy: 0.0234 - val_loss: 4.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0519 - accuracy: 0.0156 - val_loss: 4.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0058 - accuracy: 0.0156 - val_loss: 4.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8770 - accuracy: 0.0156 - val_loss: 4.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8432 - accuracy: 0.0078 - val_loss: 4.9697 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0854 - accuracy: 0.0234 - val_loss: 4.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0771 - accuracy: 0.0156 - val_loss: 5.0226 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7828 - accuracy: 0.0234 - val_loss: 5.0416 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1743 - accuracy: 0.0078 - val_loss: 5.0528 - val_accuracy: 0.0156\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8398 - accuracy: 0.0234 - val_loss: 5.0406 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9096 - accuracy: 0.0312 - val_loss: 5.0333 - val_accuracy: 0.0078\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9942 - accuracy: 0.0156 - val_loss: 5.0354 - val_accuracy: 0.0078\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8988 - accuracy: 0.0000e+00 - val_loss: 5.0211 - val_accuracy: 0.0078\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0457 - accuracy: 0.0000e+00 - val_loss: 4.9898 - val_accuracy: 0.0234\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0446 - accuracy: 0.0312 - val_loss: 4.9554 - val_accuracy: 0.0312\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8351 - accuracy: 0.0469 - val_loss: 4.9181 - val_accuracy: 0.0312\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7578 - accuracy: 0.0469 - val_loss: 4.8957 - val_accuracy: 0.0234\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9344 - accuracy: 0.0312 - val_loss: 4.9257 - val_accuracy: 0.0078\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.0647 - accuracy: 0.0000e+00 - val_loss: 4.9491 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9997 - accuracy: 0.0156 - val_loss: 4.9330 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8678 - accuracy: 0.0234 - val_loss: 4.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9828 - accuracy: 0.0156 - val_loss: 4.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9748 - accuracy: 0.0156 - val_loss: 4.8144 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8470 - accuracy: 0.0547 - val_loss: 4.7516 - val_accuracy: 0.1094\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1287 - accuracy: 0.0391 - val_loss: 4.6991 - val_accuracy: 0.1406\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9178 - accuracy: 0.0156 - val_loss: 4.6791 - val_accuracy: 0.1328\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7277 - accuracy: 0.0469 - val_loss: 4.6537 - val_accuracy: 0.1250\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9042 - accuracy: 0.0391 - val_loss: 4.6543 - val_accuracy: 0.1250\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9862 - accuracy: 0.0391 - val_loss: 4.6792 - val_accuracy: 0.0859\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8903 - accuracy: 0.0312 - val_loss: 4.7092 - val_accuracy: 0.0469\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7100 - accuracy: 0.0312 - val_loss: 4.7102 - val_accuracy: 0.0312\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7155 - accuracy: 0.0625 - val_loss: 4.7070 - val_accuracy: 0.0391\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0339 - accuracy: 0.0156 - val_loss: 4.7041 - val_accuracy: 0.0547\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9751 - accuracy: 0.0391 - val_loss: 4.6907 - val_accuracy: 0.0625\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9401 - accuracy: 0.0156 - val_loss: 4.6959 - val_accuracy: 0.0078\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9945 - accuracy: 0.0078 - val_loss: 4.7004 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9814 - accuracy: 0.0234 - val_loss: 4.6648 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1037 - accuracy: 0.0234 - val_loss: 4.6370 - val_accuracy: 0.0234\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9364 - accuracy: 0.0156 - val_loss: 4.6293 - val_accuracy: 0.0234\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9598 - accuracy: 0.0078 - val_loss: 4.6056 - val_accuracy: 0.0078\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8863 - accuracy: 0.0469 - val_loss: 4.5967 - val_accuracy: 0.0156\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8516 - accuracy: 0.0781 - val_loss: 4.6215 - val_accuracy: 0.0156\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.9768 - accuracy: 0.0156 - val_loss: 4.6441 - val_accuracy: 0.0078\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9248 - accuracy: 0.0547 - val_loss: 4.6598 - val_accuracy: 0.0156\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 5.0556 - accuracy: 0.0156 - val_loss: 4.6697 - val_accuracy: 0.0547\n",
      "Epoch 169/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 52ms/step - loss: 4.8672 - accuracy: 0.0469 - val_loss: 4.6721 - val_accuracy: 0.0703\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8413 - accuracy: 0.0000e+00 - val_loss: 4.6687 - val_accuracy: 0.0859\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8883 - accuracy: 0.0234 - val_loss: 4.6922 - val_accuracy: 0.1328\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.7006 - accuracy: 0.0391 - val_loss: 4.7015 - val_accuracy: 0.1484\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.0147 - accuracy: 0.0234 - val_loss: 4.7066 - val_accuracy: 0.1406\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8509 - accuracy: 0.0156 - val_loss: 4.6896 - val_accuracy: 0.1094\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8584 - accuracy: 0.0234 - val_loss: 4.6724 - val_accuracy: 0.0859\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9859 - accuracy: 0.0234 - val_loss: 4.6699 - val_accuracy: 0.0625\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8057 - accuracy: 0.0234 - val_loss: 4.6680 - val_accuracy: 0.0078\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7427 - accuracy: 0.0625 - val_loss: 4.6719 - val_accuracy: 0.0078\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9594 - accuracy: 0.0234 - val_loss: 4.6932 - val_accuracy: 0.0156\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7843 - accuracy: 0.0312 - val_loss: 4.6999 - val_accuracy: 0.0156\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9091 - accuracy: 0.0234 - val_loss: 4.7112 - val_accuracy: 0.0156\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0217 - accuracy: 0.0312 - val_loss: 4.7600 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 4.7176 - accuracy: 0.0312 - val_loss: 4.7771 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9553 - accuracy: 0.0547 - val_loss: 4.8006 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9014 - accuracy: 0.0234 - val_loss: 4.8530 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7140 - accuracy: 0.0156 - val_loss: 4.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9030 - accuracy: 0.0078 - val_loss: 4.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8452 - accuracy: 0.0078 - val_loss: 4.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7314 - accuracy: 0.0391 - val_loss: 5.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.0136 - accuracy: 0.0156 - val_loss: 5.0123 - val_accuracy: 0.0156\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7008 - accuracy: 0.0078 - val_loss: 4.9899 - val_accuracy: 0.0469\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7427 - accuracy: 0.0547 - val_loss: 4.9807 - val_accuracy: 0.0547\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9795 - accuracy: 0.0078 - val_loss: 4.9822 - val_accuracy: 0.0547\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9111 - accuracy: 0.0156 - val_loss: 4.9653 - val_accuracy: 0.0781\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8733 - accuracy: 0.0391 - val_loss: 4.9384 - val_accuracy: 0.0781\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0415 - accuracy: 0.0234 - val_loss: 4.9164 - val_accuracy: 0.0391\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9079 - accuracy: 0.0312 - val_loss: 4.9047 - val_accuracy: 0.0234\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8802 - accuracy: 0.0312 - val_loss: 4.9155 - val_accuracy: 0.0156\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9166 - accuracy: 0.0312 - val_loss: 4.9400 - val_accuracy: 0.0156\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8463 - accuracy: 0.0391 - val_loss: 4.9573 - val_accuracy: 0.0234\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9751 - accuracy: 0.0156 - val_loss: 4.9799 - val_accuracy: 0.0234\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8700 - accuracy: 0.0234 - val_loss: 5.0183 - val_accuracy: 0.0234\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7487 - accuracy: 0.0391 - val_loss: 5.0362 - val_accuracy: 0.0312\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9441 - accuracy: 0.0000e+00 - val_loss: 5.0389 - val_accuracy: 0.0312\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9694 - accuracy: 0.0312 - val_loss: 5.0481 - val_accuracy: 0.0234\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8571 - accuracy: 0.0156 - val_loss: 5.0548 - val_accuracy: 0.0234\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8228 - accuracy: 0.0156 - val_loss: 5.0510 - val_accuracy: 0.0234\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8053 - accuracy: 0.0078 - val_loss: 5.0506 - val_accuracy: 0.0234\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7970 - accuracy: 0.0391 - val_loss: 5.0420 - val_accuracy: 0.0234\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9107 - accuracy: 0.0078 - val_loss: 5.0400 - val_accuracy: 0.0234\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8659 - accuracy: 0.0156 - val_loss: 5.0312 - val_accuracy: 0.0234\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9147 - accuracy: 0.0312 - val_loss: 5.0220 - val_accuracy: 0.0391\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9392 - accuracy: 0.0469 - val_loss: 5.0182 - val_accuracy: 0.0312\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7605 - accuracy: 0.0156 - val_loss: 5.0354 - val_accuracy: 0.0234\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9266 - accuracy: 0.0312 - val_loss: 5.0463 - val_accuracy: 0.0234\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 4.8307 - accuracy: 0.0391 - val_loss: 5.0577 - val_accuracy: 0.0234\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7963 - accuracy: 0.0234 - val_loss: 5.0867 - val_accuracy: 0.0234\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9580 - accuracy: 0.0234 - val_loss: 5.1186 - val_accuracy: 0.0234\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8942 - accuracy: 0.0078 - val_loss: 5.1159 - val_accuracy: 0.0312\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7682 - accuracy: 0.0234 - val_loss: 5.0921 - val_accuracy: 0.0234\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9490 - accuracy: 0.0391 - val_loss: 5.0561 - val_accuracy: 0.0312\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7356 - accuracy: 0.0234 - val_loss: 5.0071 - val_accuracy: 0.0469\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9123 - accuracy: 0.0156 - val_loss: 4.9362 - val_accuracy: 0.1484\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7975 - accuracy: 0.0234 - val_loss: 4.9060 - val_accuracy: 0.1562\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8592 - accuracy: 0.0156 - val_loss: 4.8955 - val_accuracy: 0.1562\n",
      "Epoch 226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7560 - accuracy: 0.0391 - val_loss: 4.8641 - val_accuracy: 0.1641\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7184 - accuracy: 0.0234 - val_loss: 4.8246 - val_accuracy: 0.1562\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6496 - accuracy: 0.0547 - val_loss: 4.7614 - val_accuracy: 0.0156\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8076 - accuracy: 0.0547 - val_loss: 4.7370 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8443 - accuracy: 0.0391 - val_loss: 4.7439 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8952 - accuracy: 0.0078 - val_loss: 4.7509 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0004 - accuracy: 0.0078 - val_loss: 4.7587 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8443 - accuracy: 0.0078 - val_loss: 4.7655 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0780 - accuracy: 0.0078 - val_loss: 4.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8009 - accuracy: 0.0469 - val_loss: 4.8333 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6888 - accuracy: 0.0547 - val_loss: 4.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7898 - accuracy: 0.0312 - val_loss: 4.9195 - val_accuracy: 0.0078\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7607 - accuracy: 0.0469 - val_loss: 4.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8080 - accuracy: 0.0156 - val_loss: 4.9273 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7260 - accuracy: 0.0391 - val_loss: 4.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7963 - accuracy: 0.0391 - val_loss: 4.9552 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8020 - accuracy: 0.0469 - val_loss: 4.9542 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9361 - accuracy: 0.0156 - val_loss: 4.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8017 - accuracy: 0.0312 - val_loss: 4.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8463 - accuracy: 0.0312 - val_loss: 4.8905 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9129 - accuracy: 0.0078 - val_loss: 4.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9020 - accuracy: 0.0391 - val_loss: 4.7506 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6415 - accuracy: 0.0312 - val_loss: 4.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8678 - accuracy: 0.0391 - val_loss: 4.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.9548 - accuracy: 0.0234 - val_loss: 4.5781 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7590 - accuracy: 0.0312 - val_loss: 4.5342 - val_accuracy: 0.0156\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7263 - accuracy: 0.0391 - val_loss: 4.5222 - val_accuracy: 0.0156\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8873 - accuracy: 0.0156 - val_loss: 4.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.5991 - accuracy: 0.0312 - val_loss: 4.5634 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7823 - accuracy: 0.0234 - val_loss: 4.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8134 - accuracy: 0.0234 - val_loss: 4.6818 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8799 - accuracy: 0.0156 - val_loss: 4.7883 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7595 - accuracy: 0.0703 - val_loss: 4.8079 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8879 - accuracy: 0.0000e+00 - val_loss: 4.8019 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6458 - accuracy: 0.0547 - val_loss: 4.7857 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9334 - accuracy: 0.0234 - val_loss: 4.7670 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8900 - accuracy: 0.0234 - val_loss: 4.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7843 - accuracy: 0.0625 - val_loss: 4.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8813 - accuracy: 0.0391 - val_loss: 4.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8023 - accuracy: 0.0312 - val_loss: 4.6722 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7083 - accuracy: 0.0625 - val_loss: 4.7001 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8670 - accuracy: 0.0000e+00 - val_loss: 4.7455 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8828 - accuracy: 0.0625 - val_loss: 4.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8375 - accuracy: 0.0078 - val_loss: 4.8029 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8886 - accuracy: 0.0312 - val_loss: 4.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8256 - accuracy: 0.0078 - val_loss: 4.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8753 - accuracy: 0.0547 - val_loss: 4.8226 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7245 - accuracy: 0.0234 - val_loss: 4.8104 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0265 - accuracy: 0.0156 - val_loss: 4.7965 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.9799 - accuracy: 0.0156 - val_loss: 4.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7016 - accuracy: 0.0469 - val_loss: 4.7452 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6956 - accuracy: 0.0391 - val_loss: 4.7327 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8539 - accuracy: 0.0000e+00 - val_loss: 4.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8904 - accuracy: 0.0000e+00 - val_loss: 4.7722 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8609 - accuracy: 0.0469 - val_loss: 4.7794 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8318 - accuracy: 0.0312 - val_loss: 4.7945 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7468 - accuracy: 0.0156 - val_loss: 4.7947 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6008 - accuracy: 0.0078 - val_loss: 4.7997 - val_accuracy: 0.0078\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6243 - accuracy: 0.0703 - val_loss: 4.7991 - val_accuracy: 0.0078\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.9342 - accuracy: 0.0078 - val_loss: 4.7887 - val_accuracy: 0.0078\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7887 - accuracy: 0.0469 - val_loss: 4.7731 - val_accuracy: 0.0078\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.5987 - accuracy: 0.0781 - val_loss: 4.7611 - val_accuracy: 0.0078\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6761 - accuracy: 0.0469 - val_loss: 4.7545 - val_accuracy: 0.0078\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8819 - accuracy: 0.0156 - val_loss: 4.7524 - val_accuracy: 0.0078\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9009 - accuracy: 0.0078 - val_loss: 4.7561 - val_accuracy: 0.0156\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8881 - accuracy: 0.0625 - val_loss: 4.7652 - val_accuracy: 0.0156\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6837 - accuracy: 0.0625 - val_loss: 4.7661 - val_accuracy: 0.0156\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.7506 - accuracy: 0.0703 - val_loss: 4.7270 - val_accuracy: 0.0156\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7296 - accuracy: 0.0234 - val_loss: 4.7129 - val_accuracy: 0.0156\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7674 - accuracy: 0.0078 - val_loss: 4.6657 - val_accuracy: 0.0078\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9135 - accuracy: 0.0234 - val_loss: 4.6350 - val_accuracy: 0.0078\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7226 - accuracy: 0.0312 - val_loss: 4.6175 - val_accuracy: 0.0078\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8641 - accuracy: 0.0234 - val_loss: 4.6208 - val_accuracy: 0.0078\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9508 - accuracy: 0.0156 - val_loss: 4.5949 - val_accuracy: 0.0078\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0155 - accuracy: 0.0156 - val_loss: 4.5763 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8111 - accuracy: 0.0156 - val_loss: 4.5682 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7418 - accuracy: 0.0391 - val_loss: 4.5809 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8485 - accuracy: 0.0234 - val_loss: 4.6016 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6198 - accuracy: 0.0312 - val_loss: 4.6186 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.0273 - accuracy: 0.0156 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7184 - accuracy: 0.0234 - val_loss: 4.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8769 - accuracy: 0.0156 - val_loss: 4.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7409 - accuracy: 0.0469 - val_loss: 4.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8246 - accuracy: 0.0234 - val_loss: 4.6185 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7371 - accuracy: 0.0234 - val_loss: 4.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8999 - accuracy: 0.0391 - val_loss: 4.6671 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7608 - accuracy: 0.0156 - val_loss: 4.6956 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7239 - accuracy: 0.0312 - val_loss: 4.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6713 - accuracy: 0.0234 - val_loss: 4.7429 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6564 - accuracy: 0.0469 - val_loss: 4.7340 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7771 - accuracy: 0.0312 - val_loss: 4.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7410 - accuracy: 0.0312 - val_loss: 4.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6328 - accuracy: 0.0234 - val_loss: 4.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7836 - accuracy: 0.0156 - val_loss: 4.6845 - val_accuracy: 0.0078\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7538 - accuracy: 0.0469 - val_loss: 4.6504 - val_accuracy: 0.0156\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8654 - accuracy: 0.0469 - val_loss: 4.6125 - val_accuracy: 0.0312\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8204 - accuracy: 0.0312 - val_loss: 4.5848 - val_accuracy: 0.1484\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8564 - accuracy: 0.0547 - val_loss: 4.5859 - val_accuracy: 0.1406\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8448 - accuracy: 0.0312 - val_loss: 4.5959 - val_accuracy: 0.1328\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7052 - accuracy: 0.0156 - val_loss: 4.6204 - val_accuracy: 0.0781\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8210 - accuracy: 0.0625 - val_loss: 4.6508 - val_accuracy: 0.0781\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8486 - accuracy: 0.0391 - val_loss: 4.6933 - val_accuracy: 0.0859\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 4.8697 - accuracy: 0.0312 - val_loss: 4.7129 - val_accuracy: 0.0234\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8084 - accuracy: 0.0312 - val_loss: 4.7333 - val_accuracy: 0.0078\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8324 - accuracy: 0.0312 - val_loss: 4.7209 - val_accuracy: 0.0078\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9334 - accuracy: 0.0078 - val_loss: 4.7249 - val_accuracy: 0.0078\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6163 - accuracy: 0.0469 - val_loss: 4.7065 - val_accuracy: 0.0312\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9016 - accuracy: 0.0703 - val_loss: 4.6880 - val_accuracy: 0.0703\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7265 - accuracy: 0.0781 - val_loss: 4.6545 - val_accuracy: 0.1562\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7146 - accuracy: 0.0469 - val_loss: 4.6015 - val_accuracy: 0.1562\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.9147 - accuracy: 0.0156 - val_loss: 4.5439 - val_accuracy: 0.1406\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9415 - accuracy: 0.0234 - val_loss: 4.5302 - val_accuracy: 0.1328\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8257 - accuracy: 0.0156 - val_loss: 4.5359 - val_accuracy: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8263 - accuracy: 0.0000e+00 - val_loss: 4.5552 - val_accuracy: 0.0078\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9524 - accuracy: 0.0156 - val_loss: 4.5794 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9126 - accuracy: 0.0156 - val_loss: 4.6099 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7857 - accuracy: 0.0391 - val_loss: 4.6178 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.6178 - accuracy: 0.0625 - val_loss: 4.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7329 - accuracy: 0.0625 - val_loss: 4.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.6733 - accuracy: 0.0469 - val_loss: 4.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7254 - accuracy: 0.0156 - val_loss: 4.5722 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5933 - accuracy: 0.0625 - val_loss: 4.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7634 - accuracy: 0.0234 - val_loss: 4.5515 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7444 - accuracy: 0.0469 - val_loss: 4.5618 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5795 - accuracy: 0.0469 - val_loss: 4.5726 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7231 - accuracy: 0.0391 - val_loss: 4.5884 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6358 - accuracy: 0.0781 - val_loss: 4.6092 - val_accuracy: 0.0000e+00\n",
      "Epoch 00352: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 8)       48        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 8)       200       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 8)       32        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 8)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 16)      656       \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 16)      784       \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 16)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 32)      2592      \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 32)      3104      \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 32)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 32)       5152      \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 32)       3104      \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 32)       128       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 32)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 64)       10304     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 64)       12352     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 64)       20544     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 64)       12352     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 64)       0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      16640     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,560\n",
      "Trainable params: 88,696\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=89560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=320304\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 5.6162 - accuracy: 0.0000e+00 - val_loss: 5.5449 - val_accuracy: 0.0234\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.5784 - accuracy: 0.0000e+00 - val_loss: 5.5428 - val_accuracy: 0.0234\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4439 - accuracy: 0.0312 - val_loss: 5.5370 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.5176 - accuracy: 0.0000e+00 - val_loss: 5.5179 - val_accuracy: 0.0391\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.5593 - accuracy: 0.0156 - val_loss: 5.4926 - val_accuracy: 0.0391\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 91ms/step - loss: 5.4301 - accuracy: 0.0156 - val_loss: 5.4610 - val_accuracy: 0.0391\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.3734 - accuracy: 0.0000e+00 - val_loss: 5.4281 - val_accuracy: 0.0391\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.4164 - accuracy: 0.0156 - val_loss: 5.4043 - val_accuracy: 0.1641\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3032 - accuracy: 0.0391 - val_loss: 5.3792 - val_accuracy: 0.1641\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.4113 - accuracy: 0.0391 - val_loss: 5.3729 - val_accuracy: 0.0156\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4254 - accuracy: 0.0312 - val_loss: 5.3556 - val_accuracy: 0.1641\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.3650 - accuracy: 0.0469 - val_loss: 5.3440 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.3102 - accuracy: 0.0078 - val_loss: 5.3504 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2741 - accuracy: 0.0078 - val_loss: 5.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3217 - accuracy: 0.0234 - val_loss: 5.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.2988 - accuracy: 0.0234 - val_loss: 5.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1967 - accuracy: 0.0234 - val_loss: 5.2083 - val_accuracy: 0.0547\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.1891 - accuracy: 0.0391 - val_loss: 5.1626 - val_accuracy: 0.0859\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2854 - accuracy: 0.0078 - val_loss: 5.1051 - val_accuracy: 0.0234\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3145 - accuracy: 0.0156 - val_loss: 5.0731 - val_accuracy: 0.1094\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0929 - accuracy: 0.0625 - val_loss: 5.0534 - val_accuracy: 0.0078\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2586 - accuracy: 0.0156 - val_loss: 5.0458 - val_accuracy: 0.0547\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.3115 - accuracy: 0.0000e+00 - val_loss: 5.0403 - val_accuracy: 0.1562\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1270 - accuracy: 0.0547 - val_loss: 5.0329 - val_accuracy: 0.1641\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2918 - accuracy: 0.0234 - val_loss: 5.0459 - val_accuracy: 0.1328\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2618 - accuracy: 0.0000e+00 - val_loss: 5.0640 - val_accuracy: 0.0156\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1902 - accuracy: 0.0156 - val_loss: 5.0781 - val_accuracy: 0.1406\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0393 - accuracy: 0.0312 - val_loss: 5.0756 - val_accuracy: 0.1641\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1159 - accuracy: 0.0391 - val_loss: 5.0652 - val_accuracy: 0.1406\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.1987 - accuracy: 0.0156 - val_loss: 5.0604 - val_accuracy: 0.1641\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1156 - accuracy: 0.0234 - val_loss: 5.0227 - val_accuracy: 0.1641\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9612 - accuracy: 0.0391 - val_loss: 4.9707 - val_accuracy: 0.1641\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9694 - accuracy: 0.0625 - val_loss: 4.9116 - val_accuracy: 0.1641\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1065 - accuracy: 0.0469 - val_loss: 4.8821 - val_accuracy: 0.1641\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1073 - accuracy: 0.0312 - val_loss: 4.8692 - val_accuracy: 0.1641\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1275 - accuracy: 0.0156 - val_loss: 4.8778 - val_accuracy: 0.1641\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0609 - accuracy: 0.0312 - val_loss: 4.9022 - val_accuracy: 0.1484\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0935 - accuracy: 0.0156 - val_loss: 4.8849 - val_accuracy: 0.1250\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9006 - accuracy: 0.0625 - val_loss: 4.8816 - val_accuracy: 0.0781\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7971 - accuracy: 0.0781 - val_loss: 4.8789 - val_accuracy: 0.0781\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0807 - accuracy: 0.0156 - val_loss: 4.8796 - val_accuracy: 0.0859\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0419 - accuracy: 0.0391 - val_loss: 4.8520 - val_accuracy: 0.1172\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8781 - accuracy: 0.0312 - val_loss: 4.7846 - val_accuracy: 0.1562\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9590 - accuracy: 0.0547 - val_loss: 4.7782 - val_accuracy: 0.1562\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7534 - accuracy: 0.0859 - val_loss: 4.7733 - val_accuracy: 0.1562\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9901 - accuracy: 0.0234 - val_loss: 4.7746 - val_accuracy: 0.1562\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8457 - accuracy: 0.0234 - val_loss: 4.7821 - val_accuracy: 0.1562\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8715 - accuracy: 0.0469 - val_loss: 4.8452 - val_accuracy: 0.0625\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8347 - accuracy: 0.0469 - val_loss: 5.0157 - val_accuracy: 0.0312\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9145 - accuracy: 0.0156 - val_loss: 5.0879 - val_accuracy: 0.0234\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7963 - accuracy: 0.0391 - val_loss: 4.9683 - val_accuracy: 0.0469\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9698 - accuracy: 0.0391 - val_loss: 4.9090 - val_accuracy: 0.0156\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9169 - accuracy: 0.0312 - val_loss: 4.9061 - val_accuracy: 0.0625\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7935 - accuracy: 0.0156 - val_loss: 4.9682 - val_accuracy: 0.0703\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0674 - accuracy: 0.0156 - val_loss: 5.0201 - val_accuracy: 0.1250\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1139 - accuracy: 0.0234 - val_loss: 5.0610 - val_accuracy: 0.1406\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7849 - accuracy: 0.0547 - val_loss: 5.1628 - val_accuracy: 0.1406\n",
      "Epoch 58/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6291 - accuracy: 0.1094 - val_loss: 5.2478 - val_accuracy: 0.1406\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8392 - accuracy: 0.0156 - val_loss: 5.4542 - val_accuracy: 0.0781\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9560 - accuracy: 0.0312 - val_loss: 5.7418 - val_accuracy: 0.0391\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6913 - accuracy: 0.0625 - val_loss: 5.9795 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8149 - accuracy: 0.0000e+00 - val_loss: 6.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6478 - accuracy: 0.0469 - val_loss: 6.3509 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8900 - accuracy: 0.0234 - val_loss: 6.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8193 - accuracy: 0.0312 - val_loss: 5.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9354 - accuracy: 0.0156 - val_loss: 5.7259 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5152 - accuracy: 0.0625 - val_loss: 5.3842 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8461 - accuracy: 0.0078 - val_loss: 5.2965 - val_accuracy: 0.0156\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6274 - accuracy: 0.0547 - val_loss: 5.0349 - val_accuracy: 0.0156\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0050 - accuracy: 0.0234 - val_loss: 4.8912 - val_accuracy: 0.0312\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5084 - accuracy: 0.0625 - val_loss: 4.9455 - val_accuracy: 0.0234\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0051 - accuracy: 0.0156 - val_loss: 5.1075 - val_accuracy: 0.0391\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8893 - accuracy: 0.0156 - val_loss: 5.1097 - val_accuracy: 0.0234\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8148 - accuracy: 0.0391 - val_loss: 5.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8145 - accuracy: 0.0391 - val_loss: 5.0190 - val_accuracy: 0.0156\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7724 - accuracy: 0.0547 - val_loss: 5.1421 - val_accuracy: 0.0234\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7453 - accuracy: 0.0312 - val_loss: 5.0435 - val_accuracy: 0.0156\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5157 - accuracy: 0.1094 - val_loss: 4.8887 - val_accuracy: 0.0234\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7199 - accuracy: 0.0625 - val_loss: 4.8942 - val_accuracy: 0.0234\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6331 - accuracy: 0.0312 - val_loss: 5.1354 - val_accuracy: 0.0156\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6865 - accuracy: 0.0078 - val_loss: 5.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5700 - accuracy: 0.0938 - val_loss: 6.1609 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7416 - accuracy: 0.0312 - val_loss: 6.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6486 - accuracy: 0.0625 - val_loss: 7.7795 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.8540 - accuracy: 0.0312 - val_loss: 8.0550 - val_accuracy: 0.0078\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7583 - accuracy: 0.0234 - val_loss: 7.6322 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5005 - accuracy: 0.0703 - val_loss: 6.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8903 - accuracy: 0.0312 - val_loss: 6.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7379 - accuracy: 0.0391 - val_loss: 6.9316 - val_accuracy: 0.0234\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8444 - accuracy: 0.0469 - val_loss: 6.8160 - val_accuracy: 0.0156\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7114 - accuracy: 0.0703 - val_loss: 6.4257 - val_accuracy: 0.0156\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7073 - accuracy: 0.0234 - val_loss: 6.3265 - val_accuracy: 0.0156\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7899 - accuracy: 0.0312 - val_loss: 5.9130 - val_accuracy: 0.0078\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4772 - accuracy: 0.0938 - val_loss: 5.4541 - val_accuracy: 0.0234\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.4852 - accuracy: 0.0156 - val_loss: 5.5437 - val_accuracy: 0.0234\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5943 - accuracy: 0.0859 - val_loss: 5.8812 - val_accuracy: 0.0234\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5347 - accuracy: 0.0781 - val_loss: 6.1532 - val_accuracy: 0.0156\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4634 - accuracy: 0.0547 - val_loss: 6.9931 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6523 - accuracy: 0.0625 - val_loss: 8.4648 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6752 - accuracy: 0.0078 - val_loss: 8.4340 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5080 - accuracy: 0.0312 - val_loss: 7.9874 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5179 - accuracy: 0.0547 - val_loss: 7.8008 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.3374 - accuracy: 0.0547 - val_loss: 7.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6769 - accuracy: 0.0469 - val_loss: 7.5437 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.4777 - accuracy: 0.0625 - val_loss: 9.0239 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2866 - accuracy: 0.1172 - val_loss: 9.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4079 - accuracy: 0.1094 - val_loss: 8.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.4180 - accuracy: 0.0625 - val_loss: 6.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6261 - accuracy: 0.0156 - val_loss: 5.8008 - val_accuracy: 0.0078\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.2669 - accuracy: 0.0859 - val_loss: 6.0612 - val_accuracy: 0.0078\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.3522 - accuracy: 0.0547 - val_loss: 6.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6987 - accuracy: 0.0156 - val_loss: 6.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4395 - accuracy: 0.0078 - val_loss: 6.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2513 - accuracy: 0.1172 - val_loss: 6.4934 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2649 - accuracy: 0.1094 - val_loss: 6.8149 - val_accuracy: 0.0078\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4574 - accuracy: 0.0312 - val_loss: 6.2711 - val_accuracy: 0.0078\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.5057 - accuracy: 0.1016 - val_loss: 5.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.3126 - accuracy: 0.0547 - val_loss: 5.4866 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5197 - accuracy: 0.0547 - val_loss: 5.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4708 - accuracy: 0.0391 - val_loss: 4.9556 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4265 - accuracy: 0.0078 - val_loss: 4.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.4162 - accuracy: 0.0781 - val_loss: 4.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4003 - accuracy: 0.0391 - val_loss: 5.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.3902 - accuracy: 0.0859 - val_loss: 5.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.2179 - accuracy: 0.0547 - val_loss: 5.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3520 - accuracy: 0.0547 - val_loss: 6.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5384 - accuracy: 0.0469 - val_loss: 6.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.3345 - accuracy: 0.0312 - val_loss: 6.6814 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4311 - accuracy: 0.0781 - val_loss: 6.4028 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1203 - accuracy: 0.1250 - val_loss: 6.1932 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.1866 - accuracy: 0.1328 - val_loss: 5.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.1940 - accuracy: 0.0625 - val_loss: 4.5104 - val_accuracy: 0.0156\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2037 - accuracy: 0.0703 - val_loss: 4.5601 - val_accuracy: 0.0469\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1860 - accuracy: 0.0781 - val_loss: 4.2304 - val_accuracy: 0.1016\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4469 - accuracy: 0.0703 - val_loss: 4.1840 - val_accuracy: 0.1719\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1509 - accuracy: 0.0391 - val_loss: 4.3101 - val_accuracy: 0.1484\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.0209 - accuracy: 0.1484 - val_loss: 4.5320 - val_accuracy: 0.1328\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.2681 - accuracy: 0.0938 - val_loss: 4.4542 - val_accuracy: 0.1719\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4495 - accuracy: 0.0781 - val_loss: 4.0596 - val_accuracy: 0.1797\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.0863 - accuracy: 0.0781 - val_loss: 3.8427 - val_accuracy: 0.1484\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5157 - accuracy: 0.0938 - val_loss: 3.9835 - val_accuracy: 0.1250\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.3437 - accuracy: 0.0781 - val_loss: 4.1535 - val_accuracy: 0.0703\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.2173 - accuracy: 0.0859 - val_loss: 4.2052 - val_accuracy: 0.0312\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1012 - accuracy: 0.0781 - val_loss: 4.3692 - val_accuracy: 0.0156\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1168 - accuracy: 0.0547 - val_loss: 4.2992 - val_accuracy: 0.0078\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5213 - accuracy: 0.0469 - val_loss: 4.1384 - val_accuracy: 0.0312\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0293 - accuracy: 0.0781 - val_loss: 4.3653 - val_accuracy: 0.0625\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5498 - accuracy: 0.0859 - val_loss: 4.5877 - val_accuracy: 0.0391\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.1942 - accuracy: 0.0469 - val_loss: 4.3923 - val_accuracy: 0.0078\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2934 - accuracy: 0.0625 - val_loss: 4.2226 - val_accuracy: 0.0234\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.3416 - accuracy: 0.0469 - val_loss: 4.3036 - val_accuracy: 0.0156\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2970 - accuracy: 0.0625 - val_loss: 4.3109 - val_accuracy: 0.0703\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.0908 - accuracy: 0.0859 - val_loss: 4.3827 - val_accuracy: 0.0781\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0774 - accuracy: 0.0703 - val_loss: 4.8745 - val_accuracy: 0.0234\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2235 - accuracy: 0.1094 - val_loss: 5.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2456 - accuracy: 0.0781 - val_loss: 4.7071 - val_accuracy: 0.0312\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0501 - accuracy: 0.1172 - val_loss: 4.5300 - val_accuracy: 0.0703\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.1517 - accuracy: 0.1016 - val_loss: 4.5435 - val_accuracy: 0.0547\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.0608 - accuracy: 0.0938 - val_loss: 4.6183 - val_accuracy: 0.0312\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9016 - accuracy: 0.1406 - val_loss: 4.7484 - val_accuracy: 0.0312\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.8121 - accuracy: 0.1172 - val_loss: 4.7770 - val_accuracy: 0.0391\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.1119 - accuracy: 0.0938 - val_loss: 4.9756 - val_accuracy: 0.0156\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8862 - accuracy: 0.1250 - val_loss: 4.6513 - val_accuracy: 0.0234\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1521 - accuracy: 0.0938 - val_loss: 4.0959 - val_accuracy: 0.0938\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9334 - accuracy: 0.1250 - val_loss: 5.0289 - val_accuracy: 0.0547\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1872 - accuracy: 0.1172 - val_loss: 5.5984 - val_accuracy: 0.0391\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9859 - accuracy: 0.1328 - val_loss: 4.8289 - val_accuracy: 0.0234\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.2447 - accuracy: 0.0625 - val_loss: 4.3141 - val_accuracy: 0.0391\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.0283 - accuracy: 0.0703 - val_loss: 4.3458 - val_accuracy: 0.0781\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9474 - accuracy: 0.0938 - val_loss: 4.3668 - val_accuracy: 0.0859\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9637 - accuracy: 0.1250 - val_loss: 4.5002 - val_accuracy: 0.0703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.2512 - accuracy: 0.0938 - val_loss: 4.5423 - val_accuracy: 0.0391\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9510 - accuracy: 0.1406 - val_loss: 4.5681 - val_accuracy: 0.0391\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.1486 - accuracy: 0.0469 - val_loss: 5.2906 - val_accuracy: 0.0156\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8051 - accuracy: 0.1250 - val_loss: 5.4436 - val_accuracy: 0.0156\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9867 - accuracy: 0.1484 - val_loss: 5.1335 - val_accuracy: 0.0156\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6727 - accuracy: 0.1250 - val_loss: 4.7874 - val_accuracy: 0.0312\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.9513 - accuracy: 0.0859 - val_loss: 4.5991 - val_accuracy: 0.1094\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.0689 - accuracy: 0.0703 - val_loss: 4.5009 - val_accuracy: 0.0938\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.2514 - accuracy: 0.0859 - val_loss: 4.5217 - val_accuracy: 0.0625\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9678 - accuracy: 0.1250 - val_loss: 4.2034 - val_accuracy: 0.0938\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9663 - accuracy: 0.1328 - val_loss: 4.1096 - val_accuracy: 0.1172\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.1282 - accuracy: 0.1094 - val_loss: 4.0084 - val_accuracy: 0.1406\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9139 - accuracy: 0.0781 - val_loss: 3.8641 - val_accuracy: 0.1406\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.7582 - accuracy: 0.2031 - val_loss: 4.0257 - val_accuracy: 0.0859\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9041 - accuracy: 0.1484 - val_loss: 4.2406 - val_accuracy: 0.0703\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.8736 - accuracy: 0.1250 - val_loss: 4.1122 - val_accuracy: 0.0625\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.1691 - accuracy: 0.0312 - val_loss: 4.1498 - val_accuracy: 0.0625\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.0505 - accuracy: 0.0312 - val_loss: 4.4728 - val_accuracy: 0.0234\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.0158 - accuracy: 0.1094 - val_loss: 4.3343 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1859 - accuracy: 0.0938 - val_loss: 4.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.9633 - accuracy: 0.1172 - val_loss: 4.3603 - val_accuracy: 0.0078\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.0500 - accuracy: 0.0625 - val_loss: 4.0392 - val_accuracy: 0.0469\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.9656 - accuracy: 0.0859 - val_loss: 3.8025 - val_accuracy: 0.1094\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9354 - accuracy: 0.1406 - val_loss: 3.7900 - val_accuracy: 0.0625\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8293 - accuracy: 0.1094 - val_loss: 3.8860 - val_accuracy: 0.0547\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.9100 - accuracy: 0.1172 - val_loss: 4.0037 - val_accuracy: 0.0547\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1846 - accuracy: 0.0156 - val_loss: 4.1733 - val_accuracy: 0.0547\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.8840 - accuracy: 0.1484 - val_loss: 4.2047 - val_accuracy: 0.0469\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.6850 - accuracy: 0.1562 - val_loss: 4.3595 - val_accuracy: 0.0391\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8934 - accuracy: 0.1562 - val_loss: 4.3344 - val_accuracy: 0.0469\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.9156 - accuracy: 0.0547 - val_loss: 4.2413 - val_accuracy: 0.0703\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7398 - accuracy: 0.1094 - val_loss: 3.9743 - val_accuracy: 0.0781\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.8172 - accuracy: 0.1250 - val_loss: 3.5969 - val_accuracy: 0.1094\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7983 - accuracy: 0.0703 - val_loss: 3.8772 - val_accuracy: 0.1328\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8351 - accuracy: 0.1172 - val_loss: 4.3774 - val_accuracy: 0.1250\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.9335 - accuracy: 0.0938 - val_loss: 4.5052 - val_accuracy: 0.1406\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7923 - accuracy: 0.1172 - val_loss: 4.0375 - val_accuracy: 0.0703\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.9174 - accuracy: 0.1172 - val_loss: 3.5074 - val_accuracy: 0.0703\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6466 - accuracy: 0.1641 - val_loss: 3.6265 - val_accuracy: 0.0625\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.8180 - accuracy: 0.1094 - val_loss: 4.2059 - val_accuracy: 0.0547\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8476 - accuracy: 0.0859 - val_loss: 4.6481 - val_accuracy: 0.0234\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.0866 - accuracy: 0.0625 - val_loss: 4.1938 - val_accuracy: 0.0625\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.8590 - accuracy: 0.1016 - val_loss: 4.0384 - val_accuracy: 0.0547\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.7598 - accuracy: 0.1484 - val_loss: 4.7763 - val_accuracy: 0.0312\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.6396 - accuracy: 0.1641 - val_loss: 5.1861 - val_accuracy: 0.0234\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7337 - accuracy: 0.1875 - val_loss: 4.9577 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7012 - accuracy: 0.0938 - val_loss: 4.5356 - val_accuracy: 0.0391\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.5744 - accuracy: 0.1562 - val_loss: 4.3480 - val_accuracy: 0.0391\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.6471 - accuracy: 0.1250 - val_loss: 3.9917 - val_accuracy: 0.1406\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.9069 - accuracy: 0.0859 - val_loss: 3.8246 - val_accuracy: 0.1094\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.8816 - accuracy: 0.1016 - val_loss: 4.3518 - val_accuracy: 0.0781\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.7353 - accuracy: 0.1172 - val_loss: 4.9619 - val_accuracy: 0.0078\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.7644 - accuracy: 0.0859 - val_loss: 4.7390 - val_accuracy: 0.0234\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7615 - accuracy: 0.1172 - val_loss: 4.3142 - val_accuracy: 0.0859\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5610 - accuracy: 0.1797 - val_loss: 4.1694 - val_accuracy: 0.1094\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.7925 - accuracy: 0.1406 - val_loss: 4.3204 - val_accuracy: 0.1016\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.7634 - accuracy: 0.1016 - val_loss: 4.5618 - val_accuracy: 0.1406\n",
      "Epoch 229/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5103 - accuracy: 0.1797 - val_loss: 4.4194 - val_accuracy: 0.1250\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.6646 - accuracy: 0.1797 - val_loss: 4.5004 - val_accuracy: 0.0859\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.9313 - accuracy: 0.0859 - val_loss: 4.3838 - val_accuracy: 0.0703\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.5731 - accuracy: 0.0781 - val_loss: 4.1714 - val_accuracy: 0.1016\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.5097 - accuracy: 0.1484 - val_loss: 4.2593 - val_accuracy: 0.0703\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.7217 - accuracy: 0.1250 - val_loss: 4.7115 - val_accuracy: 0.0156\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7538 - accuracy: 0.0938 - val_loss: 4.9921 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6340 - accuracy: 0.1719 - val_loss: 4.6283 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6906 - accuracy: 0.0703 - val_loss: 4.0316 - val_accuracy: 0.0156\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.3172 - accuracy: 0.2031 - val_loss: 3.8535 - val_accuracy: 0.0469\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.3707 - accuracy: 0.1797 - val_loss: 3.4730 - val_accuracy: 0.1250\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4224 - accuracy: 0.1953 - val_loss: 3.5923 - val_accuracy: 0.0781\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.6639 - accuracy: 0.1328 - val_loss: 3.4932 - val_accuracy: 0.1016\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.9359 - accuracy: 0.0703 - val_loss: 3.4496 - val_accuracy: 0.1250\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.6989 - accuracy: 0.1406 - val_loss: 3.6633 - val_accuracy: 0.0234\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6592 - accuracy: 0.1016 - val_loss: 3.4967 - val_accuracy: 0.0469\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6463 - accuracy: 0.1953 - val_loss: 3.6397 - val_accuracy: 0.0078\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6792 - accuracy: 0.1016 - val_loss: 3.9532 - val_accuracy: 0.0234\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5754 - accuracy: 0.1797 - val_loss: 4.4049 - val_accuracy: 0.0156\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.7396 - accuracy: 0.0781 - val_loss: 4.0975 - val_accuracy: 0.0469\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5654 - accuracy: 0.1719 - val_loss: 4.0568 - val_accuracy: 0.0547\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4873 - accuracy: 0.1797 - val_loss: 4.0739 - val_accuracy: 0.0547\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.7517 - accuracy: 0.1016 - val_loss: 3.8371 - val_accuracy: 0.0625\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6633 - accuracy: 0.1797 - val_loss: 3.7417 - val_accuracy: 0.0625\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6813 - accuracy: 0.1250 - val_loss: 3.6860 - val_accuracy: 0.1016\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4001 - accuracy: 0.1797 - val_loss: 3.6839 - val_accuracy: 0.0625\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.5410 - accuracy: 0.1797 - val_loss: 3.8359 - val_accuracy: 0.0625\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.8326 - accuracy: 0.0625 - val_loss: 4.6858 - val_accuracy: 0.0312\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.6403 - accuracy: 0.1484 - val_loss: 4.8882 - val_accuracy: 0.0469\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 3.6287 - accuracy: 0.1328 - val_loss: 3.9651 - val_accuracy: 0.0859\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4691 - accuracy: 0.1797 - val_loss: 3.6108 - val_accuracy: 0.0547\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.4623 - accuracy: 0.1484 - val_loss: 3.8416 - val_accuracy: 0.0391\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.5289 - accuracy: 0.0547 - val_loss: 4.0456 - val_accuracy: 0.0469\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4530 - accuracy: 0.1719 - val_loss: 4.7895 - val_accuracy: 0.0703\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6710 - accuracy: 0.1641 - val_loss: 5.2797 - val_accuracy: 0.0156\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5521 - accuracy: 0.1719 - val_loss: 4.4976 - val_accuracy: 0.0156\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.1894 - accuracy: 0.2188 - val_loss: 3.8294 - val_accuracy: 0.1641\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4153 - accuracy: 0.1172 - val_loss: 3.7138 - val_accuracy: 0.1719\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5615 - accuracy: 0.1250 - val_loss: 4.0777 - val_accuracy: 0.1797\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.2939 - accuracy: 0.2266 - val_loss: 3.9596 - val_accuracy: 0.2188\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.2221 - accuracy: 0.2500 - val_loss: 3.5460 - val_accuracy: 0.2734\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.1916 - accuracy: 0.2344 - val_loss: 3.0731 - val_accuracy: 0.2969\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6799 - accuracy: 0.1406 - val_loss: 2.9282 - val_accuracy: 0.3438\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5947 - accuracy: 0.0938 - val_loss: 3.2403 - val_accuracy: 0.2109\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3371 - accuracy: 0.2188 - val_loss: 3.5838 - val_accuracy: 0.1641\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3204 - accuracy: 0.2109 - val_loss: 3.6354 - val_accuracy: 0.1953\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3958 - accuracy: 0.2656 - val_loss: 3.8676 - val_accuracy: 0.1562\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3842 - accuracy: 0.2422 - val_loss: 3.7842 - val_accuracy: 0.1719\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2476 - accuracy: 0.2812 - val_loss: 4.0893 - val_accuracy: 0.1328\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.9573 - accuracy: 0.0547 - val_loss: 4.5332 - val_accuracy: 0.0703\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.5954 - accuracy: 0.1172 - val_loss: 4.9349 - val_accuracy: 0.0312\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.5746 - accuracy: 0.1250 - val_loss: 4.8678 - val_accuracy: 0.0703\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8780 - accuracy: 0.0703 - val_loss: 4.3562 - val_accuracy: 0.0469\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.6374 - accuracy: 0.0781 - val_loss: 3.8339 - val_accuracy: 0.0547\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.5777 - accuracy: 0.1406 - val_loss: 3.9759 - val_accuracy: 0.0234\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.7970 - accuracy: 0.0547 - val_loss: 4.1346 - val_accuracy: 0.0312\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3301 - accuracy: 0.2188 - val_loss: 4.2624 - val_accuracy: 0.0078\n",
      "Epoch 286/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3556 - accuracy: 0.2500 - val_loss: 3.8442 - val_accuracy: 0.0469\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5537 - accuracy: 0.2109 - val_loss: 3.7967 - val_accuracy: 0.0312\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2828 - accuracy: 0.2266 - val_loss: 4.0141 - val_accuracy: 0.0156\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.5757 - accuracy: 0.1641 - val_loss: 4.1287 - val_accuracy: 0.0078\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.3775 - accuracy: 0.2578 - val_loss: 3.8978 - val_accuracy: 0.0234\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.6801 - accuracy: 0.1406 - val_loss: 3.7856 - val_accuracy: 0.0234\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3963 - accuracy: 0.2109 - val_loss: 3.9149 - val_accuracy: 0.0469\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.4884 - accuracy: 0.0938 - val_loss: 3.9865 - val_accuracy: 0.1094\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4243 - accuracy: 0.1641 - val_loss: 3.8754 - val_accuracy: 0.1641\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3311 - accuracy: 0.1875 - val_loss: 3.8227 - val_accuracy: 0.1953\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.5236 - accuracy: 0.1094 - val_loss: 3.6588 - val_accuracy: 0.1953\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.7044 - accuracy: 0.0703 - val_loss: 3.5400 - val_accuracy: 0.2109\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3400 - accuracy: 0.2109 - val_loss: 3.6457 - val_accuracy: 0.2266\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2800 - accuracy: 0.2578 - val_loss: 3.5151 - val_accuracy: 0.1875\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4663 - accuracy: 0.2422 - val_loss: 3.8495 - val_accuracy: 0.1719\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.5268 - accuracy: 0.1875 - val_loss: 4.2671 - val_accuracy: 0.0781\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.5109 - accuracy: 0.1328 - val_loss: 4.3745 - val_accuracy: 0.1016\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.4402 - accuracy: 0.1094 - val_loss: 3.6246 - val_accuracy: 0.2031\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.5150 - accuracy: 0.1016 - val_loss: 3.3181 - val_accuracy: 0.2031\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3505 - accuracy: 0.1641 - val_loss: 2.9970 - val_accuracy: 0.2188\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3008 - accuracy: 0.1641 - val_loss: 3.1436 - val_accuracy: 0.1172\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3881 - accuracy: 0.1172 - val_loss: 3.3661 - val_accuracy: 0.1094\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3070 - accuracy: 0.0781 - val_loss: 3.3372 - val_accuracy: 0.2109\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4215 - accuracy: 0.1875 - val_loss: 3.3168 - val_accuracy: 0.0938\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5792 - accuracy: 0.1250 - val_loss: 3.3851 - val_accuracy: 0.0391\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4825 - accuracy: 0.1875 - val_loss: 3.5457 - val_accuracy: 0.0625\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3816 - accuracy: 0.2109 - val_loss: 3.6432 - val_accuracy: 0.0391\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4975 - accuracy: 0.1797 - val_loss: 3.8004 - val_accuracy: 0.0312\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3524 - accuracy: 0.1875 - val_loss: 3.9701 - val_accuracy: 0.0391\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.3423 - accuracy: 0.1719 - val_loss: 3.7104 - val_accuracy: 0.0312\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.9960 - accuracy: 0.2969 - val_loss: 3.6613 - val_accuracy: 0.0469\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.4169 - accuracy: 0.1328 - val_loss: 3.9499 - val_accuracy: 0.0391\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 3.5071 - accuracy: 0.1484 - val_loss: 4.0658 - val_accuracy: 0.0391\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.2208 - accuracy: 0.2031 - val_loss: 4.2661 - val_accuracy: 0.0312\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4172 - accuracy: 0.2031 - val_loss: 4.3166 - val_accuracy: 0.0078\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1704 - accuracy: 0.2266 - val_loss: 4.2256 - val_accuracy: 0.0078\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3851 - accuracy: 0.1875 - val_loss: 4.2731 - val_accuracy: 0.0078\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.4973 - accuracy: 0.1094 - val_loss: 4.0924 - val_accuracy: 0.0078\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.1635 - accuracy: 0.2500 - val_loss: 3.6946 - val_accuracy: 0.0391\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 3.0338 - accuracy: 0.2344 - val_loss: 3.3696 - val_accuracy: 0.0781\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2057 - accuracy: 0.2188 - val_loss: 3.3460 - val_accuracy: 0.0938\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.2275 - accuracy: 0.2734 - val_loss: 3.3701 - val_accuracy: 0.0625\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5185 - accuracy: 0.1250 - val_loss: 3.4325 - val_accuracy: 0.0547\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1009 - accuracy: 0.2031 - val_loss: 3.5976 - val_accuracy: 0.0312\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3429 - accuracy: 0.1641 - val_loss: 3.5903 - val_accuracy: 0.0469\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.2874 - accuracy: 0.1562 - val_loss: 3.5290 - val_accuracy: 0.0703\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.2077 - accuracy: 0.1875 - val_loss: 3.5075 - val_accuracy: 0.0469\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.4043 - accuracy: 0.1328 - val_loss: 3.5122 - val_accuracy: 0.0312\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.0611 - accuracy: 0.2109 - val_loss: 3.4694 - val_accuracy: 0.0469\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2977 - accuracy: 0.2266 - val_loss: 3.5544 - val_accuracy: 0.0469\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.1678 - accuracy: 0.2344 - val_loss: 4.1311 - val_accuracy: 0.0078\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.2321 - accuracy: 0.2109 - val_loss: 4.7274 - val_accuracy: 0.0078\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.5624 - accuracy: 0.1719 - val_loss: 4.3351 - val_accuracy: 0.0156\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2555 - accuracy: 0.2266 - val_loss: 4.1752 - val_accuracy: 0.0078\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.5668 - accuracy: 0.0938 - val_loss: 3.8375 - val_accuracy: 0.0156\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2392 - accuracy: 0.2109 - val_loss: 3.5208 - val_accuracy: 0.0312\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.1436 - accuracy: 0.1953 - val_loss: 3.5233 - val_accuracy: 0.0859\n",
      "Epoch 343/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0336 - accuracy: 0.2891 - val_loss: 3.4744 - val_accuracy: 0.1406\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.2011 - accuracy: 0.2109 - val_loss: 3.4597 - val_accuracy: 0.1797\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4821 - accuracy: 0.1016 - val_loss: 3.2755 - val_accuracy: 0.1328\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2646 - accuracy: 0.1328 - val_loss: 3.2369 - val_accuracy: 0.1484\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.2672 - accuracy: 0.1719 - val_loss: 3.2415 - val_accuracy: 0.0703\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.0135 - accuracy: 0.2266 - val_loss: 3.1868 - val_accuracy: 0.0938\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.2139 - accuracy: 0.2344 - val_loss: 3.0028 - val_accuracy: 0.1797\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.1239 - accuracy: 0.1562 - val_loss: 2.9418 - val_accuracy: 0.3516\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.0704 - accuracy: 0.2656 - val_loss: 3.0376 - val_accuracy: 0.3594\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.1136 - accuracy: 0.2031 - val_loss: 2.8340 - val_accuracy: 0.3359\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1295 - accuracy: 0.2500 - val_loss: 2.8055 - val_accuracy: 0.3672\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.2310 - accuracy: 0.2031 - val_loss: 2.7556 - val_accuracy: 0.3828\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.2577 - accuracy: 0.2422 - val_loss: 2.7855 - val_accuracy: 0.3984\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.1220 - accuracy: 0.2422 - val_loss: 2.7679 - val_accuracy: 0.4531\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.1230 - accuracy: 0.2188 - val_loss: 2.6934 - val_accuracy: 0.4219\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.4775 - accuracy: 0.1250 - val_loss: 3.0568 - val_accuracy: 0.2578\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.1363 - accuracy: 0.1875 - val_loss: 3.8249 - val_accuracy: 0.0938\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3350 - accuracy: 0.1406 - val_loss: 3.8625 - val_accuracy: 0.1016\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.2529 - accuracy: 0.1641 - val_loss: 3.5242 - val_accuracy: 0.1094\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9646 - accuracy: 0.3047 - val_loss: 3.3656 - val_accuracy: 0.1250\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.2506 - accuracy: 0.2031 - val_loss: 3.3233 - val_accuracy: 0.1172\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.4270 - accuracy: 0.1953 - val_loss: 3.4552 - val_accuracy: 0.1484\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.1120 - accuracy: 0.2500 - val_loss: 3.8593 - val_accuracy: 0.1172\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.0403 - accuracy: 0.2344 - val_loss: 3.7065 - val_accuracy: 0.1641\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.9367 - accuracy: 0.2500 - val_loss: 3.4363 - val_accuracy: 0.2422\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.0265 - accuracy: 0.2266 - val_loss: 3.4020 - val_accuracy: 0.1875\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.1947 - accuracy: 0.1875 - val_loss: 3.4852 - val_accuracy: 0.1484\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.6749 - accuracy: 0.3594 - val_loss: 3.2759 - val_accuracy: 0.2500\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3730 - accuracy: 0.1641 - val_loss: 3.7413 - val_accuracy: 0.1016\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.3557 - accuracy: 0.1406 - val_loss: 3.8680 - val_accuracy: 0.0781\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2626 - accuracy: 0.2422 - val_loss: 3.9761 - val_accuracy: 0.0156\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.8300 - accuracy: 0.3438 - val_loss: 3.9962 - val_accuracy: 0.0078\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.7432 - accuracy: 0.3125 - val_loss: 3.9376 - val_accuracy: 0.0156\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.0698 - accuracy: 0.2656 - val_loss: 3.9602 - val_accuracy: 0.0234\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.9523 - accuracy: 0.2422 - val_loss: 4.1211 - val_accuracy: 0.0156\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.0823 - accuracy: 0.2344 - val_loss: 4.0426 - val_accuracy: 0.0156\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2222 - accuracy: 0.1797 - val_loss: 3.7825 - val_accuracy: 0.0312\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.0933 - accuracy: 0.1797 - val_loss: 3.6551 - val_accuracy: 0.0391\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9789 - accuracy: 0.2422 - val_loss: 3.6956 - val_accuracy: 0.0547\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.8926 - accuracy: 0.2188 - val_loss: 3.5496 - val_accuracy: 0.0625\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2369 - accuracy: 0.2031 - val_loss: 3.2392 - val_accuracy: 0.1328\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.9717 - accuracy: 0.2266 - val_loss: 3.1836 - val_accuracy: 0.1406\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.0812 - accuracy: 0.2422 - val_loss: 3.2735 - val_accuracy: 0.1406\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.0232 - accuracy: 0.2656 - val_loss: 3.4658 - val_accuracy: 0.1016\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.1060 - accuracy: 0.1719 - val_loss: 3.4927 - val_accuracy: 0.0859\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.9966 - accuracy: 0.2266 - val_loss: 3.3458 - val_accuracy: 0.0938\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.9252 - accuracy: 0.2812 - val_loss: 3.2912 - val_accuracy: 0.0703\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.3057 - accuracy: 0.1484 - val_loss: 3.2248 - val_accuracy: 0.0703\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.0383 - accuracy: 0.2031 - val_loss: 3.6036 - val_accuracy: 0.0703\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.9077 - accuracy: 0.2812 - val_loss: 3.7518 - val_accuracy: 0.0547\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.7723 - accuracy: 0.2578 - val_loss: 3.5537 - val_accuracy: 0.0938\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3709 - accuracy: 0.1719 - val_loss: 3.5732 - val_accuracy: 0.0547\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0455 - accuracy: 0.2188 - val_loss: 3.7254 - val_accuracy: 0.0391\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9987 - accuracy: 0.1953 - val_loss: 3.6543 - val_accuracy: 0.0469\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.9145 - accuracy: 0.2969 - val_loss: 3.3147 - val_accuracy: 0.0859\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1231 - accuracy: 0.1328 - val_loss: 3.0296 - val_accuracy: 0.2344\n",
      "Epoch 399/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.8859 - accuracy: 0.3906 - val_loss: 2.9058 - val_accuracy: 0.3125\n",
      "Epoch 400/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 70ms/step - loss: 2.8214 - accuracy: 0.2891 - val_loss: 2.8871 - val_accuracy: 0.2891\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.9226 - accuracy: 0.2500 - val_loss: 3.0377 - val_accuracy: 0.1797\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.1645 - accuracy: 0.2266 - val_loss: 3.3024 - val_accuracy: 0.1719\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4070 - accuracy: 0.1484 - val_loss: 4.0037 - val_accuracy: 0.0703\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.1027 - accuracy: 0.2578 - val_loss: 4.5383 - val_accuracy: 0.0703\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.8740 - accuracy: 0.2734 - val_loss: 4.3516 - val_accuracy: 0.0859\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.8801 - accuracy: 0.3125 - val_loss: 4.3683 - val_accuracy: 0.1406\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.8388 - accuracy: 0.3125 - val_loss: 4.5562 - val_accuracy: 0.0469\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4430 - accuracy: 0.1484 - val_loss: 3.8535 - val_accuracy: 0.1016\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.0719 - accuracy: 0.1953 - val_loss: 3.4650 - val_accuracy: 0.1328\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.9908 - accuracy: 0.2734 - val_loss: 3.5280 - val_accuracy: 0.0703\n",
      "Epoch 411/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.1672 - accuracy: 0.1953 - val_loss: 3.5780 - val_accuracy: 0.1016\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.7706 - accuracy: 0.2500 - val_loss: 3.3093 - val_accuracy: 0.1094\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0435 - accuracy: 0.2812 - val_loss: 2.9880 - val_accuracy: 0.1484\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.7734 - accuracy: 0.3125 - val_loss: 2.8767 - val_accuracy: 0.2266\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.1007 - accuracy: 0.1953 - val_loss: 2.9874 - val_accuracy: 0.2031\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.8841 - accuracy: 0.2656 - val_loss: 3.3044 - val_accuracy: 0.0859\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.0270 - accuracy: 0.2031 - val_loss: 3.6474 - val_accuracy: 0.0547\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8496 - accuracy: 0.2656 - val_loss: 3.6996 - val_accuracy: 0.0625\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.8195 - accuracy: 0.2188 - val_loss: 3.5190 - val_accuracy: 0.0156\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.9811 - accuracy: 0.2656 - val_loss: 3.4026 - val_accuracy: 0.0859\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.1194 - accuracy: 0.1953 - val_loss: 3.3328 - val_accuracy: 0.0547\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.8690 - accuracy: 0.2656 - val_loss: 3.5480 - val_accuracy: 0.0625\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.6536 - accuracy: 0.3047 - val_loss: 3.6986 - val_accuracy: 0.0938\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 2.8319 - accuracy: 0.2891 - val_loss: 3.6347 - val_accuracy: 0.0938\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.7087 - accuracy: 0.2969 - val_loss: 4.0503 - val_accuracy: 0.1016\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 3.0533 - accuracy: 0.2031 - val_loss: 4.0921 - val_accuracy: 0.0859\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9012 - accuracy: 0.2656 - val_loss: 3.8566 - val_accuracy: 0.0938\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9155 - accuracy: 0.3125 - val_loss: 3.7079 - val_accuracy: 0.1406\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.2034 - accuracy: 0.2266 - val_loss: 3.5116 - val_accuracy: 0.1406\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.8484 - accuracy: 0.3516 - val_loss: 3.2191 - val_accuracy: 0.2109\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.8145 - accuracy: 0.3203 - val_loss: 3.0081 - val_accuracy: 0.2578\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.7445 - accuracy: 0.2656 - val_loss: 2.9296 - val_accuracy: 0.2031\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.6534 - accuracy: 0.3438 - val_loss: 3.0036 - val_accuracy: 0.1328\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.9131 - accuracy: 0.2891 - val_loss: 3.0722 - val_accuracy: 0.0859\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.7471 - accuracy: 0.3203 - val_loss: 3.4053 - val_accuracy: 0.0078\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.1035 - accuracy: 0.2031 - val_loss: 3.7049 - val_accuracy: 0.0625\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.7858 - accuracy: 0.2656 - val_loss: 3.9545 - val_accuracy: 0.0703\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.8518 - accuracy: 0.1875 - val_loss: 3.5852 - val_accuracy: 0.0781\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.8186 - accuracy: 0.2656 - val_loss: 3.4357 - val_accuracy: 0.1016\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.6335 - accuracy: 0.3672 - val_loss: 3.4344 - val_accuracy: 0.1641\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.9479 - accuracy: 0.2656 - val_loss: 3.4410 - val_accuracy: 0.1562\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9391 - accuracy: 0.2266 - val_loss: 3.1588 - val_accuracy: 0.1875\n",
      "Epoch 443/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.8761 - accuracy: 0.2031 - val_loss: 3.2231 - val_accuracy: 0.2031\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.8567 - accuracy: 0.2266 - val_loss: 3.3435 - val_accuracy: 0.1797\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.7333 - accuracy: 0.3828 - val_loss: 3.3539 - val_accuracy: 0.1016\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 3.2899 - accuracy: 0.1953 - val_loss: 3.3197 - val_accuracy: 0.1406\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.8532 - accuracy: 0.2266 - val_loss: 3.0358 - val_accuracy: 0.2422\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.9494 - accuracy: 0.3438 - val_loss: 2.8427 - val_accuracy: 0.3438\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.8358 - accuracy: 0.2109 - val_loss: 2.9689 - val_accuracy: 0.2969\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.1527 - accuracy: 0.1562 - val_loss: 3.1186 - val_accuracy: 0.1875\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.8803 - accuracy: 0.2812 - val_loss: 3.0132 - val_accuracy: 0.1641\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.6528 - accuracy: 0.2969 - val_loss: 3.0528 - val_accuracy: 0.1484\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 3.0515 - accuracy: 0.2266 - val_loss: 2.7957 - val_accuracy: 0.2188\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 2.8950 - accuracy: 0.2578 - val_loss: 2.7993 - val_accuracy: 0.2188\n",
      "Epoch 455/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.7016 - accuracy: 0.2891 - val_loss: 2.9524 - val_accuracy: 0.2578\n",
      "Epoch 456/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.8426 - accuracy: 0.2578 - val_loss: 3.2023 - val_accuracy: 0.2734\n",
      "Epoch 457/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 63ms/step - loss: 2.9366 - accuracy: 0.2578 - val_loss: 3.2213 - val_accuracy: 0.2266\n",
      "Epoch 00457: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=320304\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=320304\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 542ms/step - loss: 5.6956 - accuracy: 0.0000e+00 - val_loss: 5.5363 - val_accuracy: 0.1641\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.6178 - accuracy: 0.0000e+00 - val_loss: 5.5280 - val_accuracy: 0.1641\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5819 - accuracy: 0.0156 - val_loss: 5.5280 - val_accuracy: 0.1641\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.4651 - accuracy: 0.0000e+00 - val_loss: 5.5254 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.5214 - accuracy: 0.0156 - val_loss: 5.5134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.4037 - accuracy: 0.0312 - val_loss: 5.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3728 - accuracy: 0.0078 - val_loss: 5.4686 - val_accuracy: 0.1641\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3657 - accuracy: 0.0312 - val_loss: 5.4392 - val_accuracy: 0.1641\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.3843 - accuracy: 0.0234 - val_loss: 5.4127 - val_accuracy: 0.1641\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3302 - accuracy: 0.0156 - val_loss: 5.3939 - val_accuracy: 0.1641\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.3276 - accuracy: 0.0391 - val_loss: 5.3612 - val_accuracy: 0.1641\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 5.2733 - accuracy: 0.0625 - val_loss: 5.3298 - val_accuracy: 0.1641\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2190 - accuracy: 0.0234 - val_loss: 5.2985 - val_accuracy: 0.1641\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3669 - accuracy: 0.0391 - val_loss: 5.2729 - val_accuracy: 0.1641\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.3136 - accuracy: 0.0312 - val_loss: 5.2399 - val_accuracy: 0.1641\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1146 - accuracy: 0.0391 - val_loss: 5.2092 - val_accuracy: 0.1641\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1750 - accuracy: 0.0703 - val_loss: 5.1764 - val_accuracy: 0.1641\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3533 - accuracy: 0.0234 - val_loss: 5.1762 - val_accuracy: 0.0078\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.3135 - accuracy: 0.0156 - val_loss: 5.1953 - val_accuracy: 0.0078\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.3228 - accuracy: 0.0312 - val_loss: 5.2275 - val_accuracy: 0.0078\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2334 - accuracy: 0.0469 - val_loss: 5.2721 - val_accuracy: 0.0078\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 5.2150 - accuracy: 0.0391 - val_loss: 5.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1841 - accuracy: 0.0078 - val_loss: 5.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2268 - accuracy: 0.0547 - val_loss: 5.2376 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2070 - accuracy: 0.0234 - val_loss: 5.2288 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0198 - accuracy: 0.0391 - val_loss: 5.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1393 - accuracy: 0.0547 - val_loss: 5.2527 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.1387 - accuracy: 0.0547 - val_loss: 5.2912 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1326 - accuracy: 0.0547 - val_loss: 5.3251 - val_accuracy: 0.0078\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9828 - accuracy: 0.0703 - val_loss: 5.3553 - val_accuracy: 0.0078\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0968 - accuracy: 0.0312 - val_loss: 5.3972 - val_accuracy: 0.0078\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.2157 - accuracy: 0.0234 - val_loss: 5.4341 - val_accuracy: 0.0078\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.3273 - accuracy: 0.0078 - val_loss: 5.4526 - val_accuracy: 0.0078\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0499 - accuracy: 0.0391 - val_loss: 5.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.1085 - accuracy: 0.0078 - val_loss: 5.5062 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1375 - accuracy: 0.0312 - val_loss: 5.4932 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2053 - accuracy: 0.0156 - val_loss: 5.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9331 - accuracy: 0.0547 - val_loss: 5.4918 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1876 - accuracy: 0.0234 - val_loss: 5.4533 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2419 - accuracy: 0.0156 - val_loss: 5.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1256 - accuracy: 0.0234 - val_loss: 5.2939 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0431 - accuracy: 0.0234 - val_loss: 5.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1727 - accuracy: 0.0391 - val_loss: 5.1411 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2296 - accuracy: 0.0078 - val_loss: 5.0842 - val_accuracy: 0.1484\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0632 - accuracy: 0.0391 - val_loss: 5.0576 - val_accuracy: 0.1562\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2103 - accuracy: 0.0156 - val_loss: 5.0580 - val_accuracy: 0.0781\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.1292 - accuracy: 0.0156 - val_loss: 5.0454 - val_accuracy: 0.0859\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9640 - accuracy: 0.0547 - val_loss: 5.0524 - val_accuracy: 0.0781\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.0008 - accuracy: 0.0312 - val_loss: 5.0631 - val_accuracy: 0.0312\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8497 - accuracy: 0.0703 - val_loss: 5.0802 - val_accuracy: 0.0078\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0101 - accuracy: 0.0547 - val_loss: 5.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1087 - accuracy: 0.0312 - val_loss: 5.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1012 - accuracy: 0.0156 - val_loss: 5.1016 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9432 - accuracy: 0.0391 - val_loss: 5.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8596 - accuracy: 0.0781 - val_loss: 5.0949 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0825 - accuracy: 0.0078 - val_loss: 5.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9939 - accuracy: 0.0312 - val_loss: 5.2038 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8657 - accuracy: 0.0312 - val_loss: 5.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8911 - accuracy: 0.0391 - val_loss: 5.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.0499 - accuracy: 0.0000e+00 - val_loss: 5.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8526 - accuracy: 0.0156 - val_loss: 5.7611 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9538 - accuracy: 0.0625 - val_loss: 6.2796 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9458 - accuracy: 0.0156 - val_loss: 6.8502 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1033 - accuracy: 0.0000e+00 - val_loss: 6.9084 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9906 - accuracy: 0.0234 - val_loss: 6.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0945 - accuracy: 0.0234 - val_loss: 5.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.9323 - accuracy: 0.0312 - val_loss: 5.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9275 - accuracy: 0.0156 - val_loss: 5.4049 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.8759 - accuracy: 0.0156 - val_loss: 5.0982 - val_accuracy: 0.0547\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1148 - accuracy: 0.0078 - val_loss: 4.8987 - val_accuracy: 0.0859\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9438 - accuracy: 0.0156 - val_loss: 4.8091 - val_accuracy: 0.1172\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9811 - accuracy: 0.0312 - val_loss: 4.8275 - val_accuracy: 0.1562\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.0283 - accuracy: 0.0078 - val_loss: 4.9171 - val_accuracy: 0.1562\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9706 - accuracy: 0.0312 - val_loss: 4.9566 - val_accuracy: 0.1484\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9644 - accuracy: 0.0547 - val_loss: 4.9840 - val_accuracy: 0.1250\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9254 - accuracy: 0.0156 - val_loss: 4.9953 - val_accuracy: 0.1094\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.7799 - accuracy: 0.0156 - val_loss: 5.0785 - val_accuracy: 0.0547\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9886 - accuracy: 0.0234 - val_loss: 5.0445 - val_accuracy: 0.1328\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.0455 - accuracy: 0.0312 - val_loss: 4.9808 - val_accuracy: 0.0781\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9629 - accuracy: 0.0234 - val_loss: 5.0673 - val_accuracy: 0.0547\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9011 - accuracy: 0.0234 - val_loss: 5.1241 - val_accuracy: 0.0625\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7994 - accuracy: 0.0703 - val_loss: 5.2072 - val_accuracy: 0.0547\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8277 - accuracy: 0.0547 - val_loss: 5.2424 - val_accuracy: 0.0625\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7033 - accuracy: 0.0391 - val_loss: 5.1695 - val_accuracy: 0.0703\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8569 - accuracy: 0.0469 - val_loss: 5.1310 - val_accuracy: 0.1016\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.0177 - accuracy: 0.0156 - val_loss: 5.1708 - val_accuracy: 0.0312\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8179 - accuracy: 0.0312 - val_loss: 5.4058 - val_accuracy: 0.0625\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9426 - accuracy: 0.0312 - val_loss: 5.6983 - val_accuracy: 0.0547\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8352 - accuracy: 0.0078 - val_loss: 5.6025 - val_accuracy: 0.0859\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9185 - accuracy: 0.0234 - val_loss: 5.5055 - val_accuracy: 0.0625\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.5472 - accuracy: 0.0391 - val_loss: 5.3488 - val_accuracy: 0.1016\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0447 - accuracy: 0.0312 - val_loss: 5.1883 - val_accuracy: 0.1484\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0962 - accuracy: 0.0078 - val_loss: 5.0531 - val_accuracy: 0.1562\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8691 - accuracy: 0.0469 - val_loss: 4.9465 - val_accuracy: 0.1641\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6878 - accuracy: 0.0625 - val_loss: 4.8936 - val_accuracy: 0.1641\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9440 - accuracy: 0.0547 - val_loss: 4.8506 - val_accuracy: 0.1562\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6243 - accuracy: 0.0234 - val_loss: 4.9387 - val_accuracy: 0.1562\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7981 - accuracy: 0.0156 - val_loss: 4.9316 - val_accuracy: 0.1406\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7242 - accuracy: 0.0234 - val_loss: 4.9821 - val_accuracy: 0.0703\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8429 - accuracy: 0.0547 - val_loss: 5.1408 - val_accuracy: 0.0469\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8804 - accuracy: 0.0547 - val_loss: 5.2709 - val_accuracy: 0.0625\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8733 - accuracy: 0.0234 - val_loss: 5.3762 - val_accuracy: 0.1250\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6931 - accuracy: 0.0234 - val_loss: 5.5740 - val_accuracy: 0.1406\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6417 - accuracy: 0.0547 - val_loss: 5.7180 - val_accuracy: 0.1562\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8002 - accuracy: 0.0156 - val_loss: 5.7317 - val_accuracy: 0.1562\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.7848 - accuracy: 0.0078 - val_loss: 5.9595 - val_accuracy: 0.1562\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7714 - accuracy: 0.0234 - val_loss: 6.5209 - val_accuracy: 0.1641\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6874 - accuracy: 0.0547 - val_loss: 6.7183 - val_accuracy: 0.1641\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6713 - accuracy: 0.0391 - val_loss: 6.6564 - val_accuracy: 0.1641\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6554 - accuracy: 0.0625 - val_loss: 6.4846 - val_accuracy: 0.1562\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6436 - accuracy: 0.0625 - val_loss: 6.6005 - val_accuracy: 0.1484\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7225 - accuracy: 0.0312 - val_loss: 6.6415 - val_accuracy: 0.0469\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8915 - accuracy: 0.0234 - val_loss: 6.3725 - val_accuracy: 0.0156\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7674 - accuracy: 0.0703 - val_loss: 6.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6172 - accuracy: 0.0234 - val_loss: 5.7358 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8502 - accuracy: 0.0469 - val_loss: 5.3243 - val_accuracy: 0.0156\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5468 - accuracy: 0.0938 - val_loss: 5.2608 - val_accuracy: 0.0078\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7932 - accuracy: 0.0078 - val_loss: 5.2505 - val_accuracy: 0.0625\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7813 - accuracy: 0.0156 - val_loss: 5.2104 - val_accuracy: 0.1172\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6878 - accuracy: 0.0312 - val_loss: 5.1175 - val_accuracy: 0.1328\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8482 - accuracy: 0.0312 - val_loss: 5.1586 - val_accuracy: 0.1328\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5359 - accuracy: 0.0469 - val_loss: 5.3373 - val_accuracy: 0.1484\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8759 - accuracy: 0.0391 - val_loss: 5.4888 - val_accuracy: 0.1484\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5370 - accuracy: 0.0391 - val_loss: 5.6941 - val_accuracy: 0.1484\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5122 - accuracy: 0.0547 - val_loss: 5.8519 - val_accuracy: 0.1562\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5997 - accuracy: 0.0703 - val_loss: 5.7611 - val_accuracy: 0.1562\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8250 - accuracy: 0.0312 - val_loss: 5.3300 - val_accuracy: 0.1484\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6423 - accuracy: 0.0391 - val_loss: 5.3389 - val_accuracy: 0.1172\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8130 - accuracy: 0.0156 - val_loss: 5.6004 - val_accuracy: 0.0703\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7942 - accuracy: 0.0234 - val_loss: 5.9742 - val_accuracy: 0.0078\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8196 - accuracy: 0.0469 - val_loss: 6.2037 - val_accuracy: 0.0078\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6509 - accuracy: 0.0391 - val_loss: 6.3063 - val_accuracy: 0.0078\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7035 - accuracy: 0.0156 - val_loss: 6.0350 - val_accuracy: 0.0234\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7634 - accuracy: 0.0391 - val_loss: 5.9262 - val_accuracy: 0.0234\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6536 - accuracy: 0.0547 - val_loss: 5.9928 - val_accuracy: 0.0312\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5639 - accuracy: 0.0859 - val_loss: 6.0984 - val_accuracy: 0.0234\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7349 - accuracy: 0.0156 - val_loss: 6.2072 - val_accuracy: 0.0312\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5516 - accuracy: 0.0547 - val_loss: 6.2014 - val_accuracy: 0.0234\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5696 - accuracy: 0.0391 - val_loss: 6.2960 - val_accuracy: 0.0234\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6561 - accuracy: 0.0078 - val_loss: 6.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7444 - accuracy: 0.0547 - val_loss: 6.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5828 - accuracy: 0.0703 - val_loss: 6.4972 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6336 - accuracy: 0.0312 - val_loss: 6.2464 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5648 - accuracy: 0.0391 - val_loss: 6.1030 - val_accuracy: 0.0859\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4486 - accuracy: 0.0781 - val_loss: 6.0672 - val_accuracy: 0.1641\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7263 - accuracy: 0.0391 - val_loss: 5.9434 - val_accuracy: 0.1641\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7705 - accuracy: 0.0469 - val_loss: 5.6768 - val_accuracy: 0.1406\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.5343 - accuracy: 0.0469 - val_loss: 5.5712 - val_accuracy: 0.1484\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5963 - accuracy: 0.0156 - val_loss: 5.5189 - val_accuracy: 0.1406\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.4381 - accuracy: 0.0859 - val_loss: 5.5657 - val_accuracy: 0.1484\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5766 - accuracy: 0.0156 - val_loss: 5.6746 - val_accuracy: 0.1328\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6081 - accuracy: 0.0625 - val_loss: 5.6934 - val_accuracy: 0.0781\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5003 - accuracy: 0.0547 - val_loss: 5.6490 - val_accuracy: 0.0234\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.2721 - accuracy: 0.1484 - val_loss: 5.6690 - val_accuracy: 0.0391\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7367 - accuracy: 0.0391 - val_loss: 5.7248 - val_accuracy: 0.0547\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0139 - accuracy: 0.0156 - val_loss: 5.8243 - val_accuracy: 0.1016\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7276 - accuracy: 0.0391 - val_loss: 6.0958 - val_accuracy: 0.1328\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.4832 - accuracy: 0.0469 - val_loss: 6.1017 - val_accuracy: 0.0938\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4577 - accuracy: 0.0469 - val_loss: 5.9487 - val_accuracy: 0.0469\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5025 - accuracy: 0.0625 - val_loss: 5.9384 - val_accuracy: 0.0547\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6769 - accuracy: 0.0391 - val_loss: 5.9698 - val_accuracy: 0.0469\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.4362 - accuracy: 0.0391 - val_loss: 5.9392 - val_accuracy: 0.0391\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6267 - accuracy: 0.0156 - val_loss: 5.8518 - val_accuracy: 0.0547\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5214 - accuracy: 0.0625 - val_loss: 5.6907 - val_accuracy: 0.0547\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9061 - accuracy: 0.0078 - val_loss: 5.4655 - val_accuracy: 0.0547\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5852 - accuracy: 0.0547 - val_loss: 5.2864 - val_accuracy: 0.0391\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.3887 - accuracy: 0.0703 - val_loss: 5.2715 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5540 - accuracy: 0.0391 - val_loss: 5.3539 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4205 - accuracy: 0.0391 - val_loss: 5.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5893 - accuracy: 0.0625 - val_loss: 5.5634 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5206 - accuracy: 0.0781 - val_loss: 5.4692 - val_accuracy: 0.0000e+00\n",
      "Epoch 00171: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=320304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=320304\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 501ms/step - loss: 5.5860 - accuracy: 0.0078 - val_loss: 5.5459 - val_accuracy: 0.0078\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.5645 - accuracy: 0.0000e+00 - val_loss: 5.5456 - val_accuracy: 0.0078\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.5362 - accuracy: 0.0078 - val_loss: 5.5441 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.5278 - accuracy: 0.0156 - val_loss: 5.5419 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.4795 - accuracy: 0.0078 - val_loss: 5.5400 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.5314 - accuracy: 0.0000e+00 - val_loss: 5.5389 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.4757 - accuracy: 0.0156 - val_loss: 5.5360 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.4356 - accuracy: 0.0156 - val_loss: 5.5312 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.4400 - accuracy: 0.0000e+00 - val_loss: 5.5205 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 5.3865 - accuracy: 0.0000e+00 - val_loss: 5.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3946 - accuracy: 0.0312 - val_loss: 5.4809 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.3385 - accuracy: 0.0312 - val_loss: 5.4485 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.3882 - accuracy: 0.0156 - val_loss: 5.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2745 - accuracy: 0.0234 - val_loss: 5.4021 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.3616 - accuracy: 0.0156 - val_loss: 5.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2855 - accuracy: 0.0859 - val_loss: 5.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.3278 - accuracy: 0.0000e+00 - val_loss: 5.3473 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2847 - accuracy: 0.0312 - val_loss: 5.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2590 - accuracy: 0.0234 - val_loss: 5.3177 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2052 - accuracy: 0.0469 - val_loss: 5.3123 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2766 - accuracy: 0.0000e+00 - val_loss: 5.3130 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2391 - accuracy: 0.0312 - val_loss: 5.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.3630 - accuracy: 0.0234 - val_loss: 5.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1231 - accuracy: 0.0312 - val_loss: 5.3481 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.2911 - accuracy: 0.0234 - val_loss: 5.3651 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.2113 - accuracy: 0.0000e+00 - val_loss: 5.3748 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1148 - accuracy: 0.0234 - val_loss: 5.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0781 - accuracy: 0.0234 - val_loss: 5.3686 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2335 - accuracy: 0.0078 - val_loss: 5.3687 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1603 - accuracy: 0.0156 - val_loss: 5.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.2972 - accuracy: 0.0391 - val_loss: 5.2976 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2894 - accuracy: 0.0156 - val_loss: 5.2760 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.3683 - accuracy: 0.0078 - val_loss: 5.2910 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0739 - accuracy: 0.0234 - val_loss: 5.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1770 - accuracy: 0.0312 - val_loss: 5.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1794 - accuracy: 0.0234 - val_loss: 5.2997 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1217 - accuracy: 0.0312 - val_loss: 5.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1224 - accuracy: 0.0156 - val_loss: 5.2461 - val_accuracy: 0.0078\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.2783 - accuracy: 0.0156 - val_loss: 5.2130 - val_accuracy: 0.0078\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1507 - accuracy: 0.0703 - val_loss: 5.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2043 - accuracy: 0.0156 - val_loss: 5.2026 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1878 - accuracy: 0.0312 - val_loss: 5.2274 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0892 - accuracy: 0.0156 - val_loss: 5.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0298 - accuracy: 0.0234 - val_loss: 5.2799 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.2701 - accuracy: 0.0078 - val_loss: 5.3025 - val_accuracy: 0.0078\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0858 - accuracy: 0.0234 - val_loss: 5.3210 - val_accuracy: 0.0078\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0959 - accuracy: 0.0469 - val_loss: 5.3537 - val_accuracy: 0.0078\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9798 - accuracy: 0.0312 - val_loss: 5.4178 - val_accuracy: 0.0078\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1381 - accuracy: 0.0000e+00 - val_loss: 5.4507 - val_accuracy: 0.0078\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1469 - accuracy: 0.0234 - val_loss: 5.3942 - val_accuracy: 0.0078\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.2070 - accuracy: 0.0078 - val_loss: 5.3464 - val_accuracy: 0.0078\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1251 - accuracy: 0.0234 - val_loss: 5.3015 - val_accuracy: 0.0078\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.0992 - accuracy: 0.0078 - val_loss: 5.2679 - val_accuracy: 0.0078\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9949 - accuracy: 0.0078 - val_loss: 5.2646 - val_accuracy: 0.0078\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9084 - accuracy: 0.0469 - val_loss: 5.2893 - val_accuracy: 0.0078\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9519 - accuracy: 0.0312 - val_loss: 5.3262 - val_accuracy: 0.0078\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1583 - accuracy: 0.0234 - val_loss: 5.3663 - val_accuracy: 0.0078\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9836 - accuracy: 0.0312 - val_loss: 5.4181 - val_accuracy: 0.0078\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9605 - accuracy: 0.0547 - val_loss: 5.4748 - val_accuracy: 0.0078\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9338 - accuracy: 0.0234 - val_loss: 5.4960 - val_accuracy: 0.0078\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0491 - accuracy: 0.0312 - val_loss: 5.5272 - val_accuracy: 0.0078\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0300 - accuracy: 0.0391 - val_loss: 5.5551 - val_accuracy: 0.0078\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1706 - accuracy: 0.0078 - val_loss: 5.5602 - val_accuracy: 0.0078\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1563 - accuracy: 0.0234 - val_loss: 5.6122 - val_accuracy: 0.0078\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1563 - accuracy: 0.0078 - val_loss: 5.6839 - val_accuracy: 0.0078\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9956 - accuracy: 0.0312 - val_loss: 5.7411 - val_accuracy: 0.0078\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.1988 - accuracy: 0.0078 - val_loss: 5.7892 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0349 - accuracy: 0.0312 - val_loss: 5.7814 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0569 - accuracy: 0.0078 - val_loss: 5.8046 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.1087 - accuracy: 0.0156 - val_loss: 5.7802 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8676 - accuracy: 0.0391 - val_loss: 5.6554 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0993 - accuracy: 0.0156 - val_loss: 5.5791 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9656 - accuracy: 0.0391 - val_loss: 5.4765 - val_accuracy: 0.0078\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8238 - accuracy: 0.0312 - val_loss: 5.4266 - val_accuracy: 0.0078\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8902 - accuracy: 0.0469 - val_loss: 5.3287 - val_accuracy: 0.0078\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 5.1919 - accuracy: 0.0391 - val_loss: 5.2508 - val_accuracy: 0.0078\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.1931 - accuracy: 0.0078 - val_loss: 5.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 5.1185 - accuracy: 0.0312 - val_loss: 5.2063 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9435 - accuracy: 0.0312 - val_loss: 5.2123 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0812 - accuracy: 0.0312 - val_loss: 5.2394 - val_accuracy: 0.0078\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0917 - accuracy: 0.0234 - val_loss: 5.2437 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8578 - accuracy: 0.0078 - val_loss: 5.2452 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8878 - accuracy: 0.0547 - val_loss: 5.2343 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.0582 - accuracy: 0.0234 - val_loss: 5.1708 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8146 - accuracy: 0.0469 - val_loss: 5.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0848 - accuracy: 0.0156 - val_loss: 5.0580 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 5.0952 - accuracy: 0.0078 - val_loss: 4.9636 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0696 - accuracy: 0.0156 - val_loss: 4.9120 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.1072 - accuracy: 0.0312 - val_loss: 4.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8481 - accuracy: 0.0547 - val_loss: 4.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8817 - accuracy: 0.0156 - val_loss: 4.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0210 - accuracy: 0.0156 - val_loss: 4.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.2075 - accuracy: 0.0000e+00 - val_loss: 4.9718 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8989 - accuracy: 0.0391 - val_loss: 5.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9863 - accuracy: 0.0234 - val_loss: 5.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9237 - accuracy: 0.0781 - val_loss: 5.0244 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8746 - accuracy: 0.0234 - val_loss: 5.0364 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0310 - accuracy: 0.0234 - val_loss: 5.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8572 - accuracy: 0.0312 - val_loss: 5.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9570 - accuracy: 0.0234 - val_loss: 5.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9350 - accuracy: 0.0078 - val_loss: 5.0628 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8437 - accuracy: 0.0391 - val_loss: 5.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9471 - accuracy: 0.0234 - val_loss: 5.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9875 - accuracy: 0.0234 - val_loss: 5.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0002 - accuracy: 0.0078 - val_loss: 5.1896 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9646 - accuracy: 0.0156 - val_loss: 5.2029 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9069 - accuracy: 0.0391 - val_loss: 5.2083 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7522 - accuracy: 0.0391 - val_loss: 5.1991 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.9912 - accuracy: 0.0156 - val_loss: 5.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8241 - accuracy: 0.0312 - val_loss: 5.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9721 - accuracy: 0.0391 - val_loss: 5.2282 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9941 - accuracy: 0.0391 - val_loss: 5.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0710 - accuracy: 0.0156 - val_loss: 5.2101 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.8747 - accuracy: 0.0547 - val_loss: 5.2015 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7232 - accuracy: 0.0156 - val_loss: 5.2259 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 5.0592 - accuracy: 0.0156 - val_loss: 5.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1611 - accuracy: 0.0078 - val_loss: 5.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9758 - accuracy: 0.0234 - val_loss: 5.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 5.1265 - accuracy: 0.0078 - val_loss: 5.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9503 - accuracy: 0.0234 - val_loss: 5.3695 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8314 - accuracy: 0.0391 - val_loss: 5.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9261 - accuracy: 0.0156 - val_loss: 5.3803 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9554 - accuracy: 0.0156 - val_loss: 5.3783 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8097 - accuracy: 0.0469 - val_loss: 5.3480 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8344 - accuracy: 0.0391 - val_loss: 5.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0569 - accuracy: 0.0078 - val_loss: 5.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7335 - accuracy: 0.0312 - val_loss: 5.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8906 - accuracy: 0.0234 - val_loss: 5.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0233 - accuracy: 0.0156 - val_loss: 5.2636 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 5.0733 - accuracy: 0.0000e+00 - val_loss: 5.2265 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8910 - accuracy: 0.0469 - val_loss: 5.2095 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8262 - accuracy: 0.0156 - val_loss: 5.1859 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9876 - accuracy: 0.0312 - val_loss: 5.1517 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9614 - accuracy: 0.0156 - val_loss: 5.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8137 - accuracy: 0.0391 - val_loss: 5.1002 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.0112 - accuracy: 0.0156 - val_loss: 5.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8927 - accuracy: 0.0078 - val_loss: 5.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8813 - accuracy: 0.0469 - val_loss: 5.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9424 - accuracy: 0.0000e+00 - val_loss: 5.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8213 - accuracy: 0.0156 - val_loss: 5.0905 - val_accuracy: 0.0078\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8928 - accuracy: 0.0625 - val_loss: 5.0305 - val_accuracy: 0.0078\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.9946 - accuracy: 0.0312 - val_loss: 4.9421 - val_accuracy: 0.0312\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 5.0014 - accuracy: 0.0156 - val_loss: 4.8809 - val_accuracy: 0.0547\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9359 - accuracy: 0.0156 - val_loss: 4.8470 - val_accuracy: 0.0469\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9003 - accuracy: 0.0312 - val_loss: 4.8242 - val_accuracy: 0.0625\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9431 - accuracy: 0.0312 - val_loss: 4.8258 - val_accuracy: 0.0625\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6633 - accuracy: 0.0625 - val_loss: 4.8010 - val_accuracy: 0.0391\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7569 - accuracy: 0.0391 - val_loss: 4.7727 - val_accuracy: 0.0312\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 5.0465 - accuracy: 0.0078 - val_loss: 4.7082 - val_accuracy: 0.0312\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8080 - accuracy: 0.0156 - val_loss: 4.6681 - val_accuracy: 0.0234\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9444 - accuracy: 0.0234 - val_loss: 4.6702 - val_accuracy: 0.0156\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9706 - accuracy: 0.0391 - val_loss: 4.6950 - val_accuracy: 0.0156\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0125 - accuracy: 0.0234 - val_loss: 4.7148 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7628 - accuracy: 0.0547 - val_loss: 4.7337 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9515 - accuracy: 0.0234 - val_loss: 4.7542 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6963 - accuracy: 0.0469 - val_loss: 4.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0122 - accuracy: 0.0156 - val_loss: 4.7966 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8711 - accuracy: 0.0703 - val_loss: 4.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7707 - accuracy: 0.0391 - val_loss: 4.8051 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8879 - accuracy: 0.0312 - val_loss: 4.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8730 - accuracy: 0.0312 - val_loss: 4.7373 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7167 - accuracy: 0.0469 - val_loss: 4.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8715 - accuracy: 0.0391 - val_loss: 4.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9099 - accuracy: 0.0469 - val_loss: 4.8406 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7697 - accuracy: 0.0391 - val_loss: 4.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8870 - accuracy: 0.0078 - val_loss: 4.9051 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8549 - accuracy: 0.0547 - val_loss: 4.8771 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7822 - accuracy: 0.0391 - val_loss: 4.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9082 - accuracy: 0.0078 - val_loss: 4.8111 - val_accuracy: 0.0156\n",
      "Epoch 170/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7743 - accuracy: 0.0469 - val_loss: 4.7686 - val_accuracy: 0.0234\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7994 - accuracy: 0.0469 - val_loss: 4.7462 - val_accuracy: 0.0703\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8779 - accuracy: 0.0234 - val_loss: 4.7377 - val_accuracy: 0.1172\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 95ms/step - loss: 4.8062 - accuracy: 0.0391 - val_loss: 4.7334 - val_accuracy: 0.1250\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8956 - accuracy: 0.0391 - val_loss: 4.7421 - val_accuracy: 0.1406\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8261 - accuracy: 0.0156 - val_loss: 4.7679 - val_accuracy: 0.1172\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9011 - accuracy: 0.0234 - val_loss: 4.8204 - val_accuracy: 0.0859\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6828 - accuracy: 0.0625 - val_loss: 4.8524 - val_accuracy: 0.0469\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.9041 - accuracy: 0.0312 - val_loss: 4.8943 - val_accuracy: 0.0312\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7007 - accuracy: 0.0312 - val_loss: 4.9106 - val_accuracy: 0.0156\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.5495 - accuracy: 0.0625 - val_loss: 4.9796 - val_accuracy: 0.0156\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7563 - accuracy: 0.0469 - val_loss: 5.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.7957 - accuracy: 0.0078 - val_loss: 5.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9852 - accuracy: 0.0234 - val_loss: 4.9269 - val_accuracy: 0.0078\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7386 - accuracy: 0.0156 - val_loss: 4.8067 - val_accuracy: 0.0078\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8847 - accuracy: 0.0469 - val_loss: 4.7875 - val_accuracy: 0.0078\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8898 - accuracy: 0.0312 - val_loss: 4.7646 - val_accuracy: 0.0078\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7376 - accuracy: 0.0234 - val_loss: 4.7434 - val_accuracy: 0.0156\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.8268 - accuracy: 0.0469 - val_loss: 4.7405 - val_accuracy: 0.0156\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8407 - accuracy: 0.0234 - val_loss: 4.7429 - val_accuracy: 0.0156\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8392 - accuracy: 0.0391 - val_loss: 4.7758 - val_accuracy: 0.0078\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9125 - accuracy: 0.0156 - val_loss: 4.8585 - val_accuracy: 0.0078\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8092 - accuracy: 0.0234 - val_loss: 4.9747 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9349 - accuracy: 0.0078 - val_loss: 5.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7375 - accuracy: 0.0312 - val_loss: 5.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8685 - accuracy: 0.0234 - val_loss: 5.2706 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.8148 - accuracy: 0.0156 - val_loss: 5.2383 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9209 - accuracy: 0.0234 - val_loss: 5.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9132 - accuracy: 0.0312 - val_loss: 5.0353 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8937 - accuracy: 0.0156 - val_loss: 5.0425 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.8894 - accuracy: 0.0156 - val_loss: 5.0531 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8585 - accuracy: 0.0312 - val_loss: 5.0835 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5913 - accuracy: 0.0391 - val_loss: 5.1029 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9427 - accuracy: 0.0234 - val_loss: 5.0470 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8138 - accuracy: 0.0234 - val_loss: 4.9484 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5318 - accuracy: 0.1016 - val_loss: 4.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.6482 - accuracy: 0.0469 - val_loss: 4.8168 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.9809 - accuracy: 0.0000e+00 - val_loss: 4.8050 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8379 - accuracy: 0.0156 - val_loss: 4.7925 - val_accuracy: 0.0078\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7326 - accuracy: 0.0156 - val_loss: 4.8039 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6958 - accuracy: 0.0625 - val_loss: 4.8186 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7909 - accuracy: 0.0234 - val_loss: 4.8154 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8423 - accuracy: 0.0234 - val_loss: 4.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8303 - accuracy: 0.0312 - val_loss: 4.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7433 - accuracy: 0.0156 - val_loss: 4.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6877 - accuracy: 0.0391 - val_loss: 4.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.9091 - accuracy: 0.0234 - val_loss: 4.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7841 - accuracy: 0.0391 - val_loss: 4.9201 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6370 - accuracy: 0.0703 - val_loss: 4.9297 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9179 - accuracy: 0.0391 - val_loss: 4.8892 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6835 - accuracy: 0.0156 - val_loss: 4.8408 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8153 - accuracy: 0.0391 - val_loss: 4.8153 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7985 - accuracy: 0.0703 - val_loss: 4.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8765 - accuracy: 0.0234 - val_loss: 4.8191 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7300 - accuracy: 0.0547 - val_loss: 4.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7554 - accuracy: 0.0078 - val_loss: 4.8114 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7150 - accuracy: 0.0625 - val_loss: 4.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7503 - accuracy: 0.0391 - val_loss: 4.8525 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7154 - accuracy: 0.0234 - val_loss: 4.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7394 - accuracy: 0.0156 - val_loss: 4.7687 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6125 - accuracy: 0.0391 - val_loss: 4.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7548 - accuracy: 0.0234 - val_loss: 4.7014 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7449 - accuracy: 0.0312 - val_loss: 4.7003 - val_accuracy: 0.0078\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6403 - accuracy: 0.0391 - val_loss: 4.7052 - val_accuracy: 0.0078\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.7807 - accuracy: 0.0312 - val_loss: 4.7610 - val_accuracy: 0.0078\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7639 - accuracy: 0.0312 - val_loss: 4.7974 - val_accuracy: 0.0078\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7300 - accuracy: 0.0234 - val_loss: 4.7613 - val_accuracy: 0.0156\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8720 - accuracy: 0.0156 - val_loss: 4.6949 - val_accuracy: 0.0156\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8500 - accuracy: 0.0312 - val_loss: 4.6023 - val_accuracy: 0.0391\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.7727 - accuracy: 0.0078 - val_loss: 4.5341 - val_accuracy: 0.0625\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6873 - accuracy: 0.0234 - val_loss: 4.5181 - val_accuracy: 0.0547\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.3973 - accuracy: 0.0781 - val_loss: 4.5301 - val_accuracy: 0.0625\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.5262 - accuracy: 0.0703 - val_loss: 4.5377 - val_accuracy: 0.1094\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7071 - accuracy: 0.0156 - val_loss: 4.5466 - val_accuracy: 0.1484\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.8357 - accuracy: 0.0547 - val_loss: 4.5842 - val_accuracy: 0.1641\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6156 - accuracy: 0.0703 - val_loss: 4.6588 - val_accuracy: 0.1641\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5779 - accuracy: 0.0781 - val_loss: 4.8002 - val_accuracy: 0.1094\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7522 - accuracy: 0.0469 - val_loss: 4.8618 - val_accuracy: 0.0625\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8704 - accuracy: 0.0391 - val_loss: 4.8117 - val_accuracy: 0.0469\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8382 - accuracy: 0.0391 - val_loss: 4.7466 - val_accuracy: 0.0391\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8025 - accuracy: 0.0312 - val_loss: 4.7077 - val_accuracy: 0.0391\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7461 - accuracy: 0.0156 - val_loss: 4.8133 - val_accuracy: 0.0078\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.9388 - accuracy: 0.0078 - val_loss: 4.8478 - val_accuracy: 0.0078\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.9264 - accuracy: 0.0234 - val_loss: 4.8291 - val_accuracy: 0.0078\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9919 - accuracy: 0.0156 - val_loss: 4.8597 - val_accuracy: 0.0078\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7838 - accuracy: 0.0547 - val_loss: 4.9295 - val_accuracy: 0.0078\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7863 - accuracy: 0.0391 - val_loss: 5.0396 - val_accuracy: 0.0078\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8396 - accuracy: 0.0234 - val_loss: 5.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7815 - accuracy: 0.0312 - val_loss: 5.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6808 - accuracy: 0.0391 - val_loss: 5.3246 - val_accuracy: 0.0078\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.0106 - accuracy: 0.0234 - val_loss: 5.4577 - val_accuracy: 0.0078\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7058 - accuracy: 0.0312 - val_loss: 5.5823 - val_accuracy: 0.0078\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7749 - accuracy: 0.0234 - val_loss: 5.7273 - val_accuracy: 0.0156\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6288 - accuracy: 0.0547 - val_loss: 5.8221 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8167 - accuracy: 0.0000e+00 - val_loss: 5.7850 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6863 - accuracy: 0.0391 - val_loss: 5.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6852 - accuracy: 0.0469 - val_loss: 5.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7809 - accuracy: 0.0234 - val_loss: 5.5354 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9363 - accuracy: 0.0078 - val_loss: 5.3547 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7853 - accuracy: 0.0469 - val_loss: 5.1599 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7949 - accuracy: 0.0391 - val_loss: 5.0266 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7957 - accuracy: 0.0312 - val_loss: 4.9928 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6131 - accuracy: 0.0391 - val_loss: 5.0353 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.8230 - accuracy: 0.0156 - val_loss: 4.9965 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.5109 - accuracy: 0.0859 - val_loss: 5.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6912 - accuracy: 0.0312 - val_loss: 5.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6193 - accuracy: 0.0625 - val_loss: 5.0037 - val_accuracy: 0.0156\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6047 - accuracy: 0.0312 - val_loss: 4.9924 - val_accuracy: 0.0078\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6701 - accuracy: 0.0469 - val_loss: 5.0952 - val_accuracy: 0.0078\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.6069 - accuracy: 0.0547 - val_loss: 5.1765 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.4847 - accuracy: 0.0859 - val_loss: 5.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7838 - accuracy: 0.0234 - val_loss: 5.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8597 - accuracy: 0.0234 - val_loss: 5.4841 - val_accuracy: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8209 - accuracy: 0.0156 - val_loss: 5.3244 - val_accuracy: 0.0156\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.6312 - accuracy: 0.0391 - val_loss: 5.1589 - val_accuracy: 0.0156\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7725 - accuracy: 0.0234 - val_loss: 5.0593 - val_accuracy: 0.0234\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7503 - accuracy: 0.0547 - val_loss: 5.0374 - val_accuracy: 0.0078\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.9166 - accuracy: 0.0234 - val_loss: 5.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7383 - accuracy: 0.0312 - val_loss: 5.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7741 - accuracy: 0.0625 - val_loss: 5.2101 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5729 - accuracy: 0.0469 - val_loss: 5.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6002 - accuracy: 0.0391 - val_loss: 5.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.8010 - accuracy: 0.0469 - val_loss: 5.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8853 - accuracy: 0.0156 - val_loss: 5.1601 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.4474 - accuracy: 0.0703 - val_loss: 5.2073 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.4007 - accuracy: 0.1250 - val_loss: 5.3610 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 58ms/step - loss: 4.8108 - accuracy: 0.0000e+00 - val_loss: 5.4663 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7088 - accuracy: 0.0469 - val_loss: 5.6245 - val_accuracy: 0.0078\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 4.8661 - accuracy: 0.0312 - val_loss: 5.6296 - val_accuracy: 0.0078\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7822 - accuracy: 0.0312 - val_loss: 5.5075 - val_accuracy: 0.0078\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8229 - accuracy: 0.0469 - val_loss: 5.3036 - val_accuracy: 0.0078\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7901 - accuracy: 0.0234 - val_loss: 5.2637 - val_accuracy: 0.0078\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9579 - accuracy: 0.0234 - val_loss: 5.3173 - val_accuracy: 0.0078\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8526 - accuracy: 0.0312 - val_loss: 5.3509 - val_accuracy: 0.0156\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7276 - accuracy: 0.0234 - val_loss: 5.3154 - val_accuracy: 0.0078\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.6362 - accuracy: 0.0625 - val_loss: 5.2190 - val_accuracy: 0.0078\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8410 - accuracy: 0.0156 - val_loss: 5.0630 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.7014 - accuracy: 0.0859 - val_loss: 5.0318 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.7702 - accuracy: 0.0312 - val_loss: 5.1531 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.8351 - accuracy: 0.0156 - val_loss: 5.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.7632 - accuracy: 0.0312 - val_loss: 5.2349 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5981 - accuracy: 0.0156 - val_loss: 5.2661 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.6835 - accuracy: 0.0547 - val_loss: 5.2708 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7352 - accuracy: 0.0547 - val_loss: 5.2280 - val_accuracy: 0.0078\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7639 - accuracy: 0.0156 - val_loss: 5.1362 - val_accuracy: 0.0078\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7357 - accuracy: 0.0312 - val_loss: 4.9620 - val_accuracy: 0.0391\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9123 - accuracy: 0.0078 - val_loss: 4.8409 - val_accuracy: 0.0547\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6650 - accuracy: 0.0469 - val_loss: 4.7618 - val_accuracy: 0.0625\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6638 - accuracy: 0.0234 - val_loss: 4.6474 - val_accuracy: 0.0859\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8263 - accuracy: 0.0234 - val_loss: 4.5768 - val_accuracy: 0.1094\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.6901 - accuracy: 0.0234 - val_loss: 4.5684 - val_accuracy: 0.0859\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8558 - accuracy: 0.0156 - val_loss: 4.5726 - val_accuracy: 0.0703\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7884 - accuracy: 0.0312 - val_loss: 4.5990 - val_accuracy: 0.0547\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 4.5859 - accuracy: 0.0547 - val_loss: 4.6582 - val_accuracy: 0.0391\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 60ms/step - loss: 4.5425 - accuracy: 0.0391 - val_loss: 4.7667 - val_accuracy: 0.0234\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 4.6910 - accuracy: 0.0391 - val_loss: 4.8576 - val_accuracy: 0.0078\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.6927 - accuracy: 0.0156 - val_loss: 4.8966 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.6359 - accuracy: 0.0547 - val_loss: 4.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6593 - accuracy: 0.0312 - val_loss: 4.8667 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 4.5808 - accuracy: 0.0469 - val_loss: 4.8812 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.6881 - accuracy: 0.0547 - val_loss: 5.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 4.7320 - accuracy: 0.0312 - val_loss: 5.2201 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.7024 - accuracy: 0.0547 - val_loss: 5.3225 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.7485 - accuracy: 0.0469 - val_loss: 5.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.5454 - accuracy: 0.0391 - val_loss: 5.2826 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5157 - accuracy: 0.0703 - val_loss: 5.2345 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7816 - accuracy: 0.0234 - val_loss: 5.2324 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7410 - accuracy: 0.0078 - val_loss: 5.3031 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6110 - accuracy: 0.0469 - val_loss: 5.3291 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6655 - accuracy: 0.0078 - val_loss: 5.3831 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.4756 - accuracy: 0.0625 - val_loss: 5.1962 - val_accuracy: 0.0000e+00\n",
      "Epoch 00340: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 16)      96        \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 16)      784       \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 16)      64        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 16)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 32)      2592      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 32)      3104      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 32)      128       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 32)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 64)      10304     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 64)      12352     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 64)      256       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 64)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 64)       20544     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 64)       12352     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 64)       256       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 64)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 128)      41088     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 128)      49280     \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 128)      82048     \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 128)      49280     \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 128)      512       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 128)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      33024     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320,304\n",
      "Trainable params: 318,576\n",
      "Non-trainable params: 1,728\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=320304\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=692488\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 5.6826 - accuracy: 0.0000e+00 - val_loss: 5.5410 - val_accuracy: 0.0078\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.6150 - accuracy: 0.0156 - val_loss: 5.5279 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.4607 - accuracy: 0.0234 - val_loss: 5.5102 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 5.5156 - accuracy: 0.0234 - val_loss: 5.4941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.4538 - accuracy: 0.0234 - val_loss: 5.4824 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.3998 - accuracy: 0.0312 - val_loss: 5.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1003 - accuracy: 0.0625 - val_loss: 5.4768 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.3910 - accuracy: 0.0469 - val_loss: 5.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.4191 - accuracy: 0.0078 - val_loss: 5.4828 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.2838 - accuracy: 0.0156 - val_loss: 5.5112 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.2475 - accuracy: 0.0312 - val_loss: 5.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.2912 - accuracy: 0.0078 - val_loss: 5.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9384 - accuracy: 0.0938 - val_loss: 5.5349 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1256 - accuracy: 0.0312 - val_loss: 5.5342 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.3930 - accuracy: 0.0156 - val_loss: 5.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.2488 - accuracy: 0.0000e+00 - val_loss: 5.4972 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0981 - accuracy: 0.0391 - val_loss: 5.4976 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9295 - accuracy: 0.0469 - val_loss: 5.4985 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0156 - accuracy: 0.0547 - val_loss: 5.4998 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.4231 - accuracy: 0.0078 - val_loss: 5.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.1496 - accuracy: 0.0312 - val_loss: 5.4794 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8782 - accuracy: 0.1016 - val_loss: 5.4708 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9418 - accuracy: 0.0312 - val_loss: 5.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9801 - accuracy: 0.0234 - val_loss: 5.4360 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.1139 - accuracy: 0.0234 - val_loss: 5.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1537 - accuracy: 0.0234 - val_loss: 5.3618 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.1461 - accuracy: 0.0234 - val_loss: 5.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0349 - accuracy: 0.0547 - val_loss: 5.2520 - val_accuracy: 0.0312\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.1558 - accuracy: 0.0078 - val_loss: 5.2567 - val_accuracy: 0.0312\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8945 - accuracy: 0.0625 - val_loss: 5.2765 - val_accuracy: 0.0312\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 5.0971 - accuracy: 0.0156 - val_loss: 5.2378 - val_accuracy: 0.0312\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0528 - accuracy: 0.0156 - val_loss: 5.1936 - val_accuracy: 0.0312\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0484 - accuracy: 0.0234 - val_loss: 5.1434 - val_accuracy: 0.0312\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8510 - accuracy: 0.0469 - val_loss: 5.0978 - val_accuracy: 0.0859\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9603 - accuracy: 0.0625 - val_loss: 5.0454 - val_accuracy: 0.1406\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1088 - accuracy: 0.0078 - val_loss: 4.9908 - val_accuracy: 0.0703\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0673 - accuracy: 0.0312 - val_loss: 5.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9806 - accuracy: 0.0312 - val_loss: 5.0002 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7807 - accuracy: 0.1094 - val_loss: 4.9741 - val_accuracy: 0.0312\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8120 - accuracy: 0.0391 - val_loss: 5.0384 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8697 - accuracy: 0.0547 - val_loss: 5.0874 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9750 - accuracy: 0.0156 - val_loss: 5.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8029 - accuracy: 0.0312 - val_loss: 5.0781 - val_accuracy: 0.0547\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.0456 - accuracy: 0.0156 - val_loss: 5.0794 - val_accuracy: 0.0234\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8796 - accuracy: 0.0469 - val_loss: 5.0041 - val_accuracy: 0.0859\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9872 - accuracy: 0.0078 - val_loss: 4.9457 - val_accuracy: 0.1328\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7171 - accuracy: 0.0938 - val_loss: 4.8999 - val_accuracy: 0.1172\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8378 - accuracy: 0.0391 - val_loss: 4.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.8784 - accuracy: 0.0469 - val_loss: 4.9012 - val_accuracy: 0.0547\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7796 - accuracy: 0.0547 - val_loss: 4.8522 - val_accuracy: 0.0781\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7999 - accuracy: 0.0391 - val_loss: 4.8916 - val_accuracy: 0.0859\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8387 - accuracy: 0.0391 - val_loss: 4.9948 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7416 - accuracy: 0.0938 - val_loss: 4.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9507 - accuracy: 0.0469 - val_loss: 4.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.0902 - accuracy: 0.0078 - val_loss: 4.9478 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7613 - accuracy: 0.0312 - val_loss: 4.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7621 - accuracy: 0.0781 - val_loss: 4.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6304 - accuracy: 0.0703 - val_loss: 4.9924 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6996 - accuracy: 0.0391 - val_loss: 5.0173 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6569 - accuracy: 0.0547 - val_loss: 5.0031 - val_accuracy: 0.0156\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6599 - accuracy: 0.0781 - val_loss: 5.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6877 - accuracy: 0.0469 - val_loss: 5.0897 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.6663 - accuracy: 0.0156 - val_loss: 5.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7111 - accuracy: 0.0781 - val_loss: 5.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6226 - accuracy: 0.0391 - val_loss: 5.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.4537 - accuracy: 0.0859 - val_loss: 5.2901 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7305 - accuracy: 0.0547 - val_loss: 5.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 4.6632 - accuracy: 0.0391 - val_loss: 5.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0791 - accuracy: 0.1172 - val_loss: 5.1274 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7686 - accuracy: 0.0234 - val_loss: 5.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2935 - accuracy: 0.1172 - val_loss: 5.1630 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.3833 - accuracy: 0.0859 - val_loss: 5.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.5685 - accuracy: 0.0938 - val_loss: 5.3311 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6058 - accuracy: 0.0703 - val_loss: 5.3434 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.3810 - accuracy: 0.0938 - val_loss: 5.3659 - val_accuracy: 0.0078\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.4543 - accuracy: 0.0859 - val_loss: 5.1551 - val_accuracy: 0.0312\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.5500 - accuracy: 0.0312 - val_loss: 5.2752 - val_accuracy: 0.0078\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8330 - accuracy: 0.0234 - val_loss: 5.4009 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.6433 - accuracy: 0.0625 - val_loss: 5.4952 - val_accuracy: 0.0156\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7167 - accuracy: 0.0547 - val_loss: 5.5065 - val_accuracy: 0.0391\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.5143 - accuracy: 0.0781 - val_loss: 5.3234 - val_accuracy: 0.0469\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.2938 - accuracy: 0.1016 - val_loss: 5.0657 - val_accuracy: 0.0234\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3541 - accuracy: 0.0938 - val_loss: 4.9506 - val_accuracy: 0.0156\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6593 - accuracy: 0.0156 - val_loss: 5.5876 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.3979 - accuracy: 0.0547 - val_loss: 5.6264 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3853 - accuracy: 0.0703 - val_loss: 5.5065 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3191 - accuracy: 0.1016 - val_loss: 5.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.2286 - accuracy: 0.1094 - val_loss: 5.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6801 - accuracy: 0.0156 - val_loss: 5.4106 - val_accuracy: 0.0078\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.2123 - accuracy: 0.1172 - val_loss: 5.2166 - val_accuracy: 0.0078\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.3081 - accuracy: 0.0859 - val_loss: 5.5765 - val_accuracy: 0.0078\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.6028 - accuracy: 0.0469 - val_loss: 5.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.2534 - accuracy: 0.1250 - val_loss: 5.6660 - val_accuracy: 0.0859\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.9229 - accuracy: 0.1484 - val_loss: 5.8882 - val_accuracy: 0.0234\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2049 - accuracy: 0.0938 - val_loss: 6.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.2030 - accuracy: 0.1094 - val_loss: 6.5583 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.0385 - accuracy: 0.1641 - val_loss: 6.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6176 - accuracy: 0.0625 - val_loss: 5.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.0281 - accuracy: 0.0859 - val_loss: 5.5287 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0977 - accuracy: 0.1562 - val_loss: 5.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7097 - accuracy: 0.0312 - val_loss: 5.4961 - val_accuracy: 0.0078\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0566 - accuracy: 0.1562 - val_loss: 5.3411 - val_accuracy: 0.0078\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.2384 - accuracy: 0.1406 - val_loss: 5.5627 - val_accuracy: 0.0234\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.2010 - accuracy: 0.1406 - val_loss: 5.6594 - val_accuracy: 0.0781\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3299 - accuracy: 0.0703 - val_loss: 5.3901 - val_accuracy: 0.0859\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.1067 - accuracy: 0.1172 - val_loss: 5.5660 - val_accuracy: 0.0625\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.2419 - accuracy: 0.0625 - val_loss: 5.5935 - val_accuracy: 0.0469\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.0672 - accuracy: 0.1406 - val_loss: 5.4282 - val_accuracy: 0.0234\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.0638 - accuracy: 0.1328 - val_loss: 5.2109 - val_accuracy: 0.0234\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.2126 - accuracy: 0.0859 - val_loss: 4.9684 - val_accuracy: 0.0312\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0835 - accuracy: 0.1562 - val_loss: 4.7945 - val_accuracy: 0.1172\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.3238 - accuracy: 0.1016 - val_loss: 4.6132 - val_accuracy: 0.1484\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.4158 - accuracy: 0.0469 - val_loss: 4.8135 - val_accuracy: 0.1016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2096 - accuracy: 0.0703 - val_loss: 5.3297 - val_accuracy: 0.0703\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.1024 - accuracy: 0.1172 - val_loss: 6.2640 - val_accuracy: 0.0078\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8892 - accuracy: 0.1406 - val_loss: 6.3596 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.0116 - accuracy: 0.1016 - val_loss: 6.6891 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.1222 - accuracy: 0.0781 - val_loss: 5.6863 - val_accuracy: 0.0234\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.8801 - accuracy: 0.1719 - val_loss: 5.2839 - val_accuracy: 0.0312\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0917 - accuracy: 0.0938 - val_loss: 5.1384 - val_accuracy: 0.0234\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.9665 - accuracy: 0.0938 - val_loss: 5.0715 - val_accuracy: 0.0547\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.7532 - accuracy: 0.1641 - val_loss: 5.1059 - val_accuracy: 0.0234\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.9318 - accuracy: 0.1484 - val_loss: 5.0933 - val_accuracy: 0.0156\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.8872 - accuracy: 0.1562 - val_loss: 5.7410 - val_accuracy: 0.0078\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.1743 - accuracy: 0.0156 - val_loss: 5.5094 - val_accuracy: 0.0234\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.4356 - accuracy: 0.0625 - val_loss: 5.4569 - val_accuracy: 0.0156\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.0312 - accuracy: 0.1406 - val_loss: 6.0665 - val_accuracy: 0.0391\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0967 - accuracy: 0.0625 - val_loss: 5.7832 - val_accuracy: 0.0156\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.7205 - accuracy: 0.1406 - val_loss: 5.3480 - val_accuracy: 0.0156\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.0269 - accuracy: 0.1328 - val_loss: 5.1153 - val_accuracy: 0.0078\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.0219 - accuracy: 0.1016 - val_loss: 5.2713 - val_accuracy: 0.0078\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2773 - accuracy: 0.0547 - val_loss: 5.3102 - val_accuracy: 0.0234\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 3.9211 - accuracy: 0.1016 - val_loss: 5.1557 - val_accuracy: 0.0078\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.0740 - accuracy: 0.1328 - val_loss: 5.1572 - val_accuracy: 0.0156\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2189 - accuracy: 0.0703 - val_loss: 5.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.0065 - accuracy: 0.1172 - val_loss: 5.0194 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.0058 - accuracy: 0.1172 - val_loss: 4.9496 - val_accuracy: 0.0078\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.9808 - accuracy: 0.0781 - val_loss: 5.1923 - val_accuracy: 0.0078\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.6292 - accuracy: 0.1484 - val_loss: 6.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.9065 - accuracy: 0.1797 - val_loss: 6.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.1082 - accuracy: 0.0703 - val_loss: 6.1223 - val_accuracy: 0.0078\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.9712 - accuracy: 0.1016 - val_loss: 5.5963 - val_accuracy: 0.0078\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.9061 - accuracy: 0.1172 - val_loss: 5.0974 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.7293 - accuracy: 0.1016 - val_loss: 5.0093 - val_accuracy: 0.0078\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.8416 - accuracy: 0.0781 - val_loss: 5.0815 - val_accuracy: 0.0078\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.8347 - accuracy: 0.0938 - val_loss: 5.0334 - val_accuracy: 0.0078\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7983 - accuracy: 0.1250 - val_loss: 5.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.0294 - accuracy: 0.0312 - val_loss: 4.8924 - val_accuracy: 0.0078\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.7472 - accuracy: 0.1406 - val_loss: 4.5714 - val_accuracy: 0.0547\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0535 - accuracy: 0.0781 - val_loss: 4.1331 - val_accuracy: 0.0781\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.8032 - accuracy: 0.1328 - val_loss: 3.9045 - val_accuracy: 0.0859\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.6940 - accuracy: 0.0938 - val_loss: 3.8619 - val_accuracy: 0.0781\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.8936 - accuracy: 0.0859 - val_loss: 3.6972 - val_accuracy: 0.1172\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.6670 - accuracy: 0.1484 - val_loss: 3.9177 - val_accuracy: 0.0625\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.4808 - accuracy: 0.2500 - val_loss: 3.4468 - val_accuracy: 0.1797\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8406 - accuracy: 0.0625 - val_loss: 3.4063 - val_accuracy: 0.1719\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.6368 - accuracy: 0.1250 - val_loss: 3.7300 - val_accuracy: 0.1172\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.8378 - accuracy: 0.1094 - val_loss: 4.0769 - val_accuracy: 0.0547\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.8274 - accuracy: 0.1016 - val_loss: 4.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.6806 - accuracy: 0.0859 - val_loss: 4.3613 - val_accuracy: 0.0078\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.8135 - accuracy: 0.0703 - val_loss: 4.8988 - val_accuracy: 0.0078\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4964 - accuracy: 0.1406 - val_loss: 5.0330 - val_accuracy: 0.0156\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.3704 - accuracy: 0.2188 - val_loss: 4.7884 - val_accuracy: 0.0391\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.0502 - accuracy: 0.0547 - val_loss: 4.4064 - val_accuracy: 0.0312\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.6121 - accuracy: 0.1406 - val_loss: 4.2434 - val_accuracy: 0.0469\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5091 - accuracy: 0.1172 - val_loss: 4.2833 - val_accuracy: 0.0391\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.6613 - accuracy: 0.0938 - val_loss: 4.3165 - val_accuracy: 0.0391\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.3578 - accuracy: 0.2656 - val_loss: 4.4498 - val_accuracy: 0.0312\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.6052 - accuracy: 0.1406 - val_loss: 4.2756 - val_accuracy: 0.0312\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.5397 - accuracy: 0.1094 - val_loss: 4.0479 - val_accuracy: 0.0391\n",
      "Epoch 171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5328 - accuracy: 0.1797 - val_loss: 4.2573 - val_accuracy: 0.0312\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.8916 - accuracy: 0.1406 - val_loss: 4.2389 - val_accuracy: 0.0781\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4496 - accuracy: 0.1641 - val_loss: 4.2980 - val_accuracy: 0.1016\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 90ms/step - loss: 3.8647 - accuracy: 0.1562 - val_loss: 4.3414 - val_accuracy: 0.1250\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5441 - accuracy: 0.1250 - val_loss: 4.2840 - val_accuracy: 0.1328\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.7910 - accuracy: 0.0547 - val_loss: 4.3953 - val_accuracy: 0.1484\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.4893 - accuracy: 0.1875 - val_loss: 4.5480 - val_accuracy: 0.0938\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.6435 - accuracy: 0.0938 - val_loss: 4.0151 - val_accuracy: 0.0703\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.5220 - accuracy: 0.1328 - val_loss: 3.6607 - val_accuracy: 0.0938\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3677 - accuracy: 0.1953 - val_loss: 4.0521 - val_accuracy: 0.1016\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.6591 - accuracy: 0.1250 - val_loss: 4.4955 - val_accuracy: 0.0547\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.9168 - accuracy: 0.0234 - val_loss: 4.1544 - val_accuracy: 0.0781\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.8080 - accuracy: 0.0938 - val_loss: 3.8515 - val_accuracy: 0.0859\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4397 - accuracy: 0.2109 - val_loss: 3.8075 - val_accuracy: 0.0547\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5359 - accuracy: 0.1484 - val_loss: 4.1548 - val_accuracy: 0.0391\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.6292 - accuracy: 0.1875 - val_loss: 4.5361 - val_accuracy: 0.0156\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.3760 - accuracy: 0.2031 - val_loss: 4.0213 - val_accuracy: 0.0391\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.6090 - accuracy: 0.1484 - val_loss: 3.8910 - val_accuracy: 0.0938\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.5990 - accuracy: 0.1797 - val_loss: 4.0498 - val_accuracy: 0.1172\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.6858 - accuracy: 0.1094 - val_loss: 4.4889 - val_accuracy: 0.0312\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.4894 - accuracy: 0.1328 - val_loss: 4.4205 - val_accuracy: 0.0312\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.4285 - accuracy: 0.1797 - val_loss: 4.2279 - val_accuracy: 0.0391\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5172 - accuracy: 0.1719 - val_loss: 4.0784 - val_accuracy: 0.0703\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2659 - accuracy: 0.2891 - val_loss: 3.9288 - val_accuracy: 0.0859\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.2967 - accuracy: 0.2344 - val_loss: 4.4277 - val_accuracy: 0.0312\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.6578 - accuracy: 0.1719 - val_loss: 4.7959 - val_accuracy: 0.0156\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.2896 - accuracy: 0.1953 - val_loss: 4.2611 - val_accuracy: 0.0391\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 3.3407 - accuracy: 0.1641 - val_loss: 4.0556 - val_accuracy: 0.0156\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2497 - accuracy: 0.2109 - val_loss: 4.7825 - val_accuracy: 0.0234\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 3.6067 - accuracy: 0.1172 - val_loss: 4.8797 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4334 - accuracy: 0.2344 - val_loss: 5.2720 - val_accuracy: 0.0312\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.3306 - accuracy: 0.1406 - val_loss: 4.7208 - val_accuracy: 0.1016\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2975 - accuracy: 0.1953 - val_loss: 4.2128 - val_accuracy: 0.1484\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.3261 - accuracy: 0.1797 - val_loss: 4.0204 - val_accuracy: 0.1328\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1274 - accuracy: 0.2734 - val_loss: 4.1324 - val_accuracy: 0.0703\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.4869 - accuracy: 0.1094 - val_loss: 4.3865 - val_accuracy: 0.0312\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.5390 - accuracy: 0.1484 - val_loss: 4.5083 - val_accuracy: 0.0156\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.2006 - accuracy: 0.1875 - val_loss: 4.8167 - val_accuracy: 0.0234\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.5943 - accuracy: 0.1172 - val_loss: 4.6508 - val_accuracy: 0.0312\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4129 - accuracy: 0.1172 - val_loss: 4.9344 - val_accuracy: 0.0469\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2712 - accuracy: 0.1797 - val_loss: 4.9469 - val_accuracy: 0.0391\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1640 - accuracy: 0.2656 - val_loss: 4.9542 - val_accuracy: 0.0078\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2313 - accuracy: 0.1953 - val_loss: 4.4781 - val_accuracy: 0.0156\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5813 - accuracy: 0.1953 - val_loss: 4.6577 - val_accuracy: 0.0078\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3048 - accuracy: 0.1641 - val_loss: 5.0753 - val_accuracy: 0.0156\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.4865 - accuracy: 0.1406 - val_loss: 4.9582 - val_accuracy: 0.0078\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4893 - accuracy: 0.1250 - val_loss: 5.0384 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2994 - accuracy: 0.1875 - val_loss: 4.8076 - val_accuracy: 0.0156\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0569 - accuracy: 0.3047 - val_loss: 4.6752 - val_accuracy: 0.0234\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1694 - accuracy: 0.1484 - val_loss: 4.1808 - val_accuracy: 0.0469\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2916 - accuracy: 0.2188 - val_loss: 3.8233 - val_accuracy: 0.1797\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.5318 - accuracy: 0.1406 - val_loss: 3.4101 - val_accuracy: 0.2188\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.1371 - accuracy: 0.2500 - val_loss: 3.5677 - val_accuracy: 0.1953\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3423 - accuracy: 0.1953 - val_loss: 3.6218 - val_accuracy: 0.1953\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.1685 - accuracy: 0.2109 - val_loss: 4.0516 - val_accuracy: 0.0781\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.2077 - accuracy: 0.2188 - val_loss: 3.7510 - val_accuracy: 0.0781\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2444 - accuracy: 0.1719 - val_loss: 3.4476 - val_accuracy: 0.1250\n",
      "Epoch 228/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3464 - accuracy: 0.1328 - val_loss: 3.3838 - val_accuracy: 0.0859\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.2323 - accuracy: 0.2031 - val_loss: 3.4633 - val_accuracy: 0.1094\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.5450 - accuracy: 0.2031 - val_loss: 3.6891 - val_accuracy: 0.0469\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8445 - accuracy: 0.2891 - val_loss: 3.5028 - val_accuracy: 0.0547\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.2979 - accuracy: 0.2578 - val_loss: 3.5813 - val_accuracy: 0.0469\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.0931 - accuracy: 0.2500 - val_loss: 3.6810 - val_accuracy: 0.0156\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2768 - accuracy: 0.1641 - val_loss: 3.6014 - val_accuracy: 0.0234\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3889 - accuracy: 0.1016 - val_loss: 4.0137 - val_accuracy: 0.0078\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0504 - accuracy: 0.2891 - val_loss: 4.0925 - val_accuracy: 0.0156\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3051 - accuracy: 0.1484 - val_loss: 3.8004 - val_accuracy: 0.0156\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1520 - accuracy: 0.2266 - val_loss: 3.5829 - val_accuracy: 0.0469\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2130 - accuracy: 0.2656 - val_loss: 3.6659 - val_accuracy: 0.0781\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.1235 - accuracy: 0.1719 - val_loss: 3.5590 - val_accuracy: 0.1016\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.2231 - accuracy: 0.2344 - val_loss: 3.9433 - val_accuracy: 0.0938\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.3293 - accuracy: 0.1641 - val_loss: 3.6819 - val_accuracy: 0.1484\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.0135 - accuracy: 0.2344 - val_loss: 3.5907 - val_accuracy: 0.1250\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.1737 - accuracy: 0.2188 - val_loss: 3.4283 - val_accuracy: 0.1016\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0643 - accuracy: 0.2656 - val_loss: 3.2922 - val_accuracy: 0.1406\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.4719 - accuracy: 0.1250 - val_loss: 3.3707 - val_accuracy: 0.1328\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8816 - accuracy: 0.3125 - val_loss: 3.2333 - val_accuracy: 0.2109\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.5051 - accuracy: 0.1328 - val_loss: 2.9594 - val_accuracy: 0.2578\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9790 - accuracy: 0.3281 - val_loss: 3.0665 - val_accuracy: 0.2031\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2874 - accuracy: 0.2656 - val_loss: 3.1977 - val_accuracy: 0.1797\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.0389 - accuracy: 0.2812 - val_loss: 3.4563 - val_accuracy: 0.0938\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.1334 - accuracy: 0.1953 - val_loss: 3.1589 - val_accuracy: 0.1797\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8296 - accuracy: 0.3125 - val_loss: 3.0656 - val_accuracy: 0.1875\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.0786 - accuracy: 0.2734 - val_loss: 3.2347 - val_accuracy: 0.2109\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.3518 - accuracy: 0.1562 - val_loss: 3.1478 - val_accuracy: 0.2109\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.1445 - accuracy: 0.3125 - val_loss: 2.9541 - val_accuracy: 0.2422\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3533 - accuracy: 0.1562 - val_loss: 2.8077 - val_accuracy: 0.3125\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.3621 - accuracy: 0.1484 - val_loss: 2.7661 - val_accuracy: 0.2812\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9011 - accuracy: 0.2578 - val_loss: 3.0058 - val_accuracy: 0.2344\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.9898 - accuracy: 0.2656 - val_loss: 3.9894 - val_accuracy: 0.1562\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.9372 - accuracy: 0.2344 - val_loss: 3.2139 - val_accuracy: 0.2422\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.1736 - accuracy: 0.1797 - val_loss: 3.3597 - val_accuracy: 0.2031\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.1044 - accuracy: 0.2578 - val_loss: 3.6394 - val_accuracy: 0.1953\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.3605 - accuracy: 0.1875 - val_loss: 3.4735 - val_accuracy: 0.1953\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.3655 - accuracy: 0.1484 - val_loss: 3.3026 - val_accuracy: 0.1641\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.9452 - accuracy: 0.2344 - val_loss: 3.4269 - val_accuracy: 0.1250\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.9668 - accuracy: 0.3203 - val_loss: 3.1039 - val_accuracy: 0.2031\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.1113 - accuracy: 0.2109 - val_loss: 3.5392 - val_accuracy: 0.1016\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.4994 - accuracy: 0.1406 - val_loss: 4.1903 - val_accuracy: 0.0469\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.0194 - accuracy: 0.2344 - val_loss: 4.8829 - val_accuracy: 0.0156\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9912 - accuracy: 0.2422 - val_loss: 4.3667 - val_accuracy: 0.0234\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1255 - accuracy: 0.2500 - val_loss: 3.5646 - val_accuracy: 0.0703\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8074 - accuracy: 0.2266 - val_loss: 3.4785 - val_accuracy: 0.0547\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9600 - accuracy: 0.2266 - val_loss: 3.5067 - val_accuracy: 0.0391\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2994 - accuracy: 0.2188 - val_loss: 3.6709 - val_accuracy: 0.0781\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.0174 - accuracy: 0.2344 - val_loss: 3.5201 - val_accuracy: 0.1484\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.1250 - accuracy: 0.2266 - val_loss: 3.0418 - val_accuracy: 0.3516\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 2.9100 - accuracy: 0.3516 - val_loss: 2.8299 - val_accuracy: 0.3203\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.0910 - accuracy: 0.2266 - val_loss: 2.8666 - val_accuracy: 0.3281\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.1584 - accuracy: 0.1875 - val_loss: 3.0077 - val_accuracy: 0.2656\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.9981 - accuracy: 0.2266 - val_loss: 3.1739 - val_accuracy: 0.1875\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1520 - accuracy: 0.1953 - val_loss: 3.1845 - val_accuracy: 0.1719\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.0181 - accuracy: 0.2344 - val_loss: 3.1955 - val_accuracy: 0.1797\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8895 - accuracy: 0.2344 - val_loss: 3.4144 - val_accuracy: 0.1250\n",
      "Epoch 285/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 87ms/step - loss: 2.9334 - accuracy: 0.2422 - val_loss: 3.6929 - val_accuracy: 0.1016\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.6256 - accuracy: 0.2734 - val_loss: 3.9141 - val_accuracy: 0.0547\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.9034 - accuracy: 0.2344 - val_loss: 3.8565 - val_accuracy: 0.0469\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.2073 - accuracy: 0.2188 - val_loss: 3.8174 - val_accuracy: 0.0234\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6334 - accuracy: 0.2734 - val_loss: 3.8029 - val_accuracy: 0.0234\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4074 - accuracy: 0.4141 - val_loss: 3.9886 - val_accuracy: 0.0312\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.6856 - accuracy: 0.3359 - val_loss: 3.9440 - val_accuracy: 0.0312\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.2603 - accuracy: 0.2500 - val_loss: 4.0374 - val_accuracy: 0.0156\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9513 - accuracy: 0.2031 - val_loss: 4.1869 - val_accuracy: 0.0156\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7447 - accuracy: 0.3281 - val_loss: 3.9265 - val_accuracy: 0.0234\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.0179 - accuracy: 0.1328 - val_loss: 3.7721 - val_accuracy: 0.0391\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.9077 - accuracy: 0.2344 - val_loss: 3.9095 - val_accuracy: 0.0703\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.9362 - accuracy: 0.2422 - val_loss: 3.6670 - val_accuracy: 0.0859\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.9866 - accuracy: 0.2188 - val_loss: 3.3706 - val_accuracy: 0.1484\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.0549 - accuracy: 0.1719 - val_loss: 3.7613 - val_accuracy: 0.0312\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6115 - accuracy: 0.3203 - val_loss: 3.8663 - val_accuracy: 0.0547\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.8561 - accuracy: 0.3125 - val_loss: 3.1867 - val_accuracy: 0.1875\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9953 - accuracy: 0.2422 - val_loss: 2.8984 - val_accuracy: 0.2422\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9981 - accuracy: 0.2734 - val_loss: 3.3857 - val_accuracy: 0.1875\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.0460 - accuracy: 0.1953 - val_loss: 3.5158 - val_accuracy: 0.1250\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2065 - accuracy: 0.1797 - val_loss: 3.0586 - val_accuracy: 0.1406\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9883 - accuracy: 0.1797 - val_loss: 3.2196 - val_accuracy: 0.1016\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.0223 - accuracy: 0.2422 - val_loss: 3.2356 - val_accuracy: 0.0391\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.8740 - accuracy: 0.2578 - val_loss: 3.3765 - val_accuracy: 0.0703\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.9665 - accuracy: 0.2578 - val_loss: 3.5518 - val_accuracy: 0.1016\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.7663 - accuracy: 0.2344 - val_loss: 3.5619 - val_accuracy: 0.0703\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.7744 - accuracy: 0.2891 - val_loss: 3.5099 - val_accuracy: 0.0703\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7032 - accuracy: 0.3516 - val_loss: 3.3643 - val_accuracy: 0.0547\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0380 - accuracy: 0.2422 - val_loss: 3.1865 - val_accuracy: 0.0547\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.5588 - accuracy: 0.3516 - val_loss: 3.2526 - val_accuracy: 0.0859\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8967 - accuracy: 0.2188 - val_loss: 3.8620 - val_accuracy: 0.0938\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.0602 - accuracy: 0.2422 - val_loss: 4.5287 - val_accuracy: 0.1016\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2304 - accuracy: 0.2031 - val_loss: 4.9057 - val_accuracy: 0.0625\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.1040 - accuracy: 0.2500 - val_loss: 4.3150 - val_accuracy: 0.0703\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9561 - accuracy: 0.2109 - val_loss: 3.7530 - val_accuracy: 0.0391\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.0758 - accuracy: 0.3359 - val_loss: 3.7801 - val_accuracy: 0.0547\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9021 - accuracy: 0.2656 - val_loss: 3.9728 - val_accuracy: 0.0547\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8623 - accuracy: 0.2891 - val_loss: 3.9320 - val_accuracy: 0.0859\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.9730 - accuracy: 0.3203 - val_loss: 3.3232 - val_accuracy: 0.1797\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.9691 - accuracy: 0.2891 - val_loss: 3.3774 - val_accuracy: 0.1484\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8195 - accuracy: 0.2734 - val_loss: 3.6846 - val_accuracy: 0.0312\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.0911 - accuracy: 0.1719 - val_loss: 3.8333 - val_accuracy: 0.0312\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.8306 - accuracy: 0.2500 - val_loss: 3.5933 - val_accuracy: 0.0391\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9837 - accuracy: 0.2344 - val_loss: 3.2291 - val_accuracy: 0.0547\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.7925 - accuracy: 0.3125 - val_loss: 3.6166 - val_accuracy: 0.0391\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.8326 - accuracy: 0.2969 - val_loss: 3.7440 - val_accuracy: 0.0547\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.9039 - accuracy: 0.2188 - val_loss: 3.3631 - val_accuracy: 0.0469\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.6842 - accuracy: 0.3516 - val_loss: 3.7327 - val_accuracy: 0.0547\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.0294 - accuracy: 0.2109 - val_loss: 3.4141 - val_accuracy: 0.0859\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6915 - accuracy: 0.2891 - val_loss: 3.1628 - val_accuracy: 0.1172\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.9518 - accuracy: 0.2656 - val_loss: 3.1459 - val_accuracy: 0.1406\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.6018 - accuracy: 0.3125 - val_loss: 3.2794 - val_accuracy: 0.1797\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.3230 - accuracy: 0.3750 - val_loss: 3.1539 - val_accuracy: 0.2656\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8407 - accuracy: 0.2734 - val_loss: 2.7096 - val_accuracy: 0.2656\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7556 - accuracy: 0.2969 - val_loss: 2.7260 - val_accuracy: 0.2344\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7942 - accuracy: 0.3359 - val_loss: 2.9571 - val_accuracy: 0.1797\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.5716 - accuracy: 0.3359 - val_loss: 3.1328 - val_accuracy: 0.1562\n",
      "Epoch 342/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 2.9490 - accuracy: 0.1719 - val_loss: 3.1845 - val_accuracy: 0.1406\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7078 - accuracy: 0.2656 - val_loss: 2.6023 - val_accuracy: 0.2500\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.9394 - accuracy: 0.2109 - val_loss: 2.6929 - val_accuracy: 0.2969\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7593 - accuracy: 0.2578 - val_loss: 3.2032 - val_accuracy: 0.2344\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6828 - accuracy: 0.2812 - val_loss: 3.4409 - val_accuracy: 0.2422\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6388 - accuracy: 0.2891 - val_loss: 3.3871 - val_accuracy: 0.1875\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.8182 - accuracy: 0.2734 - val_loss: 2.9250 - val_accuracy: 0.3281\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.5220 - accuracy: 0.3203 - val_loss: 2.9301 - val_accuracy: 0.2500\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7040 - accuracy: 0.2734 - val_loss: 2.8987 - val_accuracy: 0.2422\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8588 - accuracy: 0.2656 - val_loss: 2.7859 - val_accuracy: 0.3203\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7103 - accuracy: 0.3281 - val_loss: 2.7636 - val_accuracy: 0.3203\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8232 - accuracy: 0.2578 - val_loss: 3.6545 - val_accuracy: 0.0859\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.4313 - accuracy: 0.3828 - val_loss: 4.3813 - val_accuracy: 0.0469\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.9481 - accuracy: 0.2500 - val_loss: 4.1011 - val_accuracy: 0.0703\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.1395 - accuracy: 0.2422 - val_loss: 4.0761 - val_accuracy: 0.0625\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.7466 - accuracy: 0.2734 - val_loss: 3.7403 - val_accuracy: 0.1406\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7575 - accuracy: 0.2891 - val_loss: 3.3701 - val_accuracy: 0.1641\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8445 - accuracy: 0.2266 - val_loss: 3.2309 - val_accuracy: 0.1406\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.8025 - accuracy: 0.3438 - val_loss: 2.7738 - val_accuracy: 0.2266\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6615 - accuracy: 0.2578 - val_loss: 2.9430 - val_accuracy: 0.2031\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.4702 - accuracy: 0.3906 - val_loss: 3.0918 - val_accuracy: 0.1875\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6760 - accuracy: 0.3438 - val_loss: 2.8918 - val_accuracy: 0.2656\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.6247 - accuracy: 0.2656 - val_loss: 2.7973 - val_accuracy: 0.2812\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1241 - accuracy: 0.4375 - val_loss: 2.8323 - val_accuracy: 0.2812\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.7354 - accuracy: 0.2266 - val_loss: 3.2004 - val_accuracy: 0.2031\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.3552 - accuracy: 0.4062 - val_loss: 3.0254 - val_accuracy: 0.2266\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.5588 - accuracy: 0.3125 - val_loss: 2.7969 - val_accuracy: 0.2656\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4475 - accuracy: 0.3828 - val_loss: 3.0325 - val_accuracy: 0.1641\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.5346 - accuracy: 0.3594 - val_loss: 3.3595 - val_accuracy: 0.1328\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7431 - accuracy: 0.2734 - val_loss: 3.4029 - val_accuracy: 0.0938\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.8128 - accuracy: 0.3281 - val_loss: 3.4101 - val_accuracy: 0.1094\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.7349 - accuracy: 0.2500 - val_loss: 3.4034 - val_accuracy: 0.1328\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.5234 - accuracy: 0.4062 - val_loss: 3.6311 - val_accuracy: 0.0859\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.6833 - accuracy: 0.2969 - val_loss: 4.4813 - val_accuracy: 0.0469\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.4198 - accuracy: 0.3594 - val_loss: 4.3645 - val_accuracy: 0.0547\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.5788 - accuracy: 0.2969 - val_loss: 3.7087 - val_accuracy: 0.1094\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.7857 - accuracy: 0.2891 - val_loss: 2.8270 - val_accuracy: 0.3047\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.0518 - accuracy: 0.2109 - val_loss: 2.5035 - val_accuracy: 0.3438\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.3506 - accuracy: 0.2891 - val_loss: 2.4777 - val_accuracy: 0.3203\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.5280 - accuracy: 0.3125 - val_loss: 2.5849 - val_accuracy: 0.3125\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6875 - accuracy: 0.3125 - val_loss: 3.1276 - val_accuracy: 0.1562\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5791 - accuracy: 0.3359 - val_loss: 3.7999 - val_accuracy: 0.0469\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.4138 - accuracy: 0.3047 - val_loss: 3.7071 - val_accuracy: 0.0312\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.5548 - accuracy: 0.3750 - val_loss: 3.1759 - val_accuracy: 0.1328\n",
      "Epoch 386/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.4804 - accuracy: 0.3359 - val_loss: 3.2118 - val_accuracy: 0.1406\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4797 - accuracy: 0.3047 - val_loss: 3.2217 - val_accuracy: 0.1562\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6847 - accuracy: 0.2344 - val_loss: 3.3368 - val_accuracy: 0.1953\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.4109 - accuracy: 0.3438 - val_loss: 3.7166 - val_accuracy: 0.1172\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8348 - accuracy: 0.2812 - val_loss: 3.6113 - val_accuracy: 0.1328\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.3855 - accuracy: 0.3359 - val_loss: 3.4568 - val_accuracy: 0.1797\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.4363 - accuracy: 0.3281 - val_loss: 3.0628 - val_accuracy: 0.2422\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4049 - accuracy: 0.3828 - val_loss: 3.1425 - val_accuracy: 0.2344\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8769 - accuracy: 0.2969 - val_loss: 3.1115 - val_accuracy: 0.1875\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5064 - accuracy: 0.3203 - val_loss: 3.2516 - val_accuracy: 0.1562\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1572 - accuracy: 0.4531 - val_loss: 2.7139 - val_accuracy: 0.2891\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2519 - accuracy: 0.3828 - val_loss: 2.5581 - val_accuracy: 0.4297\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6108 - accuracy: 0.2891 - val_loss: 2.9158 - val_accuracy: 0.2969\n",
      "Epoch 399/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5960 - accuracy: 0.2500 - val_loss: 2.8161 - val_accuracy: 0.3281\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6243 - accuracy: 0.3438 - val_loss: 2.8641 - val_accuracy: 0.2500\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6106 - accuracy: 0.3281 - val_loss: 2.9467 - val_accuracy: 0.1875\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.6344 - accuracy: 0.2031 - val_loss: 3.2930 - val_accuracy: 0.1328\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5083 - accuracy: 0.3281 - val_loss: 3.4160 - val_accuracy: 0.0938\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4991 - accuracy: 0.3750 - val_loss: 3.4656 - val_accuracy: 0.1016\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.8214 - accuracy: 0.2969 - val_loss: 3.4289 - val_accuracy: 0.1172\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6256 - accuracy: 0.3672 - val_loss: 3.3842 - val_accuracy: 0.1094\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.6650 - accuracy: 0.3047 - val_loss: 3.3104 - val_accuracy: 0.1328\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4440 - accuracy: 0.3906 - val_loss: 3.0860 - val_accuracy: 0.1484\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.4925 - accuracy: 0.3359 - val_loss: 3.0370 - val_accuracy: 0.1875\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.4998 - accuracy: 0.3828 - val_loss: 3.2166 - val_accuracy: 0.1172\n",
      "Epoch 411/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6211 - accuracy: 0.2500 - val_loss: 3.7694 - val_accuracy: 0.0234\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.5425 - accuracy: 0.3750 - val_loss: 4.4913 - val_accuracy: 0.0234\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.9324 - accuracy: 0.2500 - val_loss: 4.4697 - val_accuracy: 0.0156\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.6898 - accuracy: 0.2578 - val_loss: 4.3612 - val_accuracy: 0.0312\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.6763 - accuracy: 0.3125 - val_loss: 3.7836 - val_accuracy: 0.0938\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.6576 - accuracy: 0.1797 - val_loss: 3.1161 - val_accuracy: 0.1250\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.6962 - accuracy: 0.1953 - val_loss: 3.1818 - val_accuracy: 0.0859\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.5081 - accuracy: 0.3750 - val_loss: 3.6659 - val_accuracy: 0.1172\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.9341 - accuracy: 0.2500 - val_loss: 3.7298 - val_accuracy: 0.0625\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.5754 - accuracy: 0.3438 - val_loss: 4.2259 - val_accuracy: 0.0234\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4602 - accuracy: 0.3281 - val_loss: 4.5611 - val_accuracy: 0.0312\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.0334 - accuracy: 0.2109 - val_loss: 4.1190 - val_accuracy: 0.1562\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.3666 - accuracy: 0.2891 - val_loss: 3.7070 - val_accuracy: 0.1953\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.2084 - accuracy: 0.3906 - val_loss: 3.3445 - val_accuracy: 0.1719\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.9534 - accuracy: 0.2578 - val_loss: 3.2482 - val_accuracy: 0.1484\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.7347 - accuracy: 0.2891 - val_loss: 3.1808 - val_accuracy: 0.1797\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3788 - accuracy: 0.3516 - val_loss: 3.0413 - val_accuracy: 0.2266\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3156 - accuracy: 0.3984 - val_loss: 2.6872 - val_accuracy: 0.2969\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.4877 - accuracy: 0.2891 - val_loss: 2.8544 - val_accuracy: 0.3047\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.4902 - accuracy: 0.3906 - val_loss: 3.5833 - val_accuracy: 0.1797\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.4940 - accuracy: 0.3984 - val_loss: 3.2664 - val_accuracy: 0.1875\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.5238 - accuracy: 0.3359 - val_loss: 3.0746 - val_accuracy: 0.2109\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5203 - accuracy: 0.3828 - val_loss: 2.9322 - val_accuracy: 0.2109\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.7242 - accuracy: 0.2734 - val_loss: 2.9957 - val_accuracy: 0.1562\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6934 - accuracy: 0.3438 - val_loss: 3.0985 - val_accuracy: 0.1875\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.4448 - accuracy: 0.3359 - val_loss: 3.1691 - val_accuracy: 0.1953\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6396 - accuracy: 0.3438 - val_loss: 2.8083 - val_accuracy: 0.2344\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.5084 - accuracy: 0.3047 - val_loss: 2.8374 - val_accuracy: 0.2344\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8001 - accuracy: 0.2188 - val_loss: 3.0221 - val_accuracy: 0.2031\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.3564 - accuracy: 0.3359 - val_loss: 2.8204 - val_accuracy: 0.1719\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.5766 - accuracy: 0.3125 - val_loss: 2.7823 - val_accuracy: 0.2109\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.6301 - accuracy: 0.3047 - val_loss: 2.7421 - val_accuracy: 0.2422\n",
      "Epoch 443/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.3988 - accuracy: 0.4219 - val_loss: 2.4544 - val_accuracy: 0.3281\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1938 - accuracy: 0.4766 - val_loss: 2.2748 - val_accuracy: 0.3516\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.3649 - accuracy: 0.4219 - val_loss: 2.3218 - val_accuracy: 0.3672\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.7322 - accuracy: 0.2578 - val_loss: 2.5918 - val_accuracy: 0.3203\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.2663 - accuracy: 0.3984 - val_loss: 2.6756 - val_accuracy: 0.2578\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.2202 - accuracy: 0.3828 - val_loss: 2.5668 - val_accuracy: 0.2812\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1569 - accuracy: 0.4688 - val_loss: 2.4323 - val_accuracy: 0.3438\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.3745 - accuracy: 0.3750 - val_loss: 2.3417 - val_accuracy: 0.4141\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3894 - accuracy: 0.3594 - val_loss: 2.3073 - val_accuracy: 0.3828\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3303 - accuracy: 0.3516 - val_loss: 2.3630 - val_accuracy: 0.3906\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.5515 - accuracy: 0.3359 - val_loss: 2.4467 - val_accuracy: 0.3203\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.7277 - accuracy: 0.1719 - val_loss: 2.6791 - val_accuracy: 0.2891\n",
      "Epoch 455/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.1820 - accuracy: 0.4375 - val_loss: 2.7887 - val_accuracy: 0.2266\n",
      "Epoch 456/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 79ms/step - loss: 2.3907 - accuracy: 0.3281 - val_loss: 3.0026 - val_accuracy: 0.2266\n",
      "Epoch 457/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1133 - accuracy: 0.3750 - val_loss: 3.4501 - val_accuracy: 0.2500\n",
      "Epoch 458/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.6172 - accuracy: 0.2891 - val_loss: 3.6193 - val_accuracy: 0.0859\n",
      "Epoch 459/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.1566 - accuracy: 0.4297 - val_loss: 3.3828 - val_accuracy: 0.1406\n",
      "Epoch 460/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5673 - accuracy: 0.3359 - val_loss: 2.5525 - val_accuracy: 0.2734\n",
      "Epoch 461/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.5879 - accuracy: 0.3125 - val_loss: 2.5303 - val_accuracy: 0.2812\n",
      "Epoch 462/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.4687 - accuracy: 0.3359 - val_loss: 3.0314 - val_accuracy: 0.1953\n",
      "Epoch 463/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4384 - accuracy: 0.4141 - val_loss: 3.0532 - val_accuracy: 0.0781\n",
      "Epoch 464/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4611 - accuracy: 0.2734 - val_loss: 3.3693 - val_accuracy: 0.0625\n",
      "Epoch 465/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.8546 - accuracy: 0.2344 - val_loss: 3.3632 - val_accuracy: 0.0312\n",
      "Epoch 466/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2908 - accuracy: 0.3750 - val_loss: 3.0677 - val_accuracy: 0.0703\n",
      "Epoch 467/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.4121 - accuracy: 0.3672 - val_loss: 3.0429 - val_accuracy: 0.1172\n",
      "Epoch 468/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.1836 - accuracy: 0.3672 - val_loss: 2.8410 - val_accuracy: 0.1562\n",
      "Epoch 469/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2015 - accuracy: 0.3906 - val_loss: 2.7163 - val_accuracy: 0.2266\n",
      "Epoch 470/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6748 - accuracy: 0.3281 - val_loss: 2.5930 - val_accuracy: 0.2500\n",
      "Epoch 471/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4198 - accuracy: 0.3594 - val_loss: 2.5783 - val_accuracy: 0.2656\n",
      "Epoch 472/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.3041 - accuracy: 0.3672 - val_loss: 2.8623 - val_accuracy: 0.2422\n",
      "Epoch 473/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2701 - accuracy: 0.3594 - val_loss: 2.9879 - val_accuracy: 0.1797\n",
      "Epoch 474/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5440 - accuracy: 0.2734 - val_loss: 3.1868 - val_accuracy: 0.1172\n",
      "Epoch 475/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4676 - accuracy: 0.3125 - val_loss: 3.2059 - val_accuracy: 0.1016\n",
      "Epoch 476/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.3430 - accuracy: 0.3438 - val_loss: 3.3454 - val_accuracy: 0.1172\n",
      "Epoch 477/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.4279 - accuracy: 0.4688 - val_loss: 3.2663 - val_accuracy: 0.1172\n",
      "Epoch 478/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.1823 - accuracy: 0.4375 - val_loss: 3.0387 - val_accuracy: 0.1484\n",
      "Epoch 479/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.4700 - accuracy: 0.3750 - val_loss: 3.0210 - val_accuracy: 0.1953\n",
      "Epoch 480/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.3524 - accuracy: 0.4141 - val_loss: 3.0799 - val_accuracy: 0.2422\n",
      "Epoch 481/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2827 - accuracy: 0.3984 - val_loss: 3.0495 - val_accuracy: 0.2578\n",
      "Epoch 482/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.9935 - accuracy: 0.4453 - val_loss: 3.2100 - val_accuracy: 0.2500\n",
      "Epoch 483/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2917 - accuracy: 0.3750 - val_loss: 3.0860 - val_accuracy: 0.3203\n",
      "Epoch 484/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9881 - accuracy: 0.4297 - val_loss: 3.1873 - val_accuracy: 0.2812\n",
      "Epoch 485/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.3406 - accuracy: 0.3984 - val_loss: 3.4631 - val_accuracy: 0.2422\n",
      "Epoch 486/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.2119 - accuracy: 0.3984 - val_loss: 3.4264 - val_accuracy: 0.1562\n",
      "Epoch 487/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3270 - accuracy: 0.3672 - val_loss: 3.0639 - val_accuracy: 0.2188\n",
      "Epoch 488/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.3955 - accuracy: 0.3516 - val_loss: 2.8278 - val_accuracy: 0.2500\n",
      "Epoch 489/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4310 - accuracy: 0.3359 - val_loss: 3.1341 - val_accuracy: 0.1641\n",
      "Epoch 490/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.6590 - accuracy: 0.3359 - val_loss: 3.3647 - val_accuracy: 0.1406\n",
      "Epoch 491/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3793 - accuracy: 0.3516 - val_loss: 2.9125 - val_accuracy: 0.2266\n",
      "Epoch 492/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.4289 - accuracy: 0.3438 - val_loss: 2.5683 - val_accuracy: 0.2891\n",
      "Epoch 493/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.0420 - accuracy: 0.4609 - val_loss: 2.7253 - val_accuracy: 0.2188\n",
      "Epoch 494/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.3730 - accuracy: 0.3281 - val_loss: 2.6478 - val_accuracy: 0.2500\n",
      "Epoch 495/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3531 - accuracy: 0.3828 - val_loss: 2.5995 - val_accuracy: 0.2031\n",
      "Epoch 496/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.3002 - accuracy: 0.4219 - val_loss: 2.5372 - val_accuracy: 0.2266\n",
      "Epoch 497/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.3443 - accuracy: 0.3906 - val_loss: 2.6161 - val_accuracy: 0.2734\n",
      "Epoch 498/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2947 - accuracy: 0.3438 - val_loss: 3.0168 - val_accuracy: 0.1562\n",
      "Epoch 499/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3784 - accuracy: 0.3906 - val_loss: 2.9310 - val_accuracy: 0.1406\n",
      "Epoch 500/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2115 - accuracy: 0.3984 - val_loss: 2.4826 - val_accuracy: 0.3594\n",
      "Epoch 501/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.6033 - accuracy: 0.2812 - val_loss: 2.2736 - val_accuracy: 0.4688\n",
      "Epoch 502/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.3762 - accuracy: 0.3438 - val_loss: 2.3265 - val_accuracy: 0.4375\n",
      "Epoch 503/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1679 - accuracy: 0.4453 - val_loss: 2.4879 - val_accuracy: 0.4219\n",
      "Epoch 504/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2469 - accuracy: 0.4062 - val_loss: 2.5266 - val_accuracy: 0.4141\n",
      "Epoch 505/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1733 - accuracy: 0.4219 - val_loss: 2.3758 - val_accuracy: 0.4062\n",
      "Epoch 506/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3033 - accuracy: 0.3672 - val_loss: 2.3128 - val_accuracy: 0.4531\n",
      "Epoch 507/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2579 - accuracy: 0.4375 - val_loss: 2.5349 - val_accuracy: 0.4219\n",
      "Epoch 508/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3293 - accuracy: 0.4141 - val_loss: 2.9525 - val_accuracy: 0.2734\n",
      "Epoch 509/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.1524 - accuracy: 0.4297 - val_loss: 2.8375 - val_accuracy: 0.2734\n",
      "Epoch 510/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.1181 - accuracy: 0.5000 - val_loss: 2.7931 - val_accuracy: 0.2578\n",
      "Epoch 511/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5192 - accuracy: 0.3438 - val_loss: 3.2128 - val_accuracy: 0.2109\n",
      "Epoch 512/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.1604 - accuracy: 0.4062 - val_loss: 3.4189 - val_accuracy: 0.2344\n",
      "Epoch 513/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 81ms/step - loss: 2.2962 - accuracy: 0.3594 - val_loss: 3.3348 - val_accuracy: 0.1797\n",
      "Epoch 514/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1173 - accuracy: 0.4219 - val_loss: 3.3301 - val_accuracy: 0.1641\n",
      "Epoch 515/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.2009 - accuracy: 0.3906 - val_loss: 2.7607 - val_accuracy: 0.2734\n",
      "Epoch 516/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.3923 - accuracy: 0.4531 - val_loss: 2.3986 - val_accuracy: 0.3359\n",
      "Epoch 517/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2943 - accuracy: 0.3125 - val_loss: 2.4436 - val_accuracy: 0.2812\n",
      "Epoch 518/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9776 - accuracy: 0.5000 - val_loss: 3.3112 - val_accuracy: 0.1328\n",
      "Epoch 519/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.2006 - accuracy: 0.4219 - val_loss: 3.7056 - val_accuracy: 0.1094\n",
      "Epoch 520/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1049 - accuracy: 0.4062 - val_loss: 3.5720 - val_accuracy: 0.1250\n",
      "Epoch 521/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3334 - accuracy: 0.3438 - val_loss: 3.1114 - val_accuracy: 0.1484\n",
      "Epoch 522/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.0019 - accuracy: 0.4375 - val_loss: 2.8240 - val_accuracy: 0.1641\n",
      "Epoch 523/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.3593 - accuracy: 0.4297 - val_loss: 2.9299 - val_accuracy: 0.1797\n",
      "Epoch 524/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2999 - accuracy: 0.4219 - val_loss: 2.8103 - val_accuracy: 0.1797\n",
      "Epoch 525/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.9497 - accuracy: 0.4062 - val_loss: 2.7964 - val_accuracy: 0.1797\n",
      "Epoch 526/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4274 - accuracy: 0.3750 - val_loss: 2.9031 - val_accuracy: 0.1562\n",
      "Epoch 527/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.6191 - accuracy: 0.2578 - val_loss: 2.8601 - val_accuracy: 0.2188\n",
      "Epoch 528/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.1289 - accuracy: 0.3828 - val_loss: 2.7434 - val_accuracy: 0.2266\n",
      "Epoch 529/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2736 - accuracy: 0.2812 - val_loss: 2.6167 - val_accuracy: 0.2656\n",
      "Epoch 530/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.7561 - accuracy: 0.2734 - val_loss: 2.6465 - val_accuracy: 0.2891\n",
      "Epoch 531/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2782 - accuracy: 0.4375 - val_loss: 2.5401 - val_accuracy: 0.2812\n",
      "Epoch 532/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2666 - accuracy: 0.4141 - val_loss: 2.6890 - val_accuracy: 0.3125\n",
      "Epoch 533/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2983 - accuracy: 0.3906 - val_loss: 2.6765 - val_accuracy: 0.2969\n",
      "Epoch 534/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.4540 - accuracy: 0.3594 - val_loss: 2.8523 - val_accuracy: 0.1797\n",
      "Epoch 535/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1521 - accuracy: 0.4141 - val_loss: 2.8815 - val_accuracy: 0.1875\n",
      "Epoch 536/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3459 - accuracy: 0.3750 - val_loss: 2.8688 - val_accuracy: 0.2031\n",
      "Epoch 537/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.3570 - accuracy: 0.3828 - val_loss: 2.9245 - val_accuracy: 0.1797\n",
      "Epoch 538/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2356 - accuracy: 0.3594 - val_loss: 2.7033 - val_accuracy: 0.2812\n",
      "Epoch 539/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.0985 - accuracy: 0.4297 - val_loss: 2.5651 - val_accuracy: 0.2812\n",
      "Epoch 540/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.4235 - accuracy: 0.2891 - val_loss: 2.7154 - val_accuracy: 0.2969\n",
      "Epoch 541/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0251 - accuracy: 0.4297 - val_loss: 2.9889 - val_accuracy: 0.2344\n",
      "Epoch 542/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3037 - accuracy: 0.3828 - val_loss: 3.1017 - val_accuracy: 0.1953\n",
      "Epoch 543/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7499 - accuracy: 0.3125 - val_loss: 3.0281 - val_accuracy: 0.1797\n",
      "Epoch 544/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9879 - accuracy: 0.4141 - val_loss: 2.5544 - val_accuracy: 0.3359\n",
      "Epoch 545/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.3755 - accuracy: 0.4062 - val_loss: 2.1727 - val_accuracy: 0.4844\n",
      "Epoch 546/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3253 - accuracy: 0.3672 - val_loss: 2.6912 - val_accuracy: 0.3281\n",
      "Epoch 547/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.4925 - accuracy: 0.3516 - val_loss: 2.5703 - val_accuracy: 0.3516\n",
      "Epoch 548/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.6858 - accuracy: 0.5312 - val_loss: 2.4261 - val_accuracy: 0.4062\n",
      "Epoch 549/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2746 - accuracy: 0.4531 - val_loss: 2.1413 - val_accuracy: 0.4766\n",
      "Epoch 550/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.4590 - accuracy: 0.3594 - val_loss: 2.0809 - val_accuracy: 0.4688\n",
      "Epoch 551/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.9293 - accuracy: 0.5000 - val_loss: 2.3253 - val_accuracy: 0.3672\n",
      "Epoch 552/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4022 - accuracy: 0.2578 - val_loss: 2.4551 - val_accuracy: 0.3203\n",
      "Epoch 553/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2548 - accuracy: 0.3672 - val_loss: 2.9250 - val_accuracy: 0.2578\n",
      "Epoch 554/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1224 - accuracy: 0.3984 - val_loss: 3.4511 - val_accuracy: 0.1016\n",
      "Epoch 555/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2790 - accuracy: 0.3828 - val_loss: 3.4267 - val_accuracy: 0.0938\n",
      "Epoch 556/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.3372 - accuracy: 0.3281 - val_loss: 3.0285 - val_accuracy: 0.1484\n",
      "Epoch 557/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1282 - accuracy: 0.4453 - val_loss: 3.0108 - val_accuracy: 0.1797\n",
      "Epoch 558/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1503 - accuracy: 0.3906 - val_loss: 3.1272 - val_accuracy: 0.2344\n",
      "Epoch 559/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2204 - accuracy: 0.4141 - val_loss: 2.8993 - val_accuracy: 0.3047\n",
      "Epoch 560/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.4080 - accuracy: 0.3438 - val_loss: 2.4121 - val_accuracy: 0.4531\n",
      "Epoch 561/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.2753 - accuracy: 0.3750 - val_loss: 2.2650 - val_accuracy: 0.4219\n",
      "Epoch 562/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.3267 - accuracy: 0.3672 - val_loss: 2.3452 - val_accuracy: 0.3984\n",
      "Epoch 563/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.5434 - accuracy: 0.3047 - val_loss: 2.4183 - val_accuracy: 0.4062\n",
      "Epoch 564/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.0231 - accuracy: 0.4766 - val_loss: 2.5147 - val_accuracy: 0.3516\n",
      "Epoch 565/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 1.9840 - accuracy: 0.4141 - val_loss: 2.5844 - val_accuracy: 0.3203\n",
      "Epoch 566/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0187 - accuracy: 0.4609 - val_loss: 2.8350 - val_accuracy: 0.1953\n",
      "Epoch 567/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.2176 - accuracy: 0.3672 - val_loss: 2.8243 - val_accuracy: 0.2500\n",
      "Epoch 568/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.5253 - accuracy: 0.2656 - val_loss: 3.3714 - val_accuracy: 0.1172\n",
      "Epoch 569/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.2884 - accuracy: 0.4062 - val_loss: 3.6877 - val_accuracy: 0.0703\n",
      "Epoch 570/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1672 - accuracy: 0.4375 - val_loss: 3.3048 - val_accuracy: 0.1094\n",
      "Epoch 571/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3381 - accuracy: 0.4297 - val_loss: 3.4342 - val_accuracy: 0.0547\n",
      "Epoch 572/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2703 - accuracy: 0.3281 - val_loss: 3.7201 - val_accuracy: 0.0156\n",
      "Epoch 573/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.4790 - accuracy: 0.3281 - val_loss: 3.7342 - val_accuracy: 0.0391\n",
      "Epoch 574/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0769 - accuracy: 0.4141 - val_loss: 3.4921 - val_accuracy: 0.0703\n",
      "Epoch 575/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.0995 - accuracy: 0.3672 - val_loss: 3.0694 - val_accuracy: 0.2188\n",
      "Epoch 576/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.0441 - accuracy: 0.4062 - val_loss: 2.7645 - val_accuracy: 0.2500\n",
      "Epoch 577/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.1991 - accuracy: 0.4219 - val_loss: 2.6550 - val_accuracy: 0.2500\n",
      "Epoch 578/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.3873 - accuracy: 0.3828 - val_loss: 2.7329 - val_accuracy: 0.2422\n",
      "Epoch 579/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.0508 - accuracy: 0.4062 - val_loss: 2.7187 - val_accuracy: 0.2656\n",
      "Epoch 580/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.5120 - accuracy: 0.4062 - val_loss: 2.7886 - val_accuracy: 0.2344\n",
      "Epoch 581/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 2.4046 - accuracy: 0.2969 - val_loss: 2.7377 - val_accuracy: 0.2031\n",
      "Epoch 582/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.1638 - accuracy: 0.4375 - val_loss: 2.7348 - val_accuracy: 0.1484\n",
      "Epoch 583/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2343 - accuracy: 0.3516 - val_loss: 2.7134 - val_accuracy: 0.2031\n",
      "Epoch 584/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2565 - accuracy: 0.3672 - val_loss: 2.7535 - val_accuracy: 0.2266\n",
      "Epoch 585/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2493 - accuracy: 0.3438 - val_loss: 2.8751 - val_accuracy: 0.1719\n",
      "Epoch 586/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1140 - accuracy: 0.4219 - val_loss: 3.3408 - val_accuracy: 0.1406\n",
      "Epoch 587/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.0912 - accuracy: 0.4922 - val_loss: 3.5246 - val_accuracy: 0.1641\n",
      "Epoch 588/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1413 - accuracy: 0.4766 - val_loss: 2.9625 - val_accuracy: 0.1953\n",
      "Epoch 589/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.0746 - accuracy: 0.5156 - val_loss: 2.4912 - val_accuracy: 0.3594\n",
      "Epoch 590/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1474 - accuracy: 0.3828 - val_loss: 2.4254 - val_accuracy: 0.3828\n",
      "Epoch 591/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1897 - accuracy: 0.3906 - val_loss: 2.4935 - val_accuracy: 0.3828\n",
      "Epoch 592/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.3612 - accuracy: 0.3672 - val_loss: 2.6106 - val_accuracy: 0.2812\n",
      "Epoch 593/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.0825 - accuracy: 0.4062 - val_loss: 2.5861 - val_accuracy: 0.3750\n",
      "Epoch 594/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1566 - accuracy: 0.4453 - val_loss: 2.6661 - val_accuracy: 0.3594\n",
      "Epoch 595/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.4638 - accuracy: 0.3281 - val_loss: 2.6715 - val_accuracy: 0.3672\n",
      "Epoch 596/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.5100 - accuracy: 0.3828 - val_loss: 2.6180 - val_accuracy: 0.3281\n",
      "Epoch 597/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2620 - accuracy: 0.3828 - val_loss: 2.7022 - val_accuracy: 0.2969\n",
      "Epoch 598/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.1860 - accuracy: 0.3672 - val_loss: 2.7079 - val_accuracy: 0.2891\n",
      "Epoch 599/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.5538 - accuracy: 0.3516 - val_loss: 2.6324 - val_accuracy: 0.3672\n",
      "Epoch 600/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.9626 - accuracy: 0.4453 - val_loss: 2.7863 - val_accuracy: 0.3672\n",
      "Epoch 601/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1712 - accuracy: 0.4297 - val_loss: 2.6023 - val_accuracy: 0.3516\n",
      "Epoch 602/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.2430 - accuracy: 0.3750 - val_loss: 2.4460 - val_accuracy: 0.3672\n",
      "Epoch 603/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.3936 - accuracy: 0.2891 - val_loss: 2.2704 - val_accuracy: 0.4219\n",
      "Epoch 604/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9607 - accuracy: 0.4219 - val_loss: 2.5975 - val_accuracy: 0.3203\n",
      "Epoch 605/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9378 - accuracy: 0.4766 - val_loss: 2.9886 - val_accuracy: 0.1875\n",
      "Epoch 606/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.3503 - accuracy: 0.3203 - val_loss: 3.1378 - val_accuracy: 0.1250\n",
      "Epoch 607/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.2850 - accuracy: 0.3359 - val_loss: 3.1268 - val_accuracy: 0.1328\n",
      "Epoch 608/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.1117 - accuracy: 0.4453 - val_loss: 3.2722 - val_accuracy: 0.1094\n",
      "Epoch 609/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 1.8738 - accuracy: 0.5000 - val_loss: 3.3400 - val_accuracy: 0.1562\n",
      "Epoch 610/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1304 - accuracy: 0.4141 - val_loss: 2.9750 - val_accuracy: 0.1797\n",
      "Epoch 611/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.8445 - accuracy: 0.5078 - val_loss: 2.6465 - val_accuracy: 0.2891\n",
      "Epoch 612/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.0360 - accuracy: 0.4219 - val_loss: 2.6030 - val_accuracy: 0.3125\n",
      "Epoch 613/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1017 - accuracy: 0.4375 - val_loss: 2.5882 - val_accuracy: 0.3125\n",
      "Epoch 614/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9050 - accuracy: 0.4688 - val_loss: 2.4110 - val_accuracy: 0.3594\n",
      "Epoch 615/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9102 - accuracy: 0.4844 - val_loss: 2.2002 - val_accuracy: 0.4375\n",
      "Epoch 616/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9851 - accuracy: 0.4609 - val_loss: 2.1689 - val_accuracy: 0.4531\n",
      "Epoch 617/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.1644 - accuracy: 0.4531 - val_loss: 2.2023 - val_accuracy: 0.4219\n",
      "Epoch 618/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.2435 - accuracy: 0.4219 - val_loss: 2.3708 - val_accuracy: 0.3750\n",
      "Epoch 619/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.8631 - accuracy: 0.4766 - val_loss: 2.5242 - val_accuracy: 0.3281\n",
      "Epoch 620/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.2205 - accuracy: 0.4297 - val_loss: 2.5038 - val_accuracy: 0.3906\n",
      "Epoch 621/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.1660 - accuracy: 0.4531 - val_loss: 2.6276 - val_accuracy: 0.3125\n",
      "Epoch 622/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.0050 - accuracy: 0.4609 - val_loss: 2.8924 - val_accuracy: 0.2578\n",
      "Epoch 623/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5121 - accuracy: 0.2969 - val_loss: 2.8296 - val_accuracy: 0.2812\n",
      "Epoch 624/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.7115 - accuracy: 0.5156 - val_loss: 3.1308 - val_accuracy: 0.2500\n",
      "Epoch 625/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1125 - accuracy: 0.3984 - val_loss: 3.0965 - val_accuracy: 0.1875\n",
      "Epoch 626/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.0498 - accuracy: 0.4844 - val_loss: 3.1379 - val_accuracy: 0.1484\n",
      "Epoch 627/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 81ms/step - loss: 2.0184 - accuracy: 0.4297 - val_loss: 3.1934 - val_accuracy: 0.1953\n",
      "Epoch 628/5000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2.3457 - accuracy: 0.3516 - val_loss: 3.2677 - val_accuracy: 0.2031\n",
      "Epoch 629/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1243 - accuracy: 0.4297 - val_loss: 2.9486 - val_accuracy: 0.2266\n",
      "Epoch 630/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0980 - accuracy: 0.3281 - val_loss: 2.9307 - val_accuracy: 0.2578\n",
      "Epoch 631/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2652 - accuracy: 0.2969 - val_loss: 2.9569 - val_accuracy: 0.2578\n",
      "Epoch 632/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.9953 - accuracy: 0.4453 - val_loss: 2.7750 - val_accuracy: 0.2578\n",
      "Epoch 633/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.4708 - accuracy: 0.3594 - val_loss: 2.7294 - val_accuracy: 0.3125\n",
      "Epoch 634/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5010 - accuracy: 0.3281 - val_loss: 2.6405 - val_accuracy: 0.3438\n",
      "Epoch 635/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.8977 - accuracy: 0.5078 - val_loss: 3.1329 - val_accuracy: 0.1719\n",
      "Epoch 636/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.9661 - accuracy: 0.5312 - val_loss: 3.7709 - val_accuracy: 0.0781\n",
      "Epoch 637/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.1647 - accuracy: 0.3984 - val_loss: 3.0440 - val_accuracy: 0.1172\n",
      "Epoch 638/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3085 - accuracy: 0.4141 - val_loss: 2.6023 - val_accuracy: 0.2578\n",
      "Epoch 639/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1244 - accuracy: 0.4766 - val_loss: 2.5358 - val_accuracy: 0.2969\n",
      "Epoch 640/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1271 - accuracy: 0.4531 - val_loss: 2.6573 - val_accuracy: 0.3047\n",
      "Epoch 641/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.2924 - accuracy: 0.3828 - val_loss: 2.6289 - val_accuracy: 0.2656\n",
      "Epoch 642/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.3192 - accuracy: 0.4141 - val_loss: 2.6864 - val_accuracy: 0.2578\n",
      "Epoch 643/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.9174 - accuracy: 0.5000 - val_loss: 2.6393 - val_accuracy: 0.3281\n",
      "Epoch 644/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9419 - accuracy: 0.4141 - val_loss: 2.5177 - val_accuracy: 0.3594\n",
      "Epoch 645/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 1.9505 - accuracy: 0.4922 - val_loss: 2.4693 - val_accuracy: 0.3828\n",
      "Epoch 646/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.2699 - accuracy: 0.3906 - val_loss: 2.3681 - val_accuracy: 0.4062\n",
      "Epoch 647/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2498 - accuracy: 0.4453 - val_loss: 2.4415 - val_accuracy: 0.3047\n",
      "Epoch 648/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.2278 - accuracy: 0.3594 - val_loss: 2.2476 - val_accuracy: 0.3750\n",
      "Epoch 649/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9471 - accuracy: 0.4297 - val_loss: 2.1207 - val_accuracy: 0.4297\n",
      "Epoch 650/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1603 - accuracy: 0.3438 - val_loss: 1.9823 - val_accuracy: 0.4844\n",
      "Epoch 651/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2100 - accuracy: 0.3828 - val_loss: 2.0045 - val_accuracy: 0.4766\n",
      "Epoch 652/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9419 - accuracy: 0.4453 - val_loss: 2.1240 - val_accuracy: 0.4531\n",
      "Epoch 653/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.1315 - accuracy: 0.4219 - val_loss: 2.2433 - val_accuracy: 0.4062\n",
      "Epoch 654/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.9768 - accuracy: 0.4453 - val_loss: 2.2253 - val_accuracy: 0.4219\n",
      "Epoch 655/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.3407 - accuracy: 0.3750 - val_loss: 2.4449 - val_accuracy: 0.3047\n",
      "Epoch 656/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.0508 - accuracy: 0.4766 - val_loss: 2.6553 - val_accuracy: 0.2812\n",
      "Epoch 657/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9797 - accuracy: 0.5234 - val_loss: 2.7273 - val_accuracy: 0.2891\n",
      "Epoch 658/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.1646 - accuracy: 0.3984 - val_loss: 2.7708 - val_accuracy: 0.2266\n",
      "Epoch 659/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.8285 - accuracy: 0.4688 - val_loss: 2.7646 - val_accuracy: 0.2422\n",
      "Epoch 660/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.0973 - accuracy: 0.3984 - val_loss: 2.7272 - val_accuracy: 0.2500\n",
      "Epoch 661/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.3260 - accuracy: 0.3672 - val_loss: 2.6095 - val_accuracy: 0.3203\n",
      "Epoch 662/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1087 - accuracy: 0.4141 - val_loss: 2.5721 - val_accuracy: 0.3203\n",
      "Epoch 663/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.8608 - accuracy: 0.5000 - val_loss: 2.5248 - val_accuracy: 0.3203\n",
      "Epoch 664/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.2173 - accuracy: 0.4219 - val_loss: 2.4245 - val_accuracy: 0.3594\n",
      "Epoch 665/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.8743 - accuracy: 0.4844 - val_loss: 2.2632 - val_accuracy: 0.4141\n",
      "Epoch 666/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2170 - accuracy: 0.3672 - val_loss: 2.2454 - val_accuracy: 0.3516\n",
      "Epoch 667/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.8475 - accuracy: 0.4844 - val_loss: 2.3981 - val_accuracy: 0.3281\n",
      "Epoch 668/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.9060 - accuracy: 0.4844 - val_loss: 2.6806 - val_accuracy: 0.3203\n",
      "Epoch 669/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.7537 - accuracy: 0.4766 - val_loss: 2.9781 - val_accuracy: 0.2891\n",
      "Epoch 670/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.8193 - accuracy: 0.4922 - val_loss: 3.1475 - val_accuracy: 0.2500\n",
      "Epoch 671/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.2089 - accuracy: 0.4531 - val_loss: 3.1142 - val_accuracy: 0.2422\n",
      "Epoch 672/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0426 - accuracy: 0.4688 - val_loss: 3.1081 - val_accuracy: 0.2266\n",
      "Epoch 673/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9208 - accuracy: 0.4531 - val_loss: 3.0300 - val_accuracy: 0.2578\n",
      "Epoch 674/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 2.0443 - accuracy: 0.4375 - val_loss: 3.2488 - val_accuracy: 0.2031\n",
      "Epoch 675/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.1647 - accuracy: 0.4219 - val_loss: 3.1148 - val_accuracy: 0.2188\n",
      "Epoch 676/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.5500 - accuracy: 0.3125 - val_loss: 2.8264 - val_accuracy: 0.2344\n",
      "Epoch 677/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.8765 - accuracy: 0.4375 - val_loss: 2.4895 - val_accuracy: 0.3203\n",
      "Epoch 678/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.0038 - accuracy: 0.4453 - val_loss: 2.4921 - val_accuracy: 0.2969\n",
      "Epoch 679/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.9955 - accuracy: 0.4844 - val_loss: 2.6781 - val_accuracy: 0.2500\n",
      "Epoch 680/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.8467 - accuracy: 0.5469 - val_loss: 2.5915 - val_accuracy: 0.2578\n",
      "Epoch 681/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.4088 - accuracy: 0.4219 - val_loss: 2.6096 - val_accuracy: 0.2891\n",
      "Epoch 682/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.9067 - accuracy: 0.4688 - val_loss: 2.8205 - val_accuracy: 0.2266\n",
      "Epoch 683/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.1514 - accuracy: 0.4297 - val_loss: 3.3050 - val_accuracy: 0.1797\n",
      "Epoch 684/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 86ms/step - loss: 2.0726 - accuracy: 0.4453 - val_loss: 3.3446 - val_accuracy: 0.1328\n",
      "Epoch 685/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.2804 - accuracy: 0.4219 - val_loss: 2.9927 - val_accuracy: 0.1953\n",
      "Epoch 686/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1391 - accuracy: 0.4141 - val_loss: 2.9070 - val_accuracy: 0.2656\n",
      "Epoch 687/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1988 - accuracy: 0.3984 - val_loss: 3.0165 - val_accuracy: 0.2266\n",
      "Epoch 688/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.9386 - accuracy: 0.4219 - val_loss: 2.9672 - val_accuracy: 0.1953\n",
      "Epoch 689/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.9565 - accuracy: 0.4141 - val_loss: 2.7010 - val_accuracy: 0.1953\n",
      "Epoch 690/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.8184 - accuracy: 0.4922 - val_loss: 2.5566 - val_accuracy: 0.3047\n",
      "Epoch 691/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1069 - accuracy: 0.3594 - val_loss: 2.5136 - val_accuracy: 0.3438\n",
      "Epoch 692/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.6978 - accuracy: 0.4844 - val_loss: 2.7482 - val_accuracy: 0.2891\n",
      "Epoch 693/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.0731 - accuracy: 0.4453 - val_loss: 2.4531 - val_accuracy: 0.3281\n",
      "Epoch 694/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1821 - accuracy: 0.4297 - val_loss: 2.5681 - val_accuracy: 0.3203\n",
      "Epoch 695/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.8242 - accuracy: 0.4766 - val_loss: 2.3896 - val_accuracy: 0.3672\n",
      "Epoch 696/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.1102 - accuracy: 0.4297 - val_loss: 2.2312 - val_accuracy: 0.4375\n",
      "Epoch 697/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.2334 - accuracy: 0.3438 - val_loss: 2.7160 - val_accuracy: 0.2578\n",
      "Epoch 698/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1126 - accuracy: 0.3984 - val_loss: 2.9038 - val_accuracy: 0.2422\n",
      "Epoch 699/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.9363 - accuracy: 0.5156 - val_loss: 2.8187 - val_accuracy: 0.2578\n",
      "Epoch 700/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.9745 - accuracy: 0.4609 - val_loss: 2.6925 - val_accuracy: 0.3359\n",
      "Epoch 701/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.8424 - accuracy: 0.4844 - val_loss: 2.7885 - val_accuracy: 0.2734\n",
      "Epoch 702/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.8292 - accuracy: 0.5625 - val_loss: 3.2048 - val_accuracy: 0.1406\n",
      "Epoch 703/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 1.6881 - accuracy: 0.5156 - val_loss: 3.2317 - val_accuracy: 0.1484\n",
      "Epoch 704/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.5141 - accuracy: 0.3125 - val_loss: 2.7862 - val_accuracy: 0.2188\n",
      "Epoch 705/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.1441 - accuracy: 0.4453 - val_loss: 2.7542 - val_accuracy: 0.1953\n",
      "Epoch 706/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.2298 - accuracy: 0.4062 - val_loss: 3.0273 - val_accuracy: 0.1641\n",
      "Epoch 707/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1956 - accuracy: 0.4688 - val_loss: 2.7842 - val_accuracy: 0.2578\n",
      "Epoch 708/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.8735 - accuracy: 0.4844 - val_loss: 2.4423 - val_accuracy: 0.3359\n",
      "Epoch 709/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1328 - accuracy: 0.4297 - val_loss: 2.3573 - val_accuracy: 0.3594\n",
      "Epoch 710/5000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 2.1847 - accuracy: 0.3516 - val_loss: 2.3327 - val_accuracy: 0.3359\n",
      "Epoch 711/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.1032 - accuracy: 0.4062 - val_loss: 2.4600 - val_accuracy: 0.3594\n",
      "Epoch 712/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.3942 - accuracy: 0.3984 - val_loss: 2.7325 - val_accuracy: 0.3203\n",
      "Epoch 713/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.1180 - accuracy: 0.4141 - val_loss: 2.8107 - val_accuracy: 0.3203\n",
      "Epoch 714/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3107 - accuracy: 0.3281 - val_loss: 2.6649 - val_accuracy: 0.2969\n",
      "Epoch 715/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.8224 - accuracy: 0.4609 - val_loss: 2.6144 - val_accuracy: 0.3047\n",
      "Epoch 716/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.8955 - accuracy: 0.4609 - val_loss: 2.6231 - val_accuracy: 0.3281\n",
      "Epoch 717/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.9242 - accuracy: 0.4297 - val_loss: 2.6860 - val_accuracy: 0.3203\n",
      "Epoch 718/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.2719 - accuracy: 0.3438 - val_loss: 2.7910 - val_accuracy: 0.3281\n",
      "Epoch 719/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.3031 - accuracy: 0.3047 - val_loss: 2.8630 - val_accuracy: 0.2500\n",
      "Epoch 720/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 1.9087 - accuracy: 0.4688 - val_loss: 2.8410 - val_accuracy: 0.2578\n",
      "Epoch 721/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9852 - accuracy: 0.4297 - val_loss: 2.8066 - val_accuracy: 0.2656\n",
      "Epoch 722/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.0332 - accuracy: 0.4219 - val_loss: 2.7938 - val_accuracy: 0.2578\n",
      "Epoch 723/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1675 - accuracy: 0.4531 - val_loss: 3.1006 - val_accuracy: 0.1797\n",
      "Epoch 724/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 1.7294 - accuracy: 0.4844 - val_loss: 3.1324 - val_accuracy: 0.2266\n",
      "Epoch 725/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.0220 - accuracy: 0.4922 - val_loss: 2.7310 - val_accuracy: 0.2734\n",
      "Epoch 726/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.8509 - accuracy: 0.4922 - val_loss: 2.4150 - val_accuracy: 0.3750\n",
      "Epoch 727/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.2257 - accuracy: 0.3594 - val_loss: 2.2492 - val_accuracy: 0.4297\n",
      "Epoch 728/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 1.8134 - accuracy: 0.4453 - val_loss: 2.1988 - val_accuracy: 0.3828\n",
      "Epoch 729/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.8194 - accuracy: 0.5156 - val_loss: 2.2454 - val_accuracy: 0.3281\n",
      "Epoch 730/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.7625 - accuracy: 0.5547 - val_loss: 2.3450 - val_accuracy: 0.3516\n",
      "Epoch 731/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 1.9628 - accuracy: 0.4531 - val_loss: 2.3957 - val_accuracy: 0.3438\n",
      "Epoch 732/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.8927 - accuracy: 0.5000 - val_loss: 2.4846 - val_accuracy: 0.3594\n",
      "Epoch 733/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.9126 - accuracy: 0.4453 - val_loss: 2.7815 - val_accuracy: 0.2812\n",
      "Epoch 734/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 1.9472 - accuracy: 0.5391 - val_loss: 3.1731 - val_accuracy: 0.1875\n",
      "Epoch 735/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.9014 - accuracy: 0.4531 - val_loss: 3.1744 - val_accuracy: 0.1484\n",
      "Epoch 736/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 1.9841 - accuracy: 0.3828 - val_loss: 2.9534 - val_accuracy: 0.1953\n",
      "Epoch 737/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.0419 - accuracy: 0.4453 - val_loss: 2.9256 - val_accuracy: 0.2266\n",
      "Epoch 738/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 1.9505 - accuracy: 0.4922 - val_loss: 3.1433 - val_accuracy: 0.1953\n",
      "Epoch 739/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.1739 - accuracy: 0.3906 - val_loss: 3.3890 - val_accuracy: 0.1797\n",
      "Epoch 740/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.0798 - accuracy: 0.4141 - val_loss: 3.2283 - val_accuracy: 0.2031\n",
      "Epoch 741/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 72ms/step - loss: 1.9238 - accuracy: 0.4688 - val_loss: 3.0025 - val_accuracy: 0.2031\n",
      "Epoch 742/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 1.8962 - accuracy: 0.4531 - val_loss: 2.6801 - val_accuracy: 0.2812\n",
      "Epoch 743/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 1.6452 - accuracy: 0.5469 - val_loss: 2.5657 - val_accuracy: 0.2812\n",
      "Epoch 744/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.8664 - accuracy: 0.4688 - val_loss: 2.5403 - val_accuracy: 0.2266\n",
      "Epoch 745/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 1.9817 - accuracy: 0.4531 - val_loss: 2.6957 - val_accuracy: 0.1797\n",
      "Epoch 746/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.2390 - accuracy: 0.3594 - val_loss: 2.9165 - val_accuracy: 0.1484\n",
      "Epoch 747/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 1.6680 - accuracy: 0.5312 - val_loss: 3.0652 - val_accuracy: 0.1484\n",
      "Epoch 748/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 1.6499 - accuracy: 0.4766 - val_loss: 2.9294 - val_accuracy: 0.1719\n",
      "Epoch 749/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 1.9236 - accuracy: 0.4766 - val_loss: 2.5608 - val_accuracy: 0.3125\n",
      "Epoch 750/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 1.9098 - accuracy: 0.4766 - val_loss: 2.2371 - val_accuracy: 0.4219\n",
      "Epoch 00750: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1, params=692488\n",
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=692488\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 5.6908 - accuracy: 0.0078 - val_loss: 5.5467 - val_accuracy: 0.0234\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 5.5798 - accuracy: 0.0078 - val_loss: 5.5468 - val_accuracy: 0.0234\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 5.5566 - accuracy: 0.0078 - val_loss: 5.5438 - val_accuracy: 0.0234\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 5.5193 - accuracy: 0.0078 - val_loss: 5.5377 - val_accuracy: 0.0234\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.3237 - accuracy: 0.0547 - val_loss: 5.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.4026 - accuracy: 0.0078 - val_loss: 5.5253 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.2847 - accuracy: 0.0547 - val_loss: 5.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.3660 - accuracy: 0.0391 - val_loss: 5.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1710 - accuracy: 0.0391 - val_loss: 5.5429 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2151 - accuracy: 0.0312 - val_loss: 5.5662 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.3288 - accuracy: 0.0234 - val_loss: 5.5843 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3089 - accuracy: 0.0312 - val_loss: 5.5888 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.3041 - accuracy: 0.0312 - val_loss: 5.5924 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 5.3392 - accuracy: 0.0312 - val_loss: 5.5952 - val_accuracy: 0.0078\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2573 - accuracy: 0.0234 - val_loss: 5.5952 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.1839 - accuracy: 0.0625 - val_loss: 5.5968 - val_accuracy: 0.0078\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.2957 - accuracy: 0.0078 - val_loss: 5.6003 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.2181 - accuracy: 0.0312 - val_loss: 5.6194 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.2978 - accuracy: 0.0156 - val_loss: 5.6438 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.2070 - accuracy: 0.0312 - val_loss: 5.6655 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.2530 - accuracy: 0.0234 - val_loss: 5.6867 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.2688 - accuracy: 0.0312 - val_loss: 5.6726 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.3768 - accuracy: 0.0234 - val_loss: 5.6716 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1504 - accuracy: 0.0547 - val_loss: 5.6743 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1571 - accuracy: 0.0156 - val_loss: 5.6646 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0477 - accuracy: 0.0312 - val_loss: 5.6106 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1746 - accuracy: 0.0234 - val_loss: 5.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.1515 - accuracy: 0.0312 - val_loss: 5.4201 - val_accuracy: 0.0078\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.2750 - accuracy: 0.0078 - val_loss: 5.4528 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0641 - accuracy: 0.0156 - val_loss: 5.5232 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0878 - accuracy: 0.0312 - val_loss: 5.5628 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9655 - accuracy: 0.0781 - val_loss: 5.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0987 - accuracy: 0.0391 - val_loss: 5.5644 - val_accuracy: 0.0078\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.1290 - accuracy: 0.0156 - val_loss: 5.5726 - val_accuracy: 0.0078\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 5.0016 - accuracy: 0.0469 - val_loss: 5.5628 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 5.1766 - accuracy: 0.0078 - val_loss: 5.6319 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8883 - accuracy: 0.0469 - val_loss: 5.6274 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0363 - accuracy: 0.0391 - val_loss: 5.6087 - val_accuracy: 0.0078\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.0125 - accuracy: 0.0078 - val_loss: 5.6892 - val_accuracy: 0.0078\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.1877 - accuracy: 0.0156 - val_loss: 5.6077 - val_accuracy: 0.0078\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9427 - accuracy: 0.0391 - val_loss: 5.5206 - val_accuracy: 0.0078\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9875 - accuracy: 0.0547 - val_loss: 5.7494 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.9916 - accuracy: 0.0469 - val_loss: 6.0610 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8206 - accuracy: 0.0469 - val_loss: 6.1559 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0733 - accuracy: 0.0234 - val_loss: 6.1279 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0227 - accuracy: 0.0391 - val_loss: 6.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7905 - accuracy: 0.0703 - val_loss: 6.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.1186 - accuracy: 0.0156 - val_loss: 5.9876 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0456 - accuracy: 0.0391 - val_loss: 5.6415 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6711 - accuracy: 0.0703 - val_loss: 5.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.0262 - accuracy: 0.0391 - val_loss: 5.2062 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1092 - accuracy: 0.0391 - val_loss: 5.2103 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8549 - accuracy: 0.0391 - val_loss: 5.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1523 - accuracy: 0.0234 - val_loss: 5.1771 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.9355 - accuracy: 0.0156 - val_loss: 5.2492 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.1908 - accuracy: 0.0391 - val_loss: 5.2546 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9312 - accuracy: 0.0156 - val_loss: 5.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.8244 - accuracy: 0.0078 - val_loss: 5.1465 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 88ms/step - loss: 4.8057 - accuracy: 0.0547 - val_loss: 5.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9909 - accuracy: 0.0234 - val_loss: 4.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.8029 - accuracy: 0.0703 - val_loss: 4.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7561 - accuracy: 0.0781 - val_loss: 4.9471 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8161 - accuracy: 0.0312 - val_loss: 4.9469 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9517 - accuracy: 0.0391 - val_loss: 4.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.1062 - accuracy: 0.0234 - val_loss: 4.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7950 - accuracy: 0.0547 - val_loss: 4.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9273 - accuracy: 0.0312 - val_loss: 4.9321 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.9153 - accuracy: 0.0391 - val_loss: 4.8892 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.8646 - accuracy: 0.0156 - val_loss: 4.8849 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8254 - accuracy: 0.0391 - val_loss: 4.8169 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.7532 - accuracy: 0.0312 - val_loss: 4.7621 - val_accuracy: 0.0156\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.9288 - accuracy: 0.0625 - val_loss: 4.7109 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8823 - accuracy: 0.0391 - val_loss: 4.7339 - val_accuracy: 0.0078\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7260 - accuracy: 0.0547 - val_loss: 4.8122 - val_accuracy: 0.0078\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8579 - accuracy: 0.0234 - val_loss: 4.9123 - val_accuracy: 0.0078\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.8122 - accuracy: 0.0547 - val_loss: 5.0078 - val_accuracy: 0.0078\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7837 - accuracy: 0.0234 - val_loss: 5.1132 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8779 - accuracy: 0.0391 - val_loss: 5.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 4.6833 - accuracy: 0.0625 - val_loss: 5.4368 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.0020 - accuracy: 0.0156 - val_loss: 5.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8065 - accuracy: 0.0234 - val_loss: 5.3830 - val_accuracy: 0.0078\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0443 - accuracy: 0.0156 - val_loss: 5.3792 - val_accuracy: 0.0078\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7134 - accuracy: 0.0234 - val_loss: 5.3555 - val_accuracy: 0.0078\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8273 - accuracy: 0.0469 - val_loss: 5.3414 - val_accuracy: 0.0078\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9727 - accuracy: 0.0078 - val_loss: 5.2507 - val_accuracy: 0.0078\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8595 - accuracy: 0.0312 - val_loss: 5.1790 - val_accuracy: 0.0078\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7216 - accuracy: 0.0391 - val_loss: 5.1139 - val_accuracy: 0.0078\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8413 - accuracy: 0.0156 - val_loss: 5.0910 - val_accuracy: 0.0078\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9304 - accuracy: 0.0156 - val_loss: 5.0421 - val_accuracy: 0.0078\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9488 - accuracy: 0.0469 - val_loss: 5.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9216 - accuracy: 0.0156 - val_loss: 5.0527 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9673 - accuracy: 0.0234 - val_loss: 5.0964 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7007 - accuracy: 0.0078 - val_loss: 5.1171 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9802 - accuracy: 0.0312 - val_loss: 5.0883 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6273 - accuracy: 0.0312 - val_loss: 5.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.9980 - accuracy: 0.0156 - val_loss: 5.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9954 - accuracy: 0.0000e+00 - val_loss: 5.1015 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8652 - accuracy: 0.0234 - val_loss: 5.0348 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7229 - accuracy: 0.0391 - val_loss: 5.0177 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5771 - accuracy: 0.0234 - val_loss: 5.0528 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0524 - accuracy: 0.0156 - val_loss: 5.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9340 - accuracy: 0.0234 - val_loss: 5.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5928 - accuracy: 0.0312 - val_loss: 5.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.6855 - accuracy: 0.0547 - val_loss: 5.0277 - val_accuracy: 0.0078\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7182 - accuracy: 0.0703 - val_loss: 4.9051 - val_accuracy: 0.0078\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8374 - accuracy: 0.0156 - val_loss: 4.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6311 - accuracy: 0.0469 - val_loss: 4.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.5886 - accuracy: 0.0547 - val_loss: 4.7257 - val_accuracy: 0.0078\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7201 - accuracy: 0.0234 - val_loss: 4.7743 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5252 - accuracy: 0.0625 - val_loss: 4.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5438 - accuracy: 0.0703 - val_loss: 4.9782 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7322 - accuracy: 0.0234 - val_loss: 5.0268 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.8939 - accuracy: 0.0234 - val_loss: 5.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 4.8780 - accuracy: 0.0078 - val_loss: 4.9820 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7272 - accuracy: 0.0312 - val_loss: 4.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.7982 - accuracy: 0.0234 - val_loss: 4.8548 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8040 - accuracy: 0.0312 - val_loss: 4.7733 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8961 - accuracy: 0.0312 - val_loss: 4.7144 - val_accuracy: 0.0078\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.5996 - accuracy: 0.1016 - val_loss: 4.6488 - val_accuracy: 0.0156\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5581 - accuracy: 0.0781 - val_loss: 4.5318 - val_accuracy: 0.0156\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.4187 - accuracy: 0.0938 - val_loss: 4.5036 - val_accuracy: 0.0078\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0514 - accuracy: 0.0000e+00 - val_loss: 4.5247 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.8088 - accuracy: 0.0000e+00 - val_loss: 4.5079 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7519 - accuracy: 0.0156 - val_loss: 4.4358 - val_accuracy: 0.0078\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.8244 - accuracy: 0.0156 - val_loss: 4.4269 - val_accuracy: 0.0469\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.6965 - accuracy: 0.0078 - val_loss: 4.6159 - val_accuracy: 0.0312\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6299 - accuracy: 0.0312 - val_loss: 4.9723 - val_accuracy: 0.0078\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.5587 - accuracy: 0.0469 - val_loss: 5.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7952 - accuracy: 0.0156 - val_loss: 5.5734 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7576 - accuracy: 0.0312 - val_loss: 5.4406 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5849 - accuracy: 0.0781 - val_loss: 5.3016 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6593 - accuracy: 0.0078 - val_loss: 5.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7722 - accuracy: 0.0156 - val_loss: 5.1592 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.5757 - accuracy: 0.0547 - val_loss: 5.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.4134 - accuracy: 0.0703 - val_loss: 5.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5556 - accuracy: 0.0703 - val_loss: 5.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6578 - accuracy: 0.0312 - val_loss: 5.2205 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5620 - accuracy: 0.0391 - val_loss: 5.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.8416 - accuracy: 0.0547 - val_loss: 5.0609 - val_accuracy: 0.0078\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7413 - accuracy: 0.0156 - val_loss: 4.9368 - val_accuracy: 0.0156\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6308 - accuracy: 0.0469 - val_loss: 4.7814 - val_accuracy: 0.0938\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7956 - accuracy: 0.0234 - val_loss: 4.7141 - val_accuracy: 0.1172\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8530 - accuracy: 0.0469 - val_loss: 4.7470 - val_accuracy: 0.0312\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.7419 - accuracy: 0.0312 - val_loss: 4.8147 - val_accuracy: 0.0156\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7657 - accuracy: 0.0312 - val_loss: 4.8748 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5461 - accuracy: 0.0938 - val_loss: 4.7829 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8029 - accuracy: 0.0078 - val_loss: 4.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.5392 - accuracy: 0.0391 - val_loss: 4.6492 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6997 - accuracy: 0.0781 - val_loss: 4.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.5401 - accuracy: 0.0703 - val_loss: 4.7393 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8611 - accuracy: 0.0469 - val_loss: 4.8173 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.4915 - accuracy: 0.0781 - val_loss: 4.8731 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.6339 - accuracy: 0.0625 - val_loss: 4.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6594 - accuracy: 0.0000e+00 - val_loss: 4.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8977 - accuracy: 0.0391 - val_loss: 4.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7180 - accuracy: 0.0469 - val_loss: 5.1167 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7487 - accuracy: 0.0234 - val_loss: 4.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5765 - accuracy: 0.0625 - val_loss: 4.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 4.4893 - accuracy: 0.0703 - val_loss: 4.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7668 - accuracy: 0.0391 - val_loss: 4.7388 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8409 - accuracy: 0.0312 - val_loss: 4.8263 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6097 - accuracy: 0.0469 - val_loss: 5.0884 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.5278 - accuracy: 0.0547 - val_loss: 5.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7659 - accuracy: 0.0312 - val_loss: 5.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5863 - accuracy: 0.0469 - val_loss: 4.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5343 - accuracy: 0.0234 - val_loss: 4.8965 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4839 - accuracy: 0.0938 - val_loss: 4.7841 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5599 - accuracy: 0.0234 - val_loss: 4.7376 - val_accuracy: 0.0078\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.4400 - accuracy: 0.1328 - val_loss: 5.1711 - val_accuracy: 0.0234\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7382 - accuracy: 0.0234 - val_loss: 5.1042 - val_accuracy: 0.0234\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.7338 - accuracy: 0.0156 - val_loss: 4.7528 - val_accuracy: 0.0547\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8157 - accuracy: 0.0234 - val_loss: 4.6093 - val_accuracy: 0.0469\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7079 - accuracy: 0.0312 - val_loss: 4.6977 - val_accuracy: 0.0391\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.6849 - accuracy: 0.0156 - val_loss: 5.0075 - val_accuracy: 0.0469\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6747 - accuracy: 0.0391 - val_loss: 5.2155 - val_accuracy: 0.0547\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.3361 - accuracy: 0.0625 - val_loss: 4.6135 - val_accuracy: 0.1094\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.6869 - accuracy: 0.0312 - val_loss: 4.3992 - val_accuracy: 0.1641\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6162 - accuracy: 0.0391 - val_loss: 4.5217 - val_accuracy: 0.1641\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5627 - accuracy: 0.0391 - val_loss: 4.4703 - val_accuracy: 0.1484\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.1924 - accuracy: 0.0234 - val_loss: 4.4099 - val_accuracy: 0.0703\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.4721 - accuracy: 0.0312 - val_loss: 4.4893 - val_accuracy: 0.0469\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4817 - accuracy: 0.0625 - val_loss: 4.5649 - val_accuracy: 0.0469\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3128 - accuracy: 0.1016 - val_loss: 4.4936 - val_accuracy: 0.0234\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6084 - accuracy: 0.0625 - val_loss: 4.5026 - val_accuracy: 0.0234\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3759 - accuracy: 0.0469 - val_loss: 4.7529 - val_accuracy: 0.0078\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7375 - accuracy: 0.0156 - val_loss: 4.8135 - val_accuracy: 0.0078\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.7022 - accuracy: 0.0156 - val_loss: 4.6428 - val_accuracy: 0.0078\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5432 - accuracy: 0.0391 - val_loss: 4.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.1002 - accuracy: 0.1406 - val_loss: 4.3917 - val_accuracy: 0.0234\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6784 - accuracy: 0.0078 - val_loss: 4.3856 - val_accuracy: 0.1016\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 4.7358 - accuracy: 0.0078 - val_loss: 4.3877 - val_accuracy: 0.0938\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.7726 - accuracy: 0.0234 - val_loss: 4.2953 - val_accuracy: 0.1328\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.4227 - accuracy: 0.0859 - val_loss: 4.1530 - val_accuracy: 0.1484\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.4692 - accuracy: 0.0469 - val_loss: 4.1694 - val_accuracy: 0.1172\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.4215 - accuracy: 0.0625 - val_loss: 4.2451 - val_accuracy: 0.0938\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6851 - accuracy: 0.0469 - val_loss: 4.2881 - val_accuracy: 0.1016\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6137 - accuracy: 0.0469 - val_loss: 4.3074 - val_accuracy: 0.0625\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.5013 - accuracy: 0.0703 - val_loss: 4.4893 - val_accuracy: 0.0625\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4688 - accuracy: 0.0625 - val_loss: 4.7649 - val_accuracy: 0.0234\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.5159 - accuracy: 0.0625 - val_loss: 4.6751 - val_accuracy: 0.0234\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3374 - accuracy: 0.0547 - val_loss: 4.6377 - val_accuracy: 0.0156\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.1416 - accuracy: 0.0625 - val_loss: 4.4186 - val_accuracy: 0.0078\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3845 - accuracy: 0.0156 - val_loss: 4.3623 - val_accuracy: 0.0078\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.2707 - accuracy: 0.0312 - val_loss: 4.3839 - val_accuracy: 0.0078\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6129 - accuracy: 0.0391 - val_loss: 4.4263 - val_accuracy: 0.0156\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.0482 - accuracy: 0.0781 - val_loss: 4.5609 - val_accuracy: 0.0156\n",
      "Epoch 207/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.4923 - accuracy: 0.0547 - val_loss: 4.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.1587 - accuracy: 0.0781 - val_loss: 4.4224 - val_accuracy: 0.0078\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.2573 - accuracy: 0.0938 - val_loss: 4.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3350 - accuracy: 0.0703 - val_loss: 4.4066 - val_accuracy: 0.0312\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3944 - accuracy: 0.1406 - val_loss: 4.4354 - val_accuracy: 0.0234\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3709 - accuracy: 0.0312 - val_loss: 4.4919 - val_accuracy: 0.0312\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.4758 - accuracy: 0.0469 - val_loss: 4.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3227 - accuracy: 0.0547 - val_loss: 4.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.2896 - accuracy: 0.0547 - val_loss: 4.5900 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.2932 - accuracy: 0.0859 - val_loss: 4.7326 - val_accuracy: 0.0078\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.1848 - accuracy: 0.1250 - val_loss: 4.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.3972 - accuracy: 0.0859 - val_loss: 4.4146 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9805 - accuracy: 0.1172 - val_loss: 4.1770 - val_accuracy: 0.0234\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.2833 - accuracy: 0.0625 - val_loss: 4.0900 - val_accuracy: 0.0234\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5740 - accuracy: 0.0625 - val_loss: 4.1759 - val_accuracy: 0.0469\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.0933 - accuracy: 0.0703 - val_loss: 4.0287 - val_accuracy: 0.0469\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4436 - accuracy: 0.0547 - val_loss: 3.9702 - val_accuracy: 0.0547\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.1393 - accuracy: 0.0938 - val_loss: 3.8765 - val_accuracy: 0.1328\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3640 - accuracy: 0.0625 - val_loss: 4.0541 - val_accuracy: 0.1016\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3916 - accuracy: 0.0703 - val_loss: 4.4433 - val_accuracy: 0.0312\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.3467 - accuracy: 0.0938 - val_loss: 4.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.2352 - accuracy: 0.0547 - val_loss: 4.6500 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.0934 - accuracy: 0.0703 - val_loss: 4.6170 - val_accuracy: 0.0078\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.9740 - accuracy: 0.1484 - val_loss: 5.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3375 - accuracy: 0.0078 - val_loss: 5.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0297 - accuracy: 0.1172 - val_loss: 5.6775 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.1395 - accuracy: 0.1016 - val_loss: 6.2784 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 4.2416 - accuracy: 0.1094 - val_loss: 6.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2528 - accuracy: 0.0859 - val_loss: 6.2345 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.0729 - accuracy: 0.0703 - val_loss: 5.7637 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.2272 - accuracy: 0.0469 - val_loss: 5.3491 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.0639 - accuracy: 0.0703 - val_loss: 4.6680 - val_accuracy: 0.0078\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.3597 - accuracy: 0.0625 - val_loss: 4.9892 - val_accuracy: 0.0312\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0492 - accuracy: 0.1328 - val_loss: 4.3901 - val_accuracy: 0.0469\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3093 - accuracy: 0.0781 - val_loss: 4.2419 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.1981 - accuracy: 0.0625 - val_loss: 4.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1585 - accuracy: 0.0781 - val_loss: 4.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.2222 - accuracy: 0.0625 - val_loss: 4.9713 - val_accuracy: 0.0078\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.2451 - accuracy: 0.0391 - val_loss: 4.8417 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.1234 - accuracy: 0.1172 - val_loss: 4.9672 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.0613 - accuracy: 0.1016 - val_loss: 5.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.1198 - accuracy: 0.1094 - val_loss: 5.0143 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.9419 - accuracy: 0.0938 - val_loss: 4.3345 - val_accuracy: 0.0078\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.9909 - accuracy: 0.1328 - val_loss: 4.0700 - val_accuracy: 0.0156\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.2626 - accuracy: 0.1016 - val_loss: 4.1612 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.3022 - accuracy: 0.0156 - val_loss: 4.1360 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.9783 - accuracy: 0.0703 - val_loss: 4.3099 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.6597 - accuracy: 0.1875 - val_loss: 4.7201 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.0709 - accuracy: 0.1172 - val_loss: 5.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.1519 - accuracy: 0.0547 - val_loss: 5.0564 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.1122 - accuracy: 0.1094 - val_loss: 4.6973 - val_accuracy: 0.0156\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.1651 - accuracy: 0.0391 - val_loss: 4.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0727 - accuracy: 0.0781 - val_loss: 4.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.1986 - accuracy: 0.0938 - val_loss: 4.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.8640 - accuracy: 0.0938 - val_loss: 4.9260 - val_accuracy: 0.0078\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.4357 - accuracy: 0.0312 - val_loss: 4.8917 - val_accuracy: 0.0156\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.8510 - accuracy: 0.0781 - val_loss: 4.8575 - val_accuracy: 0.0156\n",
      "Epoch 264/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.8424 - accuracy: 0.1250 - val_loss: 5.0253 - val_accuracy: 0.0078\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.9159 - accuracy: 0.1250 - val_loss: 5.1389 - val_accuracy: 0.0078\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0673 - accuracy: 0.1016 - val_loss: 4.9503 - val_accuracy: 0.0078\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.9573 - accuracy: 0.1250 - val_loss: 4.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.9576 - accuracy: 0.0938 - val_loss: 4.7375 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.1022 - accuracy: 0.1172 - val_loss: 4.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.0687 - accuracy: 0.0703 - val_loss: 4.4960 - val_accuracy: 0.0078\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.9105 - accuracy: 0.1484 - val_loss: 4.6566 - val_accuracy: 0.0078\n",
      "Epoch 272/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step - loss: 4.2020 - accuracy: 0.0859 - val_loss: 4.8799 - val_accuracy: 0.0156\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.7344 - accuracy: 0.1484 - val_loss: 5.0462 - val_accuracy: 0.0156\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.0058 - accuracy: 0.0547 - val_loss: 5.0337 - val_accuracy: 0.0078\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.0793 - accuracy: 0.0938 - val_loss: 4.6022 - val_accuracy: 0.0078\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.2250 - accuracy: 0.0859 - val_loss: 4.2208 - val_accuracy: 0.0156\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.8117 - accuracy: 0.1719 - val_loss: 4.1063 - val_accuracy: 0.0156\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.8360 - accuracy: 0.0859 - val_loss: 4.3103 - val_accuracy: 0.0234\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.9492 - accuracy: 0.0781 - val_loss: 4.6513 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0848 - accuracy: 0.0312 - val_loss: 4.9854 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.0476 - accuracy: 0.1016 - val_loss: 4.9786 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.9704 - accuracy: 0.0859 - val_loss: 4.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.8188 - accuracy: 0.0938 - val_loss: 4.4203 - val_accuracy: 0.0312\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.9757 - accuracy: 0.1328 - val_loss: 4.1424 - val_accuracy: 0.0781\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.7521 - accuracy: 0.0859 - val_loss: 4.1016 - val_accuracy: 0.0703\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.0614 - accuracy: 0.0938 - val_loss: 4.3130 - val_accuracy: 0.0312\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.0408 - accuracy: 0.1250 - val_loss: 4.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7770 - accuracy: 0.1406 - val_loss: 4.2527 - val_accuracy: 0.0625\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.9051 - accuracy: 0.1328 - val_loss: 3.8537 - val_accuracy: 0.1484\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.7713 - accuracy: 0.0938 - val_loss: 3.7067 - val_accuracy: 0.2188\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.5115 - accuracy: 0.2344 - val_loss: 3.5599 - val_accuracy: 0.2109\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0592 - accuracy: 0.0938 - val_loss: 3.4131 - val_accuracy: 0.2422\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.1409 - accuracy: 0.1094 - val_loss: 3.4964 - val_accuracy: 0.2188\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.8994 - accuracy: 0.0859 - val_loss: 3.7967 - val_accuracy: 0.1328\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.0318 - accuracy: 0.0938 - val_loss: 3.8157 - val_accuracy: 0.0859\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.1167 - accuracy: 0.0703 - val_loss: 3.7859 - val_accuracy: 0.0391\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2132 - accuracy: 0.0547 - val_loss: 3.6688 - val_accuracy: 0.0703\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.6806 - accuracy: 0.1797 - val_loss: 3.7707 - val_accuracy: 0.0547\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.8987 - accuracy: 0.0781 - val_loss: 4.0870 - val_accuracy: 0.0078\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.8096 - accuracy: 0.1250 - val_loss: 4.2553 - val_accuracy: 0.0078\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.9227 - accuracy: 0.1719 - val_loss: 4.2724 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.8551 - accuracy: 0.1953 - val_loss: 4.5502 - val_accuracy: 0.0156\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.7054 - accuracy: 0.1797 - val_loss: 4.5892 - val_accuracy: 0.0234\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9259 - accuracy: 0.1172 - val_loss: 4.1810 - val_accuracy: 0.0234\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.6622 - accuracy: 0.0625 - val_loss: 3.9752 - val_accuracy: 0.0391\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.1921 - accuracy: 0.0859 - val_loss: 3.9954 - val_accuracy: 0.0469\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6754 - accuracy: 0.1328 - val_loss: 4.1722 - val_accuracy: 0.0312\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.8039 - accuracy: 0.0391 - val_loss: 4.1831 - val_accuracy: 0.0312\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5914 - accuracy: 0.1406 - val_loss: 4.0257 - val_accuracy: 0.0234\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.7923 - accuracy: 0.1250 - val_loss: 4.0766 - val_accuracy: 0.0234\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.6817 - accuracy: 0.1172 - val_loss: 4.1229 - val_accuracy: 0.0078\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.6847 - accuracy: 0.1172 - val_loss: 3.9793 - val_accuracy: 0.0234\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.5694 - accuracy: 0.1250 - val_loss: 3.9068 - val_accuracy: 0.0391\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.8509 - accuracy: 0.1016 - val_loss: 3.9184 - val_accuracy: 0.0547\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.7265 - accuracy: 0.1328 - val_loss: 3.9044 - val_accuracy: 0.0469\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 92ms/step - loss: 3.9562 - accuracy: 0.0703 - val_loss: 3.8274 - val_accuracy: 0.0391\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.7446 - accuracy: 0.1484 - val_loss: 3.8094 - val_accuracy: 0.0234\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.0058 - accuracy: 0.0859 - val_loss: 3.8760 - val_accuracy: 0.0312\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.8298 - accuracy: 0.0938 - val_loss: 4.0913 - val_accuracy: 0.0391\n",
      "Epoch 320/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.6611 - accuracy: 0.1328 - val_loss: 4.0858 - val_accuracy: 0.0391\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.6969 - accuracy: 0.0859 - val_loss: 4.2397 - val_accuracy: 0.0312\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.6501 - accuracy: 0.1016 - val_loss: 4.3250 - val_accuracy: 0.0234\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.5531 - accuracy: 0.1250 - val_loss: 4.0962 - val_accuracy: 0.0547\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.7486 - accuracy: 0.1875 - val_loss: 3.5955 - val_accuracy: 0.2188\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8411 - accuracy: 0.0703 - val_loss: 3.4020 - val_accuracy: 0.2266\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.8236 - accuracy: 0.1172 - val_loss: 3.5222 - val_accuracy: 0.2031\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4686 - accuracy: 0.2031 - val_loss: 3.7011 - val_accuracy: 0.1484\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.9553 - accuracy: 0.0547 - val_loss: 3.7390 - val_accuracy: 0.1016\n",
      "Epoch 329/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7626 - accuracy: 0.1016 - val_loss: 3.9244 - val_accuracy: 0.1094\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.7426 - accuracy: 0.1328 - val_loss: 4.0757 - val_accuracy: 0.0859\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.9287 - accuracy: 0.0938 - val_loss: 4.1690 - val_accuracy: 0.0859\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.8885 - accuracy: 0.0703 - val_loss: 4.1103 - val_accuracy: 0.0547\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.6691 - accuracy: 0.1328 - val_loss: 3.8812 - val_accuracy: 0.0938\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.7336 - accuracy: 0.0859 - val_loss: 3.4962 - val_accuracy: 0.2344\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.7209 - accuracy: 0.0859 - val_loss: 3.5632 - val_accuracy: 0.2031\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.4938 - accuracy: 0.1641 - val_loss: 4.0146 - val_accuracy: 0.1172\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8233 - accuracy: 0.0469 - val_loss: 4.3657 - val_accuracy: 0.0469\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.9945 - accuracy: 0.1016 - val_loss: 4.5139 - val_accuracy: 0.0469\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.6969 - accuracy: 0.1328 - val_loss: 4.5973 - val_accuracy: 0.0391\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.6563 - accuracy: 0.0859 - val_loss: 4.5357 - val_accuracy: 0.0469\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.8824 - accuracy: 0.0938 - val_loss: 4.2312 - val_accuracy: 0.0938\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.6654 - accuracy: 0.1250 - val_loss: 3.9959 - val_accuracy: 0.1016\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.7118 - accuracy: 0.1406 - val_loss: 4.0201 - val_accuracy: 0.0703\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.4002 - accuracy: 0.2344 - val_loss: 4.2918 - val_accuracy: 0.0703\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.7204 - accuracy: 0.0703 - val_loss: 4.3866 - val_accuracy: 0.0469\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.6291 - accuracy: 0.1953 - val_loss: 4.2199 - val_accuracy: 0.0312\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.8486 - accuracy: 0.0859 - val_loss: 4.0330 - val_accuracy: 0.0078\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.5092 - accuracy: 0.1875 - val_loss: 4.2551 - val_accuracy: 0.0078\n",
      "Epoch 349/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.8504 - accuracy: 0.0781 - val_loss: 4.4118 - val_accuracy: 0.0078\n",
      "Epoch 350/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.9548 - accuracy: 0.0547 - val_loss: 4.2970 - val_accuracy: 0.0156\n",
      "Epoch 351/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.7076 - accuracy: 0.0938 - val_loss: 4.2121 - val_accuracy: 0.0078\n",
      "Epoch 352/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4458 - accuracy: 0.1953 - val_loss: 4.1765 - val_accuracy: 0.0078\n",
      "Epoch 353/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7907 - accuracy: 0.0859 - val_loss: 4.0197 - val_accuracy: 0.0078\n",
      "Epoch 354/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.2706 - accuracy: 0.1875 - val_loss: 3.7786 - val_accuracy: 0.0781\n",
      "Epoch 355/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5421 - accuracy: 0.0781 - val_loss: 3.7971 - val_accuracy: 0.1250\n",
      "Epoch 356/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.4063 - accuracy: 0.1328 - val_loss: 3.6825 - val_accuracy: 0.1406\n",
      "Epoch 357/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.0241 - accuracy: 0.0938 - val_loss: 3.4079 - val_accuracy: 0.1641\n",
      "Epoch 358/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.6549 - accuracy: 0.0781 - val_loss: 3.4113 - val_accuracy: 0.0938\n",
      "Epoch 359/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4818 - accuracy: 0.1562 - val_loss: 3.5408 - val_accuracy: 0.0859\n",
      "Epoch 360/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.6515 - accuracy: 0.1172 - val_loss: 3.6125 - val_accuracy: 0.0781\n",
      "Epoch 361/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.6736 - accuracy: 0.1562 - val_loss: 3.7948 - val_accuracy: 0.0625\n",
      "Epoch 362/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3123 - accuracy: 0.1875 - val_loss: 4.1855 - val_accuracy: 0.0781\n",
      "Epoch 363/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.7621 - accuracy: 0.1016 - val_loss: 4.8051 - val_accuracy: 0.0859\n",
      "Epoch 364/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5703 - accuracy: 0.1406 - val_loss: 4.3776 - val_accuracy: 0.2188\n",
      "Epoch 365/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.6331 - accuracy: 0.1484 - val_loss: 3.6638 - val_accuracy: 0.2188\n",
      "Epoch 366/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.3956 - accuracy: 0.1484 - val_loss: 3.8840 - val_accuracy: 0.1328\n",
      "Epoch 367/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3712 - accuracy: 0.1016 - val_loss: 4.5717 - val_accuracy: 0.0312\n",
      "Epoch 368/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3516 - accuracy: 0.1797 - val_loss: 4.0984 - val_accuracy: 0.1016\n",
      "Epoch 369/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.4184 - accuracy: 0.1953 - val_loss: 3.6355 - val_accuracy: 0.1406\n",
      "Epoch 370/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2194 - accuracy: 0.2109 - val_loss: 3.4439 - val_accuracy: 0.1016\n",
      "Epoch 371/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.4626 - accuracy: 0.1328 - val_loss: 3.4833 - val_accuracy: 0.0703\n",
      "Epoch 372/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.4925 - accuracy: 0.1953 - val_loss: 3.5710 - val_accuracy: 0.0391\n",
      "Epoch 373/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4882 - accuracy: 0.1875 - val_loss: 4.0683 - val_accuracy: 0.0078\n",
      "Epoch 374/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.6476 - accuracy: 0.1250 - val_loss: 4.3570 - val_accuracy: 0.0078\n",
      "Epoch 375/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4086 - accuracy: 0.1406 - val_loss: 4.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.8127 - accuracy: 0.0859 - val_loss: 3.8063 - val_accuracy: 0.0156\n",
      "Epoch 377/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.8531 - accuracy: 0.0859 - val_loss: 4.0068 - val_accuracy: 0.0078\n",
      "Epoch 378/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.5984 - accuracy: 0.0938 - val_loss: 4.1940 - val_accuracy: 0.0156\n",
      "Epoch 379/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.7805 - accuracy: 0.0938 - val_loss: 4.3443 - val_accuracy: 0.0078\n",
      "Epoch 380/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4487 - accuracy: 0.1875 - val_loss: 4.4239 - val_accuracy: 0.0234\n",
      "Epoch 381/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7588 - accuracy: 0.1094 - val_loss: 3.9228 - val_accuracy: 0.0469\n",
      "Epoch 382/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.5698 - accuracy: 0.1797 - val_loss: 3.7060 - val_accuracy: 0.1094\n",
      "Epoch 383/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.5700 - accuracy: 0.0703 - val_loss: 3.6399 - val_accuracy: 0.1484\n",
      "Epoch 384/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.3982 - accuracy: 0.1562 - val_loss: 3.6096 - val_accuracy: 0.1641\n",
      "Epoch 385/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.7851 - accuracy: 0.0938 - val_loss: 3.7801 - val_accuracy: 0.0781\n",
      "Epoch 386/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5953 - accuracy: 0.1250 - val_loss: 3.5761 - val_accuracy: 0.0938\n",
      "Epoch 387/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3750 - accuracy: 0.1797 - val_loss: 3.4250 - val_accuracy: 0.1406\n",
      "Epoch 388/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5973 - accuracy: 0.1328 - val_loss: 3.2997 - val_accuracy: 0.2266\n",
      "Epoch 389/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.3241 - accuracy: 0.1875 - val_loss: 3.2168 - val_accuracy: 0.2578\n",
      "Epoch 390/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.4558 - accuracy: 0.1641 - val_loss: 3.0381 - val_accuracy: 0.2734\n",
      "Epoch 391/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.3841 - accuracy: 0.1250 - val_loss: 2.9320 - val_accuracy: 0.3828\n",
      "Epoch 392/5000\n",
      "4/4 [==============================] - 0s 89ms/step - loss: 3.5710 - accuracy: 0.0938 - val_loss: 3.1354 - val_accuracy: 0.2656\n",
      "Epoch 393/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.5224 - accuracy: 0.1250 - val_loss: 3.1760 - val_accuracy: 0.2266\n",
      "Epoch 394/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.1209 - accuracy: 0.1641 - val_loss: 3.1812 - val_accuracy: 0.1953\n",
      "Epoch 395/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4921 - accuracy: 0.1016 - val_loss: 3.3859 - val_accuracy: 0.1719\n",
      "Epoch 396/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3755 - accuracy: 0.1406 - val_loss: 3.4007 - val_accuracy: 0.1406\n",
      "Epoch 397/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5407 - accuracy: 0.1406 - val_loss: 3.2029 - val_accuracy: 0.2734\n",
      "Epoch 398/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.6840 - accuracy: 0.1328 - val_loss: 3.1697 - val_accuracy: 0.2734\n",
      "Epoch 399/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3680 - accuracy: 0.1250 - val_loss: 3.2004 - val_accuracy: 0.2422\n",
      "Epoch 400/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.2875 - accuracy: 0.2422 - val_loss: 3.3256 - val_accuracy: 0.1953\n",
      "Epoch 401/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.6205 - accuracy: 0.1406 - val_loss: 3.3354 - val_accuracy: 0.2109\n",
      "Epoch 402/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.0337 - accuracy: 0.2812 - val_loss: 3.3552 - val_accuracy: 0.1875\n",
      "Epoch 403/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 3.3291 - accuracy: 0.1406 - val_loss: 3.3969 - val_accuracy: 0.1172\n",
      "Epoch 404/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.3578 - accuracy: 0.1484 - val_loss: 3.2334 - val_accuracy: 0.2266\n",
      "Epoch 405/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.5831 - accuracy: 0.2031 - val_loss: 3.3013 - val_accuracy: 0.2422\n",
      "Epoch 406/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.5460 - accuracy: 0.1641 - val_loss: 3.3199 - val_accuracy: 0.2422\n",
      "Epoch 407/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.6339 - accuracy: 0.0938 - val_loss: 3.5493 - val_accuracy: 0.2188\n",
      "Epoch 408/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.4665 - accuracy: 0.1172 - val_loss: 4.0639 - val_accuracy: 0.1250\n",
      "Epoch 409/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.5658 - accuracy: 0.1250 - val_loss: 4.2322 - val_accuracy: 0.1172\n",
      "Epoch 410/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.5206 - accuracy: 0.1016 - val_loss: 3.5813 - val_accuracy: 0.1719\n",
      "Epoch 411/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4052 - accuracy: 0.1562 - val_loss: 3.3079 - val_accuracy: 0.2188\n",
      "Epoch 412/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.5170 - accuracy: 0.1172 - val_loss: 3.4494 - val_accuracy: 0.1094\n",
      "Epoch 413/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.2187 - accuracy: 0.2031 - val_loss: 3.5623 - val_accuracy: 0.0859\n",
      "Epoch 414/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1405 - accuracy: 0.2266 - val_loss: 3.5440 - val_accuracy: 0.0703\n",
      "Epoch 415/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4703 - accuracy: 0.1719 - val_loss: 3.6947 - val_accuracy: 0.0391\n",
      "Epoch 416/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4172 - accuracy: 0.1797 - val_loss: 3.7520 - val_accuracy: 0.0391\n",
      "Epoch 417/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.1215 - accuracy: 0.2422 - val_loss: 3.8013 - val_accuracy: 0.0391\n",
      "Epoch 418/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3228 - accuracy: 0.1094 - val_loss: 3.7505 - val_accuracy: 0.0781\n",
      "Epoch 419/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4446 - accuracy: 0.1797 - val_loss: 3.6018 - val_accuracy: 0.2266\n",
      "Epoch 420/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2886 - accuracy: 0.1953 - val_loss: 3.4606 - val_accuracy: 0.2422\n",
      "Epoch 421/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3487 - accuracy: 0.1484 - val_loss: 3.3184 - val_accuracy: 0.2578\n",
      "Epoch 422/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.1350 - accuracy: 0.2734 - val_loss: 3.0281 - val_accuracy: 0.2891\n",
      "Epoch 423/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.4389 - accuracy: 0.1406 - val_loss: 2.9328 - val_accuracy: 0.2500\n",
      "Epoch 424/5000\n",
      "4/4 [==============================] - 0s 63ms/step - loss: 3.5627 - accuracy: 0.0938 - val_loss: 2.9549 - val_accuracy: 0.2891\n",
      "Epoch 425/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4069 - accuracy: 0.1641 - val_loss: 3.1282 - val_accuracy: 0.2188\n",
      "Epoch 426/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.6065 - accuracy: 0.0547 - val_loss: 3.2629 - val_accuracy: 0.1797\n",
      "Epoch 427/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2636 - accuracy: 0.1719 - val_loss: 3.3953 - val_accuracy: 0.1406\n",
      "Epoch 428/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.9791 - accuracy: 0.2266 - val_loss: 3.5359 - val_accuracy: 0.0781\n",
      "Epoch 429/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3217 - accuracy: 0.1641 - val_loss: 3.8100 - val_accuracy: 0.0547\n",
      "Epoch 430/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4738 - accuracy: 0.1172 - val_loss: 3.7854 - val_accuracy: 0.0859\n",
      "Epoch 431/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5359 - accuracy: 0.1016 - val_loss: 3.8822 - val_accuracy: 0.0625\n",
      "Epoch 432/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.2762 - accuracy: 0.1406 - val_loss: 4.2374 - val_accuracy: 0.0156\n",
      "Epoch 433/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.6314 - accuracy: 0.1641 - val_loss: 3.9013 - val_accuracy: 0.0391\n",
      "Epoch 434/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.1794 - accuracy: 0.2656 - val_loss: 3.4404 - val_accuracy: 0.0938\n",
      "Epoch 435/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4089 - accuracy: 0.1719 - val_loss: 3.0981 - val_accuracy: 0.2344\n",
      "Epoch 436/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1925 - accuracy: 0.2188 - val_loss: 3.2179 - val_accuracy: 0.2109\n",
      "Epoch 437/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4001 - accuracy: 0.2500 - val_loss: 3.5324 - val_accuracy: 0.1562\n",
      "Epoch 438/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2389 - accuracy: 0.1406 - val_loss: 3.6192 - val_accuracy: 0.1094\n",
      "Epoch 439/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.2793 - accuracy: 0.1484 - val_loss: 3.9405 - val_accuracy: 0.0547\n",
      "Epoch 440/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3991 - accuracy: 0.1875 - val_loss: 3.7044 - val_accuracy: 0.0859\n",
      "Epoch 441/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 3.1553 - accuracy: 0.2344 - val_loss: 3.6438 - val_accuracy: 0.0938\n",
      "Epoch 442/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.4920 - accuracy: 0.0859 - val_loss: 3.4668 - val_accuracy: 0.0547\n",
      "Epoch 443/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 70ms/step - loss: 3.2391 - accuracy: 0.1719 - val_loss: 3.0051 - val_accuracy: 0.1953\n",
      "Epoch 444/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.5541 - accuracy: 0.1406 - val_loss: 2.8837 - val_accuracy: 0.2500\n",
      "Epoch 445/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2767 - accuracy: 0.1406 - val_loss: 2.9191 - val_accuracy: 0.2266\n",
      "Epoch 446/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2929 - accuracy: 0.2500 - val_loss: 2.8821 - val_accuracy: 0.2656\n",
      "Epoch 447/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2893 - accuracy: 0.1172 - val_loss: 3.1652 - val_accuracy: 0.2422\n",
      "Epoch 448/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3089 - accuracy: 0.1328 - val_loss: 3.2360 - val_accuracy: 0.2188\n",
      "Epoch 449/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.5292 - accuracy: 0.1953 - val_loss: 3.2846 - val_accuracy: 0.1719\n",
      "Epoch 450/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.1044 - accuracy: 0.2109 - val_loss: 3.1400 - val_accuracy: 0.2188\n",
      "Epoch 451/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9070 - accuracy: 0.3281 - val_loss: 2.8877 - val_accuracy: 0.2969\n",
      "Epoch 452/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.6801 - accuracy: 0.0859 - val_loss: 2.8580 - val_accuracy: 0.3203\n",
      "Epoch 453/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.1693 - accuracy: 0.1641 - val_loss: 3.1309 - val_accuracy: 0.2422\n",
      "Epoch 454/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.2438 - accuracy: 0.1797 - val_loss: 3.5932 - val_accuracy: 0.1016\n",
      "Epoch 455/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3498 - accuracy: 0.2656 - val_loss: 3.8352 - val_accuracy: 0.0703\n",
      "Epoch 456/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.5336 - accuracy: 0.1641 - val_loss: 3.9794 - val_accuracy: 0.0156\n",
      "Epoch 457/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.7754 - accuracy: 0.0781 - val_loss: 3.9638 - val_accuracy: 0.0234\n",
      "Epoch 458/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.2951 - accuracy: 0.2266 - val_loss: 3.8849 - val_accuracy: 0.0312\n",
      "Epoch 459/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.4533 - accuracy: 0.1484 - val_loss: 3.8147 - val_accuracy: 0.0469\n",
      "Epoch 460/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.7732 - accuracy: 0.2344 - val_loss: 3.4945 - val_accuracy: 0.1016\n",
      "Epoch 461/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3518 - accuracy: 0.2031 - val_loss: 3.3033 - val_accuracy: 0.1484\n",
      "Epoch 462/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3551 - accuracy: 0.1797 - val_loss: 3.3524 - val_accuracy: 0.1328\n",
      "Epoch 463/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.1459 - accuracy: 0.2109 - val_loss: 3.4717 - val_accuracy: 0.1406\n",
      "Epoch 464/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.2096 - accuracy: 0.1797 - val_loss: 3.6459 - val_accuracy: 0.0938\n",
      "Epoch 465/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3628 - accuracy: 0.1562 - val_loss: 3.5853 - val_accuracy: 0.1094\n",
      "Epoch 466/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.3864 - accuracy: 0.1875 - val_loss: 2.9860 - val_accuracy: 0.3125\n",
      "Epoch 467/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.9967 - accuracy: 0.1797 - val_loss: 2.6665 - val_accuracy: 0.3750\n",
      "Epoch 468/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.6791 - accuracy: 0.1016 - val_loss: 2.8097 - val_accuracy: 0.2891\n",
      "Epoch 469/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.8368 - accuracy: 0.3438 - val_loss: 2.9473 - val_accuracy: 0.2578\n",
      "Epoch 470/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1584 - accuracy: 0.2969 - val_loss: 2.9352 - val_accuracy: 0.2734\n",
      "Epoch 471/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.3147 - accuracy: 0.1016 - val_loss: 3.0954 - val_accuracy: 0.2344\n",
      "Epoch 472/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3639 - accuracy: 0.0859 - val_loss: 3.2745 - val_accuracy: 0.1953\n",
      "Epoch 473/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.4685 - accuracy: 0.1641 - val_loss: 3.3621 - val_accuracy: 0.1953\n",
      "Epoch 474/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2939 - accuracy: 0.2422 - val_loss: 3.2431 - val_accuracy: 0.2188\n",
      "Epoch 475/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9851 - accuracy: 0.3438 - val_loss: 3.2792 - val_accuracy: 0.2422\n",
      "Epoch 476/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3759 - accuracy: 0.2109 - val_loss: 3.1599 - val_accuracy: 0.2969\n",
      "Epoch 477/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 3.6028 - accuracy: 0.1016 - val_loss: 3.1222 - val_accuracy: 0.3359\n",
      "Epoch 478/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1712 - accuracy: 0.2031 - val_loss: 3.1830 - val_accuracy: 0.2969\n",
      "Epoch 479/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3072 - accuracy: 0.1641 - val_loss: 3.3358 - val_accuracy: 0.2734\n",
      "Epoch 480/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3784 - accuracy: 0.1328 - val_loss: 3.3430 - val_accuracy: 0.2266\n",
      "Epoch 481/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1788 - accuracy: 0.1562 - val_loss: 3.6528 - val_accuracy: 0.0938\n",
      "Epoch 482/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.2119 - accuracy: 0.2109 - val_loss: 3.0589 - val_accuracy: 0.2812\n",
      "Epoch 483/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.9409 - accuracy: 0.3203 - val_loss: 2.8161 - val_accuracy: 0.3594\n",
      "Epoch 484/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1381 - accuracy: 0.1719 - val_loss: 2.9044 - val_accuracy: 0.3125\n",
      "Epoch 485/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3839 - accuracy: 0.1797 - val_loss: 2.7569 - val_accuracy: 0.3594\n",
      "Epoch 486/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.6342 - accuracy: 0.0781 - val_loss: 2.8315 - val_accuracy: 0.3359\n",
      "Epoch 487/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.3506 - accuracy: 0.2031 - val_loss: 3.1478 - val_accuracy: 0.2422\n",
      "Epoch 488/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3973 - accuracy: 0.1875 - val_loss: 3.2459 - val_accuracy: 0.2266\n",
      "Epoch 489/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.5097 - accuracy: 0.1562 - val_loss: 3.1756 - val_accuracy: 0.1875\n",
      "Epoch 490/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1021 - accuracy: 0.2109 - val_loss: 3.1797 - val_accuracy: 0.2109\n",
      "Epoch 491/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.3306 - accuracy: 0.1562 - val_loss: 3.1179 - val_accuracy: 0.2578\n",
      "Epoch 492/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.9813 - accuracy: 0.2500 - val_loss: 2.8815 - val_accuracy: 0.3594\n",
      "Epoch 493/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.0787 - accuracy: 0.2109 - val_loss: 2.6928 - val_accuracy: 0.4141\n",
      "Epoch 494/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2703 - accuracy: 0.1719 - val_loss: 2.7107 - val_accuracy: 0.4219\n",
      "Epoch 495/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 3.4412 - accuracy: 0.1641 - val_loss: 2.7747 - val_accuracy: 0.3906\n",
      "Epoch 496/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.0812 - accuracy: 0.2031 - val_loss: 2.8385 - val_accuracy: 0.3438\n",
      "Epoch 497/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.9957 - accuracy: 0.2188 - val_loss: 2.8540 - val_accuracy: 0.2969\n",
      "Epoch 498/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.7978 - accuracy: 0.2500 - val_loss: 2.7053 - val_accuracy: 0.3359\n",
      "Epoch 499/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.5165 - accuracy: 0.1484 - val_loss: 2.5772 - val_accuracy: 0.4219\n",
      "Epoch 500/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 78ms/step - loss: 3.2306 - accuracy: 0.1797 - val_loss: 2.6026 - val_accuracy: 0.4141\n",
      "Epoch 501/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2929 - accuracy: 0.1484 - val_loss: 2.7897 - val_accuracy: 0.3203\n",
      "Epoch 502/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1048 - accuracy: 0.1484 - val_loss: 2.9895 - val_accuracy: 0.2500\n",
      "Epoch 503/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.0864 - accuracy: 0.2500 - val_loss: 3.1399 - val_accuracy: 0.2031\n",
      "Epoch 504/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3791 - accuracy: 0.2031 - val_loss: 3.1843 - val_accuracy: 0.1953\n",
      "Epoch 505/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.4288 - accuracy: 0.1562 - val_loss: 3.0936 - val_accuracy: 0.2500\n",
      "Epoch 506/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.3008 - accuracy: 0.1953 - val_loss: 3.1420 - val_accuracy: 0.2109\n",
      "Epoch 507/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.1808 - accuracy: 0.1484 - val_loss: 3.0443 - val_accuracy: 0.2344\n",
      "Epoch 508/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.2281 - accuracy: 0.2109 - val_loss: 3.0537 - val_accuracy: 0.1797\n",
      "Epoch 509/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.1055 - accuracy: 0.2266 - val_loss: 2.9675 - val_accuracy: 0.1328\n",
      "Epoch 510/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2092 - accuracy: 0.1719 - val_loss: 3.0148 - val_accuracy: 0.1094\n",
      "Epoch 511/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.0178 - accuracy: 0.2656 - val_loss: 3.2147 - val_accuracy: 0.1250\n",
      "Epoch 512/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.9282 - accuracy: 0.2109 - val_loss: 3.1558 - val_accuracy: 0.1172\n",
      "Epoch 513/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.2950 - accuracy: 0.1641 - val_loss: 3.0024 - val_accuracy: 0.2578\n",
      "Epoch 514/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0270 - accuracy: 0.2734 - val_loss: 3.1511 - val_accuracy: 0.2422\n",
      "Epoch 515/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.0672 - accuracy: 0.1875 - val_loss: 2.8574 - val_accuracy: 0.2578\n",
      "Epoch 516/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2952 - accuracy: 0.1562 - val_loss: 2.7476 - val_accuracy: 0.2578\n",
      "Epoch 517/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9425 - accuracy: 0.1797 - val_loss: 3.0803 - val_accuracy: 0.1484\n",
      "Epoch 518/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 3.4851 - accuracy: 0.1797 - val_loss: 2.9776 - val_accuracy: 0.1953\n",
      "Epoch 519/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0833 - accuracy: 0.1719 - val_loss: 2.9185 - val_accuracy: 0.2422\n",
      "Epoch 520/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8699 - accuracy: 0.2578 - val_loss: 2.8522 - val_accuracy: 0.2812\n",
      "Epoch 521/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1740 - accuracy: 0.2266 - val_loss: 2.9815 - val_accuracy: 0.2500\n",
      "Epoch 522/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.4171 - accuracy: 0.1172 - val_loss: 2.9054 - val_accuracy: 0.2891\n",
      "Epoch 523/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9292 - accuracy: 0.2500 - val_loss: 2.9480 - val_accuracy: 0.2969\n",
      "Epoch 524/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.3235 - accuracy: 0.1719 - val_loss: 3.1190 - val_accuracy: 0.2656\n",
      "Epoch 525/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9143 - accuracy: 0.2422 - val_loss: 3.1172 - val_accuracy: 0.2891\n",
      "Epoch 526/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9267 - accuracy: 0.2969 - val_loss: 3.0521 - val_accuracy: 0.3281\n",
      "Epoch 527/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.7137 - accuracy: 0.3047 - val_loss: 2.8880 - val_accuracy: 0.3594\n",
      "Epoch 528/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.0040 - accuracy: 0.3125 - val_loss: 2.8120 - val_accuracy: 0.3828\n",
      "Epoch 529/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.0620 - accuracy: 0.2500 - val_loss: 2.7748 - val_accuracy: 0.3906\n",
      "Epoch 530/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9088 - accuracy: 0.2422 - val_loss: 2.8590 - val_accuracy: 0.3516\n",
      "Epoch 531/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1569 - accuracy: 0.1797 - val_loss: 2.9106 - val_accuracy: 0.3047\n",
      "Epoch 532/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.0602 - accuracy: 0.2891 - val_loss: 3.0006 - val_accuracy: 0.2578\n",
      "Epoch 533/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0855 - accuracy: 0.2188 - val_loss: 3.2190 - val_accuracy: 0.1797\n",
      "Epoch 534/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 3.4810 - accuracy: 0.1484 - val_loss: 3.1771 - val_accuracy: 0.2266\n",
      "Epoch 535/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.9946 - accuracy: 0.2109 - val_loss: 2.8633 - val_accuracy: 0.2812\n",
      "Epoch 536/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.0022 - accuracy: 0.2422 - val_loss: 2.7839 - val_accuracy: 0.2969\n",
      "Epoch 537/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.0261 - accuracy: 0.2266 - val_loss: 3.0426 - val_accuracy: 0.2266\n",
      "Epoch 538/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 2.7758 - accuracy: 0.2891 - val_loss: 2.9629 - val_accuracy: 0.3125\n",
      "Epoch 539/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.7679 - accuracy: 0.2734 - val_loss: 2.5318 - val_accuracy: 0.4062\n",
      "Epoch 540/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 3.0920 - accuracy: 0.2734 - val_loss: 2.4640 - val_accuracy: 0.4297\n",
      "Epoch 541/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.0368 - accuracy: 0.2422 - val_loss: 2.5726 - val_accuracy: 0.4141\n",
      "Epoch 542/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 3.1392 - accuracy: 0.2734 - val_loss: 2.7561 - val_accuracy: 0.3906\n",
      "Epoch 543/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.3092 - accuracy: 0.0625 - val_loss: 3.2859 - val_accuracy: 0.2891\n",
      "Epoch 544/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 3.0757 - accuracy: 0.1328 - val_loss: 3.2209 - val_accuracy: 0.2188\n",
      "Epoch 545/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.8424 - accuracy: 0.2266 - val_loss: 2.8125 - val_accuracy: 0.2188\n",
      "Epoch 546/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.2539 - accuracy: 0.1484 - val_loss: 3.0049 - val_accuracy: 0.1094\n",
      "Epoch 547/5000\n",
      "4/4 [==============================] - 0s 62ms/step - loss: 2.9404 - accuracy: 0.2344 - val_loss: 3.0302 - val_accuracy: 0.1328\n",
      "Epoch 548/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.0851 - accuracy: 0.2109 - val_loss: 3.2433 - val_accuracy: 0.1797\n",
      "Epoch 549/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.9929 - accuracy: 0.2422 - val_loss: 3.3749 - val_accuracy: 0.2188\n",
      "Epoch 550/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.2021 - accuracy: 0.1797 - val_loss: 3.3060 - val_accuracy: 0.2031\n",
      "Epoch 551/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.1917 - accuracy: 0.2500 - val_loss: 3.4107 - val_accuracy: 0.2109\n",
      "Epoch 552/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9651 - accuracy: 0.2656 - val_loss: 3.5058 - val_accuracy: 0.1875\n",
      "Epoch 553/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9388 - accuracy: 0.2734 - val_loss: 3.7846 - val_accuracy: 0.1953\n",
      "Epoch 554/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.9788 - accuracy: 0.1797 - val_loss: 3.8784 - val_accuracy: 0.2266\n",
      "Epoch 555/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9868 - accuracy: 0.2656 - val_loss: 3.5851 - val_accuracy: 0.2656\n",
      "Epoch 556/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.9441 - accuracy: 0.2266 - val_loss: 3.2053 - val_accuracy: 0.2969\n",
      "Epoch 557/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 74ms/step - loss: 3.2125 - accuracy: 0.1953 - val_loss: 3.0887 - val_accuracy: 0.2969\n",
      "Epoch 558/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.8439 - accuracy: 0.2891 - val_loss: 2.9141 - val_accuracy: 0.3047\n",
      "Epoch 559/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9832 - accuracy: 0.1719 - val_loss: 3.1966 - val_accuracy: 0.3281\n",
      "Epoch 560/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 2.9048 - accuracy: 0.2266 - val_loss: 3.1754 - val_accuracy: 0.3594\n",
      "Epoch 561/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1781 - accuracy: 0.1641 - val_loss: 3.1160 - val_accuracy: 0.3672\n",
      "Epoch 562/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.6627 - accuracy: 0.1172 - val_loss: 3.1438 - val_accuracy: 0.3047\n",
      "Epoch 563/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.5260 - accuracy: 0.2891 - val_loss: 3.1222 - val_accuracy: 0.2188\n",
      "Epoch 564/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1529 - accuracy: 0.1641 - val_loss: 3.0757 - val_accuracy: 0.1562\n",
      "Epoch 565/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.1766 - accuracy: 0.2266 - val_loss: 3.0904 - val_accuracy: 0.1484\n",
      "Epoch 566/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 3.0336 - accuracy: 0.2188 - val_loss: 3.2157 - val_accuracy: 0.1172\n",
      "Epoch 567/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.2253 - accuracy: 0.1875 - val_loss: 3.2403 - val_accuracy: 0.1328\n",
      "Epoch 568/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0890 - accuracy: 0.2109 - val_loss: 3.2882 - val_accuracy: 0.1484\n",
      "Epoch 569/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.8948 - accuracy: 0.2344 - val_loss: 3.3042 - val_accuracy: 0.1250\n",
      "Epoch 570/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.9237 - accuracy: 0.2109 - val_loss: 3.3808 - val_accuracy: 0.0938\n",
      "Epoch 571/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.8935 - accuracy: 0.2500 - val_loss: 3.2017 - val_accuracy: 0.1172\n",
      "Epoch 572/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1375 - accuracy: 0.2344 - val_loss: 3.1607 - val_accuracy: 0.1328\n",
      "Epoch 573/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 2.9015 - accuracy: 0.2578 - val_loss: 2.9609 - val_accuracy: 0.1641\n",
      "Epoch 574/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9140 - accuracy: 0.2812 - val_loss: 3.1134 - val_accuracy: 0.2188\n",
      "Epoch 575/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.7530 - accuracy: 0.2891 - val_loss: 3.0992 - val_accuracy: 0.2500\n",
      "Epoch 576/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.3101 - accuracy: 0.2031 - val_loss: 2.9585 - val_accuracy: 0.2188\n",
      "Epoch 577/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.6478 - accuracy: 0.3047 - val_loss: 2.7308 - val_accuracy: 0.2500\n",
      "Epoch 578/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.8841 - accuracy: 0.2188 - val_loss: 2.8759 - val_accuracy: 0.1328\n",
      "Epoch 579/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 3.2299 - accuracy: 0.1719 - val_loss: 3.0216 - val_accuracy: 0.1016\n",
      "Epoch 580/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 3.1473 - accuracy: 0.2031 - val_loss: 3.0383 - val_accuracy: 0.1328\n",
      "Epoch 581/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.9669 - accuracy: 0.2500 - val_loss: 3.0801 - val_accuracy: 0.1562\n",
      "Epoch 582/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.1202 - accuracy: 0.1719 - val_loss: 3.0369 - val_accuracy: 0.1641\n",
      "Epoch 583/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.0731 - accuracy: 0.2188 - val_loss: 2.9986 - val_accuracy: 0.1094\n",
      "Epoch 584/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.0022 - accuracy: 0.1875 - val_loss: 2.9510 - val_accuracy: 0.0938\n",
      "Epoch 585/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.9399 - accuracy: 0.2734 - val_loss: 2.9102 - val_accuracy: 0.1797\n",
      "Epoch 586/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 3.1188 - accuracy: 0.2188 - val_loss: 2.7637 - val_accuracy: 0.1719\n",
      "Epoch 587/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.8939 - accuracy: 0.2656 - val_loss: 2.5626 - val_accuracy: 0.3828\n",
      "Epoch 588/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.7412 - accuracy: 0.2734 - val_loss: 2.3878 - val_accuracy: 0.4375\n",
      "Epoch 589/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.8504 - accuracy: 0.2422 - val_loss: 2.5037 - val_accuracy: 0.3359\n",
      "Epoch 590/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9955 - accuracy: 0.2109 - val_loss: 2.7910 - val_accuracy: 0.2266\n",
      "Epoch 591/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0331 - accuracy: 0.2734 - val_loss: 2.9816 - val_accuracy: 0.2344\n",
      "Epoch 592/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.6083 - accuracy: 0.2969 - val_loss: 3.2138 - val_accuracy: 0.2109\n",
      "Epoch 593/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1872 - accuracy: 0.2109 - val_loss: 3.6104 - val_accuracy: 0.1250\n",
      "Epoch 594/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.0740 - accuracy: 0.1484 - val_loss: 4.0989 - val_accuracy: 0.1016\n",
      "Epoch 595/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8118 - accuracy: 0.2969 - val_loss: 4.1465 - val_accuracy: 0.1016\n",
      "Epoch 596/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8162 - accuracy: 0.2969 - val_loss: 4.3271 - val_accuracy: 0.0781\n",
      "Epoch 597/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.6422 - accuracy: 0.3125 - val_loss: 3.9347 - val_accuracy: 0.1719\n",
      "Epoch 598/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8467 - accuracy: 0.3281 - val_loss: 3.6664 - val_accuracy: 0.2969\n",
      "Epoch 599/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8538 - accuracy: 0.2812 - val_loss: 3.0749 - val_accuracy: 0.3281\n",
      "Epoch 600/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.1728 - accuracy: 0.1406 - val_loss: 2.5570 - val_accuracy: 0.3984\n",
      "Epoch 601/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8195 - accuracy: 0.2656 - val_loss: 2.6171 - val_accuracy: 0.3750\n",
      "Epoch 602/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.7691 - accuracy: 0.2344 - val_loss: 2.8492 - val_accuracy: 0.2734\n",
      "Epoch 603/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.5035 - accuracy: 0.3359 - val_loss: 3.2954 - val_accuracy: 0.0938\n",
      "Epoch 604/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8775 - accuracy: 0.2656 - val_loss: 3.8496 - val_accuracy: 0.0312\n",
      "Epoch 605/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 3.0407 - accuracy: 0.2109 - val_loss: 3.6794 - val_accuracy: 0.0391\n",
      "Epoch 606/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.9079 - accuracy: 0.2734 - val_loss: 3.2636 - val_accuracy: 0.0547\n",
      "Epoch 607/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9675 - accuracy: 0.2578 - val_loss: 3.2798 - val_accuracy: 0.1094\n",
      "Epoch 608/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8078 - accuracy: 0.2422 - val_loss: 3.3382 - val_accuracy: 0.1406\n",
      "Epoch 609/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8693 - accuracy: 0.2656 - val_loss: 3.1707 - val_accuracy: 0.1562\n",
      "Epoch 610/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.9463 - accuracy: 0.2344 - val_loss: 3.1252 - val_accuracy: 0.1875\n",
      "Epoch 611/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.8255 - accuracy: 0.2969 - val_loss: 3.0995 - val_accuracy: 0.1250\n",
      "Epoch 612/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.1706 - accuracy: 0.1875 - val_loss: 2.9303 - val_accuracy: 0.1797\n",
      "Epoch 613/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 3.0754 - accuracy: 0.1719 - val_loss: 3.2165 - val_accuracy: 0.0781\n",
      "Epoch 614/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7651 - accuracy: 0.3125 - val_loss: 3.1549 - val_accuracy: 0.0859\n",
      "Epoch 615/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.8896 - accuracy: 0.2500 - val_loss: 3.0516 - val_accuracy: 0.1172\n",
      "Epoch 616/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0479 - accuracy: 0.2031 - val_loss: 3.1218 - val_accuracy: 0.1094\n",
      "Epoch 617/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.7842 - accuracy: 0.2344 - val_loss: 3.1223 - val_accuracy: 0.1328\n",
      "Epoch 618/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 3.2106 - accuracy: 0.2109 - val_loss: 3.0982 - val_accuracy: 0.1406\n",
      "Epoch 619/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.9011 - accuracy: 0.2109 - val_loss: 3.0670 - val_accuracy: 0.2188\n",
      "Epoch 620/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8219 - accuracy: 0.2734 - val_loss: 3.1303 - val_accuracy: 0.1875\n",
      "Epoch 621/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.3322 - accuracy: 0.1875 - val_loss: 3.3480 - val_accuracy: 0.2031\n",
      "Epoch 622/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0072 - accuracy: 0.1719 - val_loss: 3.6054 - val_accuracy: 0.1172\n",
      "Epoch 623/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.2256 - accuracy: 0.1562 - val_loss: 3.6221 - val_accuracy: 0.1406\n",
      "Epoch 624/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.9534 - accuracy: 0.2656 - val_loss: 3.4362 - val_accuracy: 0.1797\n",
      "Epoch 625/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.0306 - accuracy: 0.1719 - val_loss: 3.3211 - val_accuracy: 0.1406\n",
      "Epoch 626/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.7943 - accuracy: 0.3281 - val_loss: 3.3646 - val_accuracy: 0.1406\n",
      "Epoch 627/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 3.1135 - accuracy: 0.2188 - val_loss: 3.5345 - val_accuracy: 0.1094\n",
      "Epoch 628/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.7485 - accuracy: 0.2812 - val_loss: 3.6155 - val_accuracy: 0.1250\n",
      "Epoch 629/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 2.9878 - accuracy: 0.2109 - val_loss: 3.4229 - val_accuracy: 0.1641\n",
      "Epoch 630/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.7267 - accuracy: 0.2500 - val_loss: 3.2539 - val_accuracy: 0.1562\n",
      "Epoch 631/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8771 - accuracy: 0.3203 - val_loss: 2.8528 - val_accuracy: 0.2578\n",
      "Epoch 632/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.9611 - accuracy: 0.2422 - val_loss: 2.6030 - val_accuracy: 0.3359\n",
      "Epoch 633/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.6228 - accuracy: 0.2812 - val_loss: 2.4830 - val_accuracy: 0.3906\n",
      "Epoch 634/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.6426 - accuracy: 0.3594 - val_loss: 2.4635 - val_accuracy: 0.3906\n",
      "Epoch 635/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.0044 - accuracy: 0.2422 - val_loss: 2.6542 - val_accuracy: 0.3750\n",
      "Epoch 636/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.8726 - accuracy: 0.1797 - val_loss: 2.9683 - val_accuracy: 0.3359\n",
      "Epoch 637/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 2.7760 - accuracy: 0.2969 - val_loss: 2.7375 - val_accuracy: 0.3750\n",
      "Epoch 638/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 3.1421 - accuracy: 0.2266 - val_loss: 2.5119 - val_accuracy: 0.4141\n",
      "Epoch 639/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.7763 - accuracy: 0.2109 - val_loss: 2.5815 - val_accuracy: 0.3750\n",
      "Epoch 640/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.9724 - accuracy: 0.2422 - val_loss: 2.7043 - val_accuracy: 0.3828\n",
      "Epoch 641/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.8806 - accuracy: 0.2812 - val_loss: 2.5273 - val_accuracy: 0.4766\n",
      "Epoch 642/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 3.0596 - accuracy: 0.2031 - val_loss: 2.8088 - val_accuracy: 0.3359\n",
      "Epoch 643/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 3.0661 - accuracy: 0.1953 - val_loss: 2.9704 - val_accuracy: 0.3438\n",
      "Epoch 644/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 2.4656 - accuracy: 0.3594 - val_loss: 3.0071 - val_accuracy: 0.2969\n",
      "Epoch 645/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.3652 - accuracy: 0.3359 - val_loss: 3.5408 - val_accuracy: 0.1953\n",
      "Epoch 646/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.7818 - accuracy: 0.2656 - val_loss: 3.3816 - val_accuracy: 0.1406\n",
      "Epoch 647/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 3.1227 - accuracy: 0.1641 - val_loss: 2.9867 - val_accuracy: 0.1953\n",
      "Epoch 648/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 2.6872 - accuracy: 0.3438 - val_loss: 2.9292 - val_accuracy: 0.2266\n",
      "Epoch 649/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.5362 - accuracy: 0.2500 - val_loss: 2.6768 - val_accuracy: 0.3203\n",
      "Epoch 650/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.9381 - accuracy: 0.2891 - val_loss: 2.7200 - val_accuracy: 0.3359\n",
      "Epoch 651/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.8295 - accuracy: 0.2812 - val_loss: 3.0644 - val_accuracy: 0.2656\n",
      "Epoch 652/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.7543 - accuracy: 0.2109 - val_loss: 3.0969 - val_accuracy: 0.2344\n",
      "Epoch 653/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.7242 - accuracy: 0.3359 - val_loss: 3.0169 - val_accuracy: 0.2266\n",
      "Epoch 654/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.8823 - accuracy: 0.2422 - val_loss: 3.0317 - val_accuracy: 0.2109\n",
      "Epoch 655/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.8233 - accuracy: 0.2500 - val_loss: 3.0538 - val_accuracy: 0.2109\n",
      "Epoch 656/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.7452 - accuracy: 0.3203 - val_loss: 3.0725 - val_accuracy: 0.2422\n",
      "Epoch 657/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 2.7139 - accuracy: 0.2734 - val_loss: 3.1276 - val_accuracy: 0.2422\n",
      "Epoch 658/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.8728 - accuracy: 0.2578 - val_loss: 3.0483 - val_accuracy: 0.2266\n",
      "Epoch 659/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 2.6662 - accuracy: 0.3281 - val_loss: 2.9946 - val_accuracy: 0.2109\n",
      "Epoch 660/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.9917 - accuracy: 0.2188 - val_loss: 2.9679 - val_accuracy: 0.2344\n",
      "Epoch 661/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.7044 - accuracy: 0.3359 - val_loss: 3.0539 - val_accuracy: 0.1953\n",
      "Epoch 662/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 2.7931 - accuracy: 0.3203 - val_loss: 3.2411 - val_accuracy: 0.1797\n",
      "Epoch 663/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.7512 - accuracy: 0.2578 - val_loss: 3.0822 - val_accuracy: 0.2500\n",
      "Epoch 664/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 2.7495 - accuracy: 0.2578 - val_loss: 2.6413 - val_accuracy: 0.3906\n",
      "Epoch 665/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.8803 - accuracy: 0.2188 - val_loss: 2.4554 - val_accuracy: 0.4688\n",
      "Epoch 666/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.5933 - accuracy: 0.2656 - val_loss: 2.5140 - val_accuracy: 0.3672\n",
      "Epoch 667/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 3.0622 - accuracy: 0.2578 - val_loss: 2.6877 - val_accuracy: 0.3594\n",
      "Epoch 668/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.8040 - accuracy: 0.3125 - val_loss: 2.8795 - val_accuracy: 0.2578\n",
      "Epoch 669/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.7752 - accuracy: 0.2812 - val_loss: 2.8647 - val_accuracy: 0.2891\n",
      "Epoch 670/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.5507 - accuracy: 0.3203 - val_loss: 2.6415 - val_accuracy: 0.3281\n",
      "Epoch 671/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8336 - accuracy: 0.3047 - val_loss: 2.4679 - val_accuracy: 0.4219\n",
      "Epoch 672/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 2.6251 - accuracy: 0.2891 - val_loss: 2.5723 - val_accuracy: 0.3672\n",
      "Epoch 673/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.6293 - accuracy: 0.3359 - val_loss: 2.7977 - val_accuracy: 0.3125\n",
      "Epoch 674/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 2.5336 - accuracy: 0.3516 - val_loss: 3.1646 - val_accuracy: 0.3047\n",
      "Epoch 675/5000\n",
      "4/4 [==============================] - 0s 61ms/step - loss: 2.6991 - accuracy: 0.3359 - val_loss: 3.3911 - val_accuracy: 0.3203\n",
      "Epoch 676/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.8114 - accuracy: 0.2109 - val_loss: 3.2187 - val_accuracy: 0.3438\n",
      "Epoch 677/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9498 - accuracy: 0.1875 - val_loss: 2.8452 - val_accuracy: 0.3438\n",
      "Epoch 678/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.6438 - accuracy: 0.2734 - val_loss: 2.7974 - val_accuracy: 0.3516\n",
      "Epoch 679/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 2.8836 - accuracy: 0.2734 - val_loss: 3.0628 - val_accuracy: 0.2344\n",
      "Epoch 680/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8068 - accuracy: 0.2656 - val_loss: 2.7778 - val_accuracy: 0.3203\n",
      "Epoch 681/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.9439 - accuracy: 0.2344 - val_loss: 2.8788 - val_accuracy: 0.3750\n",
      "Epoch 682/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 2.7036 - accuracy: 0.2812 - val_loss: 3.2253 - val_accuracy: 0.2188\n",
      "Epoch 683/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 2.6935 - accuracy: 0.3125 - val_loss: 3.2627 - val_accuracy: 0.2188\n",
      "Epoch 684/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 2.8257 - accuracy: 0.2734 - val_loss: 3.1548 - val_accuracy: 0.1797\n",
      "Epoch 685/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 2.5868 - accuracy: 0.2734 - val_loss: 3.1827 - val_accuracy: 0.1484\n",
      "Epoch 686/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 2.3226 - accuracy: 0.3750 - val_loss: 3.1964 - val_accuracy: 0.1562\n",
      "Epoch 687/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 2.9358 - accuracy: 0.2422 - val_loss: 3.0731 - val_accuracy: 0.2109\n",
      "Epoch 688/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 2.6498 - accuracy: 0.3281 - val_loss: 2.9222 - val_accuracy: 0.2188\n",
      "Epoch 00688: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3, params=692488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5.\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=692488\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5000\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 5.6670 - accuracy: 0.0156 - val_loss: 5.5489 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.5666 - accuracy: 0.0000e+00 - val_loss: 5.5508 - val_accuracy: 0.0078\n",
      "Epoch 3/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.5172 - accuracy: 0.0156 - val_loss: 5.5531 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.5334 - accuracy: 0.0234 - val_loss: 5.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.4631 - accuracy: 0.0078 - val_loss: 5.5570 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.4677 - accuracy: 0.0156 - val_loss: 5.5579 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 5.3047 - accuracy: 0.0391 - val_loss: 5.5549 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.4951 - accuracy: 0.0000e+00 - val_loss: 5.5314 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3552 - accuracy: 0.0156 - val_loss: 5.4952 - val_accuracy: 0.0078\n",
      "Epoch 10/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.3482 - accuracy: 0.0078 - val_loss: 5.4571 - val_accuracy: 0.0078\n",
      "Epoch 11/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.3656 - accuracy: 0.0000e+00 - val_loss: 5.3974 - val_accuracy: 0.0078\n",
      "Epoch 12/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.2071 - accuracy: 0.0547 - val_loss: 5.3625 - val_accuracy: 0.0078\n",
      "Epoch 13/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.3538 - accuracy: 0.0156 - val_loss: 5.3412 - val_accuracy: 0.0078\n",
      "Epoch 14/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.3385 - accuracy: 0.0156 - val_loss: 5.3287 - val_accuracy: 0.0078\n",
      "Epoch 15/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3570 - accuracy: 0.0078 - val_loss: 5.3209 - val_accuracy: 0.0234\n",
      "Epoch 16/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.1436 - accuracy: 0.0078 - val_loss: 5.3192 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.2043 - accuracy: 0.0078 - val_loss: 5.3222 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1293 - accuracy: 0.0391 - val_loss: 5.3474 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.2824 - accuracy: 0.0078 - val_loss: 5.3967 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1816 - accuracy: 0.0625 - val_loss: 5.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1107 - accuracy: 0.0312 - val_loss: 5.4241 - val_accuracy: 0.0078\n",
      "Epoch 22/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3524 - accuracy: 0.0078 - val_loss: 5.4259 - val_accuracy: 0.0078\n",
      "Epoch 23/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1205 - accuracy: 0.0078 - val_loss: 5.3786 - val_accuracy: 0.0078\n",
      "Epoch 24/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.3248 - accuracy: 0.0078 - val_loss: 5.3252 - val_accuracy: 0.0078\n",
      "Epoch 25/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.1376 - accuracy: 0.0234 - val_loss: 5.2872 - val_accuracy: 0.0078\n",
      "Epoch 26/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1558 - accuracy: 0.0469 - val_loss: 5.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1161 - accuracy: 0.0469 - val_loss: 5.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.3614 - accuracy: 0.0000e+00 - val_loss: 5.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.3609 - accuracy: 0.0078 - val_loss: 5.2569 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 5.0858 - accuracy: 0.0469 - val_loss: 5.2850 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2164 - accuracy: 0.0000e+00 - val_loss: 5.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 5.1419 - accuracy: 0.0234 - val_loss: 5.3345 - val_accuracy: 0.0078\n",
      "Epoch 33/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1522 - accuracy: 0.0547 - val_loss: 5.3567 - val_accuracy: 0.0078\n",
      "Epoch 34/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9797 - accuracy: 0.0781 - val_loss: 5.3518 - val_accuracy: 0.0078\n",
      "Epoch 35/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0751 - accuracy: 0.0469 - val_loss: 5.3527 - val_accuracy: 0.0078\n",
      "Epoch 36/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.0543 - accuracy: 0.0312 - val_loss: 5.3500 - val_accuracy: 0.0078\n",
      "Epoch 37/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.2622 - accuracy: 0.0234 - val_loss: 5.3565 - val_accuracy: 0.0078\n",
      "Epoch 38/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 5.0953 - accuracy: 0.0078 - val_loss: 5.3589 - val_accuracy: 0.0078\n",
      "Epoch 39/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.1520 - accuracy: 0.0156 - val_loss: 5.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0775 - accuracy: 0.0391 - val_loss: 5.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.1111 - accuracy: 0.0391 - val_loss: 5.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 5.1705 - accuracy: 0.0156 - val_loss: 5.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0715 - accuracy: 0.0156 - val_loss: 5.6854 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1240 - accuracy: 0.0312 - val_loss: 5.6983 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 5.1015 - accuracy: 0.0234 - val_loss: 5.7439 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0789 - accuracy: 0.0156 - val_loss: 5.7652 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0673 - accuracy: 0.0156 - val_loss: 5.7256 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.0741 - accuracy: 0.0234 - val_loss: 5.7700 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9685 - accuracy: 0.0391 - val_loss: 5.7187 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/5000\n",
      "4/4 [==============================] - 0s 64ms/step - loss: 5.1358 - accuracy: 0.0312 - val_loss: 5.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 5.0492 - accuracy: 0.0234 - val_loss: 5.6280 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.1189 - accuracy: 0.0234 - val_loss: 5.6884 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.2094 - accuracy: 0.0156 - val_loss: 5.7638 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.8337 - accuracy: 0.0859 - val_loss: 5.7675 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8746 - accuracy: 0.0625 - val_loss: 5.7642 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 5.1239 - accuracy: 0.0312 - val_loss: 5.7809 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9993 - accuracy: 0.0234 - val_loss: 5.7247 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.0868 - accuracy: 0.0156 - val_loss: 5.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 5.0496 - accuracy: 0.0547 - val_loss: 5.6240 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9359 - accuracy: 0.0234 - val_loss: 5.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9259 - accuracy: 0.0391 - val_loss: 5.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.0921 - accuracy: 0.0156 - val_loss: 5.4856 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9320 - accuracy: 0.0391 - val_loss: 5.3195 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0333 - accuracy: 0.0156 - val_loss: 5.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.0238 - accuracy: 0.0078 - val_loss: 4.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.1672 - accuracy: 0.0000e+00 - val_loss: 4.8902 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9859 - accuracy: 0.0469 - val_loss: 4.9734 - val_accuracy: 0.0078\n",
      "Epoch 68/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 5.0260 - accuracy: 0.0156 - val_loss: 4.9899 - val_accuracy: 0.0078\n",
      "Epoch 69/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.1956 - accuracy: 0.0078 - val_loss: 4.9729 - val_accuracy: 0.0078\n",
      "Epoch 70/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9155 - accuracy: 0.0312 - val_loss: 4.9071 - val_accuracy: 0.0078\n",
      "Epoch 71/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.9720 - accuracy: 0.0234 - val_loss: 4.8313 - val_accuracy: 0.0078\n",
      "Epoch 72/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8802 - accuracy: 0.0469 - val_loss: 4.7801 - val_accuracy: 0.0078\n",
      "Epoch 73/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.0792 - accuracy: 0.0000e+00 - val_loss: 4.7933 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.9151 - accuracy: 0.0156 - val_loss: 4.7938 - val_accuracy: 0.0156\n",
      "Epoch 75/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.9591 - accuracy: 0.0156 - val_loss: 4.8365 - val_accuracy: 0.0156\n",
      "Epoch 76/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9095 - accuracy: 0.0156 - val_loss: 4.8780 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9341 - accuracy: 0.0625 - val_loss: 4.8688 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.0603 - accuracy: 0.0234 - val_loss: 4.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 5.0529 - accuracy: 0.0391 - val_loss: 4.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.2108 - accuracy: 0.0234 - val_loss: 4.9485 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8491 - accuracy: 0.0234 - val_loss: 4.9768 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.9093 - accuracy: 0.0312 - val_loss: 4.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8233 - accuracy: 0.0469 - val_loss: 5.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 5.1838 - accuracy: 0.0078 - val_loss: 5.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9357 - accuracy: 0.0625 - val_loss: 5.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 5.1672 - accuracy: 0.0078 - val_loss: 5.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0211 - accuracy: 0.0156 - val_loss: 5.0831 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 5.1533 - accuracy: 0.0156 - val_loss: 5.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.9606 - accuracy: 0.0469 - val_loss: 5.1315 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9354 - accuracy: 0.0156 - val_loss: 5.2332 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8389 - accuracy: 0.0000e+00 - val_loss: 5.3720 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.9849 - accuracy: 0.0234 - val_loss: 5.4573 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7368 - accuracy: 0.0391 - val_loss: 5.5610 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8405 - accuracy: 0.0469 - val_loss: 5.6524 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9027 - accuracy: 0.0156 - val_loss: 5.7112 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.9395 - accuracy: 0.0234 - val_loss: 5.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9950 - accuracy: 0.0391 - val_loss: 5.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9725 - accuracy: 0.0547 - val_loss: 5.3843 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7162 - accuracy: 0.0547 - val_loss: 5.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8814 - accuracy: 0.0391 - val_loss: 5.3789 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 5.0558 - accuracy: 0.0234 - val_loss: 5.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9673 - accuracy: 0.0547 - val_loss: 5.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 5.0368 - accuracy: 0.0078 - val_loss: 5.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.9392 - accuracy: 0.0156 - val_loss: 5.2354 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9282 - accuracy: 0.0703 - val_loss: 5.1656 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 5.0781 - accuracy: 0.0391 - val_loss: 5.1297 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9138 - accuracy: 0.0312 - val_loss: 5.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8770 - accuracy: 0.0312 - val_loss: 5.0501 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.7694 - accuracy: 0.0156 - val_loss: 4.9743 - val_accuracy: 0.0078\n",
      "Epoch 110/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 5.0069 - accuracy: 0.0234 - val_loss: 4.9597 - val_accuracy: 0.0078\n",
      "Epoch 111/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0093 - accuracy: 0.0234 - val_loss: 4.9729 - val_accuracy: 0.0078\n",
      "Epoch 112/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8989 - accuracy: 0.0078 - val_loss: 4.9276 - val_accuracy: 0.0078\n",
      "Epoch 113/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.0425 - accuracy: 0.0312 - val_loss: 4.9077 - val_accuracy: 0.0078\n",
      "Epoch 114/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.8412 - accuracy: 0.0234 - val_loss: 4.8682 - val_accuracy: 0.0156\n",
      "Epoch 115/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9398 - accuracy: 0.0312 - val_loss: 4.8569 - val_accuracy: 0.0078\n",
      "Epoch 116/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8764 - accuracy: 0.0078 - val_loss: 4.8411 - val_accuracy: 0.0078\n",
      "Epoch 117/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8015 - accuracy: 0.0234 - val_loss: 4.7959 - val_accuracy: 0.0078\n",
      "Epoch 118/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8399 - accuracy: 0.0234 - val_loss: 4.7658 - val_accuracy: 0.0078\n",
      "Epoch 119/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9520 - accuracy: 0.0391 - val_loss: 4.7180 - val_accuracy: 0.0391\n",
      "Epoch 120/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8735 - accuracy: 0.0078 - val_loss: 4.6924 - val_accuracy: 0.0391\n",
      "Epoch 121/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8972 - accuracy: 0.0391 - val_loss: 4.6983 - val_accuracy: 0.0234\n",
      "Epoch 122/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8603 - accuracy: 0.0156 - val_loss: 4.7012 - val_accuracy: 0.0156\n",
      "Epoch 123/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8383 - accuracy: 0.0234 - val_loss: 4.7407 - val_accuracy: 0.0156\n",
      "Epoch 124/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7608 - accuracy: 0.0391 - val_loss: 4.7698 - val_accuracy: 0.0156\n",
      "Epoch 125/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.0272 - accuracy: 0.0312 - val_loss: 4.8124 - val_accuracy: 0.0078\n",
      "Epoch 126/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7466 - accuracy: 0.0625 - val_loss: 4.8322 - val_accuracy: 0.0078\n",
      "Epoch 127/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9437 - accuracy: 0.0234 - val_loss: 4.8367 - val_accuracy: 0.0078\n",
      "Epoch 128/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 5.1511 - accuracy: 0.0234 - val_loss: 4.8765 - val_accuracy: 0.0078\n",
      "Epoch 129/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 4.9325 - accuracy: 0.0234 - val_loss: 4.9249 - val_accuracy: 0.0156\n",
      "Epoch 130/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6690 - accuracy: 0.0312 - val_loss: 5.0485 - val_accuracy: 0.0156\n",
      "Epoch 131/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9504 - accuracy: 0.0234 - val_loss: 5.1307 - val_accuracy: 0.0078\n",
      "Epoch 132/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8192 - accuracy: 0.0391 - val_loss: 5.1621 - val_accuracy: 0.0078\n",
      "Epoch 133/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8514 - accuracy: 0.0234 - val_loss: 5.1451 - val_accuracy: 0.0078\n",
      "Epoch 134/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9880 - accuracy: 0.0156 - val_loss: 5.1259 - val_accuracy: 0.0156\n",
      "Epoch 135/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9233 - accuracy: 0.0312 - val_loss: 5.0834 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.9260 - accuracy: 0.0234 - val_loss: 5.0321 - val_accuracy: 0.0156\n",
      "Epoch 137/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.8315 - accuracy: 0.0547 - val_loss: 5.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7586 - accuracy: 0.0391 - val_loss: 5.0365 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7630 - accuracy: 0.0234 - val_loss: 4.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 4.8339 - accuracy: 0.0391 - val_loss: 4.8444 - val_accuracy: 0.0078\n",
      "Epoch 141/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8942 - accuracy: 0.0391 - val_loss: 4.7503 - val_accuracy: 0.0312\n",
      "Epoch 142/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8029 - accuracy: 0.0391 - val_loss: 4.7233 - val_accuracy: 0.0234\n",
      "Epoch 143/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.9520 - accuracy: 0.0156 - val_loss: 4.6162 - val_accuracy: 0.0234\n",
      "Epoch 144/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.7728 - accuracy: 0.0156 - val_loss: 4.5429 - val_accuracy: 0.0625\n",
      "Epoch 145/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8415 - accuracy: 0.0234 - val_loss: 4.4933 - val_accuracy: 0.0547\n",
      "Epoch 146/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.8741 - accuracy: 0.0312 - val_loss: 4.4599 - val_accuracy: 0.0625\n",
      "Epoch 147/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.9896 - accuracy: 0.0234 - val_loss: 4.4831 - val_accuracy: 0.0859\n",
      "Epoch 148/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.5908 - accuracy: 0.0547 - val_loss: 4.5470 - val_accuracy: 0.0781\n",
      "Epoch 149/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8036 - accuracy: 0.0391 - val_loss: 4.5656 - val_accuracy: 0.0703\n",
      "Epoch 150/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.7771 - accuracy: 0.0547 - val_loss: 4.5878 - val_accuracy: 0.0234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.8042 - accuracy: 0.0391 - val_loss: 4.6058 - val_accuracy: 0.0234\n",
      "Epoch 152/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.8567 - accuracy: 0.0234 - val_loss: 4.5407 - val_accuracy: 0.0156\n",
      "Epoch 153/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.7891 - accuracy: 0.0469 - val_loss: 4.4544 - val_accuracy: 0.0078\n",
      "Epoch 154/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 5.0226 - accuracy: 0.0078 - val_loss: 4.4196 - val_accuracy: 0.0156\n",
      "Epoch 155/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6039 - accuracy: 0.1016 - val_loss: 4.4237 - val_accuracy: 0.0312\n",
      "Epoch 156/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8618 - accuracy: 0.0312 - val_loss: 4.3723 - val_accuracy: 0.0703\n",
      "Epoch 157/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7962 - accuracy: 0.0391 - val_loss: 4.4044 - val_accuracy: 0.0781\n",
      "Epoch 158/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7356 - accuracy: 0.0469 - val_loss: 4.3634 - val_accuracy: 0.0547\n",
      "Epoch 159/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7949 - accuracy: 0.0391 - val_loss: 4.3365 - val_accuracy: 0.0469\n",
      "Epoch 160/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7073 - accuracy: 0.0391 - val_loss: 4.3505 - val_accuracy: 0.0312\n",
      "Epoch 161/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3487 - accuracy: 0.1094 - val_loss: 4.2292 - val_accuracy: 0.0469\n",
      "Epoch 162/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7968 - accuracy: 0.0234 - val_loss: 4.2209 - val_accuracy: 0.0547\n",
      "Epoch 163/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.8150 - accuracy: 0.0547 - val_loss: 4.2989 - val_accuracy: 0.0234\n",
      "Epoch 164/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7597 - accuracy: 0.0391 - val_loss: 4.4162 - val_accuracy: 0.0078\n",
      "Epoch 165/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7618 - accuracy: 0.0547 - val_loss: 4.4700 - val_accuracy: 0.0156\n",
      "Epoch 166/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7302 - accuracy: 0.0156 - val_loss: 4.5629 - val_accuracy: 0.0078\n",
      "Epoch 167/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.8860 - accuracy: 0.0547 - val_loss: 4.6558 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8252 - accuracy: 0.0469 - val_loss: 4.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7573 - accuracy: 0.0469 - val_loss: 4.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7969 - accuracy: 0.0156 - val_loss: 5.0093 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8536 - accuracy: 0.0234 - val_loss: 4.9817 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6288 - accuracy: 0.0781 - val_loss: 5.0680 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6550 - accuracy: 0.0625 - val_loss: 5.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7398 - accuracy: 0.0469 - val_loss: 5.2324 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6891 - accuracy: 0.0234 - val_loss: 5.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8857 - accuracy: 0.0547 - val_loss: 5.3349 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.8100 - accuracy: 0.0391 - val_loss: 5.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.9422 - accuracy: 0.0000e+00 - val_loss: 5.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9850 - accuracy: 0.0078 - val_loss: 5.5356 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7798 - accuracy: 0.0391 - val_loss: 5.5503 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6228 - accuracy: 0.0547 - val_loss: 5.5585 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8546 - accuracy: 0.0234 - val_loss: 5.8415 - val_accuracy: 0.0078\n",
      "Epoch 183/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.5607 - accuracy: 0.0469 - val_loss: 6.1698 - val_accuracy: 0.0078\n",
      "Epoch 184/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.8477 - accuracy: 0.0469 - val_loss: 6.4057 - val_accuracy: 0.0078\n",
      "Epoch 185/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.6410 - accuracy: 0.0703 - val_loss: 6.5833 - val_accuracy: 0.0078\n",
      "Epoch 186/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6955 - accuracy: 0.0781 - val_loss: 6.8145 - val_accuracy: 0.0234\n",
      "Epoch 187/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8556 - accuracy: 0.0156 - val_loss: 7.0114 - val_accuracy: 0.0234\n",
      "Epoch 188/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6851 - accuracy: 0.0703 - val_loss: 7.2154 - val_accuracy: 0.0156\n",
      "Epoch 189/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8232 - accuracy: 0.0312 - val_loss: 7.4285 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.9993 - accuracy: 0.0078 - val_loss: 7.3720 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8316 - accuracy: 0.0312 - val_loss: 7.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.7243 - accuracy: 0.0391 - val_loss: 6.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.5858 - accuracy: 0.0469 - val_loss: 6.6825 - val_accuracy: 0.0078\n",
      "Epoch 194/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6562 - accuracy: 0.0625 - val_loss: 6.7626 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7646 - accuracy: 0.0312 - val_loss: 6.8266 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6169 - accuracy: 0.0078 - val_loss: 7.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8345 - accuracy: 0.0391 - val_loss: 7.9549 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7356 - accuracy: 0.0625 - val_loss: 7.8695 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7544 - accuracy: 0.0391 - val_loss: 7.5138 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7649 - accuracy: 0.0234 - val_loss: 6.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8305 - accuracy: 0.0234 - val_loss: 6.7641 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6763 - accuracy: 0.0547 - val_loss: 6.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8208 - accuracy: 0.0391 - val_loss: 6.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.9515 - accuracy: 0.0000e+00 - val_loss: 7.1779 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5254 - accuracy: 0.0312 - val_loss: 7.3594 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7156 - accuracy: 0.1094 - val_loss: 7.1308 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6735 - accuracy: 0.0234 - val_loss: 6.5848 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7701 - accuracy: 0.0469 - val_loss: 6.1187 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6428 - accuracy: 0.0625 - val_loss: 5.9886 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.5466 - accuracy: 0.0469 - val_loss: 5.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5804 - accuracy: 0.0312 - val_loss: 5.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6418 - accuracy: 0.0391 - val_loss: 5.2699 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.9054 - accuracy: 0.0312 - val_loss: 5.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/5000\n",
      "4/4 [==============================] - 0s 65ms/step - loss: 4.8256 - accuracy: 0.0156 - val_loss: 5.2796 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6508 - accuracy: 0.0391 - val_loss: 5.2727 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6262 - accuracy: 0.0391 - val_loss: 5.3088 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.7602 - accuracy: 0.0078 - val_loss: 5.3158 - val_accuracy: 0.0078\n",
      "Epoch 218/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.8131 - accuracy: 0.0469 - val_loss: 5.1078 - val_accuracy: 0.0703\n",
      "Epoch 219/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.8369 - accuracy: 0.0469 - val_loss: 4.8273 - val_accuracy: 0.0938\n",
      "Epoch 220/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6067 - accuracy: 0.0156 - val_loss: 4.6282 - val_accuracy: 0.0859\n",
      "Epoch 221/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.5269 - accuracy: 0.0391 - val_loss: 4.4765 - val_accuracy: 0.0703\n",
      "Epoch 222/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4325 - accuracy: 0.0781 - val_loss: 4.3708 - val_accuracy: 0.0703\n",
      "Epoch 223/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.8417 - accuracy: 0.0547 - val_loss: 4.3475 - val_accuracy: 0.0547\n",
      "Epoch 224/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7542 - accuracy: 0.0469 - val_loss: 4.4493 - val_accuracy: 0.0312\n",
      "Epoch 225/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.6878 - accuracy: 0.0234 - val_loss: 4.4958 - val_accuracy: 0.0312\n",
      "Epoch 226/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7797 - accuracy: 0.0312 - val_loss: 4.5275 - val_accuracy: 0.0156\n",
      "Epoch 227/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7866 - accuracy: 0.0312 - val_loss: 4.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.5598 - accuracy: 0.0312 - val_loss: 4.7844 - val_accuracy: 0.0078\n",
      "Epoch 229/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.8013 - accuracy: 0.0469 - val_loss: 4.8040 - val_accuracy: 0.0078\n",
      "Epoch 230/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.6305 - accuracy: 0.0469 - val_loss: 4.7853 - val_accuracy: 0.0078\n",
      "Epoch 231/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.5259 - accuracy: 0.0391 - val_loss: 4.7935 - val_accuracy: 0.0156\n",
      "Epoch 232/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.8407 - accuracy: 0.0156 - val_loss: 4.7840 - val_accuracy: 0.0156\n",
      "Epoch 233/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4245 - accuracy: 0.0469 - val_loss: 4.8901 - val_accuracy: 0.0156\n",
      "Epoch 234/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5205 - accuracy: 0.0312 - val_loss: 4.8894 - val_accuracy: 0.0156\n",
      "Epoch 235/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.4159 - accuracy: 0.0703 - val_loss: 4.9275 - val_accuracy: 0.0156\n",
      "Epoch 236/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.7353 - accuracy: 0.0234 - val_loss: 5.0065 - val_accuracy: 0.0156\n",
      "Epoch 237/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.6835 - accuracy: 0.0391 - val_loss: 5.0395 - val_accuracy: 0.0156\n",
      "Epoch 238/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5607 - accuracy: 0.0312 - val_loss: 4.9196 - val_accuracy: 0.0312\n",
      "Epoch 239/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.4624 - accuracy: 0.0234 - val_loss: 4.9739 - val_accuracy: 0.0703\n",
      "Epoch 240/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.8443 - accuracy: 0.0234 - val_loss: 5.0161 - val_accuracy: 0.0938\n",
      "Epoch 241/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.9241 - accuracy: 0.0391 - val_loss: 4.9477 - val_accuracy: 0.0547\n",
      "Epoch 242/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.6923 - accuracy: 0.0391 - val_loss: 4.9809 - val_accuracy: 0.0391\n",
      "Epoch 243/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.8047 - accuracy: 0.0156 - val_loss: 4.9503 - val_accuracy: 0.0312\n",
      "Epoch 244/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6071 - accuracy: 0.0391 - val_loss: 4.8891 - val_accuracy: 0.0078\n",
      "Epoch 245/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6939 - accuracy: 0.0312 - val_loss: 4.6419 - val_accuracy: 0.0391\n",
      "Epoch 246/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.5668 - accuracy: 0.0312 - val_loss: 4.3928 - val_accuracy: 0.0859\n",
      "Epoch 247/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7375 - accuracy: 0.0312 - val_loss: 4.1487 - val_accuracy: 0.1016\n",
      "Epoch 248/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4204 - accuracy: 0.0391 - val_loss: 4.1073 - val_accuracy: 0.1172\n",
      "Epoch 249/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.7196 - accuracy: 0.0391 - val_loss: 4.1775 - val_accuracy: 0.1250\n",
      "Epoch 250/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6760 - accuracy: 0.0391 - val_loss: 4.3377 - val_accuracy: 0.0625\n",
      "Epoch 251/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5012 - accuracy: 0.0703 - val_loss: 4.4771 - val_accuracy: 0.0312\n",
      "Epoch 252/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5504 - accuracy: 0.0781 - val_loss: 4.5643 - val_accuracy: 0.0078\n",
      "Epoch 253/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.7189 - accuracy: 0.0234 - val_loss: 4.5776 - val_accuracy: 0.0078\n",
      "Epoch 254/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6901 - accuracy: 0.0391 - val_loss: 4.4940 - val_accuracy: 0.0312\n",
      "Epoch 255/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5603 - accuracy: 0.0703 - val_loss: 4.4080 - val_accuracy: 0.0391\n",
      "Epoch 256/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6267 - accuracy: 0.0391 - val_loss: 4.4802 - val_accuracy: 0.0469\n",
      "Epoch 257/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.6969 - accuracy: 0.0547 - val_loss: 4.6561 - val_accuracy: 0.1172\n",
      "Epoch 258/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.6687 - accuracy: 0.0156 - val_loss: 4.5398 - val_accuracy: 0.1172\n",
      "Epoch 259/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6623 - accuracy: 0.0469 - val_loss: 4.5906 - val_accuracy: 0.0859\n",
      "Epoch 260/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.6398 - accuracy: 0.0312 - val_loss: 4.7563 - val_accuracy: 0.0312\n",
      "Epoch 261/5000\n",
      "4/4 [==============================] - 0s 86ms/step - loss: 4.8172 - accuracy: 0.0078 - val_loss: 4.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6678 - accuracy: 0.0781 - val_loss: 5.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5698 - accuracy: 0.0312 - val_loss: 5.4087 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 82ms/step - loss: 4.4000 - accuracy: 0.0391 - val_loss: 5.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.5686 - accuracy: 0.0312 - val_loss: 5.2369 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/5000\n",
      "4/4 [==============================] - 0s 83ms/step - loss: 4.4230 - accuracy: 0.0859 - val_loss: 5.2401 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.4419 - accuracy: 0.0625 - val_loss: 5.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6708 - accuracy: 0.0312 - val_loss: 5.5393 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.5387 - accuracy: 0.0312 - val_loss: 5.5838 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/5000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 4.6342 - accuracy: 0.0391 - val_loss: 5.4927 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5767 - accuracy: 0.0234 - val_loss: 5.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.5610 - accuracy: 0.0391 - val_loss: 5.3372 - val_accuracy: 0.0078\n",
      "Epoch 273/5000\n",
      "4/4 [==============================] - 0s 85ms/step - loss: 4.7643 - accuracy: 0.0547 - val_loss: 5.2610 - val_accuracy: 0.0078\n",
      "Epoch 274/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.7311 - accuracy: 0.0312 - val_loss: 5.2219 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.9087 - accuracy: 0.0312 - val_loss: 5.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.3833 - accuracy: 0.0703 - val_loss: 5.5541 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.6272 - accuracy: 0.0469 - val_loss: 5.5500 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.4554 - accuracy: 0.1016 - val_loss: 5.6639 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6418 - accuracy: 0.0625 - val_loss: 5.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/5000\n",
      "4/4 [==============================] - 0s 82ms/step - loss: 4.4984 - accuracy: 0.0469 - val_loss: 5.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.3864 - accuracy: 0.0781 - val_loss: 5.5845 - val_accuracy: 0.0078\n",
      "Epoch 282/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.5160 - accuracy: 0.0703 - val_loss: 5.5242 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/5000\n",
      "4/4 [==============================] - 0s 87ms/step - loss: 4.5053 - accuracy: 0.0391 - val_loss: 5.4084 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.7572 - accuracy: 0.0312 - val_loss: 5.4322 - val_accuracy: 0.0156\n",
      "Epoch 285/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.2789 - accuracy: 0.1250 - val_loss: 5.5459 - val_accuracy: 0.0156\n",
      "Epoch 286/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.7052 - accuracy: 0.0391 - val_loss: 5.6589 - val_accuracy: 0.0391\n",
      "Epoch 287/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5160 - accuracy: 0.0938 - val_loss: 5.6965 - val_accuracy: 0.0234\n",
      "Epoch 288/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.4883 - accuracy: 0.0781 - val_loss: 5.8538 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.5852 - accuracy: 0.0703 - val_loss: 5.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.7839 - accuracy: 0.0234 - val_loss: 5.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.5595 - accuracy: 0.0703 - val_loss: 5.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.4835 - accuracy: 0.0469 - val_loss: 5.5509 - val_accuracy: 0.0078\n",
      "Epoch 293/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3571 - accuracy: 0.0547 - val_loss: 5.4191 - val_accuracy: 0.0078\n",
      "Epoch 294/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.3896 - accuracy: 0.0703 - val_loss: 5.8156 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5072 - accuracy: 0.0469 - val_loss: 6.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.3273 - accuracy: 0.0547 - val_loss: 6.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.4717 - accuracy: 0.0938 - val_loss: 6.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3506 - accuracy: 0.0625 - val_loss: 6.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.6429 - accuracy: 0.0625 - val_loss: 6.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.6681 - accuracy: 0.0547 - val_loss: 6.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.4999 - accuracy: 0.0547 - val_loss: 6.1184 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3453 - accuracy: 0.0312 - val_loss: 5.9361 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.3082 - accuracy: 0.0781 - val_loss: 5.6169 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3204 - accuracy: 0.0391 - val_loss: 5.5192 - val_accuracy: 0.0156\n",
      "Epoch 305/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.4576 - accuracy: 0.0469 - val_loss: 5.7464 - val_accuracy: 0.0078\n",
      "Epoch 306/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.6575 - accuracy: 0.0312 - val_loss: 5.8304 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.3687 - accuracy: 0.0547 - val_loss: 5.7929 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.4913 - accuracy: 0.0625 - val_loss: 5.8375 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4659 - accuracy: 0.0703 - val_loss: 5.7934 - val_accuracy: 0.0078\n",
      "Epoch 310/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.6094 - accuracy: 0.0547 - val_loss: 5.6327 - val_accuracy: 0.0078\n",
      "Epoch 311/5000\n",
      "4/4 [==============================] - 0s 68ms/step - loss: 4.5601 - accuracy: 0.0312 - val_loss: 5.7858 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.4749 - accuracy: 0.1016 - val_loss: 5.7072 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2687 - accuracy: 0.0547 - val_loss: 5.4326 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7943 - accuracy: 0.0703 - val_loss: 5.3806 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.3556 - accuracy: 0.0234 - val_loss: 5.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/5000\n",
      "4/4 [==============================] - 0s 75ms/step - loss: 4.3240 - accuracy: 0.0703 - val_loss: 5.6439 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.5465 - accuracy: 0.0078 - val_loss: 6.4244 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.4818 - accuracy: 0.0547 - val_loss: 6.1739 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2783 - accuracy: 0.0547 - val_loss: 5.4547 - val_accuracy: 0.0625\n",
      "Epoch 320/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 80ms/step - loss: 4.3171 - accuracy: 0.0703 - val_loss: 4.9449 - val_accuracy: 0.0625\n",
      "Epoch 321/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.2413 - accuracy: 0.1016 - val_loss: 4.6271 - val_accuracy: 0.0312\n",
      "Epoch 322/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.2757 - accuracy: 0.0312 - val_loss: 5.1772 - val_accuracy: 0.0234\n",
      "Epoch 323/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.4997 - accuracy: 0.0391 - val_loss: 5.7519 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.3058 - accuracy: 0.0625 - val_loss: 5.8191 - val_accuracy: 0.0156\n",
      "Epoch 325/5000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 4.5672 - accuracy: 0.0703 - val_loss: 5.8894 - val_accuracy: 0.0156\n",
      "Epoch 326/5000\n",
      "4/4 [==============================] - 0s 72ms/step - loss: 4.3789 - accuracy: 0.0781 - val_loss: 6.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.3072 - accuracy: 0.0547 - val_loss: 5.5945 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.2231 - accuracy: 0.1094 - val_loss: 5.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.5306 - accuracy: 0.0703 - val_loss: 4.9523 - val_accuracy: 0.0391\n",
      "Epoch 330/5000\n",
      "4/4 [==============================] - 0s 71ms/step - loss: 4.7156 - accuracy: 0.0156 - val_loss: 4.7826 - val_accuracy: 0.0625\n",
      "Epoch 331/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.3549 - accuracy: 0.0859 - val_loss: 5.2334 - val_accuracy: 0.0078\n",
      "Epoch 332/5000\n",
      "4/4 [==============================] - 0s 69ms/step - loss: 4.5527 - accuracy: 0.0625 - val_loss: 5.2991 - val_accuracy: 0.0234\n",
      "Epoch 333/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.3606 - accuracy: 0.0312 - val_loss: 5.1462 - val_accuracy: 0.0312\n",
      "Epoch 334/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.2591 - accuracy: 0.0859 - val_loss: 4.9929 - val_accuracy: 0.0234\n",
      "Epoch 335/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.5359 - accuracy: 0.0469 - val_loss: 5.2135 - val_accuracy: 0.0156\n",
      "Epoch 336/5000\n",
      "4/4 [==============================] - 0s 78ms/step - loss: 4.3583 - accuracy: 0.0625 - val_loss: 5.5662 - val_accuracy: 0.0078\n",
      "Epoch 337/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.1311 - accuracy: 0.0938 - val_loss: 5.1698 - val_accuracy: 0.0156\n",
      "Epoch 338/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.6232 - accuracy: 0.0469 - val_loss: 5.0809 - val_accuracy: 0.0234\n",
      "Epoch 339/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.4100 - accuracy: 0.0391 - val_loss: 5.0070 - val_accuracy: 0.0234\n",
      "Epoch 340/5000\n",
      "4/4 [==============================] - 0s 81ms/step - loss: 4.3711 - accuracy: 0.0703 - val_loss: 5.1670 - val_accuracy: 0.0234\n",
      "Epoch 341/5000\n",
      "4/4 [==============================] - 0s 73ms/step - loss: 4.1590 - accuracy: 0.0859 - val_loss: 4.9531 - val_accuracy: 0.0156\n",
      "Epoch 342/5000\n",
      "4/4 [==============================] - 0s 77ms/step - loss: 4.4002 - accuracy: 0.0703 - val_loss: 4.7042 - val_accuracy: 0.0312\n",
      "Epoch 343/5000\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 4.2443 - accuracy: 0.0938 - val_loss: 4.5400 - val_accuracy: 0.0547\n",
      "Epoch 344/5000\n",
      "4/4 [==============================] - 0s 66ms/step - loss: 4.2953 - accuracy: 0.0547 - val_loss: 4.4390 - val_accuracy: 0.0703\n",
      "Epoch 345/5000\n",
      "4/4 [==============================] - 0s 80ms/step - loss: 4.1515 - accuracy: 0.0859 - val_loss: 4.4380 - val_accuracy: 0.0859\n",
      "Epoch 346/5000\n",
      "4/4 [==============================] - 0s 76ms/step - loss: 4.2119 - accuracy: 0.0781 - val_loss: 4.8784 - val_accuracy: 0.0547\n",
      "Epoch 347/5000\n",
      "4/4 [==============================] - 0s 74ms/step - loss: 4.4320 - accuracy: 0.0859 - val_loss: 5.7012 - val_accuracy: 0.0312\n",
      "Epoch 348/5000\n",
      "4/4 [==============================] - 0s 79ms/step - loss: 4.5219 - accuracy: 0.1016 - val_loss: 6.2833 - val_accuracy: 0.0078\n",
      "Epoch 00348: early stopping\n",
      "Model: \"vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 40, None, 1)]     0         \n",
      "                                                                 \n",
      " Conv0 (Conv2D)              (None, 40, None, 24)      144       \n",
      "                                                                 \n",
      " BN0 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 40, None, 24)      1752      \n",
      "                                                                 \n",
      " BN1 (BatchNormalization)    (None, 40, None, 24)      96        \n",
      "                                                                 \n",
      " MaxPool2D1 (MaxPooling2D)   (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20, None, 24)      0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 20, None, 48)      5808      \n",
      "                                                                 \n",
      " BN2 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " Conv3 (Conv2D)              (None, 20, None, 48)      6960      \n",
      "                                                                 \n",
      " BN3 (BatchNormalization)    (None, 20, None, 48)      192       \n",
      "                                                                 \n",
      " MaxPool2D2 (MaxPooling2D)   (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, None, 48)      0         \n",
      "                                                                 \n",
      " Conv4 (Conv2D)              (None, 10, None, 96)      23136     \n",
      "                                                                 \n",
      " BN4 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " Conv5 (Conv2D)              (None, 10, None, 96)      27744     \n",
      "                                                                 \n",
      " BN5 (BatchNormalization)    (None, 10, None, 96)      384       \n",
      "                                                                 \n",
      " MaxPool2D3 (MaxPooling2D)   (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5, None, 96)       0         \n",
      "                                                                 \n",
      " Conv6 (Conv2D)              (None, 5, None, 96)       46176     \n",
      "                                                                 \n",
      " BN6 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " Conv7 (Conv2D)              (None, 5, None, 96)       27744     \n",
      "                                                                 \n",
      " BN7 (BatchNormalization)    (None, 5, None, 96)       384       \n",
      "                                                                 \n",
      " MaxPool2D4 (MaxPooling2D)   (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, None, 96)       0         \n",
      "                                                                 \n",
      " Conv8 (Conv2D)              (None, 2, None, 192)      92352     \n",
      "                                                                 \n",
      " BN8 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " Conv9 (Conv2D)              (None, 2, None, 192)      110784    \n",
      "                                                                 \n",
      " BN9 (BatchNormalization)    (None, 2, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D5 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " Conv10 (Conv2D)             (None, 1, None, 192)      184512    \n",
      "                                                                 \n",
      " BN10 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " Conv11 (Conv2D)             (None, 1, None, 192)      110784    \n",
      "                                                                 \n",
      " BN11 (BatchNormalization)   (None, 1, None, 192)      768       \n",
      "                                                                 \n",
      " MaxPool2D6 (MaxPooling2D)   (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1, None, 192)      0         \n",
      "                                                                 \n",
      " 1x1 (Conv2D)                (None, 1, None, 256)      49408     \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 692,488\n",
      "Trainable params: 689,896\n",
      "Non-trainable params: 2,592\n",
      "_________________________________________________________________\n",
      "None\n",
      "lr=0.001, batch_size=32, epochs=5000, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, model_name=vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Run 0, vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5, params=692488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5.\n",
      "Trained on train.tsv\n",
      "runs=1, lr=0.001, batch_size=32, epochs=5000, patience=100, augmenter=<function tempo_augmenter at 0x7f5cd0d27790>, normalizer=<function std_normalizer at 0x7f5cd0d36160>\n",
      "----------\n",
      "val.tsv\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4157075': 139, '4161667': 108, '4162259': 128, '4162274': 119, '4162405': 122, '4162511': 122, '4163571': 167, '4163572': 147, '4163586': 133, '4163587': 119, '4163588': 181, '4166222': 119, '4166612': 122, '4172572': 174, '4186191': 126, '4191591': 133, '4192452': 174, '4193623': 122, '4207348': 126, '4214761': 120, '4216184': 133, '4218466': 111, '4226166': 181, '4226227': 133, '4226434': 141, '4231951': 141, '4233696': 119, '4235798': 133, '4237913': 117, '4264210': 119, '4264359': 167, '4265125': 174, '426992': 174, '4275052': 120, '4279669': 174, '4283622': 120, '4283854': 181, '4284345': 133, '4288893': 112, '4297277': 133, '4300617': 126, '4300619': 126, '4301518': 174, '4304445': 181, '4313859': 174, '4315749': 117, '4323506': 128, '4325441': 122, '4331667': 167, '4332592': 122, '4346730': 174, '4353566': 117, '4358231': 131, '4360483': 167, '4360488': 174, '4365752': 174, '4366506': 113, '4372309': 122, '4377106': 145, '4381717': 133, '4386702': 126, '4397324': 174, '4397469': 167, '4398117': 181, '4399289': 181, '4403315': 133, '4403519': 122, '4404346': 181, '4407745': 120, '4409752': 174, '4411925': 174, '4416336': 117, '4416506': 128, '4416888': 181, '4416962': 117, '4418582': 174, '4419049': 138, '4420924': 133, '4426890': 108, '4427618': 120, '4442121': 126, '4446908': 167, '4457771': 117, '4459005': 174, '4459187': 120, '4460536': 133, '4468729': 167, '4469489': 174, '4469780': 147, '4471292': 181, '4471702': 174, '4473065': 119, '4474027': 174, '4474029': 174, '4475855': 133, '4480118': 117, '4480454': 167, '4483708': 133, '4486124': 174, '4486412': 138, '4489017': 181, '4493439': 133, '4494659': 126, '4495270': 167, '4497852': 150, '4508138': 122, '4509910': 133, '4512512': 126, '4514851': 146, '4517258': 167, '4532060': 174, '4540818': 120, '4543103': 126, '4547732': 167, '4549757': 174, '4558106': 117, '4559522': 126, '4565270': 122, '4566667': 126, '4567978': 147, '4567979': 147, '4585539': 133, '4586220': 174, '4593850': 126, '4596215': 117, '4604737': 122, '4609093': 133, '4609944': 117, '4610426': 133, '4611640': 117, '4623143': 153, '4624663': 167}\n",
      "[0.16666666666666666, 0.5151515151515151, 0.5606060606060606, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.6829268292682927, 0.14285714285714285, 0.5833333333333334, 1.0, 0.2, 0.75, 0.5, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.16666666666666666, 0.5151515151515151, 0.5606060606060606, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.6829268292682927, 0.14285714285714285, 0.5833333333333334, 1.0, 0.2, 0.75, 0.5, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tf/directional_cnns/directional_cnns/groundtruth.py:200: RuntimeWarning: invalid value encountered in true_divide\n",
      "  acc1_hist_result = acc1_hist / acc1_hist_true\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4157075': 145, '4161667': 137, '4162259': 145, '4162274': 137, '4162405': 145, '4162511': 137, '4163571': 145, '4163572': 137, '4163586': 137, '4163587': 145, '4163588': 145, '4166222': 145, '4166612': 137, '4172572': 145, '4186191': 137, '4191591': 145, '4192452': 145, '4193623': 145, '4207348': 137, '4214761': 145, '4216184': 145, '4218466': 145, '4226166': 145, '4226227': 145, '4226434': 145, '4231951': 145, '4233696': 137, '4235798': 145, '4237913': 145, '4264210': 137, '4264359': 137, '4265125': 137, '426992': 145, '4275052': 145, '4279669': 145, '4283622': 145, '4283854': 145, '4284345': 145, '4288893': 145, '4297277': 145, '4300617': 137, '4300619': 145, '4301518': 145, '4304445': 145, '4313859': 145, '4315749': 145, '4323506': 145, '4325441': 145, '4331667': 145, '4332592': 145, '4346730': 145, '4353566': 137, '4358231': 137, '4360483': 145, '4360488': 145, '4365752': 145, '4366506': 158, '4372309': 137, '4377106': 145, '4381717': 145, '4386702': 137, '4397324': 145, '4397469': 145, '4398117': 145, '4399289': 145, '4403315': 137, '4403519': 137, '4404346': 150, '4407745': 145, '4409752': 145, '4411925': 145, '4416336': 145, '4416506': 145, '4416888': 145, '4416962': 145, '4418582': 145, '4419049': 137, '4420924': 145, '4426890': 137, '4427618': 145, '4442121': 137, '4446908': 145, '4457771': 145, '4459005': 145, '4459187': 137, '4460536': 137, '4468729': 145, '4469489': 145, '4469780': 145, '4471292': 145, '4471702': 145, '4473065': 137, '4474027': 145, '4474029': 145, '4475855': 145, '4480118': 137, '4480454': 145, '4483708': 137, '4486124': 145, '4486412': 145, '4489017': 137, '4493439': 145, '4494659': 145, '4495270': 145, '4497852': 145, '4508138': 137, '4509910': 145, '4512512': 145, '4514851': 137, '4517258': 145, '4532060': 145, '4540818': 145, '4543103': 137, '4547732': 145, '4549757': 137, '4558106': 145, '4559522': 137, '4565270': 137, '4566667': 137, '4567978': 148, '4567979': 137, '4585539': 145, '4586220': 145, '4593850': 137, '4596215': 145, '4604737': 145, '4609093': 145, '4609944': 145, '4610426': 145, '4611640': 145, '4623143': 137, '4624663': 145}\n",
      "[0.0, 0.12121212121212122, 0.12121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.25, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.12121212121212122, 0.12121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.25, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4157075': 161, '4161667': 146, '4162259': 161, '4162274': 113, '4162405': 161, '4162511': 122, '4163571': 146, '4163572': 113, '4163586': 122, '4163587': 161, '4163588': 146, '4166222': 146, '4166612': 122, '4172572': 161, '4186191': 140, '4191591': 161, '4192452': 161, '4193623': 161, '4207348': 122, '4214761': 161, '4216184': 161, '4218466': 161, '4226166': 161, '4226227': 161, '4226434': 161, '4231951': 161, '4233696': 127, '4235798': 161, '4237913': 161, '4264210': 113, '4264359': 122, '4265125': 113, '426992': 161, '4275052': 161, '4279669': 161, '4283622': 161, '4283854': 161, '4284345': 161, '4288893': 160, '4297277': 161, '4300617': 160, '4300619': 161, '4301518': 161, '4304445': 161, '4313859': 161, '4315749': 161, '4323506': 161, '4325441': 161, '4331667': 161, '4332592': 161, '4346730': 161, '4353566': 122, '4358231': 146, '4360483': 161, '4360488': 161, '4365752': 161, '4366506': 146, '4372309': 122, '4377106': 161, '4381717': 161, '4386702': 122, '4397324': 161, '4397469': 161, '4398117': 161, '4399289': 146, '4403315': 122, '4403519': 122, '4404346': 161, '4407745': 161, '4409752': 161, '4411925': 161, '4416336': 161, '4416506': 113, '4416888': 202, '4416962': 161, '4418582': 161, '4419049': 161, '4420924': 161, '4426890': 122, '4427618': 161, '4442121': 122, '4446908': 161, '4457771': 161, '4459005': 161, '4459187': 161, '4460536': 161, '4468729': 161, '4469489': 161, '4469780': 161, '4471292': 161, '4471702': 161, '4473065': 122, '4474027': 161, '4474029': 161, '4475855': 161, '4480118': 122, '4480454': 161, '4483708': 161, '4486124': 161, '4486412': 161, '4489017': 122, '4493439': 161, '4494659': 161, '4495270': 161, '4497852': 161, '4508138': 113, '4509910': 161, '4512512': 161, '4514851': 122, '4517258': 146, '4532060': 161, '4540818': 161, '4543103': 122, '4547732': 202, '4549757': 113, '4558106': 146, '4559522': 161, '4565270': 122, '4566667': 161, '4567978': 161, '4567979': 159, '4585539': 161, '4586220': 161, '4593850': 122, '4596215': 161, '4604737': 161, '4609093': 161, '4609944': 146, '4610426': 161, '4611640': 161, '4623143': 146, '4624663': 161}\n",
      "[0.0, 0.13636363636363635, 0.14393939393939395, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.2926829268292683, 0.0, 0.16666666666666666, 0.0, 0.8, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.13636363636363635, 0.14393939393939395, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.2926829268292683, 0.0, 0.16666666666666666, 0.0, 0.8, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4157075': 143, '4161667': 106, '4162259': 132, '4162274': 121, '4162405': 127, '4162511': 123, '4163571': 160, '4163572': 151, '4163586': 143, '4163587': 92, '4163588': 87, '4166222': 121, '4166612': 121, '4172572': 174, '4186191': 124, '4191591': 143, '4192452': 174, '4193623': 128, '4207348': 125, '4214761': 121, '4216184': 143, '4218466': 173, '4226166': 174, '4226227': 143, '4226434': 144, '4231951': 71, '4233696': 121, '4235798': 148, '4237913': 173, '4264210': 121, '4264359': 87, '4265125': 174, '426992': 173, '4275052': 124, '4279669': 173, '4283622': 124, '4283854': 174, '4284345': 143, '4288893': 114, '4297277': 143, '4300617': 128, '4300619': 132, '4301518': 174, '4304445': 180, '4313859': 87, '4315749': 128, '4323506': 143, '4325441': 127, '4331667': 174, '4332592': 127, '4346730': 174, '4353566': 121, '4358231': 132, '4360483': 174, '4360488': 174, '4365752': 87, '4366506': 192, '4372309': 121, '4377106': 145, '4381717': 145, '4386702': 126, '4397324': 174, '4397469': 87, '4398117': 173, '4399289': 174, '4403315': 143, '4403519': 124, '4404346': 186, '4407745': 124, '4409752': 174, '4411925': 174, '4416336': 173, '4416506': 142, '4416888': 90, '4416962': 132, '4418582': 173, '4419049': 143, '4420924': 142, '4426890': 106, '4427618': 121, '4442121': 125, '4446908': 171, '4457771': 148, '4459005': 173, '4459187': 128, '4460536': 141, '4468729': 162, '4469489': 174, '4469780': 75, '4471292': 174, '4471702': 174, '4473065': 121, '4474027': 87, '4474029': 174, '4475855': 69, '4480118': 30, '4480454': 171, '4483708': 139, '4486124': 173, '4486412': 140, '4489017': 173, '4493439': 143, '4494659': 128, '4495270': 160, '4497852': 75, '4508138': 124, '4509910': 143, '4512512': 128, '4514851': 75, '4517258': 85, '4532060': 167, '4540818': 124, '4543103': 128, '4547732': 174, '4549757': 87, '4558106': 127, '4559522': 134, '4565270': 121, '4566667': 128, '4567978': 75, '4567979': 75, '4585539': 143, '4586220': 87, '4593850': 125, '4596215': 121, '4604737': 124, '4609093': 69, '4609944': 157, '4610426': 143, '4611640': 121, '4623143': 151, '4624663': 162}\n",
      "[0.25, 0.7954545454545454, 0.9090909090909091, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.5714285714285714, 1.0, 1.0, -1.0, 0.8780487804878049, 0.7857142857142857, 0.4166666666666667, 1.0, 1.0, 0.84375, 0.5, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.25, 0.7954545454545454, 0.9090909090909091, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.5714285714285714, 1.0, 1.0, -1.0, 0.8780487804878049, 0.7857142857142857, 0.4166666666666667, 1.0, 1.0, 0.84375, 0.5, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4157075': 139, '4161667': 107, '4162259': 134, '4162274': 121, '4162405': 128, '4162511': 124, '4163571': 163, '4163572': 150, '4163586': 139, '4163587': 127, '4163588': 181, '4166222': 121, '4166612': 126, '4172572': 181, '4186191': 127, '4191591': 139, '4192452': 167, '4193623': 134, '4207348': 127, '4214761': 121, '4216184': 141, '4218466': 167, '4226166': 181, '4226227': 139, '4226434': 139, '4231951': 139, '4233696': 116, '4235798': 139, '4237913': 57, '4264210': 115, '4264359': 85, '4265125': 181, '426992': 85, '4275052': 127, '4279669': 164, '4283622': 128, '4283854': 181, '4284345': 139, '4288893': 115, '4297277': 141, '4300617': 128, '4300619': 134, '4301518': 181, '4304445': 181, '4313859': 177, '4315749': 128, '4323506': 139, '4325441': 128, '4331667': 181, '4332592': 128, '4346730': 180, '4353566': 116, '4358231': 136, '4360483': 181, '4360488': 181, '4365752': 181, '4366506': 101, '4372309': 127, '4377106': 139, '4381717': 139, '4386702': 128, '4397324': 167, '4397469': 181, '4398117': 181, '4399289': 181, '4403315': 141, '4403519': 127, '4404346': 181, '4407745': 128, '4409752': 167, '4411925': 181, '4416336': 181, '4416506': 148, '4416888': 181, '4416962': 139, '4418582': 167, '4419049': 141, '4420924': 70, '4426890': 109, '4427618': 121, '4442121': 127, '4446908': 167, '4457771': 139, '4459005': 167, '4459187': 128, '4460536': 139, '4468729': 163, '4469489': 181, '4469780': 107, '4471292': 177, '4471702': 181, '4473065': 121, '4474027': 167, '4474029': 181, '4475855': 70, '4480118': 30, '4480454': 167, '4483708': 139, '4486124': 167, '4486412': 139, '4489017': 177, '4493439': 141, '4494659': 130, '4495270': 163, '4497852': 147, '4508138': 57, '4509910': 139, '4512512': 128, '4514851': 148, '4517258': 167, '4532060': 167, '4540818': 124, '4543103': 130, '4547732': 181, '4549757': 181, '4558106': 109, '4559522': 134, '4565270': 121, '4566667': 134, '4567978': 147, '4567979': 147, '4585539': 139, '4586220': 85, '4593850': 128, '4596215': 121, '4604737': 115, '4609093': 70, '4609944': 57, '4610426': 139, '4611640': 115, '4623143': 148, '4624663': 167}\n",
      "[0.23484848484848486, 0.6287878787878788, 0.7121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.14285714285714285, 0.0, 1.0, -1.0, 0.7317073170731707, 0.8571428571428571, 0.8333333333333334, 1.0, 0.8, 0.28125, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.23484848484848486, 0.6287878787878788, 0.7121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.14285714285714285, 0.0, 1.0, -1.0, 0.7317073170731707, 0.8571428571428571, 0.8333333333333334, 1.0, 0.8, 0.28125, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4157075': 118, '4161667': 110, '4162259': 121, '4162274': 121, '4162405': 121, '4162511': 121, '4163571': 121, '4163572': 113, '4163586': 132, '4163587': 121, '4163588': 121, '4166222': 121, '4166612': 121, '4172572': 110, '4186191': 121, '4191591': 121, '4192452': 121, '4193623': 121, '4207348': 121, '4214761': 121, '4216184': 118, '4218466': 118, '4226166': 121, '4226227': 118, '4226434': 121, '4231951': 121, '4233696': 127, '4235798': 121, '4237913': 121, '4264210': 121, '4264359': 110, '4265125': 121, '426992': 114, '4275052': 118, '4279669': 118, '4283622': 118, '4283854': 118, '4284345': 118, '4288893': 110, '4297277': 121, '4300617': 121, '4300619': 121, '4301518': 121, '4304445': 118, '4313859': 121, '4315749': 118, '4323506': 130, '4325441': 118, '4331667': 114, '4332592': 121, '4346730': 121, '4353566': 121, '4358231': 121, '4360483': 114, '4360488': 114, '4365752': 114, '4366506': 110, '4372309': 121, '4377106': 121, '4381717': 118, '4386702': 113, '4397324': 121, '4397469': 118, '4398117': 110, '4399289': 110, '4403315': 132, '4403519': 121, '4404346': 110, '4407745': 121, '4409752': 118, '4411925': 114, '4416336': 121, '4416506': 30, '4416888': 118, '4416962': 118, '4418582': 121, '4419049': 132, '4420924': 118, '4426890': 121, '4427618': 121, '4442121': 113, '4446908': 121, '4457771': 118, '4459005': 121, '4459187': 121, '4460536': 132, '4468729': 129, '4469489': 121, '4469780': 121, '4471292': 118, '4471702': 121, '4473065': 113, '4474027': 118, '4474029': 114, '4475855': 121, '4480118': 113, '4480454': 118, '4483708': 121, '4486124': 118, '4486412': 130, '4489017': 121, '4493439': 130, '4494659': 121, '4495270': 118, '4497852': 131, '4508138': 30, '4509910': 118, '4512512': 121, '4514851': 109, '4517258': 92, '4532060': 114, '4540818': 121, '4543103': 121, '4547732': 110, '4549757': 98, '4558106': 121, '4559522': 121, '4565270': 121, '4566667': 118, '4567978': 131, '4567979': 130, '4585539': 130, '4586220': 121, '4593850': 121, '4596215': 121, '4604737': 118, '4609093': 121, '4609944': 121, '4610426': 121, '4611640': 118, '4623143': 130, '4624663': 121}\n",
      "[0.030303030303030304, 0.09848484848484848, 0.09848484848484848, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.5, -1.0, 0.2926829268292683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.030303030303030304, 0.09848484848484848, 0.09848484848484848, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.5, -1.0, 0.2926829268292683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4157075': 167, '4161667': 30, '4162259': 122, '4162274': 30, '4162405': 122, '4162511': 122, '4163571': 167, '4163572': 122, '4163586': 137, '4163587': 122, '4163588': 132, '4166222': 122, '4166612': 137, '4172572': 167, '4186191': 137, '4191591': 122, '4192452': 167, '4193623': 122, '4207348': 122, '4214761': 124, '4216184': 167, '4218466': 167, '4226166': 167, '4226227': 167, '4226434': 167, '4231951': 122, '4233696': 137, '4235798': 122, '4237913': 167, '4264210': 30, '4264359': 122, '4265125': 122, '426992': 167, '4275052': 167, '4279669': 167, '4283622': 122, '4283854': 167, '4284345': 122, '4288893': 30, '4297277': 122, '4300617': 122, '4300619': 122, '4301518': 167, '4304445': 167, '4313859': 167, '4315749': 167, '4323506': 167, '4325441': 122, '4331667': 167, '4332592': 122, '4346730': 122, '4353566': 137, '4358231': 167, '4360483': 167, '4360488': 167, '4365752': 167, '4366506': 122, '4372309': 137, '4377106': 122, '4381717': 167, '4386702': 137, '4397324': 167, '4397469': 167, '4398117': 167, '4399289': 124, '4403315': 137, '4403519': 30, '4404346': 167, '4407745': 122, '4409752': 167, '4411925': 167, '4416336': 122, '4416506': 30, '4416888': 167, '4416962': 167, '4418582': 167, '4419049': 137, '4420924': 167, '4426890': 137, '4427618': 122, '4442121': 137, '4446908': 167, '4457771': 167, '4459005': 167, '4459187': 122, '4460536': 132, '4468729': 167, '4469489': 122, '4469780': 150, '4471292': 167, '4471702': 122, '4473065': 122, '4474027': 167, '4474029': 167, '4475855': 122, '4480118': 30, '4480454': 167, '4483708': 132, '4486124': 167, '4486412': 122, '4489017': 132, '4493439': 167, '4494659': 122, '4495270': 167, '4497852': 167, '4508138': 137, '4509910': 167, '4512512': 122, '4514851': 122, '4517258': 122, '4532060': 167, '4540818': 122, '4543103': 137, '4547732': 167, '4549757': 132, '4558106': 122, '4559522': 122, '4565270': 137, '4566667': 122, '4567978': 122, '4567979': 122, '4585539': 167, '4586220': 124, '4593850': 122, '4596215': 132, '4604737': 167, '4609093': 167, '4609944': 137, '4610426': 167, '4611640': 167, '4623143': 122, '4624663': 167}\n",
      "[0.015151515151515152, 0.17424242424242425, 0.18181818181818182, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.3170731707317073, 0.10714285714285714, 0.08333333333333333, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.015151515151515152, 0.17424242424242425, 0.18181818181818182, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.3170731707317073, 0.10714285714285714, 0.08333333333333333, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4157075': 167, '4161667': 122, '4162259': 167, '4162274': 150, '4162405': 167, '4162511': 167, '4163571': 167, '4163572': 167, '4163586': 122, '4163587': 167, '4163588': 167, '4166222': 167, '4166612': 122, '4172572': 167, '4186191': 167, '4191591': 167, '4192452': 150, '4193623': 167, '4207348': 122, '4214761': 167, '4216184': 167, '4218466': 167, '4226166': 167, '4226227': 167, '4226434': 150, '4231951': 167, '4233696': 122, '4235798': 167, '4237913': 167, '4264210': 167, '4264359': 167, '4265125': 122, '426992': 167, '4275052': 167, '4279669': 167, '4283622': 167, '4283854': 167, '4284345': 167, '4288893': 167, '4297277': 167, '4300617': 167, '4300619': 167, '4301518': 167, '4304445': 167, '4313859': 167, '4315749': 167, '4323506': 167, '4325441': 167, '4331667': 150, '4332592': 167, '4346730': 167, '4353566': 167, '4358231': 167, '4360483': 167, '4360488': 167, '4365752': 150, '4366506': 167, '4372309': 167, '4377106': 167, '4381717': 167, '4386702': 122, '4397324': 167, '4397469': 167, '4398117': 167, '4399289': 167, '4403315': 122, '4403519': 167, '4404346': 167, '4407745': 150, '4409752': 167, '4411925': 167, '4416336': 167, '4416506': 167, '4416888': 167, '4416962': 167, '4418582': 167, '4419049': 167, '4420924': 167, '4426890': 167, '4427618': 167, '4442121': 167, '4446908': 167, '4457771': 167, '4459005': 167, '4459187': 167, '4460536': 167, '4468729': 167, '4469489': 167, '4469780': 150, '4471292': 167, '4471702': 167, '4473065': 167, '4474027': 167, '4474029': 167, '4475855': 150, '4480118': 150, '4480454': 167, '4483708': 167, '4486124': 167, '4486412': 167, '4489017': 167, '4493439': 167, '4494659': 167, '4495270': 167, '4497852': 167, '4508138': 167, '4509910': 167, '4512512': 167, '4514851': 167, '4517258': 122, '4532060': 167, '4540818': 167, '4543103': 167, '4547732': 150, '4549757': 122, '4558106': 167, '4559522': 167, '4565270': 122, '4566667': 167, '4567978': 150, '4567979': 150, '4585539': 167, '4586220': 167, '4593850': 167, '4596215': 167, '4604737': 167, '4609093': 167, '4609944': 167, '4610426': 167, '4611640': 167, '4623143': 167, '4624663': 167}\n",
      "[0.015151515151515152, 0.10606060606060606, 0.12878787878787878, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.12195121951219512, 0.0, 0.25, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.015151515151515152, 0.10606060606060606, 0.12878787878787878, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.12195121951219512, 0.0, 0.25, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4157075': 167, '4161667': 167, '4162259': 167, '4162274': 167, '4162405': 167, '4162511': 167, '4163571': 167, '4163572': 167, '4163586': 167, '4163587': 167, '4163588': 167, '4166222': 167, '4166612': 167, '4172572': 167, '4186191': 167, '4191591': 167, '4192452': 167, '4193623': 167, '4207348': 167, '4214761': 167, '4216184': 167, '4218466': 167, '4226166': 167, '4226227': 167, '4226434': 167, '4231951': 167, '4233696': 167, '4235798': 167, '4237913': 167, '4264210': 167, '4264359': 167, '4265125': 167, '426992': 167, '4275052': 167, '4279669': 167, '4283622': 167, '4283854': 167, '4284345': 167, '4288893': 167, '4297277': 167, '4300617': 167, '4300619': 167, '4301518': 167, '4304445': 167, '4313859': 167, '4315749': 167, '4323506': 167, '4325441': 167, '4331667': 167, '4332592': 167, '4346730': 167, '4353566': 167, '4358231': 167, '4360483': 167, '4360488': 167, '4365752': 167, '4366506': 167, '4372309': 167, '4377106': 167, '4381717': 167, '4386702': 167, '4397324': 167, '4397469': 167, '4398117': 167, '4399289': 167, '4403315': 167, '4403519': 167, '4404346': 167, '4407745': 167, '4409752': 167, '4411925': 167, '4416336': 167, '4416506': 167, '4416888': 167, '4416962': 167, '4418582': 167, '4419049': 167, '4420924': 167, '4426890': 167, '4427618': 167, '4442121': 167, '4446908': 167, '4457771': 167, '4459005': 167, '4459187': 167, '4460536': 167, '4468729': 167, '4469489': 167, '4469780': 167, '4471292': 167, '4471702': 167, '4473065': 167, '4474027': 167, '4474029': 167, '4475855': 167, '4480118': 167, '4480454': 167, '4483708': 167, '4486124': 167, '4486412': 167, '4489017': 167, '4493439': 167, '4494659': 167, '4495270': 167, '4497852': 167, '4508138': 139, '4509910': 167, '4512512': 167, '4514851': 167, '4517258': 167, '4532060': 167, '4540818': 167, '4543103': 167, '4547732': 167, '4549757': 167, '4558106': 167, '4559522': 167, '4565270': 167, '4566667': 167, '4567978': 167, '4567979': 167, '4585539': 167, '4586220': 167, '4593850': 167, '4596215': 167, '4604737': 167, '4609093': 167, '4609944': 167, '4610426': 167, '4611640': 167, '4623143': 167, '4624663': 167}\n",
      "[0.015151515151515152, 0.045454545454545456, 0.07575757575757576, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.015151515151515152, 0.045454545454545456, 0.07575757575757576, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.125, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4157075': 111, '4161667': 107, '4162259': 128, '4162274': 117, '4162405': 117, '4162511': 126, '4163571': 160, '4163572': 150, '4163586': 139, '4163587': 122, '4163588': 97, '4166222': 117, '4166612': 126, '4172572': 181, '4186191': 126, '4191591': 139, '4192452': 167, '4193623': 128, '4207348': 126, '4214761': 117, '4216184': 111, '4218466': 174, '4226166': 167, '4226227': 139, '4226434': 133, '4231951': 139, '4233696': 117, '4235798': 139, '4237913': 160, '4264210': 117, '4264359': 167, '4265125': 181, '426992': 167, '4275052': 122, '4279669': 167, '4283622': 122, '4283854': 174, '4284345': 139, '4288893': 117, '4297277': 139, '4300617': 126, '4300619': 126, '4301518': 167, '4304445': 174, '4313859': 181, '4315749': 117, '4323506': 139, '4325441': 117, '4331667': 167, '4332592': 117, '4346730': 167, '4353566': 117, '4358231': 126, '4360483': 174, '4360488': 167, '4365752': 167, '4366506': 112, '4372309': 126, '4377106': 111, '4381717': 139, '4386702': 126, '4397324': 167, '4397469': 167, '4398117': 181, '4399289': 181, '4403315': 133, '4403519': 117, '4404346': 97, '4407745': 126, '4409752': 167, '4411925': 174, '4416336': 111, '4416506': 117, '4416888': 184, '4416962': 111, '4418582': 174, '4419049': 139, '4420924': 150, '4426890': 108, '4427618': 117, '4442121': 126, '4446908': 167, '4457771': 111, '4459005': 167, '4459187': 117, '4460536': 122, '4468729': 160, '4469489': 181, '4469780': 111, '4471292': 167, '4471702': 174, '4473065': 117, '4474027': 174, '4474029': 167, '4475855': 139, '4480118': 30, '4480454': 167, '4483708': 139, '4486124': 181, '4486412': 139, '4489017': 111, '4493439': 139, '4494659': 126, '4495270': 160, '4497852': 111, '4508138': 181, '4509910': 139, '4512512': 126, '4514851': 156, '4517258': 167, '4532060': 167, '4540818': 122, '4543103': 126, '4547732': 167, '4549757': 94, '4558106': 117, '4559522': 117, '4565270': 126, '4566667': 126, '4567978': 150, '4567979': 150, '4585539': 139, '4586220': 87, '4593850': 126, '4596215': 117, '4604737': 122, '4609093': 117, '4609944': 139, '4610426': 139, '4611640': 117, '4623143': 139, '4624663': 181}\n",
      "[0.18181818181818182, 0.49242424242424243, 0.553030303030303, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.6341463414634146, 0.4642857142857143, 0.5833333333333334, 1.0, 0.8, 0.375, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.18181818181818182, 0.49242424242424243, 0.553030303030303, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 1.0, -1.0, 0.6341463414634146, 0.4642857142857143, 0.5833333333333334, 1.0, 0.8, 0.375, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4157075': 161, '4161667': 156, '4162259': 161, '4162274': 156, '4162405': 161, '4162511': 156, '4163571': 156, '4163572': 156, '4163586': 161, '4163587': 156, '4163588': 156, '4166222': 156, '4166612': 161, '4172572': 161, '4186191': 156, '4191591': 161, '4192452': 156, '4193623': 156, '4207348': 156, '4214761': 156, '4216184': 161, '4218466': 161, '4226166': 161, '4226227': 161, '4226434': 156, '4231951': 156, '4233696': 156, '4235798': 161, '4237913': 156, '4264210': 156, '4264359': 156, '4265125': 156, '426992': 156, '4275052': 161, '4279669': 156, '4283622': 161, '4283854': 161, '4284345': 161, '4288893': 156, '4297277': 161, '4300617': 156, '4300619': 156, '4301518': 161, '4304445': 161, '4313859': 161, '4315749': 161, '4323506': 161, '4325441': 161, '4331667': 161, '4332592': 161, '4346730': 156, '4353566': 156, '4358231': 161, '4360483': 161, '4360488': 161, '4365752': 156, '4366506': 156, '4372309': 156, '4377106': 161, '4381717': 161, '4386702': 156, '4397324': 161, '4397469': 161, '4398117': 156, '4399289': 156, '4403315': 161, '4403519': 156, '4404346': 156, '4407745': 156, '4409752': 161, '4411925': 161, '4416336': 161, '4416506': 156, '4416888': 156, '4416962': 161, '4418582': 161, '4419049': 161, '4420924': 161, '4426890': 156, '4427618': 161, '4442121': 161, '4446908': 161, '4457771': 161, '4459005': 156, '4459187': 156, '4460536': 161, '4468729': 161, '4469489': 161, '4469780': 161, '4471292': 161, '4471702': 161, '4473065': 156, '4474027': 161, '4474029': 161, '4475855': 161, '4480118': 156, '4480454': 161, '4483708': 156, '4486124': 161, '4486412': 133, '4489017': 156, '4493439': 161, '4494659': 161, '4495270': 156, '4497852': 161, '4508138': 156, '4509910': 161, '4512512': 156, '4514851': 156, '4517258': 156, '4532060': 161, '4540818': 161, '4543103': 156, '4547732': 156, '4549757': 156, '4558106': 161, '4559522': 161, '4565270': 156, '4566667': 161, '4567978': 161, '4567979': 161, '4585539': 161, '4586220': 156, '4593850': 161, '4596215': 156, '4604737': 161, '4609093': 156, '4609944': 156, '4610426': 161, '4611640': 161, '4623143': 161, '4624663': 156}\n",
      "[0.0, 0.022727272727272728, 0.022727272727272728, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.022727272727272728, 0.022727272727272728, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4157075': 167, '4161667': 167, '4162259': 167, '4162274': 167, '4162405': 167, '4162511': 167, '4163571': 167, '4163572': 167, '4163586': 167, '4163587': 167, '4163588': 167, '4166222': 167, '4166612': 167, '4172572': 167, '4186191': 167, '4191591': 167, '4192452': 30, '4193623': 167, '4207348': 167, '4214761': 30, '4216184': 167, '4218466': 167, '4226166': 167, '4226227': 167, '4226434': 167, '4231951': 167, '4233696': 167, '4235798': 30, '4237913': 30, '4264210': 167, '4264359': 167, '4265125': 167, '426992': 30, '4275052': 30, '4279669': 30, '4283622': 30, '4283854': 167, '4284345': 30, '4288893': 167, '4297277': 167, '4300617': 167, '4300619': 167, '4301518': 167, '4304445': 30, '4313859': 30, '4315749': 30, '4323506': 167, '4325441': 30, '4331667': 167, '4332592': 167, '4346730': 167, '4353566': 167, '4358231': 167, '4360483': 167, '4360488': 167, '4365752': 167, '4366506': 167, '4372309': 167, '4377106': 167, '4381717': 30, '4386702': 167, '4397324': 167, '4397469': 167, '4398117': 167, '4399289': 167, '4403315': 167, '4403519': 167, '4404346': 167, '4407745': 30, '4409752': 167, '4411925': 167, '4416336': 167, '4416506': 167, '4416888': 167, '4416962': 30, '4418582': 167, '4419049': 167, '4420924': 30, '4426890': 167, '4427618': 167, '4442121': 167, '4446908': 167, '4457771': 30, '4459005': 30, '4459187': 167, '4460536': 167, '4468729': 30, '4469489': 167, '4469780': 167, '4471292': 167, '4471702': 167, '4473065': 167, '4474027': 30, '4474029': 167, '4475855': 167, '4480118': 167, '4480454': 167, '4483708': 167, '4486124': 30, '4486412': 30, '4489017': 167, '4493439': 167, '4494659': 167, '4495270': 167, '4497852': 167, '4508138': 167, '4509910': 167, '4512512': 167, '4514851': 167, '4517258': 167, '4532060': 167, '4540818': 167, '4543103': 167, '4547732': 167, '4549757': 167, '4558106': 167, '4559522': 167, '4565270': 145, '4566667': 167, '4567978': 167, '4567979': 167, '4585539': 167, '4586220': 167, '4593850': 167, '4596215': 167, '4604737': 30, '4609093': 167, '4609944': 167, '4610426': 167, '4611640': 30, '4623143': 167, '4624663': 30}\n",
      "[0.0, 0.022727272727272728, 0.05303030303030303, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.022727272727272728, 0.05303030303030303, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09375, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4157075': 128, '4161667': 116, '4162259': 128, '4162274': 118, '4162405': 123, '4162511': 123, '4163571': 153, '4163572': 150, '4163586': 128, '4163587': 209, '4163588': 195, '4166222': 209, '4166612': 126, '4172572': 177, '4186191': 126, '4191591': 139, '4192452': 167, '4193623': 126, '4207348': 126, '4214761': 122, '4216184': 133, '4218466': 167, '4226166': 195, '4226227': 128, '4226434': 128, '4231951': 133, '4233696': 116, '4235798': 139, '4237913': 167, '4264210': 116, '4264359': 88, '4265125': 195, '426992': 167, '4275052': 122, '4279669': 167, '4283622': 123, '4283854': 209, '4284345': 139, '4288893': 117, '4297277': 133, '4300617': 123, '4300619': 126, '4301518': 167, '4304445': 167, '4313859': 167, '4315749': 209, '4323506': 128, '4325441': 123, '4331667': 167, '4332592': 128, '4346730': 195, '4353566': 116, '4358231': 126, '4360483': 167, '4360488': 177, '4365752': 195, '4366506': 99, '4372309': 126, '4377106': 128, '4381717': 139, '4386702': 126, '4397324': 167, '4397469': 167, '4398117': 195, '4399289': 195, '4403315': 133, '4403519': 209, '4404346': 99, '4407745': 126, '4409752': 167, '4411925': 167, '4416336': 195, '4416506': 108, '4416888': 195, '4416962': 128, '4418582': 167, '4419049': 133, '4420924': 128, '4426890': 116, '4427618': 123, '4442121': 126, '4446908': 167, '4457771': 139, '4459005': 167, '4459187': 126, '4460536': 133, '4468729': 153, '4469489': 195, '4469780': 145, '4471292': 167, '4471702': 167, '4473065': 118, '4474027': 209, '4474029': 177, '4475855': 133, '4480118': 99, '4480454': 167, '4483708': 128, '4486124': 167, '4486412': 133, '4489017': 195, '4493439': 133, '4494659': 123, '4495270': 153, '4497852': 145, '4508138': 99, '4509910': 128, '4512512': 126, '4514851': 153, '4517258': 83, '4532060': 167, '4540818': 123, '4543103': 126, '4547732': 88, '4549757': 177, '4558106': 209, '4559522': 209, '4565270': 123, '4566667': 126, '4567978': 153, '4567979': 145, '4585539': 139, '4586220': 167, '4593850': 126, '4596215': 118, '4604737': 128, '4609093': 128, '4609944': 139, '4610426': 128, '4611640': 122, '4623143': 156, '4624663': 167}\n",
      "[0.07575757575757576, 0.3939393939393939, 0.4166666666666667, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.2857142857142857, 0.0, 0.0, -1.0, 0.6341463414634146, 0.2857142857142857, 0.3333333333333333, 1.0, 0.4, 0.25, 0.5, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.07575757575757576, 0.3939393939393939, 0.4166666666666667, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.2857142857142857, 0.0, 0.0, -1.0, 0.6341463414634146, 0.2857142857142857, 0.3333333333333333, 1.0, 0.4, 0.25, 0.5, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4157075': 117, '4161667': 132, '4162259': 117, '4162274': 132, '4162405': 117, '4162511': 131, '4163571': 131, '4163572': 131, '4163586': 117, '4163587': 117, '4163588': 132, '4166222': 132, '4166612': 132, '4172572': 132, '4186191': 132, '4191591': 117, '4192452': 108, '4193623': 117, '4207348': 131, '4214761': 117, '4216184': 117, '4218466': 117, '4226166': 132, '4226227': 117, '4226434': 131, '4231951': 117, '4233696': 131, '4235798': 117, '4237913': 132, '4264210': 132, '4264359': 132, '4265125': 132, '426992': 108, '4275052': 117, '4279669': 112, '4283622': 117, '4283854': 117, '4284345': 117, '4288893': 132, '4297277': 117, '4300617': 132, '4300619': 117, '4301518': 117, '4304445': 117, '4313859': 117, '4315749': 108, '4323506': 117, '4325441': 117, '4331667': 117, '4332592': 132, '4346730': 132, '4353566': 132, '4358231': 117, '4360483': 117, '4360488': 117, '4365752': 117, '4366506': 132, '4372309': 132, '4377106': 117, '4381717': 108, '4386702': 131, '4397324': 117, '4397469': 117, '4398117': 117, '4399289': 132, '4403315': 132, '4403519': 132, '4404346': 117, '4407745': 117, '4409752': 117, '4411925': 117, '4416336': 117, '4416506': 132, '4416888': 117, '4416962': 112, '4418582': 117, '4419049': 132, '4420924': 117, '4426890': 132, '4427618': 117, '4442121': 131, '4446908': 117, '4457771': 117, '4459005': 117, '4459187': 117, '4460536': 131, '4468729': 108, '4469489': 132, '4469780': 117, '4471292': 112, '4471702': 117, '4473065': 132, '4474027': 117, '4474029': 117, '4475855': 117, '4480118': 132, '4480454': 117, '4483708': 117, '4486124': 108, '4486412': 117, '4489017': 117, '4493439': 132, '4494659': 117, '4495270': 131, '4497852': 117, '4508138': 131, '4509910': 117, '4512512': 117, '4514851': 132, '4517258': 132, '4532060': 117, '4540818': 117, '4543103': 132, '4547732': 117, '4549757': 132, '4558106': 132, '4559522': 117, '4565270': 131, '4566667': 117, '4567978': 117, '4567979': 117, '4585539': 117, '4586220': 117, '4593850': 132, '4596215': 132, '4604737': 117, '4609093': 117, '4609944': 132, '4610426': 117, '4611640': 117, '4623143': 117, '4624663': 117}\n",
      "[0.007575757575757576, 0.11363636363636363, 0.11363636363636363, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.34146341463414637, 0.03571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.007575757575757576, 0.11363636363636363, 0.11363636363636363, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.34146341463414637, 0.03571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_val.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4157075': 156, '4161667': 156, '4162259': 156, '4162274': 156, '4162405': 156, '4162511': 156, '4163571': 156, '4163572': 156, '4163586': 156, '4163587': 156, '4163588': 156, '4166222': 30, '4166612': 156, '4172572': 156, '4186191': 30, '4191591': 156, '4192452': 156, '4193623': 30, '4207348': 156, '4214761': 156, '4216184': 156, '4218466': 156, '4226166': 156, '4226227': 156, '4226434': 156, '4231951': 156, '4233696': 30, '4235798': 156, '4237913': 30, '4264210': 30, '4264359': 156, '4265125': 156, '426992': 156, '4275052': 156, '4279669': 156, '4283622': 156, '4283854': 156, '4284345': 156, '4288893': 156, '4297277': 156, '4300617': 156, '4300619': 156, '4301518': 156, '4304445': 156, '4313859': 156, '4315749': 156, '4323506': 156, '4325441': 156, '4331667': 156, '4332592': 156, '4346730': 156, '4353566': 30, '4358231': 156, '4360483': 156, '4360488': 156, '4365752': 156, '4366506': 156, '4372309': 30, '4377106': 156, '4381717': 156, '4386702': 156, '4397324': 156, '4397469': 156, '4398117': 156, '4399289': 156, '4403315': 30, '4403519': 156, '4404346': 156, '4407745': 156, '4409752': 156, '4411925': 156, '4416336': 156, '4416506': 30, '4416888': 156, '4416962': 156, '4418582': 156, '4419049': 156, '4420924': 156, '4426890': 156, '4427618': 156, '4442121': 156, '4446908': 156, '4457771': 156, '4459005': 156, '4459187': 156, '4460536': 156, '4468729': 156, '4469489': 156, '4469780': 156, '4471292': 156, '4471702': 156, '4473065': 156, '4474027': 156, '4474029': 156, '4475855': 156, '4480118': 156, '4480454': 156, '4483708': 156, '4486124': 156, '4486412': 156, '4489017': 156, '4493439': 156, '4494659': 156, '4495270': 156, '4497852': 156, '4508138': 30, '4509910': 156, '4512512': 156, '4514851': 156, '4517258': 156, '4532060': 156, '4540818': 156, '4543103': 156, '4547732': 156, '4549757': 156, '4558106': 156, '4559522': 156, '4565270': 156, '4566667': 156, '4567978': 156, '4567979': 156, '4585539': 156, '4586220': 30, '4593850': 156, '4596215': 156, '4604737': 156, '4609093': 156, '4609944': 30, '4610426': 156, '4611640': 156, '4623143': 156, '4624663': 30}\n",
      "[0.0, 0.022727272727272728, 0.022727272727272728, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.022727272727272728, 0.022727272727272728, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "----------\n",
      "test.tsv\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4631727': 147, '4633603': 145, '4650113': 117, '4653852': 139, '4661735': 167, '4666231': 174, '4667626': 147, '4671406': 126, '4671443': 150, '4677606': 141, '4678080': 174, '4693039': 133, '4693198': 126, '4694833': 146, '4696505': 167, '4703149': 108, '4710576': 174, '4711578': 174, '4714481': 114, '4723905': 133, '4735587': 145, '4735758': 133, '4743012': 126, '4749611': 122, '4767260': 174, '4772658': 119, '4773857': 139, '4773948': 133, '4800274': 133, '4800275': 103, '4810810': 134, '4816604': 146, '4823439': 146, '4823611': 126, '4826952': 133, '4826957': 138, '4827285': 174, '4827287': 150, '4845088': 181, '4850346': 120, '4853692': 126, '4860099': 70, '4861484': 174, '4863146': 112, '4875475': 117, '4884993': 174, '4896659': 167, '4899365': 181, '4921810': 133, '4936740': 133, '4937390': 133, '4947281': 129, '4951739': 181, '4955051': 133, '4955053': 133, '4960424': 167, '4969415': 117, '4984238': 147, '4993934': 145, '5024644': 133, '5039329': 181, '5051606': 120, '5068771': 174, '5070846': 112, '5073839': 174, '5076753': 133, '5076821': 167, '5078640': 167, '5079918': 133, '5081990': 174, '5089294': 167, '5102537': 122, '5117279': 121, '5118757': 141, '5135326': 126, '5137153': 122, '5137154': 122, '5137157': 117, '5137158': 122, '5143186': 133, '5157605': 131, '5160584': 126, '5162042': 167, '5171396': 174, '5195826': 167, '5202182': 133, '5204781': 122, '5213896': 174, '5214265': 119, '5214755': 174, '5214943': 147, '5237462': 117, '5248391': 133, '5258365': 150, '5261461': 174, '5268098': 126, '5294335': 122, '5302339': 174, '5314439': 147, '5315510': 133, '5335389': 141, '5345058': 147, '5347155': 114, '5355157': 167, '5356489': 133, '5363251': 133, '536656': 131, '5377710': 120, '5406759': 126, '5431709': 117, '547692': 174, '587794': 139, '633082': 126, '672063': 117, '672064': 181, '691688': 141, '691694': 146, '710469': 167, '750132': 131, '825292': 133, '861484': 167, '906680': 167, '906681': 167, '906760': 132, '907836': 181, '907837': 174, '925895': 133, '942357': 174, '94350': 153, '956606': 126, '986931': 139, '989704': 174}\n",
      "[0.19696969696969696, 0.5757575757575758, 0.6212121212121212, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.9090909090909091, 0.2777777777777778, 0.6470588235294118, 0.5, 0.4, 0.7575757575757576, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.19696969696969696, 0.5757575757575758, 0.6212121212121212, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.9090909090909091, 0.2777777777777778, 0.6470588235294118, 0.5, 0.4, 0.7575757575757576, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4631727': 148, '4633603': 145, '4650113': 137, '4653852': 145, '4661735': 145, '4666231': 145, '4667626': 145, '4671406': 137, '4671443': 145, '4677606': 148, '4678080': 145, '4693039': 145, '4693198': 137, '4694833': 148, '4696505': 145, '4703149': 145, '4710576': 145, '4711578': 145, '4714481': 137, '4723905': 137, '4735587': 145, '4735758': 145, '4743012': 137, '4749611': 145, '4767260': 145, '4772658': 137, '4773857': 137, '4773948': 145, '4800274': 137, '4800275': 137, '4810810': 145, '4816604': 145, '4823439': 145, '4823611': 137, '4826952': 145, '4826957': 145, '4827285': 145, '4827287': 148, '4845088': 145, '4850346': 145, '4853692': 137, '4860099': 145, '4861484': 145, '4863146': 145, '4875475': 145, '4884993': 145, '4896659': 137, '4899365': 137, '4921810': 145, '4936740': 145, '4937390': 145, '4947281': 137, '4951739': 137, '4955051': 145, '4955053': 145, '4960424': 145, '4969415': 137, '4984238': 137, '4993934': 145, '5024644': 145, '5039329': 145, '5051606': 145, '5068771': 145, '5070846': 137, '5073839': 145, '5076753': 137, '5076821': 145, '5078640': 137, '5079918': 145, '5081990': 137, '5089294': 145, '5102537': 137, '5117279': 137, '5118757': 137, '5135326': 137, '5137153': 137, '5137154': 137, '5137157': 145, '5137158': 145, '5143186': 145, '5157605': 137, '5160584': 137, '5162042': 145, '5171396': 145, '5195826': 145, '5202182': 145, '5204781': 137, '5213896': 145, '5214265': 137, '5214755': 137, '5214943': 145, '5237462': 137, '5248391': 137, '5258365': 145, '5261461': 145, '5268098': 137, '5294335': 137, '5302339': 145, '5314439': 148, '5315510': 145, '5335389': 150, '5345058': 148, '5347155': 145, '5355157': 145, '5356489': 145, '5363251': 145, '536656': 137, '5377710': 145, '5406759': 137, '5431709': 137, '547692': 145, '587794': 145, '633082': 137, '672063': 137, '672064': 145, '691688': 145, '691694': 145, '710469': 145, '750132': 137, '825292': 145, '861484': 145, '906680': 145, '906681': 145, '906760': 137, '907836': 145, '907837': 145, '925895': 137, '942357': 145, '94350': 145, '956606': 137, '986931': 145, '989704': 145}\n",
      "[0.0, 0.2196969696969697, 0.23484848484848486, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2777777777777778, 1.0, 0.5, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.2196969696969697, 0.23484848484848486, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2777777777777778, 1.0, 0.5, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4631727': 161, '4633603': 161, '4650113': 113, '4653852': 161, '4661735': 161, '4666231': 161, '4667626': 161, '4671406': 122, '4671443': 161, '4677606': 161, '4678080': 161, '4693039': 161, '4693198': 122, '4694833': 161, '4696505': 161, '4703149': 180, '4710576': 161, '4711578': 161, '4714481': 146, '4723905': 161, '4735587': 161, '4735758': 161, '4743012': 122, '4749611': 161, '4767260': 161, '4772658': 146, '4773857': 159, '4773948': 161, '4800274': 159, '4800275': 180, '4810810': 161, '4816604': 161, '4823439': 161, '4823611': 129, '4826952': 161, '4826957': 161, '4827285': 161, '4827287': 161, '4845088': 161, '4850346': 122, '4853692': 122, '4860099': 161, '4861484': 161, '4863146': 161, '4875475': 161, '4884993': 161, '4896659': 170, '4899365': 146, '4921810': 161, '4936740': 161, '4937390': 161, '4947281': 161, '4951739': 113, '4955051': 161, '4955053': 161, '4960424': 146, '4969415': 161, '4984238': 113, '4993934': 161, '5024644': 161, '5039329': 161, '5051606': 161, '5068771': 161, '5070846': 161, '5073839': 161, '5076753': 161, '5076821': 170, '5078640': 161, '5079918': 161, '5081990': 113, '5089294': 161, '5102537': 122, '5117279': 127, '5118757': 122, '5135326': 113, '5137153': 159, '5137154': 122, '5137157': 161, '5137158': 146, '5143186': 161, '5157605': 113, '5160584': 122, '5162042': 161, '5171396': 161, '5195826': 161, '5202182': 161, '5204781': 122, '5213896': 161, '5214265': 129, '5214755': 146, '5214943': 161, '5237462': 122, '5248391': 159, '5258365': 161, '5261461': 161, '5268098': 161, '5294335': 159, '5302339': 161, '5314439': 161, '5315510': 161, '5335389': 161, '5345058': 161, '5347155': 161, '5355157': 170, '5356489': 161, '5363251': 161, '536656': 122, '5377710': 161, '5406759': 161, '5431709': 122, '547692': 161, '587794': 161, '633082': 127, '672063': 161, '672064': 161, '691688': 161, '691694': 161, '710469': 161, '750132': 161, '825292': 161, '861484': 161, '906680': 161, '906681': 161, '906760': 113, '907836': 161, '907837': 161, '925895': 146, '942357': 161, '94350': 161, '956606': 122, '986931': 161, '989704': 161}\n",
      "[0.007575757575757576, 0.15151515151515152, 0.1590909090909091, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.5454545454545454, 0.0, 0.0, 0.25, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.007575757575757576, 0.15151515151515152, 0.1590909090909091, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.5454545454545454, 0.0, 0.0, 0.25, 1.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4631727': 75, '4633603': 70, '4650113': 121, '4653852': 139, '4661735': 160, '4666231': 174, '4667626': 75, '4671406': 124, '4671443': 151, '4677606': 141, '4678080': 173, '4693039': 143, '4693198': 125, '4694833': 141, '4696505': 157, '4703149': 142, '4710576': 174, '4711578': 173, '4714481': 114, '4723905': 143, '4735587': 144, '4735758': 143, '4743012': 124, '4749611': 127, '4767260': 174, '4772658': 121, '4773857': 70, '4773948': 143, '4800274': 144, '4800275': 71, '4810810': 143, '4816604': 138, '4823439': 141, '4823611': 128, '4826952': 141, '4826957': 143, '4827285': 174, '4827287': 75, '4845088': 87, '4850346': 121, '4853692': 128, '4860099': 70, '4861484': 174, '4863146': 111, '4875475': 121, '4884993': 174, '4896659': 174, '4899365': 173, '4921810': 143, '4936740': 138, '4937390': 143, '4947281': 136, '4951739': 87, '4955051': 141, '4955053': 143, '4960424': 173, '4969415': 121, '4984238': 82, '4993934': 141, '5024644': 143, '5039329': 86, '5051606': 127, '5068771': 87, '5070846': 111, '5073839': 174, '5076753': 143, '5076821': 173, '5078640': 171, '5079918': 143, '5081990': 87, '5089294': 174, '5102537': 121, '5117279': 121, '5118757': 143, '5135326': 132, '5137153': 151, '5137154': 157, '5137157': 162, '5137158': 69, '5143186': 143, '5157605': 132, '5160584': 128, '5162042': 174, '5171396': 174, '5195826': 174, '5202182': 141, '5204781': 121, '5213896': 174, '5214265': 121, '5214755': 173, '5214943': 74, '5237462': 121, '5248391': 144, '5258365': 75, '5261461': 174, '5268098': 124, '5294335': 124, '5302339': 162, '5314439': 75, '5315510': 143, '5335389': 141, '5345058': 75, '5347155': 173, '5355157': 85, '5356489': 141, '5363251': 143, '536656': 138, '5377710': 128, '5406759': 124, '5431709': 85, '547692': 167, '587794': 143, '633082': 126, '672063': 174, '672064': 174, '691688': 141, '691694': 141, '710469': 156, '750132': 132, '825292': 143, '861484': 173, '906680': 167, '906681': 171, '906760': 30, '907836': 174, '907837': 174, '925895': 138, '942357': 87, '94350': 150, '956606': 124, '986931': 143, '989704': 174}\n",
      "[0.24242424242424243, 0.803030303030303, 0.946969696969697, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.7142857142857143, 1.0, 0.8055555555555556, 0.5882352941176471, 0.75, 0.8, 0.8787878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.24242424242424243, 0.803030303030303, 0.946969696969697, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.7142857142857143, 1.0, 0.8055555555555556, 0.5882352941176471, 0.75, 0.8, 0.8787878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4631727': 147, '4633603': 70, '4650113': 115, '4653852': 70, '4661735': 163, '4666231': 181, '4667626': 147, '4671406': 127, '4671443': 148, '4677606': 141, '4678080': 167, '4693039': 141, '4693198': 126, '4694833': 141, '4696505': 163, '4703149': 109, '4710576': 181, '4711578': 167, '4714481': 109, '4723905': 141, '4735587': 139, '4735758': 141, '4743012': 127, '4749611': 130, '4767260': 181, '4772658': 116, '4773857': 70, '4773948': 139, '4800274': 139, '4800275': 139, '4810810': 139, '4816604': 70, '4823439': 139, '4823611': 127, '4826952': 141, '4826957': 139, '4827285': 174, '4827287': 160, '4845088': 181, '4850346': 121, '4853692': 127, '4860099': 70, '4861484': 167, '4863146': 109, '4875475': 115, '4884993': 181, '4896659': 167, '4899365': 177, '4921810': 139, '4936740': 139, '4937390': 139, '4947281': 139, '4951739': 85, '4955051': 139, '4955053': 139, '4960424': 177, '4969415': 115, '4984238': 109, '4993934': 141, '5024644': 139, '5039329': 181, '5051606': 128, '5068771': 181, '5070846': 109, '5073839': 181, '5076753': 141, '5076821': 167, '5078640': 167, '5079918': 141, '5081990': 85, '5089294': 167, '5102537': 121, '5117279': 121, '5118757': 141, '5135326': 132, '5137153': 57, '5137154': 148, '5137157': 163, '5137158': 148, '5143186': 141, '5157605': 67, '5160584': 128, '5162042': 167, '5171396': 181, '5195826': 181, '5202182': 139, '5204781': 121, '5213896': 181, '5214265': 116, '5214755': 174, '5214943': 76, '5237462': 116, '5248391': 139, '5258365': 147, '5261461': 181, '5268098': 127, '5294335': 124, '5302339': 167, '5314439': 147, '5315510': 141, '5335389': 139, '5345058': 147, '5347155': 167, '5355157': 85, '5356489': 141, '5363251': 141, '536656': 139, '5377710': 128, '5406759': 128, '5431709': 167, '547692': 167, '587794': 139, '633082': 128, '672063': 181, '672064': 181, '691688': 141, '691694': 141, '710469': 158, '750132': 134, '825292': 139, '861484': 167, '906680': 167, '906681': 181, '906760': 57, '907836': 167, '907837': 167, '925895': 139, '942357': 85, '94350': 147, '956606': 127, '986931': 139, '989704': 181}\n",
      "[0.21212121212121213, 0.6515151515151515, 0.7348484848484849, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.8571428571428571, 0.7727272727272727, 0.7777777777777778, 0.9411764705882353, 0.75, 0.8, 0.2727272727272727, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.21212121212121213, 0.6515151515151515, 0.7348484848484849, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.8571428571428571, 0.7727272727272727, 0.7777777777777778, 0.9411764705882353, 0.75, 0.8, 0.2727272727272727, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4631727': 132, '4633603': 118, '4650113': 121, '4653852': 121, '4661735': 121, '4666231': 118, '4667626': 130, '4671406': 121, '4671443': 121, '4677606': 130, '4678080': 118, '4693039': 121, '4693198': 113, '4694833': 124, '4696505': 121, '4703149': 118, '4710576': 118, '4711578': 118, '4714481': 113, '4723905': 130, '4735587': 130, '4735758': 118, '4743012': 121, '4749611': 113, '4767260': 114, '4772658': 121, '4773857': 130, '4773948': 118, '4800274': 130, '4800275': 121, '4810810': 118, '4816604': 118, '4823439': 118, '4823611': 121, '4826952': 118, '4826957': 118, '4827285': 114, '4827287': 124, '4845088': 121, '4850346': 121, '4853692': 121, '4860099': 121, '4861484': 121, '4863146': 121, '4875475': 118, '4884993': 121, '4896659': 121, '4899365': 121, '4921810': 118, '4936740': 121, '4937390': 121, '4947281': 121, '4951739': 98, '4955051': 118, '4955053': 118, '4960424': 110, '4969415': 121, '4984238': 121, '4993934': 121, '5024644': 121, '5039329': 121, '5051606': 118, '5068771': 121, '5070846': 121, '5073839': 118, '5076753': 121, '5076821': 110, '5078640': 157, '5079918': 130, '5081990': 110, '5089294': 121, '5102537': 121, '5117279': 121, '5118757': 126, '5135326': 121, '5137153': 113, '5137154': 113, '5137157': 121, '5137158': 113, '5143186': 121, '5157605': 121, '5160584': 127, '5162042': 114, '5171396': 121, '5195826': 114, '5202182': 118, '5204781': 113, '5213896': 118, '5214265': 121, '5214755': 118, '5214943': 121, '5237462': 121, '5248391': 121, '5258365': 130, '5261461': 118, '5268098': 121, '5294335': 121, '5302339': 121, '5314439': 130, '5315510': 121, '5335389': 110, '5345058': 124, '5347155': 121, '5355157': 92, '5356489': 121, '5363251': 118, '536656': 113, '5377710': 118, '5406759': 121, '5431709': 116, '547692': 118, '587794': 118, '633082': 127, '672063': 121, '672064': 118, '691688': 118, '691694': 121, '710469': 118, '750132': 121, '825292': 121, '861484': 174, '906680': 118, '906681': 114, '906760': 30, '907836': 121, '907837': 118, '925895': 121, '942357': 113, '94350': 130, '956606': 121, '986931': 130, '989704': 114}\n",
      "[0.05303030303030303, 0.10606060606060606, 0.10606060606060606, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.45454545454545453, 0.0, 0.0, 0.0, 0.0, 0.030303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.05303030303030303, 0.10606060606060606, 0.10606060606060606, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.45454545454545453, 0.0, 0.0, 0.0, 0.0, 0.030303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4631727': 124, '4633603': 167, '4650113': 122, '4653852': 167, '4661735': 122, '4666231': 167, '4667626': 122, '4671406': 137, '4671443': 122, '4677606': 122, '4678080': 167, '4693039': 132, '4693198': 137, '4694833': 167, '4696505': 122, '4703149': 167, '4710576': 167, '4711578': 167, '4714481': 122, '4723905': 167, '4735587': 167, '4735758': 122, '4743012': 137, '4749611': 122, '4767260': 167, '4772658': 122, '4773857': 167, '4773948': 167, '4800274': 167, '4800275': 167, '4810810': 167, '4816604': 167, '4823439': 167, '4823611': 122, '4826952': 167, '4826957': 167, '4827285': 167, '4827287': 167, '4845088': 132, '4850346': 122, '4853692': 137, '4860099': 124, '4861484': 122, '4863146': 122, '4875475': 167, '4884993': 167, '4896659': 122, '4899365': 167, '4921810': 167, '4936740': 167, '4937390': 122, '4947281': 122, '4951739': 137, '4955051': 122, '4955053': 122, '4960424': 167, '4969415': 122, '4984238': 122, '4993934': 167, '5024644': 122, '5039329': 167, '5051606': 150, '5068771': 167, '5070846': 122, '5073839': 167, '5076753': 124, '5076821': 30, '5078640': 122, '5079918': 167, '5081990': 137, '5089294': 167, '5102537': 122, '5117279': 137, '5118757': 137, '5135326': 122, '5137153': 30, '5137154': 137, '5137157': 137, '5137158': 30, '5143186': 122, '5157605': 137, '5160584': 137, '5162042': 167, '5171396': 122, '5195826': 167, '5202182': 167, '5204781': 30, '5213896': 167, '5214265': 137, '5214755': 167, '5214943': 122, '5237462': 132, '5248391': 122, '5258365': 122, '5261461': 167, '5268098': 132, '5294335': 124, '5302339': 122, '5314439': 132, '5315510': 122, '5335389': 167, '5345058': 132, '5347155': 122, '5355157': 30, '5356489': 122, '5363251': 122, '536656': 137, '5377710': 150, '5406759': 122, '5431709': 137, '547692': 167, '587794': 167, '633082': 137, '672063': 167, '672064': 167, '691688': 167, '691694': 122, '710469': 167, '750132': 122, '825292': 122, '861484': 167, '906680': 167, '906681': 167, '906760': 30, '907836': 167, '907837': 167, '925895': 30, '942357': 167, '94350': 167, '956606': 122, '986931': 167, '989704': 167}\n",
      "[0.0, 0.17424242424242425, 0.17424242424242425, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45454545454545453, 0.1111111111111111, 0.0, 0.0, 0.0, 0.2727272727272727, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.17424242424242425, 0.17424242424242425, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.45454545454545453, 0.1111111111111111, 0.0, 0.0, 0.0, 0.2727272727272727, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4631727': 150, '4633603': 150, '4650113': 167, '4653852': 167, '4661735': 167, '4666231': 167, '4667626': 167, '4671406': 167, '4671443': 167, '4677606': 167, '4678080': 167, '4693039': 167, '4693198': 167, '4694833': 167, '4696505': 122, '4703149': 150, '4710576': 167, '4711578': 167, '4714481': 167, '4723905': 167, '4735587': 167, '4735758': 167, '4743012': 122, '4749611': 167, '4767260': 167, '4772658': 167, '4773857': 167, '4773948': 167, '4800274': 150, '4800275': 122, '4810810': 167, '4816604': 167, '4823439': 167, '4823611': 167, '4826952': 167, '4826957': 167, '4827285': 167, '4827287': 167, '4845088': 167, '4850346': 122, '4853692': 122, '4860099': 150, '4861484': 167, '4863146': 167, '4875475': 167, '4884993': 167, '4896659': 122, '4899365': 167, '4921810': 150, '4936740': 150, '4937390': 167, '4947281': 167, '4951739': 122, '4955051': 167, '4955053': 167, '4960424': 167, '4969415': 167, '4984238': 122, '4993934': 167, '5024644': 167, '5039329': 167, '5051606': 167, '5068771': 167, '5070846': 167, '5073839': 167, '5076753': 167, '5076821': 167, '5078640': 167, '5079918': 167, '5081990': 167, '5089294': 167, '5102537': 167, '5117279': 122, '5118757': 139, '5135326': 167, '5137153': 122, '5137154': 167, '5137157': 122, '5137158': 167, '5143186': 167, '5157605': 167, '5160584': 122, '5162042': 167, '5171396': 167, '5195826': 167, '5202182': 167, '5204781': 167, '5213896': 150, '5214265': 122, '5214755': 167, '5214943': 167, '5237462': 167, '5248391': 167, '5258365': 167, '5261461': 167, '5268098': 122, '5294335': 122, '5302339': 167, '5314439': 167, '5315510': 167, '5335389': 167, '5345058': 167, '5347155': 167, '5355157': 167, '5356489': 167, '5363251': 167, '536656': 167, '5377710': 167, '5406759': 167, '5431709': 122, '547692': 167, '587794': 167, '633082': 122, '672063': 167, '672064': 167, '691688': 167, '691694': 167, '710469': 167, '750132': 167, '825292': 167, '861484': 167, '906680': 167, '906681': 167, '906760': 167, '907836': 167, '907837': 167, '925895': 167, '942357': 167, '94350': 167, '956606': 167, '986931': 167, '989704': 167}\n",
      "[0.015151515151515152, 0.18181818181818182, 0.1893939393939394, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.36363636363636365, 0.027777777777777776, 0.058823529411764705, 0.0, 0.6, 0.30303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.015151515151515152, 0.18181818181818182, 0.1893939393939394, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.36363636363636365, 0.027777777777777776, 0.058823529411764705, 0.0, 0.6, 0.30303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4631727': 167, '4633603': 167, '4650113': 167, '4653852': 167, '4661735': 167, '4666231': 167, '4667626': 167, '4671406': 167, '4671443': 167, '4677606': 167, '4678080': 167, '4693039': 167, '4693198': 167, '4694833': 167, '4696505': 167, '4703149': 167, '4710576': 167, '4711578': 167, '4714481': 167, '4723905': 167, '4735587': 167, '4735758': 167, '4743012': 167, '4749611': 167, '4767260': 167, '4772658': 167, '4773857': 167, '4773948': 167, '4800274': 167, '4800275': 167, '4810810': 167, '4816604': 167, '4823439': 167, '4823611': 167, '4826952': 167, '4826957': 167, '4827285': 167, '4827287': 167, '4845088': 167, '4850346': 167, '4853692': 167, '4860099': 167, '4861484': 167, '4863146': 167, '4875475': 167, '4884993': 167, '4896659': 167, '4899365': 167, '4921810': 167, '4936740': 167, '4937390': 167, '4947281': 167, '4951739': 167, '4955051': 167, '4955053': 167, '4960424': 167, '4969415': 167, '4984238': 167, '4993934': 167, '5024644': 167, '5039329': 167, '5051606': 167, '5068771': 167, '5070846': 167, '5073839': 167, '5076753': 167, '5076821': 167, '5078640': 167, '5079918': 167, '5081990': 167, '5089294': 167, '5102537': 167, '5117279': 167, '5118757': 167, '5135326': 167, '5137153': 167, '5137154': 167, '5137157': 167, '5137158': 167, '5143186': 167, '5157605': 167, '5160584': 167, '5162042': 167, '5171396': 167, '5195826': 167, '5202182': 167, '5204781': 167, '5213896': 167, '5214265': 167, '5214755': 167, '5214943': 167, '5237462': 167, '5248391': 167, '5258365': 167, '5261461': 167, '5268098': 167, '5294335': 167, '5302339': 167, '5314439': 167, '5315510': 167, '5335389': 167, '5345058': 167, '5347155': 167, '5355157': 167, '5356489': 167, '5363251': 167, '536656': 167, '5377710': 167, '5406759': 167, '5431709': 167, '547692': 167, '587794': 167, '633082': 167, '672063': 167, '672064': 167, '691688': 167, '691694': 167, '710469': 167, '750132': 167, '825292': 167, '861484': 167, '906680': 167, '906681': 167, '906760': 167, '907836': 167, '907837': 167, '925895': 167, '942357': 167, '94350': 167, '956606': 167, '986931': 167, '989704': 167}\n",
      "[0.007575757575757576, 0.10606060606060606, 0.12121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.3333333333333333, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.007575757575757576, 0.10606060606060606, 0.12121212121212122, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.3333333333333333, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4631727': 150, '4633603': 150, '4650113': 117, '4653852': 139, '4661735': 160, '4666231': 188, '4667626': 150, '4671406': 126, '4671443': 139, '4677606': 139, '4678080': 167, '4693039': 139, '4693198': 126, '4694833': 139, '4696505': 167, '4703149': 111, '4710576': 174, '4711578': 181, '4714481': 111, '4723905': 139, '4735587': 111, '4735758': 139, '4743012': 122, '4749611': 122, '4767260': 167, '4772658': 117, '4773857': 111, '4773948': 139, '4800274': 111, '4800275': 117, '4810810': 133, '4816604': 139, '4823439': 139, '4823611': 126, '4826952': 117, '4826957': 139, '4827285': 174, '4827287': 150, '4845088': 94, '4850346': 117, '4853692': 126, '4860099': 139, '4861484': 167, '4863146': 112, '4875475': 117, '4884993': 181, '4896659': 174, '4899365': 181, '4921810': 117, '4936740': 133, '4937390': 139, '4947281': 128, '4951739': 88, '4955051': 139, '4955053': 139, '4960424': 167, '4969415': 117, '4984238': 150, '4993934': 117, '5024644': 139, '5039329': 167, '5051606': 122, '5068771': 167, '5070846': 112, '5073839': 174, '5076753': 133, '5076821': 167, '5078640': 167, '5079918': 139, '5081990': 84, '5089294': 167, '5102537': 117, '5117279': 117, '5118757': 139, '5135326': 126, '5137153': 30, '5137154': 117, '5137157': 117, '5137158': 139, '5143186': 139, '5157605': 132, '5160584': 126, '5162042': 167, '5171396': 167, '5195826': 181, '5202182': 117, '5204781': 117, '5213896': 174, '5214265': 117, '5214755': 167, '5214943': 150, '5237462': 117, '5248391': 139, '5258365': 117, '5261461': 181, '5268098': 117, '5294335': 117, '5302339': 167, '5314439': 150, '5315510': 139, '5335389': 139, '5345058': 145, '5347155': 167, '5355157': 160, '5356489': 139, '5363251': 139, '536656': 128, '5377710': 122, '5406759': 126, '5431709': 167, '547692': 167, '587794': 139, '633082': 126, '672063': 188, '672064': 167, '691688': 139, '691694': 139, '710469': 160, '750132': 117, '825292': 139, '861484': 167, '906680': 174, '906681': 167, '906760': 30, '907836': 167, '907837': 181, '925895': 139, '942357': 84, '94350': 156, '956606': 126, '986931': 139, '989704': 181}\n",
      "[0.21212121212121213, 0.5833333333333334, 0.6287878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.8571428571428571, 0.7727272727272727, 0.6666666666666666, 0.7058823529411765, 0.25, 0.6, 0.3939393939393939, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.21212121212121213, 0.5833333333333334, 0.6287878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.8571428571428571, 0.7727272727272727, 0.6666666666666666, 0.7058823529411765, 0.25, 0.6, 0.3939393939393939, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4631727': 161, '4633603': 161, '4650113': 156, '4653852': 161, '4661735': 156, '4666231': 161, '4667626': 161, '4671406': 156, '4671443': 161, '4677606': 161, '4678080': 161, '4693039': 156, '4693198': 156, '4694833': 161, '4696505': 161, '4703149': 156, '4710576': 161, '4711578': 161, '4714481': 156, '4723905': 161, '4735587': 161, '4735758': 161, '4743012': 156, '4749611': 161, '4767260': 161, '4772658': 156, '4773857': 156, '4773948': 161, '4800274': 156, '4800275': 133, '4810810': 161, '4816604': 161, '4823439': 161, '4823611': 156, '4826952': 161, '4826957': 161, '4827285': 161, '4827287': 161, '4845088': 156, '4850346': 156, '4853692': 161, '4860099': 156, '4861484': 156, '4863146': 161, '4875475': 161, '4884993': 161, '4896659': 156, '4899365': 156, '4921810': 161, '4936740': 161, '4937390': 161, '4947281': 161, '4951739': 156, '4955051': 161, '4955053': 161, '4960424': 156, '4969415': 156, '4984238': 156, '4993934': 161, '5024644': 161, '5039329': 161, '5051606': 161, '5068771': 156, '5070846': 161, '5073839': 161, '5076753': 161, '5076821': 156, '5078640': 161, '5079918': 161, '5081990': 156, '5089294': 161, '5102537': 156, '5117279': 117, '5118757': 133, '5135326': 161, '5137153': 156, '5137154': 161, '5137157': 161, '5137158': 161, '5143186': 161, '5157605': 156, '5160584': 156, '5162042': 161, '5171396': 156, '5195826': 161, '5202182': 161, '5204781': 156, '5213896': 161, '5214265': 156, '5214755': 161, '5214943': 156, '5237462': 156, '5248391': 156, '5258365': 161, '5261461': 161, '5268098': 161, '5294335': 156, '5302339': 161, '5314439': 161, '5315510': 161, '5335389': 156, '5345058': 161, '5347155': 156, '5355157': 156, '5356489': 156, '5363251': 161, '536656': 161, '5377710': 161, '5406759': 156, '5431709': 156, '547692': 161, '587794': 161, '633082': 156, '672063': 161, '672064': 161, '691688': 161, '691694': 161, '710469': 161, '750132': 161, '825292': 161, '861484': 156, '906680': 161, '906681': 156, '906760': 156, '907836': 161, '907837': 161, '925895': 156, '942357': 156, '94350': 161, '956606': 156, '986931': 161, '989704': 161}\n",
      "[0.0, 0.03787878787878788, 0.03787878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.25, 0.6, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.0, 0.03787878787878788, 0.03787878787878788, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.25, 0.6, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4631727': 167, '4633603': 30, '4650113': 145, '4653852': 167, '4661735': 167, '4666231': 167, '4667626': 167, '4671406': 167, '4671443': 167, '4677606': 167, '4678080': 167, '4693039': 167, '4693198': 167, '4694833': 167, '4696505': 167, '4703149': 167, '4710576': 167, '4711578': 30, '4714481': 167, '4723905': 167, '4735587': 30, '4735758': 167, '4743012': 167, '4749611': 167, '4767260': 167, '4772658': 167, '4773857': 30, '4773948': 167, '4800274': 30, '4800275': 167, '4810810': 167, '4816604': 167, '4823439': 167, '4823611': 167, '4826952': 167, '4826957': 167, '4827285': 167, '4827287': 167, '4845088': 167, '4850346': 167, '4853692': 167, '4860099': 30, '4861484': 167, '4863146': 167, '4875475': 30, '4884993': 167, '4896659': 167, '4899365': 167, '4921810': 167, '4936740': 167, '4937390': 167, '4947281': 167, '4951739': 167, '4955051': 167, '4955053': 167, '4960424': 167, '4969415': 167, '4984238': 167, '4993934': 167, '5024644': 167, '5039329': 167, '5051606': 30, '5068771': 30, '5070846': 167, '5073839': 30, '5076753': 167, '5076821': 167, '5078640': 167, '5079918': 167, '5081990': 167, '5089294': 167, '5102537': 167, '5117279': 167, '5118757': 167, '5135326': 167, '5137153': 167, '5137154': 167, '5137157': 167, '5137158': 167, '5143186': 167, '5157605': 167, '5160584': 145, '5162042': 167, '5171396': 167, '5195826': 167, '5202182': 167, '5204781': 167, '5213896': 167, '5214265': 167, '5214755': 167, '5214943': 167, '5237462': 167, '5248391': 167, '5258365': 167, '5261461': 167, '5268098': 167, '5294335': 167, '5302339': 167, '5314439': 167, '5315510': 167, '5335389': 167, '5345058': 167, '5347155': 30, '5355157': 167, '5356489': 167, '5363251': 167, '536656': 167, '5377710': 167, '5406759': 167, '5431709': 167, '547692': 167, '587794': 167, '633082': 167, '672063': 167, '672064': 167, '691688': 30, '691694': 167, '710469': 30, '750132': 167, '825292': 167, '861484': 167, '906680': 167, '906681': 167, '906760': 167, '907836': 167, '907837': 167, '925895': 167, '942357': 30, '94350': 167, '956606': 167, '986931': 167, '989704': 167}\n",
      "[0.007575757575757576, 0.09848484848484848, 0.11363636363636363, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.30303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.007575757575757576, 0.09848484848484848, 0.11363636363636363, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.30303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "{'4631727': 153, '4633603': 128, '4650113': 116, '4653852': 128, '4661735': 156, '4666231': 167, '4667626': 153, '4671406': 126, '4671443': 156, '4677606': 145, '4678080': 167, '4693039': 139, '4693198': 126, '4694833': 139, '4696505': 153, '4703149': 116, '4710576': 167, '4711578': 167, '4714481': 116, '4723905': 139, '4735587': 128, '4735758': 139, '4743012': 126, '4749611': 126, '4767260': 167, '4772658': 209, '4773857': 128, '4773948': 128, '4800274': 128, '4800275': 128, '4810810': 133, '4816604': 133, '4823439': 139, '4823611': 126, '4826952': 128, '4826957': 133, '4827285': 177, '4827287': 153, '4845088': 195, '4850346': 118, '4853692': 126, '4860099': 139, '4861484': 167, '4863146': 116, '4875475': 122, '4884993': 167, '4896659': 195, '4899365': 167, '4921810': 128, '4936740': 128, '4937390': 133, '4947281': 132, '4951739': 90, '4955051': 128, '4955053': 139, '4960424': 177, '4969415': 118, '4984238': 145, '4993934': 128, '5024644': 133, '5039329': 195, '5051606': 126, '5068771': 167, '5070846': 116, '5073839': 167, '5076753': 128, '5076821': 177, '5078640': 167, '5079918': 139, '5081990': 85, '5089294': 167, '5102537': 118, '5117279': 126, '5118757': 133, '5135326': 123, '5137153': 128, '5137154': 202, '5137157': 128, '5137158': 128, '5143186': 139, '5157605': 131, '5160584': 123, '5162042': 167, '5171396': 167, '5195826': 167, '5202182': 128, '5204781': 126, '5213896': 195, '5214265': 116, '5214755': 195, '5214943': 146, '5237462': 116, '5248391': 128, '5258365': 153, '5261461': 167, '5268098': 123, '5294335': 123, '5302339': 167, '5314439': 153, '5315510': 139, '5335389': 128, '5345058': 153, '5347155': 195, '5355157': 84, '5356489': 133, '5363251': 133, '536656': 128, '5377710': 123, '5406759': 126, '5431709': 195, '547692': 161, '587794': 139, '633082': 126, '672063': 195, '672064': 167, '691688': 139, '691694': 139, '710469': 153, '750132': 128, '825292': 128, '861484': 88, '906680': 167, '906681': 177, '906760': 106, '907836': 195, '907837': 167, '925895': 128, '942357': 88, '94350': 156, '956606': 126, '986931': 133, '989704': 167}\n",
      "[0.06818181818181818, 0.3712121212121212, 0.4015151515151515, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.2857142857142857, 0.7727272727272727, 0.3611111111111111, 0.35294117647058826, 0.25, 0.4, 0.18181818181818182, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.06818181818181818, 0.3712121212121212, 0.4015151515151515, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.2857142857142857, 0.7727272727272727, 0.3611111111111111, 0.35294117647058826, 0.25, 0.4, 0.18181818181818182, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0.h5 not needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "{'4631727': 117, '4633603': 117, '4650113': 117, '4653852': 132, '4661735': 117, '4666231': 131, '4667626': 132, '4671406': 132, '4671443': 117, '4677606': 117, '4678080': 117, '4693039': 132, '4693198': 132, '4694833': 117, '4696505': 117, '4703149': 132, '4710576': 117, '4711578': 108, '4714481': 132, '4723905': 132, '4735587': 117, '4735758': 117, '4743012': 132, '4749611': 117, '4767260': 117, '4772658': 132, '4773857': 117, '4773948': 117, '4800274': 117, '4800275': 131, '4810810': 131, '4816604': 108, '4823439': 117, '4823611': 132, '4826952': 117, '4826957': 117, '4827285': 117, '4827287': 132, '4845088': 117, '4850346': 132, '4853692': 132, '4860099': 117, '4861484': 132, '4863146': 117, '4875475': 117, '4884993': 117, '4896659': 131, '4899365': 117, '4921810': 117, '4936740': 117, '4937390': 117, '4947281': 132, '4951739': 132, '4955051': 132, '4955053': 117, '4960424': 132, '4969415': 117, '4984238': 132, '4993934': 117, '5024644': 117, '5039329': 132, '5051606': 117, '5068771': 117, '5070846': 117, '5073839': 117, '5076753': 117, '5076821': 132, '5078640': 132, '5079918': 117, '5081990': 132, '5089294': 117, '5102537': 132, '5117279': 131, '5118757': 117, '5135326': 132, '5137153': 117, '5137154': 132, '5137157': 117, '5137158': 117, '5143186': 117, '5157605': 131, '5160584': 131, '5162042': 112, '5171396': 117, '5195826': 117, '5202182': 117, '5204781': 132, '5213896': 131, '5214265': 117, '5214755': 117, '5214943': 117, '5237462': 132, '5248391': 117, '5258365': 132, '5261461': 117, '5268098': 117, '5294335': 117, '5302339': 117, '5314439': 132, '5315510': 132, '5335389': 117, '5345058': 117, '5347155': 117, '5355157': 132, '5356489': 132, '5363251': 117, '536656': 131, '5377710': 117, '5406759': 117, '5431709': 117, '547692': 117, '587794': 117, '633082': 132, '672063': 117, '672064': 117, '691688': 117, '691694': 117, '710469': 117, '750132': 132, '825292': 117, '861484': 117, '906680': 117, '906681': 131, '906760': 132, '907836': 117, '907837': 117, '925895': 132, '942357': 117, '94350': 132, '956606': 132, '986931': 117, '989704': 117}\n",
      "[0.015151515151515152, 0.12878787878787878, 0.12878787878787878, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.45454545454545453, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.015151515151515152, 0.12878787878787878, 0.12878787878787878, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.45454545454545453, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "Loading model ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 from disk...\n",
      "Local copy for ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0.h5 not needed.\n",
      "Saving data to file ./models/model_vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5_run=0_pred_test.joblib.\n",
      "0. run vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "{'4631727': 156, '4633603': 156, '4650113': 156, '4653852': 30, '4661735': 156, '4666231': 156, '4667626': 156, '4671406': 156, '4671443': 30, '4677606': 156, '4678080': 156, '4693039': 30, '4693198': 30, '4694833': 156, '4696505': 156, '4703149': 156, '4710576': 156, '4711578': 156, '4714481': 156, '4723905': 156, '4735587': 156, '4735758': 156, '4743012': 156, '4749611': 156, '4767260': 156, '4772658': 156, '4773857': 156, '4773948': 156, '4800274': 156, '4800275': 156, '4810810': 156, '4816604': 156, '4823439': 156, '4823611': 156, '4826952': 156, '4826957': 156, '4827285': 156, '4827287': 156, '4845088': 156, '4850346': 156, '4853692': 156, '4860099': 30, '4861484': 156, '4863146': 156, '4875475': 156, '4884993': 156, '4896659': 156, '4899365': 156, '4921810': 156, '4936740': 156, '4937390': 156, '4947281': 156, '4951739': 30, '4955051': 156, '4955053': 156, '4960424': 156, '4969415': 156, '4984238': 156, '4993934': 156, '5024644': 156, '5039329': 156, '5051606': 156, '5068771': 30, '5070846': 156, '5073839': 156, '5076753': 156, '5076821': 30, '5078640': 156, '5079918': 156, '5081990': 156, '5089294': 156, '5102537': 156, '5117279': 156, '5118757': 156, '5135326': 156, '5137153': 156, '5137154': 30, '5137157': 156, '5137158': 30, '5143186': 156, '5157605': 156, '5160584': 30, '5162042': 156, '5171396': 30, '5195826': 156, '5202182': 156, '5204781': 156, '5213896': 156, '5214265': 156, '5214755': 156, '5214943': 156, '5237462': 30, '5248391': 156, '5258365': 156, '5261461': 156, '5268098': 156, '5294335': 156, '5302339': 156, '5314439': 156, '5315510': 156, '5335389': 156, '5345058': 156, '5347155': 156, '5355157': 30, '5356489': 30, '5363251': 156, '536656': 156, '5377710': 156, '5406759': 156, '5431709': 156, '547692': 156, '587794': 156, '633082': 30, '672063': 156, '672064': 156, '691688': 156, '691694': 156, '710469': 156, '750132': 156, '825292': 156, '861484': 156, '906680': 156, '906681': 156, '906760': 30, '907836': 156, '907837': 156, '925895': 156, '942357': 156, '94350': 156, '956606': 156, '986931': 156, '989704': 156}\n",
      "[0.007575757575757576, 0.030303030303030304, 0.030303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.4, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "means  : [0.007575757575757576, 0.030303030303030304, 0.030303030303030304, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.4, 0.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0]\n",
      "stddevs: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "% windowed=False\n",
      "Testset & Runs & mean Acc0 & mean Acc1 & mean Acc2 & model \\\\\n",
      " \\hline \\\\\n",
      "val              & 1 &  16.667% (0.00000) &  51.515% (0.00000) &  56.061% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "val              & 1 &   0.000% (0.00000) &  12.121% (0.00000) &  12.121% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "val              & 1 &   0.000% (0.00000) &  13.636% (0.00000) &  14.394% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "val              & 1 &  25.000% (0.00000) &  79.545% (0.00000) &  90.909% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "val              & 1 &  23.485% (0.00000) &  62.879% (0.00000) &  71.212% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "val              & 1 &   3.030% (0.00000) &   9.848% (0.00000) &   9.848% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "val              & 1 &   1.515% (0.00000) &  17.424% (0.00000) &  18.182% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "val              & 1 &   1.515% (0.00000) &  10.606% (0.00000) &  12.879% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "val              & 1 &   1.515% (0.00000) &   4.545% (0.00000) &   7.576% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "val              & 1 &  18.182% (0.00000) &  49.242% (0.00000) &  55.303% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "val              & 1 &   0.000% (0.00000) &   2.273% (0.00000) &   2.273% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "val              & 1 &   0.000% (0.00000) &   2.273% (0.00000) &   5.303% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "val              & 1 &   7.576% (0.00000) &  39.394% (0.00000) &  41.667% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "val              & 1 &   0.758% (0.00000) &  11.364% (0.00000) &  11.364% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "val              & 1 &   0.000% (0.00000) &   2.273% (0.00000) &   2.273% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "test             & 1 &  19.697% (0.00000) &  57.576% (0.00000) &  62.121% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "test             & 1 &   0.000% (0.00000) &  21.970% (0.00000) &  23.485% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "test             & 1 &   0.758% (0.00000) &  15.152% (0.00000) &  15.909% (0.00000) & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "test             & 1 &  24.242% (0.00000) &  80.303% (0.00000) &  94.697% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "test             & 1 &  21.212% (0.00000) &  65.152% (0.00000) &  73.485% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "test             & 1 &   5.303% (0.00000) &  10.606% (0.00000) &  10.606% (0.00000) & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "test             & 1 &   0.000% (0.00000) &  17.424% (0.00000) &  17.424% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "test             & 1 &   1.515% (0.00000) &  18.182% (0.00000) &  18.939% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "test             & 1 &   0.758% (0.00000) &  10.606% (0.00000) &  12.121% (0.00000) & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "test             & 1 &  21.212% (0.00000) &  58.333% (0.00000) &  62.879% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "test             & 1 &   0.000% (0.00000) &   3.788% (0.00000) &   3.788% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "test             & 1 &   0.758% (0.00000) &   9.848% (0.00000) &  11.364% (0.00000) & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "test             & 1 &   6.818% (0.00000) &  37.121% (0.00000) &  40.152% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1  \\\\\n",
      "test             & 1 &   1.515% (0.00000) &  12.879% (0.00000) &  12.879% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3  \\\\\n",
      "test             & 1 &   0.758% (0.00000) &   3.030% (0.00000) &   3.030% (0.00000) & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5  \\\\\n",
      "\n",
      "\n",
      "% windowed=False\n",
      "\\pgfplotstableread[row sep=\\\\,col sep=&]{\n",
      "Testset & Runs & Parameters & Acc1 & Std1 & Model \\\\\n",
      "val              & 1 &     320304 & 0.51515 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "val              & 1 &     320304 & 0.12121 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "val              & 1 &     320304 & 0.13636 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "val              & 1 &     692488 & 0.79545 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "val              & 1 &     692488 & 0.62879 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "val              & 1 &     692488 & 0.09848 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "val              & 1 &       9322 & 0.17424 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "val              & 1 &       9322 & 0.10606 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "val              & 1 &       9322 & 0.04545 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "val              & 1 &      27228 & 0.49242 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "val              & 1 &      27228 & 0.02273 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "val              & 1 &      27228 & 0.02273 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "val              & 1 &      89560 & 0.39394 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "val              & 1 &      89560 & 0.11364 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "val              & 1 &      89560 & 0.02273 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "test             & 1 &     320304 & 0.57576 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "test             & 1 &     320304 & 0.21970 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "test             & 1 &     320304 & 0.15152 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "test             & 1 &     692488 & 0.80303 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "test             & 1 &     692488 & 0.65152 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "test             & 1 &     692488 & 0.10606 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "test             & 1 &       9322 & 0.17424 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "test             & 1 &       9322 & 0.18182 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "test             & 1 &       9322 & 0.10606 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "test             & 1 &      27228 & 0.58333 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "test             & 1 &      27228 & 0.03788 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "test             & 1 &      27228 & 0.09848 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "test             & 1 &      89560 & 0.37121 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1 \\\\\n",
      "test             & 1 &      89560 & 0.12879 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3 \\\\\n",
      "test             & 1 &      89560 & 0.03030 & 0.00000 & vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5 \\\\\n",
      "}\\tempoaccuracy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "windowed=False\n",
      "Testset | Runs | mean Acc0 | mean Acc1 | mean Acc2 | model\n",
      "---------------------------------------------------------------------------------\n",
      "val              | 1 |  16.667% (0.00000) |  51.515% (0.00000) |  56.061% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "val              | 1 |   0.000% (0.00000) |  12.121% (0.00000) |  12.121% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "val              | 1 |   0.000% (0.00000) |  13.636% (0.00000) |  14.394% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "val              | 1 |  25.000% (0.00000) |  79.545% (0.00000) |  90.909% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "val              | 1 |  23.485% (0.00000) |  62.879% (0.00000) |  71.212% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "val              | 1 |   3.030% (0.00000) |   9.848% (0.00000) |   9.848% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "val              | 1 |   1.515% (0.00000) |  17.424% (0.00000) |  18.182% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "val              | 1 |   1.515% (0.00000) |  10.606% (0.00000) |  12.879% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "val              | 1 |   1.515% (0.00000) |   4.545% (0.00000) |   7.576% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "val              | 1 |  18.182% (0.00000) |  49.242% (0.00000) |  55.303% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "val              | 1 |   0.000% (0.00000) |   2.273% (0.00000) |   2.273% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "val              | 1 |   0.000% (0.00000) |   2.273% (0.00000) |   5.303% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "val              | 1 |   7.576% (0.00000) |  39.394% (0.00000) |  41.667% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "val              | 1 |   0.758% (0.00000) |  11.364% (0.00000) |  11.364% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "val              | 1 |   0.000% (0.00000) |   2.273% (0.00000) |   2.273% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "---------------------------------------------------------------------------------\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4157075': 1, '4161667': 1, '4162259': 3, '4162274': 1, '4162405': 3, '4162511': 1, '4163571': 3, '4163572': 1, '4163586': 3, '4163587': 3, '4163588': 2, '4166222': 1, '4166612': 1, '4172572': 0, '4186191': 1, '4191591': 3, '4192452': 0, '4193623': 3, '4207348': 1, '4214761': 1, '4216184': 3, '4218466': 3, '4226166': 1, '4226227': 3, '4226434': 1, '4231951': 0, '4233696': 1, '4235798': 3, '4237913': 3, '4264210': 1, '4264359': 2, '4265125': 0, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 1, '4300619': 3, '4301518': 0, '4304445': 1, '4313859': 2, '4315749': 3, '4323506': 3, '4325441': 1, '4331667': 3, '4332592': 3, '4346730': 2, '4353566': 1, '4358231': 1, '4360483': 3, '4360488': 0, '4365752': 0, '4366506': 3, '4372309': 1, '4377106': 3, '4381717': 3, '4386702': 1, '4397324': 0, '4397469': 3, '4398117': 1, '4399289': 3, '4403315': 3, '4403519': 1, '4404346': 1, '4407745': 3, '4409752': 0, '4411925': 0, '4416336': 3, '4416506': 1, '4416888': 2, '4416962': 3, '4418582': 0, '4419049': 1, '4420924': 3, '4426890': 1, '4427618': 1, '4442121': 1, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 0, '4469780': 0, '4471292': 3, '4471702': 0, '4473065': 1, '4474027': 0, '4474029': 0, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 0, '4486412': 1, '4489017': 3, '4493439': 3, '4494659': 1, '4495270': 3, '4497852': 1, '4508138': 1, '4509910': 3, '4512512': 1, '4514851': 1, '4517258': 2, '4532060': 1, '4540818': 3, '4543103': 1, '4547732': 3, '4549757': 0, '4558106': 3, '4559522': 3, '4565270': 1, '4566667': 1, '4567978': 0, '4567979': 0, '4585539': 3, '4586220': 0, '4593850': 1, '4596215': 1, '4604737': 1, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4157075': 1, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 3, '4163572': 3, '4163586': 1, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 1, '4226434': 3, '4231951': 1, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 3, '4358231': 1, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 1, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 1, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 1, '4468729': 3, '4469489': 3, '4469780': 1, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 3, '4483708': 1, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 1, '4508138': 3, '4509910': 1, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 1, '4565270': 3, '4566667': 3, '4567978': 1, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 1, '4610426': 1, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 1, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 1, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 1, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 1, '4275052': 3, '4279669': 2, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 1, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 1, '4377106': 3, '4381717': 3, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 1, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 1, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 1, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 1, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 1, '4480454': 3, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 1, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 1, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 1, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 1, '4610426': 3, '4611640': 3, '4623143': 1, '4624663': 1}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4157075': 1, '4161667': 0, '4162259': 1, '4162274': 0, '4162405': 1, '4162511': 1, '4163571': 0, '4163572': 1, '4163586': 1, '4163587': 3, '4163588': 1, '4166222': 1, '4166612': 1, '4172572': 0, '4186191': 1, '4191591': 1, '4192452': 0, '4193623': 1, '4207348': 1, '4214761': 1, '4216184': 1, '4218466': 1, '4226166': 1, '4226227': 1, '4226434': 1, '4231951': 2, '4233696': 0, '4235798': 3, '4237913': 3, '4264210': 1, '4264359': 1, '4265125': 0, '426992': 1, '4275052': 1, '4279669': 3, '4283622': 1, '4283854': 2, '4284345': 1, '4288893': 3, '4297277': 1, '4300617': 1, '4300619': 0, '4301518': 0, '4304445': 1, '4313859': 0, '4315749': 1, '4323506': 1, '4325441': 0, '4331667': 0, '4332592': 1, '4346730': 2, '4353566': 0, '4358231': 0, '4360483': 0, '4360488': 0, '4365752': 2, '4366506': 1, '4372309': 1, '4377106': 3, '4381717': 3, '4386702': 1, '4397324': 0, '4397469': 2, '4398117': 1, '4399289': 0, '4403315': 1, '4403519': 1, '4404346': 1, '4407745': 1, '4409752': 0, '4411925': 0, '4416336': 3, '4416506': 3, '4416888': 1, '4416962': 0, '4418582': 1, '4419049': 1, '4420924': 1, '4426890': 0, '4427618': 0, '4442121': 1, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 1, '4460536': 1, '4468729': 1, '4469489': 0, '4469780': 2, '4471292': 0, '4471702': 0, '4473065': 0, '4474027': 2, '4474029': 0, '4475855': 2, '4480118': 3, '4480454': 1, '4483708': 0, '4486124': 1, '4486412': 1, '4489017': 1, '4493439': 1, '4494659': 1, '4495270': 0, '4497852': 2, '4508138': 1, '4509910': 1, '4512512': 1, '4514851': 2, '4517258': 1, '4532060': 1, '4540818': 1, '4543103': 1, '4547732': 0, '4549757': 2, '4558106': 1, '4559522': 0, '4565270': 1, '4566667': 1, '4567978': 2, '4567979': 2, '4585539': 1, '4586220': 2, '4593850': 1, '4596215': 0, '4604737': 1, '4609093': 2, '4609944': 3, '4610426': 1, '4611640': 1, '4623143': 1, '4624663': 1}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4157075': 1, '4161667': 1, '4162259': 0, '4162274': 0, '4162405': 1, '4162511': 1, '4163571': 1, '4163572': 0, '4163586': 0, '4163587': 0, '4163588': 2, '4166222': 1, '4166612': 1, '4172572': 3, '4186191': 0, '4191591': 0, '4192452': 3, '4193623': 1, '4207348': 0, '4214761': 1, '4216184': 1, '4218466': 3, '4226166': 1, '4226227': 1, '4226434': 0, '4231951': 1, '4233696': 3, '4235798': 0, '4237913': 3, '4264210': 3, '4264359': 0, '4265125': 3, '426992': 2, '4275052': 0, '4279669': 2, '4283622': 1, '4283854': 3, '4284345': 0, '4288893': 3, '4297277': 1, '4300617': 1, '4300619': 1, '4301518': 3, '4304445': 1, '4313859': 2, '4315749': 1, '4323506': 0, '4325441': 1, '4331667': 3, '4332592': 1, '4346730': 3, '4353566': 3, '4358231': 1, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 2, '4372309': 1, '4377106': 0, '4381717': 0, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 1, '4399289': 3, '4403315': 1, '4403519': 0, '4404346': 1, '4407745': 1, '4409752': 3, '4411925': 3, '4416336': 1, '4416506': 3, '4416888': 2, '4416962': 3, '4418582': 3, '4419049': 1, '4420924': 2, '4426890': 1, '4427618': 0, '4442121': 0, '4446908': 1, '4457771': 0, '4459005': 1, '4459187': 1, '4460536': 0, '4468729': 1, '4469489': 3, '4469780': 3, '4471292': 1, '4471702': 3, '4473065': 0, '4474027': 3, '4474029': 3, '4475855': 2, '4480118': 3, '4480454': 1, '4483708': 0, '4486124': 3, '4486412': 0, '4489017': 1, '4493439': 1, '4494659': 1, '4495270': 1, '4497852': 0, '4508138': 3, '4509910': 1, '4512512': 1, '4514851': 1, '4517258': 2, '4532060': 1, '4540818': 1, '4543103': 1, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 0, '4565270': 1, '4566667': 1, '4567978': 0, '4567979': 0, '4585539': 0, '4586220': 2, '4593850': 1, '4596215': 0, '4604737': 3, '4609093': 2, '4609944': 3, '4610426': 1, '4611640': 3, '4623143': 1, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4157075': 3, '4161667': 1, '4162259': 3, '4162274': 0, '4162405': 3, '4162511': 1, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 1, '4166612': 1, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 1, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 1, '4264210': 1, '4264359': 3, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 0, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 1, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 0, '4442121': 3, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 3, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 1, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 0, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 1, '4163571': 3, '4163572': 3, '4163586': 1, '4163587': 1, '4163588': 3, '4166222': 1, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 1, '4214761': 1, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 0, '4275052': 3, '4279669': 2, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 1, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 1, '4403519': 3, '4404346': 3, '4407745': 1, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 1, '4420924': 3, '4426890': 3, '4427618': 1, '4442121': 3, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 1, '4471292': 3, '4471702': 3, '4473065': 1, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 1, '4495270': 3, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 1, '4514851': 3, '4517258': 3, '4532060': 1, '4540818': 1, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 1, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 1, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 1, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 1, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 2, '4265125': 3, '426992': 0, '4275052': 3, '4279669': 2, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 2, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 1, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 1, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 1, '4566667': 3, '4567978': 1, '4567979': 1, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 2, '4265125': 3, '426992': 0, '4275052': 3, '4279669': 2, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 2, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 2, '4532060': 1, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4157075': 3, '4161667': 1, '4162259': 3, '4162274': 1, '4162405': 3, '4162511': 1, '4163571': 0, '4163572': 0, '4163586': 0, '4163587': 1, '4163588': 3, '4166222': 3, '4166612': 1, '4172572': 3, '4186191': 1, '4191591': 0, '4192452': 3, '4193623': 1, '4207348': 1, '4214761': 3, '4216184': 3, '4218466': 0, '4226166': 3, '4226227': 1, '4226434': 3, '4231951': 1, '4233696': 1, '4235798': 0, '4237913': 3, '4264210': 3, '4264359': 2, '4265125': 3, '426992': 0, '4275052': 1, '4279669': 2, '4283622': 3, '4283854': 2, '4284345': 0, '4288893': 3, '4297277': 0, '4300617': 1, '4300619': 3, '4301518': 3, '4304445': 1, '4313859': 3, '4315749': 3, '4323506': 0, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 2, '4353566': 1, '4358231': 3, '4360483': 0, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 1, '4377106': 3, '4381717': 0, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 1, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 2, '4407745': 1, '4409752': 3, '4411925': 0, '4416336': 3, '4416506': 3, '4416888': 2, '4416962': 3, '4418582': 0, '4419049': 0, '4420924': 3, '4426890': 1, '4427618': 1, '4442121': 1, '4446908': 1, '4457771': 3, '4459005': 1, '4459187': 3, '4460536': 3, '4468729': 0, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 0, '4473065': 1, '4474027': 0, '4474029': 3, '4475855': 0, '4480118': 3, '4480454': 1, '4483708': 0, '4486124': 3, '4486412': 0, '4489017': 3, '4493439': 0, '4494659': 1, '4495270': 0, '4497852': 3, '4508138': 3, '4509910': 1, '4512512': 1, '4514851': 3, '4517258': 2, '4532060': 1, '4540818': 1, '4543103': 1, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 1, '4566667': 1, '4567978': 1, '4567979': 1, '4585539': 0, '4586220': 2, '4593850': 1, '4596215': 1, '4604737': 1, '4609093': 3, '4609944': 1, '4610426': 1, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 1, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 1, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 3, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 1, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 2, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 2, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 2, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 1, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 2, '4532060': 1, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 1, '4162405': 3, '4162511': 1, '4163571': 3, '4163572': 0, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 1, '4172572': 1, '4186191': 1, '4191591': 0, '4192452': 3, '4193623': 1, '4207348': 1, '4214761': 1, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 0, '4237913': 3, '4264210': 3, '4264359': 1, '4265125': 3, '426992': 0, '4275052': 1, '4279669': 2, '4283622': 3, '4283854': 3, '4284345': 0, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 1, '4331667': 3, '4332592': 1, '4346730': 3, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 1, '4365752': 3, '4366506': 2, '4372309': 1, '4377106': 3, '4381717': 0, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 1, '4409752': 3, '4411925': 3, '4416336': 1, '4416506': 3, '4416888': 3, '4416962': 1, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 1, '4442121': 1, '4446908': 1, '4457771': 0, '4459005': 1, '4459187': 1, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 1, '4471292': 3, '4471702': 3, '4473065': 1, '4474027': 3, '4474029': 1, '4475855': 3, '4480118': 3, '4480454': 1, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 1, '4495270': 3, '4497852': 1, '4508138': 3, '4509910': 3, '4512512': 1, '4514851': 3, '4517258': 1, '4532060': 1, '4540818': 1, '4543103': 1, '4547732': 2, '4549757': 1, '4558106': 3, '4559522': 3, '4565270': 0, '4566667': 1, '4567978': 3, '4567979': 1, '4585539': 0, '4586220': 3, '4593850': 1, '4596215': 1, '4604737': 1, '4609093': 3, '4609944': 1, '4610426': 3, '4611640': 1, '4623143': 3, '4624663': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 3, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 1, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 1, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 1, '4297277': 3, '4300617': 1, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 0, '4346730': 3, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 1, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 1, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 1, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 1, '4442121': 1, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 3, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 1, '4480454': 3, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 3, '4497852': 3, '4508138': 1, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 1, '4547732': 3, '4549757': 3, '4558106': 1, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 1, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4157075': 3, '4161667': 3, '4162259': 3, '4162274': 3, '4162405': 3, '4162511': 3, '4163571': 1, '4163572': 3, '4163586': 3, '4163587': 3, '4163588': 3, '4166222': 3, '4166612': 3, '4172572': 3, '4186191': 3, '4191591': 3, '4192452': 3, '4193623': 3, '4207348': 3, '4214761': 3, '4216184': 3, '4218466': 3, '4226166': 3, '4226227': 3, '4226434': 3, '4231951': 3, '4233696': 3, '4235798': 3, '4237913': 3, '4264210': 3, '4264359': 3, '4265125': 3, '426992': 3, '4275052': 3, '4279669': 3, '4283622': 3, '4283854': 3, '4284345': 3, '4288893': 3, '4297277': 3, '4300617': 3, '4300619': 3, '4301518': 3, '4304445': 3, '4313859': 3, '4315749': 3, '4323506': 3, '4325441': 3, '4331667': 3, '4332592': 3, '4346730': 3, '4353566': 3, '4358231': 3, '4360483': 3, '4360488': 3, '4365752': 3, '4366506': 3, '4372309': 3, '4377106': 3, '4381717': 3, '4386702': 3, '4397324': 3, '4397469': 3, '4398117': 3, '4399289': 3, '4403315': 3, '4403519': 3, '4404346': 3, '4407745': 3, '4409752': 3, '4411925': 3, '4416336': 3, '4416506': 3, '4416888': 3, '4416962': 3, '4418582': 3, '4419049': 3, '4420924': 3, '4426890': 3, '4427618': 3, '4442121': 3, '4446908': 3, '4457771': 3, '4459005': 3, '4459187': 3, '4460536': 3, '4468729': 1, '4469489': 3, '4469780': 3, '4471292': 3, '4471702': 3, '4473065': 3, '4474027': 3, '4474029': 3, '4475855': 3, '4480118': 3, '4480454': 3, '4483708': 3, '4486124': 3, '4486412': 3, '4489017': 3, '4493439': 3, '4494659': 3, '4495270': 1, '4497852': 3, '4508138': 3, '4509910': 3, '4512512': 3, '4514851': 3, '4517258': 3, '4532060': 3, '4540818': 3, '4543103': 3, '4547732': 3, '4549757': 3, '4558106': 3, '4559522': 3, '4565270': 3, '4566667': 3, '4567978': 3, '4567979': 3, '4585539': 3, '4586220': 3, '4593850': 3, '4596215': 3, '4604737': 3, '4609093': 3, '4609944': 3, '4610426': 3, '4611640': 3, '4623143': 3, '4624663': 3}\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   5.303%, ['4157075', '4231951', '4358231', '4419049', '4469780', '4497852', '4567978']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.121%, ['4162259', '4162405', '4163571', '4163587', '4191591', '4193623', '4216184', '4218466', '4235798', '4237913', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4468729', '4471292', '4475855', '4480118', '4489017', '4493439', '4495270', '4540818', '4547732', '4558106', '4585539', '4609093', '4611640', '4623143']\n",
      "- diff error     4.545%, ['4163588', '4264359', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.212%, ['4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4426890', '4427618', '4442121', '4446908', '4459005', '4469489', '4471702', '4473065', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4508138', '4512512', '4514851', '4532060', '4543103', '4549757', '4565270', '4566667', '4567979', '4586220', '4593850', '4596215', '4604737', '4624663']\n",
      "- 2nd correct    6.818%, ['4163586', '4226227', '4403315', '4460536', '4483708', '4509910', '4559522', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.091%, ['4162511', '4166612', '4207348', '4353566', '4372309', '4386702', '4403519', '4442121', '4473065', '4565270', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    38.636%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4471292', '4475855', '4483708', '4489017', '4493439', '4509910', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4610426', '4611640']\n",
      "- diff error     5.303%, ['4163588', '4264359', '4279669', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   42.424%, ['4157075', '4161667', '4162274', '4163572', '4166222', '4172572', '4186191', '4192452', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4358231', '4360488', '4365752', '4397324', '4398117', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4446908', '4459005', '4469489', '4469780', '4471702', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4532060', '4543103', '4549757', '4566667', '4567978', '4567979', '4586220', '4596215', '4604737']\n",
      "- 2nd correct    4.545%, ['426992', '4468729', '4480118', '4495270', '4609944', '4623143']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  43.182%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4469489', '4471702', '4473065', '4474029', '4480454', '4486124', '4486412', '4494659', '4508138', '4512512', '4532060', '4543103', '4565270', '4566667', '4593850', '4596215', '4604737', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.091%, ['4163587', '4235798', '4237913', '4279669', '4288893', '4346730', '4377106', '4381717', '4416336', '4457771', '4480118', '4609944']\n",
      "- diff error     3.030%, ['4283854', '4397469', '4475855', '4609093']\n",
      "- music error    0.758%, ['4346730']\n",
      "- 1st correct    8.333%, ['4231951', '4365752', '4416506', '4469780', '4474027', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220']\n",
      "- 2nd correct   36.364%, ['4162259', '4162405', '4163571', '4163586', '4163588', '4191591', '4193623', '4216184', '4218466', '4226227', '4264359', '426992', '4275052', '4283622', '4284345', '4297277', '4300619', '4313859', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4399289', '4403315', '4407745', '4416888', '4416962', '4420924', '4459187', '4460536', '4468729', '4471292', '4483708', '4489017', '4493439', '4495270', '4509910', '4517258', '4540818', '4547732', '4558106', '4559522', '4585539', '4610426', '4611640', '4623143']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  33.333%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4186191', '4207348', '4214761', '4226166', '4226434', '4231951', '4300617', '4304445', '4325441', '4358231', '4372309', '4386702', '4398117', '4403519', '4404346', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4473065', '4480454', '4486412', '4494659', '4497852', '4512512', '4514851', '4532060', '4543103', '4565270', '4566667', '4567978', '4567979', '4593850', '4596215', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    13.636%, ['4163588', '4218466', '4237913', '4283854', '4288893', '4313859', '4331667', '4360483', '4397469', '4399289', '4416888', '4416962', '4480118', '4517258', '4547732', '4558106', '4609944', '4611640']\n",
      "- diff error     5.303%, ['426992', '4279669', '4346730', '4366506', '4420924', '4475855', '4609093']\n",
      "- music error    3.030%, ['4163588', '4313859', '4416888', '4517258']\n",
      "- 1st correct   18.182%, ['4172572', '4192452', '4233696', '4264210', '4265125', '4301518', '4353566', '4360488', '4365752', '4397324', '4409752', '4411925', '4416506', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4486124', '4508138', '4549757', '4586220', '4604737']\n",
      "- 2nd correct   29.545%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4226227', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300619', '4315749', '4323506', '4332592', '4377106', '4381717', '4403315', '4407745', '4416336', '4457771', '4459187', '4460536', '4468729', '4471292', '4483708', '4489017', '4493439', '4495270', '4509910', '4540818', '4559522', '4585539', '4610426', '4623143']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.091%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- both incons    0.000%, []\n",
      "- same error    43.182%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     4.545%, ['4163588', '4264359', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   42.424%, ['4157075', '4163572', '4172572', '4186191', '4192452', '4207348', '4226166', '4226434', '4231951', '4233696', '4265125', '4300617', '4301518', '4304445', '4325441', '4358231', '4360488', '4365752', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4442121', '4446908', '4459005', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4532060', '4543103', '4549757', '4566667', '4567978', '4567979', '4586220', '4593850', '4604737', '4624663']\n",
      "- 2nd correct    0.758%, ['4237913']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.879%, ['4162511', '4166222', '4207348', '4214761', '4325441', '4419049', '4427618', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    38.636%, ['4162259', '4162405', '4163571', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     5.303%, ['4163588', '4264359', '4279669', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   38.636%, ['4157075', '4161667', '4162274', '4163572', '4166612', '4172572', '4186191', '4192452', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4353566', '4358231', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4426890', '4442121', '4469489', '4471702', '4474027', '4474029', '4486124', '4486412', '4497852', '4508138', '4514851', '4543103', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4596215', '4604737']\n",
      "- 2nd correct    4.545%, ['4163586', '4163587', '426992', '4403315', '4407745', '4540818']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   9.848%, ['4166612', '4207348', '4233696', '4386702', '4446908', '4459005', '4469780', '4480454', '4532060', '4565270', '4567978', '4567979', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    43.939%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '4264359', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4346730', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.788%, ['4163588', '4279669', '4313859', '4416888', '4517258']\n",
      "- music error    1.515%, ['4264359', '4346730']\n",
      "- 1st correct   41.667%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4172572', '4186191', '4192452', '4214761', '4226166', '4226434', '4231951', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4442121', '4469489', '4471702', '4473065', '4474027', '4474029', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4543103', '4549757', '4566667', '4586220', '4593850', '4596215', '4604737']\n",
      "- 2nd correct    0.758%, ['426992']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   3.788%, ['4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    44.697%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '4264359', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4346730', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4517258', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4163588', '4279669', '4313859', '4416888']\n",
      "- music error    2.273%, ['4264359', '4346730', '4517258']\n",
      "- 1st correct   47.727%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4442121', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4543103', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4593850', '4596215', '4604737']\n",
      "- 2nd correct    0.758%, ['426992']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  29.545%, ['4161667', '4162274', '4162511', '4163572', '4166612', '4186191', '4207348', '4231951', '4233696', '4300617', '4304445', '4353566', '4372309', '4386702', '4398117', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4471702', '4473065', '4474027', '4480454', '4486412', '4494659', '4512512', '4532060', '4543103', '4565270', '4566667', '4567978', '4567979', '4593850', '4596215', '4604737']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.758%, ['4162259', '4162405', '4216184', '4237913', '4264359', '4283622', '4288893', '4300619', '4315749', '4331667', '4332592', '4346730', '4366506', '4377106', '4397469', '4399289', '4403315', '4416336', '4416888', '4416962', '4420924', '4457771', '4459187', '4460536', '4471292', '4480118', '4489017', '4517258', '4547732', '4558106', '4559522', '4609093', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4163588', '4279669', '4283854', '4313859']\n",
      "- music error    3.030%, ['4264359', '4346730', '4416888', '4517258']\n",
      "- 1st correct   21.970%, ['4157075', '4166222', '4172572', '4192452', '4214761', '4226166', '4226434', '4264210', '4265125', '4301518', '4325441', '4358231', '4360488', '4365752', '4397324', '4403519', '4404346', '4409752', '4416506', '4469489', '4469780', '4474029', '4486124', '4497852', '4508138', '4514851', '4549757', '4586220', '4624663']\n",
      "- 2nd correct   19.697%, ['4163571', '4163586', '4163587', '4191591', '4193623', '4218466', '4226227', '4235798', '426992', '4275052', '4284345', '4297277', '4323506', '4360483', '4381717', '4407745', '4468729', '4475855', '4483708', '4493439', '4495270', '4509910', '4540818', '4585539', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    41.667%, ['4162259', '4162405', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4509910', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     4.545%, ['4163588', '4264359', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   51.515%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4532060', '4543103', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4593850', '4596215', '4604737', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    46.970%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '4264359', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4517258', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     1.515%, ['4163588', '4416888']\n",
      "- music error    3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- 1st correct   49.242%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4442121', '4459005', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4543103', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4593850', '4596215', '4604737', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  25.000%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4207348', '4214761', '4325441', '4360488', '4372309', '4386702', '4427618', '4442121', '4446908', '4459005', '4469780', '4473065', '4474029', '4480454', '4494659', '4497852', '4512512', '4532060', '4543103', '4549757', '4565270', '4566667', '4567979', '4593850', '4596215', '4604737', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4216184', '4218466', '4226227', '4237913', '4283622', '4283854', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4360483', '4377106', '4397469', '4399289', '4403315', '4420924', '4460536', '4468729', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4495270', '4509910', '4558106', '4559522', '4609093', '4610426', '4623143']\n",
      "- diff error     5.303%, ['4163588', '4279669', '4313859', '4346730', '4366506', '4416888', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   26.515%, ['4157075', '4161667', '4166222', '4192452', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4353566', '4358231', '4365752', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4469489', '4471702', '4474027', '4486124', '4486412', '4508138', '4514851', '4567978', '4586220']\n",
      "- 2nd correct   14.394%, ['4191591', '4193623', '4235798', '4264359', '426992', '4275052', '4284345', '4332592', '4381717', '4407745', '4416336', '4416962', '4457771', '4459187', '4517258', '4540818', '4585539', '4609944', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   8.333%, ['4186191', '4207348', '4300617', '4386702', '4403519', '4416506', '4427618', '4442121', '4508138', '4543103', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    40.909%, ['4162259', '4162405', '4163571', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4315749', '4323506', '4331667', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4468729', '4471292', '4475855', '4483708', '4489017', '4493439', '4495270', '4509910', '4540818', '4547732', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     4.545%, ['4163588', '4264359', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   43.182%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4192452', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4397324', '4398117', '4404346', '4409752', '4411925', '4418582', '4419049', '4426890', '4446908', '4459005', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4497852', '4512512', '4514851', '4532060', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4596215', '4604737', '4624663']\n",
      "- 2nd correct    3.030%, ['4288893', '4332592', '4480118', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    41.667%, ['4162259', '4162405', '4163586', '4163587', '4191591', '4193623', '4216184', '4218466', '4226227', '4235798', '4237913', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300619', '4315749', '4323506', '4331667', '4332592', '4360483', '4366506', '4377106', '4381717', '4397469', '4399289', '4403315', '4407745', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4471292', '4475855', '4480118', '4483708', '4489017', '4493439', '4509910', '4540818', '4547732', '4558106', '4559522', '4585539', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     4.545%, ['4163588', '4264359', '4313859', '4346730', '4416888', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   51.515%, ['4157075', '4161667', '4162274', '4162511', '4163572', '4166222', '4166612', '4172572', '4186191', '4192452', '4207348', '4214761', '4226166', '4226434', '4231951', '4233696', '4264210', '4265125', '4300617', '4301518', '4304445', '4325441', '4353566', '4358231', '4360488', '4365752', '4372309', '4386702', '4397324', '4398117', '4403519', '4404346', '4409752', '4411925', '4416506', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4469489', '4469780', '4471702', '4473065', '4474027', '4474029', '4480454', '4486124', '4486412', '4494659', '4497852', '4508138', '4512512', '4514851', '4532060', '4543103', '4549757', '4565270', '4566667', '4567978', '4567979', '4586220', '4593850', '4596215', '4604737', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.758%, ['4609944']\n",
      "- both incons    0.000%, []\n",
      "- same error    74.242%, ['4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4446908', '4457771', '4459005', '4459187', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4566667', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4611640']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   11.364%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4610426']\n",
      "- 2nd correct   12.879%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4403519', '4442121', '4468729', '4473065', '4480118', '4495270', '4565270', '4593850', '4623143', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   8.333%, ['4157075', '4163586', '4226227', '4358231', '4403315', '4419049', '4460536', '4483708', '4509910', '4559522', '4610426']\n",
      "- both incons    0.000%, []\n",
      "- same error     8.333%, ['4163587', '4235798', '4237913', '4279669', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118']\n",
      "- diff error     8.333%, ['4283854', '4346730', '4365752', '4397469', '4474027', '4475855', '4514851', '4549757', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.788%, ['4231951', '4469780', '4497852', '4567978', '4609944']\n",
      "- 2nd correct   71.212%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4264210', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4446908', '4459005', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4512512', '4517258', '4532060', '4540818', '4543103', '4547732', '4558106', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4611640', '4623143', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  10.606%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4483708', '4497852', '4509910', '4559522', '4567978', '4610426']\n",
      "- both incons    0.000%, []\n",
      "- same error    27.273%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4283854', '4288893', '4301518', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4611640']\n",
      "- diff error     8.333%, ['4163588', '426992', '4279669', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    1.515%, ['4469780', '4609944']\n",
      "- 2nd correct   52.273%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163587', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226434', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4372309', '4377106', '4381717', '4386702', '4398117', '4403519', '4404346', '4407745', '4416336', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4468729', '4471292', '4473065', '4480454', '4486412', '4489017', '4493439', '4494659', '4495270', '4512512', '4514851', '4532060', '4540818', '4543103', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4623143', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    78.030%, ['4162259', '4162405', '4163571', '4163572', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4446908', '4457771', '4459005', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4566667', '4567979', '4585539', '4586220', '4593850', '4604737', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct    9.848%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.030%, ['4163586', '4403315', '4419049', '4469780']\n",
      "- both incons    0.000%, []\n",
      "- same error    72.727%, ['4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4565270', '4566667', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4157075', '4226227', '4231951', '4358231', '4460536', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct   14.394%, ['4162511', '4163587', '4166222', '4207348', '4214761', '426992', '4325441', '4407745', '4427618', '4446908', '4459005', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['4469780', '4567978']\n",
      "- both incons    0.000%, []\n",
      "- same error    76.515%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226434', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4566667', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4279669', '4346730']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4483708', '4497852', '4509910', '4559522', '4609944', '4610426']\n",
      "- 2nd correct    9.091%, ['4166612', '4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4480454', '4532060', '4565270', '4567979', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    80.303%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4565270', '4566667', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct    4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   6.818%, ['4163586', '4226227', '4231951', '4419049', '4483708', '4509910', '4567978', '4609944', '4610426']\n",
      "- both incons    0.000%, []\n",
      "- same error    39.394%, ['4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4469489', '4471292', '4474029', '4480118', '4486124', '4489017', '4508138', '4514851', '4547732', '4549757', '4558106', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     6.061%, ['4264359', '4279669', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    5.303%, ['4157075', '4358231', '4403315', '4460536', '4469780', '4497852', '4559522']\n",
      "- 2nd correct   42.424%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4426890', '4427618', '4442121', '4446908', '4459005', '4468729', '4471702', '4473065', '4474027', '4475855', '4480454', '4486412', '4493439', '4494659', '4495270', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    85.606%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4565270', '4566667', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    82.576%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4457771', '4459005', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4565270', '4566667', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   2.273%, ['4469780', '4497852', '4609944']\n",
      "- both incons    0.000%, []\n",
      "- same error    48.485%, ['4161667', '4162259', '4162405', '4163571', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226434', '4233696', '4237913', '4264210', '4265125', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4420924', '4426890', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4514851', '4558106', '4586220', '4609093', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4483708', '4509910', '4559522', '4567978', '4610426']\n",
      "- 2nd correct   37.121%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4386702', '4407745', '4416336', '4416962', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4473065', '4474029', '4480454', '4494659', '4512512', '4517258', '4532060', '4540818', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4611640', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    76.515%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163587', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4512512', '4514851', '4517258', '4532060', '4540818', '4547732', '4549757', '4565270', '4566667', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct   11.364%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    85.606%, ['4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226434', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4565270', '4566667', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4157075', '4163586', '4226227', '4231951', '4358231', '4403315', '4419049', '4460536', '4469780', '4483708', '4497852', '4509910', '4559522', '4567978', '4609944', '4610426']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.121%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4403519', '4442121', '4468729', '4473065', '4495270', '4565270', '4593850', '4623143', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.818%, ['4163587', '4235798', '4237913', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771']\n",
      "- diff error    12.121%, ['4231951', '4279669', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    1.515%, ['4480118', '4609944']\n",
      "- 2nd correct   67.424%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4366506', '4397324', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4446908', '4459005', '4459187', '4460536', '4469489', '4471292', '4471702', '4474029', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4509910', '4512512', '4517258', '4532060', '4540818', '4543103', '4547732', '4558106', '4559522', '4566667', '4585539', '4596215', '4604737', '4610426', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  10.606%, ['4162511', '4166612', '4207348', '4372309', '4386702', '4403519', '4442121', '4468729', '4473065', '4495270', '4565270', '4593850', '4623143', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    27.273%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4279669', '4283854', '4288893', '4301518', '4331667', '4346730', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4611640']\n",
      "- diff error     6.818%, ['4163588', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    3.030%, ['426992', '4353566', '4480118', '4609944']\n",
      "- 2nd correct   52.273%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163587', '4166222', '4186191', '4191591', '4193623', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4377106', '4381717', '4398117', '4403315', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4446908', '4457771', '4459005', '4459187', '4460536', '4471292', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4532060', '4540818', '4543103', '4559522', '4566667', '4567978', '4567979', '4585539', '4596215', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   3.788%, ['4162511', '4166612', '4353566', '4372309', '4565270']\n",
      "- both incons    0.000%, []\n",
      "- same error    79.545%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4207348', '426992', '4386702', '4403519', '4442121', '4468729', '4473065', '4480118', '4495270', '4593850', '4609944', '4623143', '4624663']\n",
      "- 2nd correct    6.061%, ['4161667', '4162274', '4166222', '4214761', '4237913', '4264210', '4427618', '4596215']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   4.545%, ['4162511', '4207348', '426992', '4473065', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    73.485%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4497852', '4508138', '4509910', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    9.091%, ['4166612', '4353566', '4372309', '4386702', '4403519', '4442121', '4468729', '4480118', '4495270', '4565270', '4609944', '4623143']\n",
      "- 2nd correct   12.879%, ['4163586', '4163587', '4166222', '4214761', '4325441', '4403315', '4407745', '4419049', '4427618', '4446908', '4459005', '4469780', '4480454', '4494659', '4512512', '4532060', '4540818']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   4.545%, ['4166612', '4207348', '426992', '4386702', '4565270', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     1.515%, ['4264359', '4346730']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    9.091%, ['4162511', '4353566', '4372309', '4403519', '4442121', '4468729', '4473065', '4480118', '4495270', '4593850', '4609944', '4623143']\n",
      "- 2nd correct    6.061%, ['4233696', '4446908', '4459005', '4469780', '4480454', '4532060', '4567978', '4567979']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   1.515%, ['426992', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    81.061%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     2.273%, ['4264359', '4346730', '4517258']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   12.121%, ['4162511', '4166612', '4207348', '4353566', '4372309', '4386702', '4403519', '4442121', '4468729', '4473065', '4480118', '4495270', '4565270', '4593850', '4609944', '4623143']\n",
      "- 2nd correct    3.030%, ['4446908', '4459005', '4480454', '4532060']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  10.606%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4442121', '4468729', '4473065', '4495270', '4565270', '4593850', '4609944']\n",
      "- both incons    0.000%, []\n",
      "- same error    42.424%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4279669', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640']\n",
      "- diff error     5.303%, ['4264359', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    3.030%, ['4403519', '4480118', '4623143', '4624663']\n",
      "- 2nd correct   38.636%, ['4161667', '4162274', '4163571', '4163572', '4163586', '4163587', '4186191', '4191591', '4193623', '4218466', '4226227', '4231951', '4233696', '4235798', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4360483', '4381717', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4446908', '4459005', '4471702', '4474027', '4475855', '4480454', '4483708', '4486412', '4493439', '4494659', '4509910', '4512512', '4532060', '4540818', '4543103', '4566667', '4567978', '4567979', '4585539', '4596215', '4604737', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4403519', '4442121', '4473065', '4480118', '4565270', '4593850', '4609944', '4623143', '4624663']\n",
      "- 2nd correct    0.758%, ['4163571']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    80.303%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     3.788%, ['4264359', '4279669', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   13.636%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4403519', '4442121', '4468729', '4473065', '4480118', '4495270', '4565270', '4593850', '4609944', '4623143', '4624663']\n",
      "- 2nd correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.091%, ['4162511', '4166612', '4207348', '426992', '4372309', '4386702', '4442121', '4473065', '4565270', '4593850', '4609944', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    54.545%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4279669', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4469489', '4471292', '4471702', '4474027', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426']\n",
      "- diff error     1.515%, ['4366506', '4547732']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    4.545%, ['4353566', '4403519', '4468729', '4480118', '4495270', '4623143']\n",
      "- 2nd correct   30.303%, ['4162274', '4163572', '4172572', '4186191', '4191591', '4193623', '4214761', '4235798', '4264359', '4275052', '4284345', '4325441', '4332592', '4360488', '4381717', '4407745', '4416336', '4416962', '4427618', '4446908', '4457771', '4459005', '4459187', '4469780', '4474029', '4480454', '4494659', '4497852', '4512512', '4517258', '4532060', '4540818', '4543103', '4549757', '4566667', '4567979', '4585539', '4596215', '4604737', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   4.545%, ['4207348', '4386702', '4403519', '4442121', '4480118', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4547732', '4549757', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4162511', '4166612', '426992', '4353566', '4372309', '4468729', '4473065', '4495270', '4565270', '4609944', '4623143', '4624663']\n",
      "- 2nd correct    6.818%, ['4186191', '4288893', '4300617', '4332592', '4416506', '4427618', '4508138', '4543103', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   1.515%, ['4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4610426', '4611640']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4162511', '4166612', '4207348', '426992', '4353566', '4372309', '4386702', '4403519', '4442121', '4473065', '4480118', '4565270', '4593850', '4609944', '4623143', '4624663']\n",
      "- 2nd correct    0.758%, ['4163571']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  54.545%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226227', '4226434', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4459187', '4460536', '4468729', '4471292', '4473065', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4509910', '4512512', '4532060', '4540818', '4543103', '4559522', '4565270', '4566667', '4585539', '4593850', '4596215', '4610426', '4623143', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.061%, ['4237913', '4288893', '4416506', '4475855', '4480118', '4586220', '4609093', '4609944']\n",
      "- diff error     6.061%, ['4279669', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4549757']\n",
      "- music error    2.273%, ['4475855', '4586220', '4609093']\n",
      "- 1st correct   25.000%, ['4163588', '4172572', '4192452', '4218466', '4233696', '4264210', '4265125', '426992', '4301518', '4313859', '4331667', '4353566', '4360483', '4360488', '4366506', '4397324', '4399289', '4409752', '4411925', '4416888', '4416962', '4418582', '4420924', '4469489', '4471702', '4474029', '4486124', '4508138', '4517258', '4547732', '4558106', '4604737', '4611640']\n",
      "- 2nd correct    8.333%, ['4163587', '4231951', '4235798', '4377106', '4381717', '4416336', '4457771', '4497852', '4514851', '4567978', '4567979']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.091%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- both incons    0.000%, []\n",
      "- same error     8.333%, ['4163587', '4235798', '4279669', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   70.455%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4366506', '4386702', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4446908', '4459005', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4509910', '4512512', '4517258', '4532060', '4540818', '4543103', '4547732', '4558106', '4559522', '4566667', '4585539', '4593850', '4604737', '4610426', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    0.758%, ['4237913']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.909%, ['4162511', '4163586', '4166222', '4207348', '4214761', '426992', '4325441', '4403315', '4407745', '4419049', '4427618', '4446908', '4459005', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     7.576%, ['4235798', '4237913', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4279669', '4283854', '4346730', '4365752', '4397469', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   63.636%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474029', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4517258', '4543103', '4547732', '4558106', '4559522', '4565270', '4566667', '4585539', '4596215', '4604737', '4610426', '4611640', '4623143']\n",
      "- 2nd correct    1.515%, ['4163587', '4469780']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   8.333%, ['4166612', '4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4480454', '4532060', '4565270', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.091%, ['4163587', '4235798', '4237913', '4288893', '4346730', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error     9.091%, ['4231951', '4279669', '4283854', '4365752', '4397469', '4474027', '4475855', '4497852', '4514851', '4549757', '4586220', '4609093']\n",
      "- music error    0.758%, ['4346730']\n",
      "- 1st correct   71.212%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4264210', '4264359', '4265125', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4509910', '4512512', '4517258', '4540818', '4543103', '4547732', '4558106', '4559522', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426', '4611640', '4623143']\n",
      "- 2nd correct    2.273%, ['4469780', '4567978', '4567979']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.091%, ['4163587', '4235798', '4237913', '4288893', '4346730', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4279669', '4283854', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.758%, ['4346730']\n",
      "- 1st correct   75.000%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4509910', '4512512', '4517258', '4540818', '4543103', '4547732', '4558106', '4559522', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426', '4611640', '4623143']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  42.424%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4233696', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4468729', '4471702', '4473065', '4480454', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426']\n",
      "- both incons    0.000%, []\n",
      "- same error     7.576%, ['4237913', '4283854', '4288893', '4346730', '4377106', '4416336', '4416506', '4457771', '4480118', '4586220']\n",
      "- diff error     6.061%, ['4279669', '4365752', '4397469', '4469780', '4497852', '4514851', '4549757', '4609093']\n",
      "- music error    2.273%, ['4283854', '4346730', '4586220']\n",
      "- 1st correct   37.121%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4264210', '4264359', '4265125', '4283622', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4358231', '4360488', '4366506', '4397324', '4399289', '4403315', '4403519', '4404346', '4409752', '4416888', '4416962', '4420924', '4459187', '4460536', '4469489', '4471292', '4474029', '4486124', '4489017', '4508138', '4517258', '4547732', '4558106', '4559522', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    6.818%, ['4163587', '4231951', '4235798', '4381717', '4474027', '4475855', '4567978', '4567979', '4609944']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.091%, ['4163587', '4235798', '4237913', '4279669', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   77.273%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4446908', '4459005', '4459187', '4460536', '4469489', '4471292', '4471702', '4473065', '4474029', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4509910', '4512512', '4517258', '4532060', '4540818', '4543103', '4547732', '4558106', '4559522', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.848%, ['4163587', '4235798', '4237913', '4279669', '4288893', '4346730', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    10.606%, ['4231951', '4283854', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.758%, ['4346730']\n",
      "- 1st correct   77.273%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4459005', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4508138', '4509910', '4512512', '4517258', '4540818', '4543103', '4547732', '4558106', '4559522', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  32.576%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4386702', '4407745', '4416962', '4427618', '4442121', '4446908', '4459005', '4459187', '4473065', '4474029', '4480454', '4494659', '4512512', '4517258', '4532060', '4540818', '4543103', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4611640', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error     4.545%, ['4163587', '4237913', '4288893', '4377106', '4416506', '4480118']\n",
      "- diff error     9.091%, ['4231951', '4279669', '4283854', '4346730', '4365752', '4397469', '4474027', '4475855', '4514851', '4567978', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.970%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4265125', '4283622', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4353566', '4358231', '4360483', '4366506', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4547732', '4558106', '4559522', '4610426', '4623143']\n",
      "- 2nd correct    6.818%, ['4235798', '4381717', '4416336', '4457771', '4469780', '4497852', '4549757', '4567979', '4609944']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   9.091%, ['4186191', '4207348', '4300617', '4332592', '4386702', '4403519', '4427618', '4442121', '4508138', '4543103', '4558106', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.818%, ['4163587', '4235798', '4237913', '4279669', '4377106', '4381717', '4416336', '4457771', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   70.455%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4397324', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4459005', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474029', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4509910', '4512512', '4517258', '4532060', '4540818', '4547732', '4559522', '4565270', '4566667', '4585539', '4596215', '4604737', '4610426', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    2.273%, ['4288893', '4416506', '4480118']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.091%, ['4163587', '4235798', '4237913', '4279669', '4288893', '4377106', '4381717', '4416336', '4416506', '4457771', '4480118', '4609944']\n",
      "- diff error    11.364%, ['4231951', '4283854', '4346730', '4365752', '4397469', '4469780', '4474027', '4475855', '4497852', '4514851', '4549757', '4567978', '4567979', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   77.273%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4233696', '4264210', '4264359', '4265125', '426992', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4366506', '4372309', '4386702', '4397324', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4446908', '4459005', '4459187', '4460536', '4469489', '4471292', '4471702', '4473065', '4474029', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4508138', '4509910', '4512512', '4517258', '4532060', '4540818', '4543103', '4547732', '4558106', '4559522', '4565270', '4566667', '4585539', '4593850', '4596215', '4604737', '4610426', '4611640', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   7.576%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4372309', '4427618', '4565270', '4596215']\n",
      "- both incons    0.000%, []\n",
      "- same error    26.515%, ['4172572', '4192452', '4218466', '4233696', '4265125', '4283854', '4288893', '4301518', '4331667', '4346730', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     8.333%, ['4163588', '426992', '4279669', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   55.303%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4186191', '4191591', '4193623', '4207348', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4377106', '4381717', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4468729', '4471292', '4473065', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4532060', '4540818', '4543103', '4559522', '4566667', '4567978', '4567979', '4585539', '4593850', '4610426', '4623143', '4624663']\n",
      "- 2nd correct    2.273%, ['4237913', '4264210', '4353566']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.909%, ['4162511', '4163586', '4163587', '4166222', '4207348', '4214761', '4325441', '4403315', '4407745', '4419049', '4427618', '4446908', '4459005', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4279669', '4283854', '4288893', '4301518', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     6.818%, ['4163588', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   46.970%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4166612', '4186191', '4191591', '4193623', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4332592', '4358231', '4372309', '4377106', '4381717', '4386702', '4398117', '4403519', '4404346', '4416336', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4471292', '4483708', '4486412', '4489017', '4493439', '4495270', '4497852', '4509910', '4514851', '4543103', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4596215', '4610426', '4623143']\n",
      "- 2nd correct    1.515%, ['426992', '4469780']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   8.333%, ['4166612', '4207348', '4386702', '4446908', '4459005', '4480454', '4532060', '4565270', '4567978', '4567979', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    27.273%, ['4172572', '4192452', '4218466', '4237913', '4264210', '4265125', '4279669', '4283854', '4288893', '4301518', '4331667', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     7.576%, ['4163588', '4313859', '4346730', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   54.545%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4166222', '4186191', '4191591', '4193623', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4377106', '4381717', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4468729', '4471292', '4473065', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4540818', '4543103', '4559522', '4566667', '4585539', '4593850', '4596215', '4610426', '4623143']\n",
      "- 2nd correct    2.273%, ['4233696', '426992', '4469780']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   3.788%, ['4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    29.545%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4279669', '4283854', '4288893', '4301518', '4331667', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4517258', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     6.818%, ['4163588', '4313859', '4346730', '4366506', '4416888', '4420924', '4475855', '4586220', '4609093']\n",
      "- music error    1.515%, ['4279669', '4517258']\n",
      "- 1st correct   59.091%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4377106', '4381717', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4468729', '4471292', '4473065', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4540818', '4543103', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4610426', '4623143']\n",
      "- 2nd correct    0.758%, ['426992']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  40.152%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4226227', '4231951', '4235798', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4372309', '4381717', '4386702', '4398117', '4407745', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4468729', '4473065', '4480454', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4610426']\n",
      "- both incons    0.000%, []\n",
      "- same error    22.727%, ['4172572', '4192452', '4237913', '4264210', '4265125', '4279669', '4288893', '4301518', '4331667', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4416506', '4416888', '4416962', '4469489', '4469780', '4474029', '4480118', '4486124', '4508138', '4517258', '4547732', '4549757', '4558106', '4586220', '4611640']\n",
      "- diff error     5.303%, ['4163588', '4283854', '4313859', '4346730', '4366506', '4420924', '4609093']\n",
      "- music error    3.030%, ['4279669', '4416888', '4517258', '4586220']\n",
      "- 1st correct   22.727%, ['4157075', '4162259', '4162405', '4166222', '4214761', '4216184', '4226166', '4226434', '4264359', '4283622', '4300619', '4315749', '4325441', '4332592', '4358231', '4377106', '4403315', '4403519', '4404346', '4416336', '4457771', '4459187', '4460536', '4471292', '4489017', '4497852', '4514851', '4559522', '4623143', '4624663']\n",
      "- 2nd correct    9.091%, ['4218466', '4233696', '426992', '4353566', '4360483', '4411925', '4418582', '4471702', '4474027', '4475855', '4604737', '4609944']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4283854', '4288893', '4301518', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     8.333%, ['4163588', '426992', '4279669', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   60.606%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4377106', '4381717', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4471292', '4473065', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4532060', '4540818', '4543103', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4610426', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    29.545%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4283854', '4288893', '4301518', '4313859', '4331667', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4517258', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     7.576%, ['4163588', '426992', '4279669', '4346730', '4366506', '4416888', '4420924', '4475855', '4586220', '4609093']\n",
      "- music error    1.515%, ['4313859', '4517258']\n",
      "- 1st correct   60.606%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4377106', '4381717', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4442121', '4457771', '4459005', '4459187', '4460536', '4468729', '4471292', '4473065', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4540818', '4543103', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4610426', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  31.061%, ['4162274', '4162511', '4163572', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '4275052', '4284345', '4325441', '4332592', '4372309', '4381717', '4386702', '4407745', '4416336', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4473065', '4480454', '4494659', '4497852', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    22.727%, ['4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4279669', '4283854', '4288893', '4301518', '4331667', '4346730', '4353566', '4360483', '4365752', '4366506', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4418582', '4469489', '4471702', '4474027', '4480118', '4486124', '4508138', '4558106']\n",
      "- diff error     6.061%, ['4163588', '4313859', '4416888', '4420924', '4475855', '4547732', '4586220', '4609093']\n",
      "- music error    1.515%, ['4279669', '4366506']\n",
      "- 1st correct   31.818%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4166222', '4216184', '4226166', '4226227', '4226434', '4231951', '4283622', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4358231', '4377106', '4398117', '4403315', '4403519', '4404346', '4419049', '4426890', '4460536', '4468729', '4471292', '4483708', '4486412', '4489017', '4493439', '4495270', '4509910', '4514851', '4559522', '4567978', '4610426', '4623143']\n",
      "- 2nd correct    8.333%, ['4172572', '426992', '4360488', '4416962', '4469780', '4474029', '4517258', '4549757', '4604737', '4609944', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   7.576%, ['4186191', '4207348', '4300617', '4332592', '4386702', '4403519', '4427618', '4442121', '4543103', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.000%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4283854', '4301518', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4486124', '4547732', '4549757', '4604737', '4609944', '4611640']\n",
      "- diff error     8.333%, ['4163588', '426992', '4279669', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   55.303%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4166222', '4166612', '4191591', '4193623', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300619', '4304445', '4315749', '4323506', '4325441', '4358231', '4372309', '4377106', '4381717', '4398117', '4403315', '4404346', '4407745', '4416336', '4419049', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4468729', '4471292', '4473065', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4532060', '4540818', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4596215', '4610426', '4623143', '4624663']\n",
      "- 2nd correct    3.788%, ['4288893', '4416506', '4480118', '4508138', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4172572', '4192452', '4218466', '4233696', '4237913', '4264210', '4265125', '4283854', '4288893', '4301518', '4331667', '4346730', '4353566', '4360483', '4360488', '4365752', '4397324', '4397469', '4399289', '4409752', '4411925', '4416506', '4416962', '4418582', '4469489', '4469780', '4471702', '4474027', '4474029', '4480118', '4486124', '4508138', '4547732', '4549757', '4558106', '4604737', '4609944', '4611640']\n",
      "- diff error     8.333%, ['4163588', '426992', '4279669', '4313859', '4366506', '4416888', '4420924', '4475855', '4517258', '4586220', '4609093']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   60.606%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4166222', '4166612', '4186191', '4191591', '4193623', '4207348', '4214761', '4216184', '4226166', '4226227', '4226434', '4231951', '4235798', '4264359', '4275052', '4283622', '4284345', '4297277', '4300617', '4300619', '4304445', '4315749', '4323506', '4325441', '4332592', '4358231', '4372309', '4377106', '4381717', '4386702', '4398117', '4403315', '4403519', '4404346', '4407745', '4416336', '4419049', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4471292', '4473065', '4480454', '4483708', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4532060', '4540818', '4543103', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4610426', '4623143', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.030%, ['4162511', '4166222', '4214761', '4427618']\n",
      "- both incons    0.000%, []\n",
      "- same error    75.000%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4497852', '4508138', '4509910', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    6.818%, ['4161667', '4162274', '4166612', '4237913', '4264210', '4353566', '4372309', '4565270', '4596215']\n",
      "- 2nd correct   14.394%, ['4163586', '4163587', '4207348', '426992', '4325441', '4403315', '4407745', '4419049', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['4166612', '4565270']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4593850', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4279669', '4346730']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    8.333%, ['4161667', '4162274', '4162511', '4166222', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4596215']\n",
      "- 2nd correct    9.091%, ['4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4469780', '4480454', '4532060', '4567978', '4567979', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    82.576%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- 2nd correct    4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   6.818%, ['4161667', '4162274', '4162511', '4166612', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- both incons    0.000%, []\n",
      "- same error    41.667%, ['4157075', '4162259', '4162405', '4163588', '4172572', '4192452', '4216184', '4226166', '4226434', '4265125', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     6.061%, ['4264359', '4279669', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.030%, ['4166222', '4214761', '4237913', '4264210']\n",
      "- 2nd correct   42.424%, ['4163571', '4163572', '4163586', '4163587', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4231951', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4360483', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4442121', '4446908', '4459005', '4468729', '4471702', '4473065', '4474027', '4475855', '4480454', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4532060', '4540818', '4543103', '4566667', '4567978', '4567979', '4585539', '4593850', '4604737', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    87.879%, ['4157075', '4162259', '4162405', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4457771', '4459005', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- 2nd correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   6.061%, ['4162274', '4162511', '4166612', '4214761', '4372309', '4427618', '4565270', '4596215']\n",
      "- both incons    0.000%, []\n",
      "- same error    54.545%, ['4157075', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4265125', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.788%, ['4161667', '4166222', '4237913', '4264210', '4353566']\n",
      "- 2nd correct   33.333%, ['4163572', '4172572', '4186191', '4191591', '4193623', '4207348', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4381717', '4386702', '4407745', '4416336', '4416962', '4442121', '4446908', '4457771', '4459005', '4459187', '4469780', '4473065', '4474029', '4480454', '4494659', '4497852', '4512512', '4517258', '4532060', '4540818', '4543103', '4549757', '4566667', '4567979', '4585539', '4593850', '4604737', '4609944', '4611640', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.758%, ['4427618']\n",
      "- both incons    0.000%, []\n",
      "- same error    79.545%, ['4157075', '4162259', '4162405', '4163571', '4163572', '4163586', '4163587', '4163588', '4172572', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4547732', '4549757', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4565270', '4596215']\n",
      "- 2nd correct   10.606%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    87.879%, ['4157075', '4162259', '4162405', '4163572', '4163586', '4163587', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4358231', '4360483', '4360488', '4365752', '4366506', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4161667', '4162274', '4162511', '4166222', '4166612', '4214761', '4237913', '4264210', '4353566', '4372309', '4427618', '4565270', '4596215']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   6.061%, ['4207348', '426992', '4446908', '4459005', '4469780', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    76.515%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4497852', '4508138', '4509910', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     1.515%, ['4264359', '4346730']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   11.364%, ['4162511', '4163586', '4163587', '4166222', '4214761', '4325441', '4403315', '4407745', '4419049', '4427618', '4473065', '4494659', '4512512', '4540818', '4593850']\n",
      "- 2nd correct    4.545%, ['4166612', '4233696', '4386702', '4565270', '4567978', '4567979']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    80.303%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4497852', '4508138', '4509910', '4514851', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4346730', '4517258']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   12.879%, ['4162511', '4163586', '4163587', '4166222', '4207348', '4214761', '4325441', '4403315', '4407745', '4419049', '4427618', '4469780', '4473065', '4494659', '4512512', '4540818', '4593850']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.879%, ['4162511', '4163586', '4163587', '4207348', '426992', '4407745', '4419049', '4427618', '4446908', '4459005', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    40.909%, ['4157075', '4162259', '4162405', '4163588', '4172572', '4192452', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4279669', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4331667', '4332592', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143']\n",
      "- diff error     5.303%, ['4264359', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    4.545%, ['4166222', '4214761', '4325441', '4403315', '4469780', '4624663']\n",
      "- 2nd correct   36.364%, ['4161667', '4162274', '4163571', '4163572', '4166612', '4186191', '4191591', '4193623', '4218466', '4226227', '4231951', '4233696', '4235798', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4411925', '4418582', '4426890', '4442121', '4468729', '4471702', '4474027', '4475855', '4483708', '4486412', '4493439', '4495270', '4509910', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4596215', '4604737', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    79.545%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4497852', '4508138', '4509910', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   17.424%, ['4162511', '4163586', '4163587', '4166222', '4207348', '4214761', '426992', '4325441', '4403315', '4407745', '4419049', '4427618', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4497852', '4508138', '4509910', '4514851', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.788%, ['4264359', '4279669', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   15.152%, ['4162511', '4163586', '4163587', '4166222', '4207348', '4214761', '426992', '4325441', '4403315', '4407745', '4419049', '4427618', '4459005', '4469780', '4473065', '4494659', '4512512', '4540818', '4593850', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  13.636%, ['4162511', '4207348', '4214761', '426992', '4325441', '4407745', '4427618', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    55.303%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163588', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4279669', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     1.515%, ['4366506', '4547732']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    3.788%, ['4163586', '4163587', '4166222', '4403315', '4419049']\n",
      "- 2nd correct   25.758%, ['4162274', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4235798', '4264359', '4275052', '4284345', '4332592', '4360488', '4372309', '4381717', '4386702', '4416336', '4416962', '4442121', '4457771', '4459187', '4474029', '4497852', '4517258', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4596215', '4604737', '4609944', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   2.273%, ['4207348', '4427618', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    72.727%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163571', '4163572', '4163588', '4166612', '4172572', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4404346', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4420924', '4426890', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4497852', '4509910', '4514851', '4517258', '4547732', '4549757', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   15.152%, ['4162511', '4163586', '4163587', '4166222', '4214761', '426992', '4325441', '4403315', '4407745', '4419049', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4624663']\n",
      "- 2nd correct    9.091%, ['4186191', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4442121', '4480118', '4508138', '4543103', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    79.545%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4163572', '4163588', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403519', '4404346', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4420924', '4426890', '4442121', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4497852', '4508138', '4509910', '4514851', '4517258', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4279669']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   17.424%, ['4162511', '4163586', '4163587', '4166222', '4207348', '4214761', '426992', '4325441', '4403315', '4407745', '4419049', '4427618', '4446908', '4459005', '4469780', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4593850', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    88.636%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     0.758%, ['4517258']\n",
      "- music error    2.273%, ['4264359', '4279669', '4346730']\n",
      "- 1st correct    6.061%, ['4166612', '4207348', '4233696', '4386702', '4469780', '4565270', '4567978', '4567979']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.091%, ['4166612', '4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4480454', '4532060', '4565270', '4567978', '4567979']\n",
      "- both incons    0.000%, []\n",
      "- same error    45.455%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4264359', '4265125', '4279669', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4346730', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143']\n",
      "- diff error     3.788%, ['4283854', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    2.273%, ['4264359', '4279669', '4346730']\n",
      "- 1st correct    1.515%, ['4469780', '4624663']\n",
      "- 2nd correct   40.152%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4163587', '4186191', '4191591', '4193623', '4218466', '4226227', '4231951', '4235798', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4468729', '4471702', '4473065', '4474027', '4475855', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4540818', '4543103', '4566667', '4585539', '4593850', '4596215', '4604737', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4279669', '4346730']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4166612', '4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4469780', '4480454', '4532060', '4565270', '4567978', '4567979', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    87.121%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4313859', '4517258']\n",
      "- music error    1.515%, ['4264359', '4346730']\n",
      "- 1st correct    8.333%, ['4166612', '4207348', '4233696', '426992', '4386702', '4459005', '4469780', '4565270', '4567978', '4567979', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.091%, ['4166612', '4207348', '426992', '4386702', '4446908', '4459005', '4469780', '4480454', '4532060', '4565270', '4567979', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    56.818%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4237913', '4264210', '4265125', '4279669', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4514851', '4558106', '4559522', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4346730', '4366506', '4547732']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    1.515%, ['4233696', '4567978']\n",
      "- 2nd correct   30.303%, ['4162274', '4162511', '4163572', '4172572', '4186191', '4191591', '4193623', '4214761', '4235798', '4264359', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4407745', '4416336', '4416962', '4427618', '4442121', '4457771', '4459187', '4473065', '4474029', '4494659', '4497852', '4512512', '4517258', '4540818', '4543103', '4549757', '4566667', '4585539', '4593850', '4596215', '4604737', '4609944', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['4207348', '4386702']\n",
      "- both incons    0.000%, []\n",
      "- same error    77.273%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4457771', '4459187', '4460536', '4468729', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4517258', '4540818', '4547732', '4549757', '4559522', '4566667', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4279669', '4346730']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4166612', '4233696', '426992', '4446908', '4459005', '4469780', '4480454', '4532060', '4565270', '4567978', '4567979', '4624663']\n",
      "- 2nd correct    9.848%, ['4186191', '4288893', '4300617', '4332592', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4172572', '4186191', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4469489', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4566667', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     2.273%, ['4264359', '4279669', '4346730']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4166612', '4207348', '4233696', '426992', '4386702', '4446908', '4459005', '4469780', '4480454', '4532060', '4565270', '4567978', '4567979', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.788%, ['426992', '4446908', '4459005', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    46.970%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4264359', '4265125', '4279669', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4346730', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4517258', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4283854', '4404346', '4416888', '4586220']\n",
      "- music error    3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- 1st correct    0.758%, ['4624663']\n",
      "- 2nd correct   45.455%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4231951', '4233696', '4235798', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4468729', '4471702', '4473065', '4474027', '4475855', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4540818', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4610426']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    90.152%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    93.939%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     1.515%, ['4279669', '4313859']\n",
      "- music error    2.273%, ['4264359', '4346730', '4517258']\n",
      "- 1st correct    2.273%, ['426992', '4459005', '4624663']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- both incons    0.000%, []\n",
      "- same error    58.333%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4279669', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4346730', '4366506', '4547732']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct    0.000%, []\n",
      "- 2nd correct   34.848%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4386702', '4407745', '4416336', '4416962', '4427618', '4442121', '4457771', '4459187', '4469780', '4473065', '4474029', '4494659', '4497852', '4512512', '4517258', '4540818', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4611640']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    81.061%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4457771', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4540818', '4547732', '4549757', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- 2nd correct   11.364%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    90.152%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '4275052', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143']\n",
      "- diff error     3.030%, ['4264359', '4279669', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['426992', '4446908', '4459005', '4480454', '4532060', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    44.697%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     6.061%, ['4264359', '4279669', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.970%, ['4161667', '4162274', '4162511', '4163572', '4163586', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4231951', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4471702', '4473065', '4474027', '4475855', '4480454', '4483708', '4486412', '4493439', '4494659', '4509910', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4610426']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    46.212%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4264359', '4265125', '4283622', '4288893', '4300619', '4301518', '4315749', '4325441', '4331667', '4332592', '4346730', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4517258', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     4.545%, ['4279669', '4283854', '4313859', '4404346', '4416888', '4586220']\n",
      "- music error    2.273%, ['4264359', '4346730', '4517258']\n",
      "- 1st correct   46.970%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4231951', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4459005', '4468729', '4471702', '4473065', '4474027', '4475855', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4540818', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4610426']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  26.515%, ['4162274', '4162511', '4163572', '4166612', '4186191', '4191591', '4193623', '4207348', '4235798', '426992', '4275052', '4284345', '4372309', '4381717', '4386702', '4407745', '4427618', '4442121', '4446908', '4459005', '4473065', '4480454', '4494659', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944']\n",
      "- both incons    0.000%, []\n",
      "- same error    32.576%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4192452', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4279669', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4331667', '4358231', '4365752', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416506', '4420924', '4460536', '4469489', '4471292', '4480118', '4486124', '4489017', '4508138', '4514851', '4558106', '4559522', '4609093', '4623143']\n",
      "- diff error     5.303%, ['4283854', '4346730', '4366506', '4404346', '4416888', '4547732', '4586220']\n",
      "- music error    0.758%, ['4279669']\n",
      "- 1st correct   22.727%, ['4161667', '4163571', '4163586', '4163587', '4218466', '4226227', '4231951', '4233696', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4398117', '4411925', '4418582', '4419049', '4426890', '4468729', '4471702', '4474027', '4475855', '4483708', '4486412', '4493439', '4495270', '4509910', '4567978', '4610426']\n",
      "- 2nd correct   12.879%, ['4172572', '4214761', '4264359', '4325441', '4332592', '4360488', '4416336', '4416962', '4457771', '4459187', '4469780', '4474029', '4497852', '4517258', '4549757', '4611640', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   6.061%, ['4186191', '4207348', '4300617', '4386702', '4427618', '4442121', '4543103', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    39.394%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4283622', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4409752', '4416336', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4486124', '4489017', '4497852', '4514851', '4547732', '4549757', '4559522', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     6.061%, ['4264359', '4279669', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   43.182%, ['4161667', '4162274', '4162511', '4163571', '4163572', '4163586', '4163587', '4166612', '4191591', '4193623', '4218466', '4226227', '4231951', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4446908', '4459005', '4468729', '4471702', '4473065', '4474027', '4475855', '4480454', '4483708', '4486412', '4493439', '4494659', '4495270', '4509910', '4512512', '4532060', '4540818', '4565270', '4566667', '4567978', '4567979', '4585539', '4596215', '4604737', '4609944', '4610426']\n",
      "- 2nd correct    5.303%, ['4288893', '4332592', '4403519', '4416506', '4480118', '4508138', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    44.697%, ['4157075', '4162259', '4162405', '4163588', '4166222', '4172572', '4192452', '4214761', '4216184', '4226166', '4226434', '4237913', '4264210', '4265125', '4283622', '4288893', '4300619', '4301518', '4313859', '4315749', '4325441', '4331667', '4332592', '4358231', '4360488', '4365752', '4366506', '4377106', '4397324', '4397469', '4399289', '4403315', '4403519', '4409752', '4416336', '4416506', '4416962', '4420924', '4457771', '4459187', '4460536', '4469489', '4469780', '4471292', '4474029', '4480118', '4486124', '4489017', '4497852', '4508138', '4514851', '4547732', '4549757', '4558106', '4559522', '4609093', '4611640', '4623143', '4624663']\n",
      "- diff error     6.061%, ['4264359', '4279669', '4283854', '4346730', '4404346', '4416888', '4517258', '4586220']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.970%, ['4161667', '4162274', '4162511', '4163572', '4163586', '4163587', '4166612', '4186191', '4191591', '4193623', '4207348', '4218466', '4226227', '4231951', '4233696', '4235798', '426992', '4275052', '4284345', '4297277', '4300617', '4304445', '4323506', '4353566', '4360483', '4372309', '4381717', '4386702', '4398117', '4407745', '4411925', '4418582', '4419049', '4426890', '4427618', '4442121', '4446908', '4459005', '4471702', '4473065', '4474027', '4475855', '4480454', '4483708', '4486412', '4493439', '4494659', '4509910', '4512512', '4532060', '4540818', '4543103', '4565270', '4566667', '4567978', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4610426']\n",
      "- 2nd correct    0.000%, []\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    92.424%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "- 2nd correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    56.061%, ['4157075', '4161667', '4162259', '4162405', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "- 2nd correct   39.394%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4386702', '4407745', '4416336', '4416962', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4469780', '4473065', '4474029', '4480454', '4494659', '4497852', '4512512', '4517258', '4532060', '4540818', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4611640', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    86.364%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4547732', '4549757', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "- 2nd correct   11.364%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4163571', '4468729', '4495270']\n",
      "- both incons    0.000%, []\n",
      "- same error    97.727%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4332592', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    0.000%, []\n",
      "- 2nd correct    0.000%, []\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   2.273%, ['4446908', '4480454', '4532060']\n",
      "- both incons    0.000%, []\n",
      "- same error    56.818%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4331667', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     3.788%, ['4279669', '4313859', '4346730', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    0.000%, []\n",
      "- 2nd correct   37.121%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4386702', '4407745', '4416336', '4416962', '4427618', '4442121', '4457771', '4459005', '4459187', '4469780', '4473065', '4474029', '4494659', '4497852', '4512512', '4517258', '4540818', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4611640', '4624663']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    83.333%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163571', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4457771', '4459005', '4459187', '4460536', '4468729', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4495270', '4497852', '4509910', '4512512', '4514851', '4540818', '4547732', '4549757', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "- 2nd correct   11.364%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    92.424%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4186191', '4191591', '4192452', '4193623', '4207348', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4315749', '4323506', '4325441', '4331667', '4332592', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4386702', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4407745', '4409752', '4411925', '4416336', '4416506', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4427618', '4442121', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4508138', '4509910', '4512512', '4514851', '4540818', '4543103', '4547732', '4549757', '4558106', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4593850', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     3.030%, ['4264359', '4313859', '4346730', '4517258']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    2.273%, ['4446908', '4480454', '4532060']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   6.061%, ['4186191', '4207348', '4332592', '4386702', '4427618', '4442121', '4543103', '4593850']\n",
      "- both incons    0.000%, []\n",
      "- same error    53.030%, ['4157075', '4161667', '4162259', '4162405', '4163571', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4283622', '4283854', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4409752', '4411925', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4468729', '4469489', '4471292', '4471702', '4474027', '4475855', '4483708', '4486124', '4486412', '4489017', '4493439', '4495270', '4509910', '4514851', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   33.333%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4191591', '4193623', '4214761', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4360488', '4372309', '4381717', '4407745', '4416336', '4416962', '4446908', '4457771', '4459005', '4459187', '4469780', '4473065', '4474029', '4480454', '4494659', '4497852', '4512512', '4517258', '4532060', '4540818', '4549757', '4565270', '4566667', '4567979', '4585539', '4596215', '4604737', '4609944', '4611640', '4624663']\n",
      "- 2nd correct    5.303%, ['4288893', '4300617', '4403519', '4416506', '4480118', '4508138', '4558106']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    56.061%, ['4157075', '4161667', '4162259', '4162405', '4163586', '4163587', '4163588', '4166222', '4192452', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4237913', '4264210', '4265125', '4283622', '4283854', '4288893', '4297277', '4300617', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4331667', '4346730', '4353566', '4358231', '4360483', '4365752', '4377106', '4397324', '4397469', '4398117', '4399289', '4403315', '4403519', '4404346', '4409752', '4411925', '4416506', '4416888', '4418582', '4419049', '4420924', '4426890', '4460536', '4469489', '4471292', '4471702', '4474027', '4475855', '4480118', '4483708', '4486124', '4486412', '4489017', '4493439', '4508138', '4509910', '4514851', '4558106', '4559522', '4567978', '4586220', '4609093', '4610426', '4623143']\n",
      "- diff error     2.273%, ['4279669', '4366506', '4547732']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   39.394%, ['4162274', '4162511', '4163572', '4166612', '4172572', '4186191', '4191591', '4193623', '4207348', '4214761', '4235798', '4264359', '426992', '4275052', '4284345', '4325441', '4332592', '4360488', '4372309', '4381717', '4386702', '4407745', '4416336', '4416962', '4427618', '4442121', '4446908', '4457771', '4459005', '4459187', '4469780', '4473065', '4474029', '4480454', '4494659', '4497852', '4512512', '4517258', '4532060', '4540818', '4543103', '4549757', '4565270', '4566667', '4567979', '4585539', '4593850', '4596215', '4604737', '4609944', '4611640', '4624663']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    86.364%, ['4157075', '4161667', '4162259', '4162274', '4162405', '4162511', '4163572', '4163586', '4163587', '4163588', '4166222', '4166612', '4172572', '4191591', '4192452', '4193623', '4214761', '4216184', '4218466', '4226166', '4226227', '4226434', '4231951', '4233696', '4235798', '4237913', '4264210', '4264359', '4265125', '426992', '4275052', '4279669', '4283622', '4283854', '4284345', '4297277', '4300619', '4301518', '4304445', '4313859', '4315749', '4323506', '4325441', '4331667', '4346730', '4353566', '4358231', '4360483', '4360488', '4365752', '4366506', '4372309', '4377106', '4381717', '4397324', '4397469', '4398117', '4399289', '4403315', '4404346', '4407745', '4409752', '4411925', '4416336', '4416888', '4416962', '4418582', '4419049', '4420924', '4426890', '4446908', '4457771', '4459005', '4459187', '4460536', '4469489', '4469780', '4471292', '4471702', '4473065', '4474027', '4474029', '4475855', '4480454', '4483708', '4486124', '4486412', '4489017', '4493439', '4494659', '4497852', '4509910', '4512512', '4514851', '4517258', '4532060', '4540818', '4547732', '4549757', '4559522', '4565270', '4566667', '4567978', '4567979', '4585539', '4586220', '4596215', '4604737', '4609093', '4609944', '4610426', '4611640', '4623143', '4624663']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   11.364%, ['4186191', '4207348', '4288893', '4300617', '4332592', '4386702', '4403519', '4416506', '4427618', '4442121', '4480118', '4508138', '4543103', '4558106', '4593850']\n",
      "- 2nd correct    2.273%, ['4163571', '4468729', '4495270']\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "test             | 1 |  19.697% (0.00000) |  57.576% (0.00000) |  62.121% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "test             | 1 |   0.000% (0.00000) |  21.970% (0.00000) |  23.485% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "test             | 1 |   0.758% (0.00000) |  15.152% (0.00000) |  15.909% (0.00000) | vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "test             | 1 |  24.242% (0.00000) |  80.303% (0.00000) |  94.697% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "test             | 1 |  21.212% (0.00000) |  65.152% (0.00000) |  73.485% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "test             | 1 |   5.303% (0.00000) |  10.606% (0.00000) |  10.606% (0.00000) | vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "test             | 1 |   0.000% (0.00000) |  17.424% (0.00000) |  17.424% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "test             | 1 |   1.515% (0.00000) |  18.182% (0.00000) |  18.939% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "test             | 1 |   0.758% (0.00000) |  10.606% (0.00000) |  12.121% (0.00000) | vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "test             | 1 |  21.212% (0.00000) |  58.333% (0.00000) |  62.879% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "test             | 1 |   0.000% (0.00000) |   3.788% (0.00000) |   3.788% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "test             | 1 |   0.758% (0.00000) |   9.848% (0.00000) |  11.364% (0.00000) | vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "test             | 1 |   6.818% (0.00000) |  37.121% (0.00000) |  40.152% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "test             | 1 |   1.515% (0.00000) |  12.879% (0.00000) |  12.879% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "test             | 1 |   0.758% (0.00000) |   3.030% (0.00000) |   3.030% (0.00000) | vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "---------------------------------------------------------------------------------\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4631727': 0, '4633603': 3, '4650113': 0, '4653852': 0, '4661735': 3, '4666231': 0, '4667626': 0, '4671406': 1, '4671443': 0, '4677606': 1, '4678080': 0, '4693039': 3, '4693198': 1, '4694833': 1, '4696505': 3, '4703149': 1, '4710576': 0, '4711578': 0, '4714481': 1, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 1, '4749611': 1, '4767260': 0, '4772658': 1, '4773857': 0, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 1, '4816604': 3, '4823439': 3, '4823611': 1, '4826952': 3, '4826957': 1, '4827285': 0, '4827287': 1, '4845088': 2, '4850346': 1, '4853692': 1, '4860099': 2, '4861484': 0, '4863146': 1, '4875475': 1, '4884993': 0, '4896659': 2, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 1, '4969415': 1, '4984238': 3, '4993934': 1, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 0, '5070846': 1, '5073839': 0, '5076753': 3, '5076821': 1, '5078640': 1, '5079918': 3, '5081990': 2, '5089294': 1, '5102537': 1, '5117279': 1, '5118757': 1, '5135326': 1, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 1, '5160584': 1, '5162042': 1, '5171396': 0, '5195826': 3, '5202182': 3, '5204781': 1, '5213896': 0, '5214265': 1, '5214755': 1, '5214943': 2, '5237462': 1, '5248391': 3, '5258365': 1, '5261461': 0, '5268098': 1, '5294335': 1, '5302339': 3, '5314439': 0, '5315510': 3, '5335389': 2, '5345058': 0, '5347155': 3, '5355157': 0, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 1, '5431709': 3, '547692': 1, '587794': 0, '633082': 1, '672063': 3, '672064': 3, '691688': 1, '691694': 1, '710469': 3, '750132': 1, '825292': 3, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 0, '925895': 3, '942357': 1, '94350': 1, '956606': 1, '986931': 0, '989704': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4631727': 1, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 1, '4671406': 3, '4671443': 1, '4677606': 1, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 1, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 1, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 1, '4773948': 3, '4800274': 1, '4800275': 1, '4810810': 3, '4816604': 2, '4823439': 1, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 1, '4845088': 3, '4850346': 3, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 1, '4937390': 3, '4947281': 1, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 3, '4984238': 3, '4993934': 1, '5024644': 1, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 1, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 3, '5117279': 3, '5118757': 1, '5135326': 3, '5137153': 3, '5137154': 1, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 1, '5160584': 3, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 3, '5214943': 2, '5237462': 3, '5248391': 1, '5258365': 1, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 3, '5314439': 1, '5315510': 3, '5335389': 3, '5345058': 1, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 1, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 1, '691694': 1, '710469': 3, '750132': 1, '825292': 3, '861484': 3, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 1, '942357': 3, '94350': 1, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 1, '4653852': 3, '4661735': 1, '4666231': 3, '4667626': 3, '4671406': 1, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 1, '4694833': 3, '4696505': 1, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 1, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 1, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 1, '4853692': 1, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 2, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 3, '4984238': 1, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 1, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 1, '5117279': 3, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 1, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 1, '5213896': 3, '5214265': 3, '5214755': 3, '5214943': 3, '5237462': 1, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 1, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 1, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 0, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 1, '750132': 3, '825292': 3, '861484': 3, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 1, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4631727': 2, '4633603': 2, '4650113': 1, '4653852': 0, '4661735': 0, '4666231': 0, '4667626': 2, '4671406': 1, '4671443': 1, '4677606': 1, '4678080': 1, '4693039': 1, '4693198': 1, '4694833': 1, '4696505': 1, '4703149': 3, '4710576': 0, '4711578': 1, '4714481': 1, '4723905': 1, '4735587': 1, '4735758': 1, '4743012': 1, '4749611': 0, '4767260': 0, '4772658': 0, '4773857': 2, '4773948': 1, '4800274': 1, '4800275': 2, '4810810': 3, '4816604': 2, '4823439': 1, '4823611': 1, '4826952': 1, '4826957': 1, '4827285': 0, '4827287': 2, '4845088': 1, '4850346': 0, '4853692': 1, '4860099': 2, '4861484': 0, '4863146': 1, '4875475': 0, '4884993': 0, '4896659': 2, '4899365': 1, '4921810': 1, '4936740': 1, '4937390': 1, '4947281': 0, '4951739': 2, '4955051': 1, '4955053': 1, '4960424': 1, '4969415': 0, '4984238': 3, '4993934': 1, '5024644': 1, '5039329': 2, '5051606': 0, '5068771': 2, '5070846': 1, '5073839': 0, '5076753': 1, '5076821': 1, '5078640': 1, '5079918': 1, '5081990': 1, '5089294': 1, '5102537': 1, '5117279': 1, '5118757': 1, '5135326': 1, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 2, '5143186': 1, '5157605': 0, '5160584': 1, '5162042': 1, '5171396': 0, '5195826': 0, '5202182': 1, '5204781': 1, '5213896': 0, '5214265': 0, '5214755': 1, '5214943': 0, '5237462': 0, '5248391': 1, '5258365': 2, '5261461': 0, '5268098': 1, '5294335': 1, '5302339': 1, '5314439': 2, '5315510': 1, '5335389': 2, '5345058': 2, '5347155': 1, '5355157': 2, '5356489': 1, '5363251': 1, '536656': 1, '5377710': 1, '5406759': 1, '5431709': 1, '547692': 1, '587794': 1, '633082': 1, '672063': 0, '672064': 0, '691688': 1, '691694': 1, '710469': 0, '750132': 0, '825292': 1, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 0, '907837': 0, '925895': 1, '942357': 2, '94350': 0, '956606': 1, '986931': 1, '989704': 0}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4631727': 0, '4633603': 2, '4650113': 1, '4653852': 2, '4661735': 1, '4666231': 3, '4667626': 0, '4671406': 0, '4671443': 1, '4677606': 1, '4678080': 3, '4693039': 1, '4693198': 1, '4694833': 1, '4696505': 1, '4703149': 1, '4710576': 3, '4711578': 3, '4714481': 1, '4723905': 1, '4735587': 0, '4735758': 1, '4743012': 1, '4749611': 1, '4767260': 3, '4772658': 3, '4773857': 2, '4773948': 0, '4800274': 1, '4800275': 1, '4810810': 1, '4816604': 0, '4823439': 1, '4823611': 0, '4826952': 1, '4826957': 0, '4827285': 0, '4827287': 3, '4845088': 2, '4850346': 0, '4853692': 0, '4860099': 2, '4861484': 3, '4863146': 1, '4875475': 3, '4884993': 3, '4896659': 2, '4899365': 1, '4921810': 0, '4936740': 1, '4937390': 0, '4947281': 1, '4951739': 2, '4955051': 0, '4955053': 0, '4960424': 3, '4969415': 3, '4984238': 3, '4993934': 1, '5024644': 1, '5039329': 3, '5051606': 1, '5068771': 3, '5070846': 1, '5073839': 3, '5076753': 1, '5076821': 1, '5078640': 1, '5079918': 1, '5081990': 0, '5089294': 1, '5102537': 1, '5117279': 1, '5118757': 1, '5135326': 1, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 1, '5157605': 2, '5160584': 1, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 0, '5204781': 1, '5213896': 3, '5214265': 3, '5214755': 1, '5214943': 1, '5237462': 3, '5248391': 0, '5258365': 0, '5261461': 3, '5268098': 0, '5294335': 1, '5302339': 1, '5314439': 0, '5315510': 1, '5335389': 2, '5345058': 0, '5347155': 3, '5355157': 2, '5356489': 1, '5363251': 1, '536656': 0, '5377710': 1, '5406759': 1, '5431709': 3, '547692': 1, '587794': 0, '633082': 1, '672063': 3, '672064': 3, '691688': 1, '691694': 1, '710469': 1, '750132': 1, '825292': 0, '861484': 1, '906680': 1, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 0, '942357': 2, '94350': 1, '956606': 0, '986931': 0, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 1, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 1, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 1, '4749611': 3, '4767260': 3, '4772658': 0, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 0, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 1, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 0, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 1, '5117279': 1, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 0, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 0, '5214755': 3, '5214943': 3, '5237462': 0, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 3, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 0, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 3, '825292': 3, '861484': 1, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 1, '4767260': 3, '4772658': 1, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 1, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 1, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 1, '4969415': 1, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 1, '5102537': 1, '5117279': 3, '5118757': 1, '5135326': 3, '5137153': 3, '5137154': 1, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 1, '5160584': 3, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 1, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 1, '5294335': 1, '5302339': 3, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 1, '5377710': 3, '5406759': 1, '5431709': 3, '547692': 1, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 3, '825292': 3, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 1, '94350': 3, '956606': 1, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4631727': 1, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 1, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 1, '4853692': 1, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 1, '4969415': 3, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 1, '5078640': 1, '5079918': 3, '5081990': 2, '5089294': 1, '5102537': 3, '5117279': 1, '5118757': 0, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 1, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 1, '5214755': 1, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 1, '5294335': 1, '5302339': 1, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 0, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 1, '587794': 3, '633082': 1, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 3, '825292': 3, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 1, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 3, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 2, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 1, '4955051': 3, '4955053': 3, '4960424': 1, '4969415': 3, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 1, '5078640': 1, '5079918': 3, '5081990': 2, '5089294': 1, '5102537': 3, '5117279': 3, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 3, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 1, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 1, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 0, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 1, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 3, '825292': 3, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 1, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4631727': 1, '4633603': 3, '4650113': 0, '4653852': 0, '4661735': 0, '4666231': 3, '4667626': 1, '4671406': 1, '4671443': 3, '4677606': 1, '4678080': 3, '4693039': 0, '4693198': 1, '4694833': 1, '4696505': 3, '4703149': 1, '4710576': 0, '4711578': 3, '4714481': 1, '4723905': 1, '4735587': 3, '4735758': 0, '4743012': 1, '4749611': 1, '4767260': 3, '4772658': 1, '4773857': 3, '4773948': 0, '4800274': 3, '4800275': 3, '4810810': 1, '4816604': 2, '4823439': 1, '4823611': 1, '4826952': 3, '4826957': 0, '4827285': 0, '4827287': 1, '4845088': 3, '4850346': 1, '4853692': 1, '4860099': 0, '4861484': 3, '4863146': 1, '4875475': 1, '4884993': 3, '4896659': 2, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 0, '4947281': 3, '4951739': 2, '4955051': 0, '4955053': 0, '4960424': 1, '4969415': 1, '4984238': 3, '4993934': 3, '5024644': 1, '5039329': 3, '5051606': 1, '5068771': 3, '5070846': 1, '5073839': 0, '5076753': 3, '5076821': 1, '5078640': 1, '5079918': 0, '5081990': 1, '5089294': 1, '5102537': 3, '5117279': 1, '5118757': 0, '5135326': 1, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 0, '5143186': 0, '5157605': 0, '5160584': 1, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 0, '5214265': 1, '5214755': 1, '5214943': 2, '5237462': 1, '5248391': 0, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 1, '5314439': 1, '5315510': 0, '5335389': 2, '5345058': 1, '5347155': 3, '5355157': 3, '5356489': 0, '5363251': 0, '536656': 3, '5377710': 3, '5406759': 1, '5431709': 3, '547692': 1, '587794': 0, '633082': 1, '672063': 3, '672064': 3, '691688': 1, '691694': 1, '710469': 1, '750132': 3, '825292': 0, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 3, '925895': 0, '942357': 2, '94350': 3, '956606': 1, '986931': 0, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 1, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 1, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 3, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 3, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 3, '5117279': 1, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 3, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 3, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 1, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 1, '750132': 3, '825292': 3, '861484': 3, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 3, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 2, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 1, '4955051': 3, '4955053': 3, '4960424': 1, '4969415': 3, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 1, '5078640': 1, '5079918': 3, '5081990': 2, '5089294': 1, '5102537': 3, '5117279': 3, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 3, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 1, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 1, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 0, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 1, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 3, '825292': 3, '861484': 1, '906680': 1, '906681': 1, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 1, '4653852': 3, '4661735': 1, '4666231': 3, '4667626': 3, '4671406': 1, '4671443': 3, '4677606': 1, '4678080': 3, '4693039': 0, '4693198': 1, '4694833': 1, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 1, '4723905': 1, '4735587': 3, '4735758': 0, '4743012': 1, '4749611': 1, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 1, '4816604': 3, '4823439': 1, '4823611': 1, '4826952': 3, '4826957': 3, '4827285': 1, '4827287': 3, '4845088': 3, '4850346': 1, '4853692': 1, '4860099': 0, '4861484': 3, '4863146': 3, '4875475': 1, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 1, '4951739': 3, '4955051': 3, '4955053': 0, '4960424': 3, '4969415': 1, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 1, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 1, '5079918': 0, '5081990': 0, '5089294': 1, '5102537': 3, '5117279': 3, '5118757': 3, '5135326': 3, '5137153': 1, '5137154': 3, '5137157': 3, '5137158': 3, '5143186': 0, '5157605': 1, '5160584': 1, '5162042': 1, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 1, '5213896': 3, '5214265': 3, '5214755': 3, '5214943': 2, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 1, '5294335': 1, '5302339': 1, '5314439': 3, '5315510': 0, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 2, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 1, '5431709': 3, '547692': 3, '587794': 0, '633082': 1, '672063': 3, '672064': 3, '691688': 1, '691694': 1, '710469': 1, '750132': 1, '825292': 3, '861484': 2, '906680': 1, '906681': 1, '906760': 1, '907836': 3, '907837': 3, '925895': 3, '942357': 2, '94350': 3, '956606': 1, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 0, '4653852': 3, '4661735': 3, '4666231': 3, '4667626': 3, '4671406': 1, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 1, '4694833': 3, '4696505': 3, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 1, '4816604': 3, '4823439': 3, '4823611': 1, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 3, '4853692': 1, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 1, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 1, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 1, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 3, '5117279': 3, '5118757': 3, '5135326': 1, '5137153': 3, '5137154': 1, '5137157': 3, '5137158': 3, '5143186': 3, '5157605': 1, '5160584': 1, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 1, '5214755': 3, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 3, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 1, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 3, '750132': 0, '825292': 3, '861484': 3, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 1, '986931': 3, '989704': 3}\n",
      "consistent errors for vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "100.000% {'4631727': 3, '4633603': 3, '4650113': 3, '4653852': 3, '4661735': 1, '4666231': 3, '4667626': 3, '4671406': 3, '4671443': 3, '4677606': 3, '4678080': 3, '4693039': 3, '4693198': 3, '4694833': 3, '4696505': 1, '4703149': 3, '4710576': 3, '4711578': 3, '4714481': 3, '4723905': 3, '4735587': 3, '4735758': 3, '4743012': 3, '4749611': 3, '4767260': 3, '4772658': 3, '4773857': 3, '4773948': 3, '4800274': 3, '4800275': 3, '4810810': 3, '4816604': 3, '4823439': 3, '4823611': 3, '4826952': 3, '4826957': 3, '4827285': 3, '4827287': 3, '4845088': 3, '4850346': 3, '4853692': 3, '4860099': 3, '4861484': 3, '4863146': 3, '4875475': 3, '4884993': 3, '4896659': 3, '4899365': 3, '4921810': 3, '4936740': 3, '4937390': 3, '4947281': 3, '4951739': 3, '4955051': 3, '4955053': 3, '4960424': 3, '4969415': 3, '4984238': 3, '4993934': 3, '5024644': 3, '5039329': 3, '5051606': 3, '5068771': 3, '5070846': 3, '5073839': 3, '5076753': 3, '5076821': 3, '5078640': 3, '5079918': 3, '5081990': 3, '5089294': 3, '5102537': 3, '5117279': 3, '5118757': 3, '5135326': 3, '5137153': 3, '5137154': 3, '5137157': 1, '5137158': 3, '5143186': 3, '5157605': 3, '5160584': 3, '5162042': 3, '5171396': 3, '5195826': 3, '5202182': 3, '5204781': 3, '5213896': 3, '5214265': 3, '5214755': 3, '5214943': 3, '5237462': 3, '5248391': 3, '5258365': 3, '5261461': 3, '5268098': 3, '5294335': 3, '5302339': 3, '5314439': 3, '5315510': 3, '5335389': 3, '5345058': 3, '5347155': 3, '5355157': 3, '5356489': 3, '5363251': 3, '536656': 3, '5377710': 3, '5406759': 3, '5431709': 3, '547692': 3, '587794': 3, '633082': 3, '672063': 3, '672064': 3, '691688': 3, '691694': 3, '710469': 0, '750132': 3, '825292': 3, '861484': 3, '906680': 3, '906681': 3, '906760': 3, '907836': 3, '907837': 3, '925895': 3, '942357': 3, '94350': 3, '956606': 3, '986931': 3, '989704': 3}\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  12.879%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4773857', '4827287', '4993934', '5118757', '5157605', '5258365', '5314439', '5345058', '691688', '691694', '750132', '94350']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4633603', '4661735', '4693039', '4696505', '4735587', '4735758', '4773948', '4826952', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4984238', '5039329', '5051606', '5079918', '5137153', '5137157', '5137158', '5143186', '5195826', '5202182', '5214943', '5302339', '5315510', '5347155', '5356489', '5363251', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836']\n",
      "- diff error     4.545%, ['4816604', '4845088', '4860099', '4896659', '5081990', '5335389']\n",
      "- music error    0.758%, ['5214943']\n",
      "- 1st correct   44.697%, ['4650113', '4653852', '4666231', '4671406', '4678080', '4693198', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4810810', '4823611', '4826957', '4827285', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4960424', '4969415', '5068771', '5070846', '5073839', '5076821', '5078640', '5089294', '5102537', '5117279', '5135326', '5160584', '5162042', '5171396', '5204781', '5213896', '5214265', '5214755', '5237462', '5261461', '5268098', '5294335', '5355157', '5406759', '547692', '587794', '633082', '861484', '906680', '906681', '907837', '942357', '956606', '986931', '989704']\n",
      "- 2nd correct    9.091%, ['4723905', '4800274', '4800275', '4823439', '4936740', '4947281', '5024644', '5076753', '5137154', '5248391', '536656', '925895']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct  11.364%, ['4650113', '4671406', '4693198', '4743012', '4823611', '4850346', '4853692', '5076821', '5102537', '5160584', '5204781', '5237462', '5355157', '633082', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    34.848%, ['4633603', '4693039', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '906760', '907836', '925895']\n",
      "- diff error     3.788%, ['4845088', '4860099', '5081990', '5214943', '5335389']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   46.212%, ['4631727', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4694833', '4703149', '4710576', '4711578', '4714481', '4749611', '4767260', '4772658', '4773857', '4810810', '4826957', '4827285', '4827287', '4861484', '4863146', '4875475', '4884993', '4960424', '4969415', '4993934', '5068771', '5070846', '5073839', '5078640', '5089294', '5117279', '5118757', '5135326', '5157605', '5162042', '5171396', '5213896', '5214265', '5214755', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5406759', '547692', '587794', '691688', '691694', '750132', '861484', '906680', '906681', '907837', '942357', '94350', '986931', '989704']\n",
      "- 2nd correct    3.788%, ['4661735', '4696505', '4984238', '5302339', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  48.485%, ['4650113', '4653852', '4666231', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4823611', '4826957', '4827285', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4960424', '4969415', '4993934', '5070846', '5073839', '5076821', '5078640', '5089294', '5102537', '5117279', '5118757', '5135326', '5157605', '5160584', '5162042', '5171396', '5204781', '5213896', '5214265', '5214755', '5237462', '5261461', '5268098', '5294335', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '861484', '906680', '906681', '907837', '94350', '956606', '986931', '989704']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.061%, ['4860099', '4896659', '4984238', '5137153', '5137154', '5137157', '5335389', '906760']\n",
      "- diff error     4.545%, ['4633603', '4800275', '4816604', '4951739', '5039329', '5137158']\n",
      "- music error    2.273%, ['4860099', '4896659', '5335389']\n",
      "- 1st correct    9.091%, ['4631727', '4667626', '4703149', '4773857', '4810810', '4827287', '5068771', '5258365', '5314439', '5345058', '5355157', '942357']\n",
      "- 2nd correct   31.818%, ['4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4823439', '4826952', '4845088', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '5024644', '5051606', '5076753', '5079918', '5081990', '5143186', '5195826', '5202182', '5214943', '5248391', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '907836', '925895']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  37.121%, ['4631727', '4650113', '4667626', '4671406', '4671443', '4677606', '4693198', '4694833', '4703149', '4714481', '4743012', '4749611', '4810810', '4823611', '4826957', '4827285', '4850346', '4853692', '4863146', '4993934', '5070846', '5076821', '5078640', '5089294', '5102537', '5117279', '5118757', '5135326', '5160584', '5162042', '5204781', '5214755', '5258365', '5268098', '5294335', '5314439', '5345058', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '861484', '906680', '94350', '956606', '986931']\n",
      "- both incons    0.000%, []\n",
      "- same error    12.879%, ['4845088', '4860099', '4896659', '4984238', '5039329', '5137153', '5137154', '5137157', '5137158', '5195826', '5335389', '5347155', '5431709', '672063', '672064', '906760', '907836']\n",
      "- diff error     1.515%, ['4633603', '4951739']\n",
      "- music error    3.030%, ['4845088', '4860099', '4896659', '5335389']\n",
      "- 1st correct   20.455%, ['4653852', '4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4773857', '4827287', '4861484', '4875475', '4884993', '4960424', '4969415', '5068771', '5073839', '5157605', '5171396', '5213896', '5214265', '5237462', '5261461', '5355157', '906681', '907837', '942357', '989704']\n",
      "- 2nd correct   28.030%, ['4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '5024644', '5051606', '5076753', '5079918', '5081990', '5143186', '5202182', '5214943', '5248391', '5302339', '5315510', '5356489', '5363251', '536656', '5377710', '710469', '825292', '925895']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct  10.606%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.879%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     4.545%, ['4845088', '4860099', '4896659', '5081990', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.970%, ['4631727', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4749611', '4767260', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4853692', '4861484', '4863146', '4884993', '4960424', '4993934', '5068771', '5070846', '5073839', '5076821', '5078640', '5089294', '5118757', '5135326', '5157605', '5162042', '5171396', '5204781', '5213896', '5214755', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5355157', '5406759', '547692', '587794', '691688', '691694', '750132', '906680', '906681', '907837', '942357', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.909%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5102537', '5118757', '5157605', '5162042', '5214755', '5268098', '5294335', '5406759', '547692', '861484', '906680', '906681', '942357', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    36.364%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5302339', '5315510', '5347155', '5356489', '5363251', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     4.545%, ['4845088', '4860099', '4896659', '5081990', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   41.667%, ['4631727', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4767260', '4773857', '4810810', '4826957', '4827285', '4827287', '4853692', '4861484', '4863146', '4875475', '4884993', '4993934', '5068771', '5070846', '5073839', '5076821', '5078640', '5117279', '5135326', '5160584', '5171396', '5204781', '5213896', '5214265', '5237462', '5258365', '5261461', '5314439', '5345058', '5355157', '587794', '633082', '691688', '691694', '750132', '907837', '94350', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['5137154', '536656']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  17.424%, ['4631727', '4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5117279', '5118757', '5160584', '5162042', '5214265', '5214755', '5268098', '5294335', '5355157', '547692', '633082', '861484', '906680', '906681', '942357']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.879%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5081990', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     3.788%, ['4845088', '4860099', '4896659', '5214943', '5335389']\n",
      "- music error    0.758%, ['5081990']\n",
      "- 1st correct   40.152%, ['4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4749611', '4767260', '4772658', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4861484', '4863146', '4875475', '4884993', '4969415', '4993934', '5068771', '5070846', '5073839', '5102537', '5135326', '5157605', '5171396', '5204781', '5213896', '5237462', '5258365', '5261461', '5314439', '5345058', '5406759', '587794', '691688', '691694', '750132', '907837', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    0.758%, ['5302339']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.091%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.879%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5081990', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     3.030%, ['4845088', '4860099', '5214943', '5335389']\n",
      "- music error    1.515%, ['4896659', '5081990']\n",
      "- 1st correct   48.485%, ['4631727', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4969415', '4993934', '5068771', '5070846', '5073839', '5102537', '5117279', '5118757', '5135326', '5157605', '5160584', '5171396', '5204781', '5213896', '5214265', '5237462', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5406759', '587794', '633082', '691688', '691694', '750132', '907837', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['4951739', '5302339']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  40.152%, ['4631727', '4650113', '4653852', '4667626', '4671406', '4677606', '4693198', '4694833', '4703149', '4710576', '4714481', '4743012', '4749611', '4772658', '4810810', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4863146', '4875475', '4960424', '4969415', '5070846', '5073839', '5076821', '5078640', '5089294', '5117279', '5118757', '5135326', '5157605', '5160584', '5162042', '5213896', '5214265', '5214755', '5237462', '5314439', '5345058', '5406759', '547692', '587794', '633082', '691688', '691694', '861484', '906680', '906681', '956606', '986931']\n",
      "- both incons    0.000%, []\n",
      "- same error    21.970%, ['4633603', '4696505', '4735587', '4800274', '4800275', '4826952', '4896659', '4899365', '4921810', '4936740', '4947281', '4984238', '5039329', '5076753', '5137153', '5137154', '5137157', '5195826', '5202182', '5214943', '5335389', '5347155', '536656', '5377710', '5431709', '672063', '672064', '906760', '907836']\n",
      "- diff error     2.273%, ['4816604', '4845088', '4951739']\n",
      "- music error    2.273%, ['4896659', '5214943', '5335389']\n",
      "- 1st correct   17.424%, ['4666231', '4671443', '4678080', '4711578', '4767260', '4773857', '4861484', '4884993', '4993934', '5068771', '5102537', '5171396', '5204781', '5258365', '5261461', '5268098', '5294335', '5355157', '750132', '907837', '942357', '94350', '989704']\n",
      "- 2nd correct   18.182%, ['4661735', '4693039', '4723905', '4735758', '4773948', '4823439', '4860099', '4937390', '4955051', '4955053', '5024644', '5051606', '5079918', '5081990', '5137158', '5143186', '5248391', '5302339', '5315510', '5356489', '5363251', '710469', '825292', '925895']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.758%, ['5117279']\n",
      "- both incons    0.000%, []\n",
      "- same error    34.848%, ['4633603', '4693039', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '906760', '907836', '925895']\n",
      "- diff error     4.545%, ['4845088', '4860099', '4896659', '5081990', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   56.818%, ['4631727', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4960424', '4969415', '4993934', '5068771', '5070846', '5073839', '5076821', '5078640', '5089294', '5102537', '5118757', '5135326', '5157605', '5160584', '5162042', '5171396', '5204781', '5213896', '5214265', '5214755', '5237462', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5355157', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '861484', '906680', '906681', '907837', '942357', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5302339', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   8.333%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5355157', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.879%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5081990', '5137153', '5137154', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     3.030%, ['4845088', '4860099', '5214943', '5335389']\n",
      "- music error    1.515%, ['4896659', '5081990']\n",
      "- 1st correct   49.242%, ['4631727', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4969415', '4993934', '5068771', '5070846', '5073839', '5102537', '5117279', '5118757', '5135326', '5157605', '5160584', '5171396', '5204781', '5213896', '5214265', '5237462', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5406759', '587794', '633082', '691688', '691694', '750132', '907837', '942357', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['4951739', '5302339']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  24.242%, ['4650113', '4671406', '4677606', '4693198', '4694833', '4714481', '4743012', '4749611', '4810810', '4823611', '4827285', '4850346', '4853692', '4875475', '4969415', '5078640', '5089294', '5157605', '5160584', '5162042', '5204781', '5268098', '5294335', '5406759', '587794', '633082', '691688', '691694', '750132', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    27.273%, ['4633603', '4696505', '4735587', '4773948', '4800274', '4800275', '4816604', '4826952', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4984238', '5024644', '5039329', '5076753', '5137154', '5137157', '5137158', '5195826', '5202182', '5214943', '5248391', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '907836', '925895']\n",
      "- diff error     2.273%, ['4845088', '4896659', '5335389']\n",
      "- music error    0.758%, ['5214943']\n",
      "- 1st correct   33.333%, ['4631727', '4653852', '4666231', '4667626', '4671443', '4678080', '4703149', '4710576', '4711578', '4767260', '4772658', '4773857', '4826957', '4827287', '4861484', '4863146', '4884993', '4960424', '4993934', '5068771', '5070846', '5073839', '5076821', '5102537', '5117279', '5118757', '5135326', '5171396', '5213896', '5214265', '5214755', '5237462', '5258365', '5261461', '5314439', '5345058', '5355157', '547692', '861484', '907837', '942357', '94350', '986931', '989704']\n",
      "- 2nd correct   12.879%, ['4661735', '4693039', '4723905', '4735758', '4823439', '4860099', '4947281', '4955053', '5051606', '5079918', '5081990', '5137153', '5143186', '5302339', '5315510', '710469', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  11.364%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4969415', '5135326', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    36.364%, ['4633603', '4661735', '4693039', '4696505', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137157', '5137158', '5143186', '5195826', '5202182', '5248391', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '710469', '825292', '906760', '907836', '925895']\n",
      "- diff error     4.545%, ['4845088', '4860099', '4896659', '5081990', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   46.212%, ['4631727', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4773857', '4826957', '4827285', '4827287', '4850346', '4861484', '4863146', '4884993', '4960424', '4993934', '5068771', '5070846', '5073839', '5076821', '5078640', '5089294', '5102537', '5117279', '5118757', '5162042', '5171396', '5204781', '5213896', '5214755', '5237462', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5355157', '5406759', '547692', '587794', '691688', '691694', '861484', '906680', '906681', '907837', '942357', '94350', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['4947281', '5137154']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    34.848%, ['4633603', '4693039', '4723905', '4735587', '4735758', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '5024644', '5039329', '5051606', '5076753', '5079918', '5137153', '5137154', '5137158', '5143186', '5195826', '5202182', '5248391', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '906760', '907836', '925895']\n",
      "- diff error     4.545%, ['4845088', '4860099', '4896659', '5081990', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   57.576%, ['4631727', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4743012', '4749611', '4767260', '4772658', '4773857', '4810810', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4960424', '4969415', '4993934', '5068771', '5070846', '5073839', '5076821', '5078640', '5089294', '5102537', '5117279', '5118757', '5135326', '5157605', '5160584', '5162042', '5171396', '5204781', '5213896', '5214265', '5214755', '5237462', '5258365', '5261461', '5268098', '5294335', '5314439', '5345058', '5355157', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '861484', '906680', '906681', '907837', '942357', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    60.606%, ['4633603', '4653852', '4666231', '4678080', '4693039', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4749611', '4767260', '4772658', '4773948', '4810810', '4826952', '4826957', '4827285', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4960424', '4969415', '5039329', '5051606', '5068771', '5070846', '5073839', '5078640', '5079918', '5081990', '5089294', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5261461', '5268098', '5294335', '5315510', '5335389', '5347155', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '942357', '986931', '989704']\n",
      "- diff error     2.273%, ['4816604', '4896659', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct   15.152%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4823611', '4850346', '4853692', '4984238', '5076821', '5102537', '5160584', '5204781', '5237462', '5302339', '5355157', '633082', '710469', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.152%, ['4671443', '4677606', '4694833', '4723905', '4800274', '4823439', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5157605', '5248391', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- both incons    0.000%, []\n",
      "- same error     5.303%, ['4703149', '4810810', '4816604', '4984238', '5137153', '5137157', '906760']\n",
      "- diff error     7.576%, ['4633603', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5335389', '5355157', '942357']\n",
      "- music error    0.758%, ['4816604']\n",
      "- 1st correct    6.818%, ['4631727', '4667626', '4773857', '4800275', '4827287', '5137154', '5258365', '5314439', '5345058']\n",
      "- 2nd correct   65.152%, ['4650113', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4937390', '4955051', '4955053', '4960424', '4969415', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5135326', '5143186', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5214943', '5237462', '5261461', '5268098', '5294335', '5302339', '5315510', '5347155', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '710469', '825292', '861484', '906680', '906681', '907836', '907837', '956606', '986931', '989704']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  18.939%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4800274', '4800275', '4823439', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.000%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4861484', '4875475', '4884993', '4960424', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     6.818%, ['4633603', '4653852', '4845088', '4860099', '4896659', '4951739', '5335389', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.030%, ['4773857', '4827287', '5137154', '5157605']\n",
      "- 2nd correct   46.212%, ['4650113', '4661735', '4671406', '4693039', '4693198', '4696505', '4703149', '4714481', '4735587', '4735758', '4743012', '4749611', '4773948', '4810810', '4816604', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4937390', '4955051', '4955053', '5051606', '5070846', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5135326', '5143186', '5160584', '5162042', '5202182', '5204781', '5214755', '5214943', '5268098', '5294335', '5302339', '5315510', '5356489', '5363251', '5377710', '5406759', '547692', '587794', '633082', '710469', '825292', '861484', '906680', '956606', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    65.909%, ['4633603', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4703149', '4710576', '4711578', '4735587', '4735758', '4749611', '4767260', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4960424', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5135326', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5261461', '5268098', '5294335', '5302339', '5315510', '5335389', '5347155', '5355157', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '710469', '825292', '906680', '906681', '906760', '907836', '907837', '942357', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4816604', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct   10.606%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.030%, ['5118757', '5137154', '5157605', '536656']\n",
      "- both incons    0.000%, []\n",
      "- same error    62.121%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4767260', '4773948', '4810810', '4826952', '4826957', '4827285', '4845088', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5237462', '5261461', '5302339', '5315510', '5335389', '5347155', '5355157', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '710469', '825292', '906760', '907836', '907837', '986931', '989704']\n",
      "- diff error     1.515%, ['4816604', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   18.939%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5248391', '5258365', '5314439', '5345058', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct   14.394%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5102537', '5162042', '5214755', '5268098', '5294335', '5406759', '547692', '861484', '906680', '906681', '942357', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['4631727', '5118757']\n",
      "- both incons    0.000%, []\n",
      "- same error    59.091%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4749611', '4767260', '4772658', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4969415', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5079918', '5102537', '5135326', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5237462', '5261461', '5315510', '5335389', '5347155', '5356489', '5363251', '5377710', '5406759', '5431709', '587794', '672063', '672064', '710469', '825292', '906760', '907836', '907837', '956606', '986931', '989704']\n",
      "- diff error     2.273%, ['4816604', '5081990', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   20.455%, ['4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct   16.667%, ['4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5117279', '5160584', '5162042', '5214265', '5214755', '5268098', '5294335', '5302339', '5355157', '547692', '633082', '861484', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    64.394%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4937390', '4955051', '4955053', '4969415', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5079918', '5102537', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5237462', '5261461', '5268098', '5294335', '5315510', '5335389', '5347155', '5356489', '5363251', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '710469', '825292', '906760', '907836', '907837', '956606', '986931', '989704']\n",
      "- diff error     3.030%, ['4816604', '4896659', '5081990', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct   10.606%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.121%, ['4631727', '4667626', '4677606', '4694833', '4723905', '4823439', '4827287', '5024644', '5118757', '5157605', '5248391', '5314439', '5345058', '691688', '691694', '925895']\n",
      "- both incons    0.000%, []\n",
      "- same error    28.788%, ['4633603', '4666231', '4678080', '4696505', '4711578', '4735587', '4767260', '4816604', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4984238', '5039329', '5068771', '5102537', '5137153', '5137157', '5171396', '5195826', '5202182', '5204781', '5214943', '5261461', '5268098', '5294335', '5347155', '5355157', '5377710', '5431709', '672063', '672064', '906760', '907836', '907837', '989704']\n",
      "- diff error     3.030%, ['4896659', '4951739', '5335389', '942357']\n",
      "- music error    1.515%, ['4816604', '5214943']\n",
      "- 1st correct    9.848%, ['4671443', '4773857', '4800274', '4800275', '4936740', '4947281', '4993934', '5076753', '5137154', '5258365', '536656', '750132', '94350']\n",
      "- 2nd correct   46.212%, ['4650113', '4653852', '4661735', '4671406', '4693039', '4693198', '4703149', '4710576', '4714481', '4735758', '4743012', '4749611', '4772658', '4773948', '4810810', '4823611', '4826957', '4827285', '4850346', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4960424', '4969415', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5117279', '5135326', '5137158', '5143186', '5160584', '5162042', '5213896', '5214265', '5214755', '5237462', '5302339', '5315510', '5356489', '5363251', '5406759', '547692', '587794', '633082', '710469', '825292', '861484', '906680', '906681', '956606', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    72.727%, ['4633603', '4650113', '4653852', '4666231', '4671406', '4678080', '4693039', '4693198', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4960424', '4969415', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5237462', '5261461', '5268098', '5294335', '5315510', '5335389', '5347155', '5355157', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '942357', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4816604', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct    3.788%, ['4661735', '4696505', '5117279', '5302339', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    65.152%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4671406', '4678080', '4693039', '4693198', '4696505', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4937390', '4955051', '4955053', '4969415', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5079918', '5102537', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5237462', '5261461', '5268098', '5294335', '5315510', '5335389', '5347155', '5356489', '5363251', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '710469', '825292', '906760', '907836', '907837', '942357', '956606', '986931', '989704']\n",
      "- diff error     3.030%, ['4816604', '4896659', '5081990', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct    9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   6.818%, ['4677606', '4694833', '4723905', '4823439', '4947281', '5157605', '691688', '691694', '750132']\n",
      "- both incons    0.000%, []\n",
      "- same error    44.697%, ['4633603', '4653852', '4666231', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773948', '4826952', '4826957', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4960424', '4984238', '5039329', '5068771', '5070846', '5073839', '5076821', '5102537', '5117279', '5135326', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5214943', '5237462', '5261461', '5335389', '5347155', '5356489', '5363251', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '986931', '989704']\n",
      "- diff error     3.030%, ['4816604', '5355157', '861484', '942357']\n",
      "- music error    0.758%, ['5214943']\n",
      "- 1st correct   15.152%, ['4631727', '4667626', '4671443', '4773857', '4800274', '4800275', '4827287', '4936740', '4993934', '5024644', '5076753', '5118757', '5137154', '5248391', '5258365', '5314439', '5345058', '536656', '925895', '94350']\n",
      "- 2nd correct   30.303%, ['4650113', '4661735', '4671406', '4693039', '4693198', '4714481', '4735758', '4743012', '4749611', '4810810', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5160584', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '633082', '710469', '906680', '906681', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.030%, ['4947281', '5137154', '5157605', '750132']\n",
      "- both incons    0.000%, []\n",
      "- same error    66.667%, ['4633603', '4653852', '4661735', '4666231', '4678080', '4693039', '4696505', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4826952', '4826957', '4827285', '4845088', '4850346', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4960424', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5237462', '5261461', '5268098', '5294335', '5302339', '5315510', '5335389', '5347155', '5355157', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '710469', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '942357', '986931', '989704']\n",
      "- diff error     1.515%, ['4816604', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   18.939%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4993934', '5024644', '5076753', '5118757', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '925895', '94350']\n",
      "- 2nd correct    9.848%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4969415', '5135326', '5160584', '5214265', '633082', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    73.485%, ['4633603', '4650113', '4653852', '4666231', '4671406', '4678080', '4693039', '4693198', '4703149', '4710576', '4711578', '4714481', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4810810', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4937390', '4951739', '4955051', '4955053', '4960424', '4969415', '4984238', '5039329', '5051606', '5068771', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5135326', '5137153', '5137158', '5143186', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5237462', '5261461', '5268098', '5294335', '5302339', '5315510', '5335389', '5347155', '5355157', '5356489', '5363251', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '942357', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4816604', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   21.970%, ['4631727', '4667626', '4671443', '4677606', '4694833', '4723905', '4773857', '4800274', '4800275', '4823439', '4827287', '4936740', '4947281', '4993934', '5024644', '5076753', '5118757', '5137154', '5157605', '5248391', '5258365', '5314439', '5345058', '536656', '691688', '691694', '750132', '925895', '94350']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  13.636%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4823611', '4850346', '4853692', '5076821', '5102537', '5160584', '5204781', '5237462', '5302339', '633082', '710469', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error     5.303%, ['4703149', '4810810', '4896659', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    12.879%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct    1.515%, ['4984238', '5355157']\n",
      "- 2nd correct   66.667%, ['4653852', '4666231', '4671443', '4677606', '4678080', '4693039', '4694833', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4826952', '4826957', '4827285', '4845088', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4960424', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5214943', '5248391', '5261461', '5268098', '5294335', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  12.879%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4823611', '4850346', '4853692', '5076821', '5102537', '5160584', '5204781', '5302339', '633082', '710469', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.758%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4896659', '4960424', '4969415', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     6.818%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4951739', '5157605', '5335389', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct    2.273%, ['4984238', '5237462', '5355157']\n",
      "- 2nd correct   52.273%, ['4631727', '4667626', '4671443', '4677606', '4693039', '4694833', '4703149', '4714481', '4723905', '4735587', '4735758', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5143186', '5162042', '5202182', '5214755', '5214943', '5248391', '5258365', '5268098', '5294335', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '691688', '691694', '750132', '825292', '861484', '906680', '925895', '94350', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   5.303%, ['4650113', '4743012', '4850346', '5102537', '5160584', '5237462', '633082']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5213896', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4661735', '4671406', '4693198', '4696505', '4823611', '4853692', '4984238', '5076821', '5204781', '5302339', '5355157', '710469', '956606']\n",
      "- 2nd correct    5.303%, ['4714481', '4772658', '4875475', '4969415', '5117279', '5214265', '861484']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.030%, ['4823611', '4850346', '5102537', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    69.697%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5213896', '5214265', '5214943', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '5377710', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4853692', '4984238', '5076821', '5160584', '5204781', '5237462', '5302339', '5355157', '633082', '710469']\n",
      "- 2nd correct   14.394%, ['4749611', '4772658', '4960424', '4969415', '5089294', '5118757', '5137154', '5157605', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   6.061%, ['4743012', '4850346', '4853692', '5076821', '5160584', '5302339', '5355157', '633082']\n",
      "- both incons    0.000%, []\n",
      "- same error    71.212%, ['4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4969415', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5213896', '5214943', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4823611', '4984238', '5102537', '5204781', '5237462', '710469', '956606']\n",
      "- 2nd correct   12.121%, ['4631727', '4960424', '5078640', '5089294', '5117279', '5118757', '5162042', '5214265', '5214755', '5268098', '5294335', '547692', '861484', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['5076821', '5302339', '5355157']\n",
      "- both incons    0.000%, []\n",
      "- same error    75.758%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5117279', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5213896', '5214265', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   12.879%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4823611', '4850346', '4853692', '4984238', '5102537', '5160584', '5204781', '5237462', '633082', '710469', '956606']\n",
      "- 2nd correct    8.333%, ['4951739', '4960424', '5078640', '5089294', '5162042', '5214755', '547692', '861484', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  11.364%, ['4650113', '4661735', '4671406', '4693198', '4743012', '4823611', '4850346', '4853692', '5076821', '5160584', '5237462', '5302339', '633082', '710469', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    34.091%, ['4633603', '4666231', '4671443', '4678080', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4896659', '4899365', '4921810', '4936740', '4947281', '4993934', '5039329', '5068771', '5076753', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5258365', '5261461', '5268098', '5294335', '5347155', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     3.788%, ['4816604', '4951739', '5214943', '5335389', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct    3.788%, ['4696505', '4984238', '5102537', '5204781', '5355157']\n",
      "- 2nd correct   46.970%, ['4631727', '4653852', '4667626', '4677606', '4693039', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4749611', '4772658', '4773948', '4810810', '4823439', '4826957', '4827285', '4827287', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4960424', '4969415', '5024644', '5051606', '5070846', '5073839', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5137158', '5143186', '5157605', '5162042', '5213896', '5214265', '5214755', '5248391', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '691688', '691694', '825292', '861484', '906680', '906681', '925895', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.030%, ['4661735', '4696505', '5302339', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    83.333%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4969415', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.121%, ['4650113', '4671406', '4693198', '4743012', '4823611', '4850346', '4853692', '4984238', '5076821', '5102537', '5160584', '5204781', '5237462', '5355157', '633082', '956606']\n",
      "- 2nd correct    0.758%, ['5117279']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['5076821', '5302339', '5355157']\n",
      "- both incons    0.000%, []\n",
      "- same error    76.515%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5117279', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5213896', '5214265', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   12.879%, ['4650113', '4661735', '4671406', '4693198', '4696505', '4743012', '4823611', '4850346', '4853692', '4984238', '5102537', '5160584', '5204781', '5237462', '633082', '710469', '956606']\n",
      "- 2nd correct    7.576%, ['4951739', '4960424', '5078640', '5089294', '5162042', '5214755', '547692', '861484', '906680', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  10.606%, ['4650113', '4661735', '4671406', '4693198', '4743012', '4823611', '4850346', '4853692', '5160584', '5204781', '5302339', '633082', '710469', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    55.303%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4960424', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5117279', '5118757', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     3.030%, ['4896659', '5214943', '861484', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['4696505', '4984238', '5076821', '5102537', '5237462', '5355157']\n",
      "- 2nd correct   26.515%, ['4677606', '4693039', '4694833', '4714481', '4723905', '4735758', '4749611', '4810810', '4823439', '4827285', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5157605', '5162042', '5268098', '5294335', '5315510', '5406759', '587794', '691688', '691694', '750132', '906680', '906681', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   6.061%, ['4650113', '4671406', '4693198', '4823611', '4853692', '5160584', '633082', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    77.273%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4960424', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5213896', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.091%, ['4661735', '4696505', '4743012', '4850346', '4984238', '5076821', '5102537', '5204781', '5237462', '5302339', '5355157', '710469']\n",
      "- 2nd correct    6.818%, ['4810810', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '5214265', '750132']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-16_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4661735', '4696505', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    83.333%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4969415', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.879%, ['4650113', '4671406', '4693198', '4743012', '4823611', '4850346', '4853692', '4984238', '5076821', '5102537', '5160584', '5204781', '5237462', '5302339', '5355157', '633082', '956606']\n",
      "- 2nd correct    0.758%, ['5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  58.333%, ['4650113', '4661735', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5135326', '5143186', '5160584', '5162042', '5202182', '5204781', '5214755', '5214943', '5248391', '5268098', '5294335', '5302339', '5315510', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '633082', '691688', '691694', '710469', '750132', '825292', '861484', '906680', '925895', '94350', '956606', '986931']\n",
      "- both incons    0.000%, []\n",
      "- same error     9.848%, ['4633603', '4773857', '4860099', '4896659', '4951739', '4984238', '5137153', '5137154', '5137157', '5335389', '5355157', '906760', '942357']\n",
      "- diff error     3.030%, ['4827287', '5039329', '5068771', '5137158']\n",
      "- music error    6.061%, ['4633603', '4773857', '4860099', '4896659', '4951739', '5335389', '5355157', '942357']\n",
      "- 1st correct   21.970%, ['4653852', '4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4845088', '4861484', '4875475', '4884993', '4960424', '4969415', '5073839', '5157605', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906681', '907836', '907837', '989704']\n",
      "- 2nd correct    6.818%, ['4631727', '4667626', '4703149', '4800275', '4810810', '4816604', '5258365', '5314439', '5345058']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct  10.606%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error     5.303%, ['4703149', '4810810', '4984238', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    14.394%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   69.697%, ['4653852', '4661735', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4853692', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4960424', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5248391', '5261461', '5268098', '5294335', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906680', '906681', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.909%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5102537', '5118757', '5157605', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error     4.545%, ['4703149', '4810810', '4984238', '5137153', '5137157', '906760']\n",
      "- diff error    13.636%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '5355157']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   64.394%, ['4650113', '4653852', '4661735', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773948', '4800274', '4823439', '4826952', '4826957', '4827285', '4845088', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5117279', '5135326', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5261461', '5302339', '5315510', '5347155', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['5137154', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  15.909%, ['4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5117279', '5118757', '5160584', '5162042', '5214265', '5214755', '5268098', '5294335', '5302339', '547692', '633082', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error     5.303%, ['4703149', '4810810', '4984238', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    12.121%, ['4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   64.394%, ['4650113', '4653852', '4661735', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5135326', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5261461', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    2.273%, ['4631727', '5355157', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   8.333%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.061%, ['4703149', '4810810', '4896659', '4984238', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    11.364%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   71.970%, ['4650113', '4653852', '4661735', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5117279', '5118757', '5135326', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5261461', '5268098', '5294335', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    2.273%, ['4951739', '5355157', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  51.515%, ['4650113', '4653852', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4823439', '4823611', '4826957', '4827285', '4850346', '4853692', '4863146', '4875475', '4937390', '4955051', '4955053', '4960424', '4969415', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5143186', '5157605', '5160584', '5162042', '5213896', '5214265', '5214755', '5237462', '5248391', '5302339', '5315510', '5356489', '5363251', '5406759', '547692', '587794', '633082', '691688', '691694', '710469', '825292', '861484', '906680', '906681', '925895', '956606', '986931']\n",
      "- both incons    0.000%, []\n",
      "- same error     7.576%, ['4816604', '4896659', '4951739', '4984238', '5137153', '5137154', '5137157', '5335389', '906760', '942357']\n",
      "- diff error     5.303%, ['4633603', '4773857', '4800275', '5039329', '5068771', '5258365', '5355157']\n",
      "- music error    3.788%, ['4816604', '4896659', '4951739', '5335389', '942357']\n",
      "- 1st correct   28.788%, ['4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4800274', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4993934', '5076753', '5102537', '5171396', '5195826', '5202182', '5204781', '5214943', '5261461', '5268098', '5294335', '5347155', '536656', '5377710', '5431709', '672063', '672064', '750132', '907836', '907837', '94350', '989704']\n",
      "- 2nd correct    6.818%, ['4631727', '4667626', '4703149', '4810810', '4827287', '4860099', '5137158', '5314439', '5345058']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.788%, ['4661735', '4696505', '5117279', '5302339', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error     5.303%, ['4703149', '4810810', '4984238', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    14.394%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   76.515%, ['4650113', '4653852', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4960424', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5118757', '5135326', '5143186', '5157605', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5214943', '5237462', '5248391', '5261461', '5268098', '5294335', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   8.333%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error     6.061%, ['4703149', '4810810', '4896659', '4984238', '5137153', '5137154', '5137157', '906760']\n",
      "- diff error    12.121%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   71.970%, ['4650113', '4653852', '4661735', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5117279', '5118757', '5135326', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5261461', '5268098', '5294335', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['4951739', '5355157']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  34.091%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4823439', '4823611', '4827285', '4850346', '4853692', '4875475', '4947281', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5143186', '5157605', '5160584', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error     4.545%, ['4703149', '4984238', '5137154', '5137157', '5355157', '942357']\n",
      "- diff error    12.121%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058']\n",
      "- music error    1.515%, ['5355157', '942357']\n",
      "- 1st correct   46.212%, ['4653852', '4666231', '4671443', '4678080', '4696505', '4710576', '4711578', '4735587', '4767260', '4772658', '4773948', '4800274', '4826952', '4826957', '4845088', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4960424', '4993934', '5024644', '5070846', '5073839', '5076753', '5076821', '5102537', '5117279', '5118757', '5135326', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5214943', '5237462', '5248391', '5261461', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '861484', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- 2nd correct    3.030%, ['4810810', '4860099', '5137153', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  11.364%, ['4650113', '4671406', '4693198', '4823611', '4853692', '4875475', '4947281', '4969415', '5135326', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error     3.788%, ['4703149', '4984238', '5137153', '5137157', '906760']\n",
      "- diff error    14.394%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   68.939%, ['4653852', '4661735', '4666231', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4826952', '4826957', '4827285', '4845088', '4850346', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4955053', '4960424', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5237462', '5248391', '5261461', '5268098', '5294335', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '861484', '906680', '906681', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- 2nd correct    1.515%, ['4810810', '5137154']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4661735', '4696505', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error     4.545%, ['4703149', '4810810', '4984238', '5137153', '5137154', '906760']\n",
      "- diff error    14.394%, ['4631727', '4633603', '4667626', '4773857', '4800275', '4816604', '4827287', '4860099', '4896659', '4951739', '5039329', '5068771', '5137158', '5258365', '5314439', '5335389', '5345058', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   78.030%, ['4650113', '4653852', '4666231', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773948', '4800274', '4823439', '4823611', '4826952', '4826957', '4827285', '4845088', '4850346', '4853692', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4960424', '4969415', '4993934', '5024644', '5051606', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5135326', '5143186', '5157605', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5214943', '5237462', '5248391', '5261461', '5268098', '5294335', '5302339', '5315510', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- 2nd correct    0.758%, ['5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   6.818%, ['4650113', '4714481', '4743012', '4850346', '5102537', '5117279', '5160584', '633082', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    22.727%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4827287', '4861484', '4884993', '4960424', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     8.333%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5157605', '5335389', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   58.333%, ['4631727', '4661735', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4703149', '4723905', '4735587', '4735758', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5143186', '5162042', '5202182', '5204781', '5214755', '5214943', '5248391', '5258365', '5268098', '5294335', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '691688', '691694', '710469', '750132', '825292', '906680', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    3.788%, ['4772658', '4875475', '4969415', '5214265', '5237462']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.121%, ['4749611', '4823611', '4850346', '5089294', '5102537', '5118757', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    22.727%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4827287', '4861484', '4875475', '4884993', '4984238', '5039329', '5068771', '5073839', '5137153', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906760', '907836', '907837', '989704']\n",
      "- diff error     6.818%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5335389', '5355157']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   53.030%, ['4631727', '4650113', '4661735', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5117279', '5135326', '5143186', '5160584', '5202182', '5204781', '5214943', '5248391', '5258365', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '5377710', '587794', '633082', '691688', '691694', '710469', '750132', '825292', '925895', '94350', '986931']\n",
      "- 2nd correct    5.303%, ['4772658', '4960424', '4969415', '5137154', '5157605', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  14.394%, ['4631727', '4743012', '4850346', '4853692', '5076821', '5078640', '5089294', '5117279', '5118757', '5160584', '5162042', '5214755', '5268098', '5294335', '5302339', '547692', '633082', '861484', '906680']\n",
      "- both incons    0.000%, []\n",
      "- same error    24.242%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906760', '907836', '907837', '989704']\n",
      "- diff error     6.818%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5157605', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   50.758%, ['4650113', '4661735', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4703149', '4714481', '4723905', '4735587', '4735758', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5079918', '5081990', '5102537', '5135326', '5143186', '5202182', '5204781', '5214943', '5248391', '5258365', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '587794', '691688', '691694', '710469', '750132', '825292', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    3.788%, ['4960424', '5214265', '5355157', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   6.818%, ['5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.758%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4896659', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906760', '907836', '907837', '989704']\n",
      "- diff error     5.303%, ['4633603', '4653852', '4773857', '4845088', '4860099', '5157605', '5335389']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   58.333%, ['4631727', '4650113', '4661735', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5079918', '5081990', '5102537', '5117279', '5118757', '5135326', '5143186', '5160584', '5202182', '5204781', '5214943', '5248391', '5258365', '5268098', '5294335', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '825292', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    3.788%, ['4951739', '4960424', '5355157', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  46.970%, ['4631727', '4650113', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4714481', '4723905', '4735758', '4743012', '4749611', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4850346', '4853692', '4863146', '4937390', '4955051', '4955053', '5024644', '5051606', '5070846', '5076821', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5143186', '5160584', '5162042', '5214755', '5248391', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '633082', '691688', '691694', '710469', '825292', '861484', '906680', '925895', '956606', '986931']\n",
      "- both incons    0.000%, []\n",
      "- same error    20.455%, ['4666231', '4678080', '4711578', '4767260', '4861484', '4884993', '4896659', '4951739', '4984238', '5039329', '5068771', '5137153', '5137154', '5137157', '5171396', '5195826', '5261461', '5335389', '5347155', '5431709', '672063', '672064', '906760', '907836', '907837', '942357', '989704']\n",
      "- diff error     3.030%, ['4633603', '4773857', '4845088', '5355157']\n",
      "- music error    3.030%, ['4896659', '4951739', '5335389', '942357']\n",
      "- 1st correct   18.182%, ['4671443', '4696505', '4735587', '4800274', '4800275', '4816604', '4826952', '4899365', '4921810', '4936740', '4947281', '4993934', '5076753', '5102537', '5202182', '5204781', '5214943', '5258365', '5268098', '5294335', '536656', '5377710', '750132', '94350']\n",
      "- 2nd correct   11.364%, ['4653852', '4710576', '4772658', '4827287', '4860099', '4875475', '4960424', '4969415', '5073839', '5137158', '5157605', '5213896', '5214265', '5237462', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.788%, ['4661735', '4696505', '5117279', '5302339', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    26.515%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4960424', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     8.333%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5157605', '5335389', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   61.364%, ['4631727', '4650113', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5118757', '5135326', '5143186', '5160584', '5162042', '5202182', '5204781', '5214755', '5214943', '5248391', '5258365', '5268098', '5294335', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '825292', '861484', '906680', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   6.818%, ['5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.758%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4896659', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906760', '907836', '907837', '989704']\n",
      "- diff error     6.061%, ['4633603', '4653852', '4773857', '4845088', '4860099', '5157605', '5335389', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   58.333%, ['4631727', '4650113', '4661735', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4696505', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5079918', '5081990', '5102537', '5117279', '5118757', '5135326', '5143186', '5160584', '5202182', '5204781', '5214943', '5248391', '5258365', '5268098', '5294335', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '825292', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    3.030%, ['4951739', '4960424', '5355157', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  31.818%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4947281', '4955053', '5051606', '5078640', '5079918', '5081990', '5089294', '5143186', '5160584', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '906680', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    24.242%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4884993', '4960424', '4984238', '5039329', '5068771', '5073839', '5137154', '5137157', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5355157', '5431709', '672063', '672064', '907836', '907837', '942357', '989704']\n",
      "- diff error     5.303%, ['4633603', '4653852', '4773857', '4845088', '4896659', '4951739', '5335389']\n",
      "- music error    1.515%, ['5355157', '942357']\n",
      "- 1st correct   33.333%, ['4631727', '4667626', '4671443', '4696505', '4703149', '4735587', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4863146', '4899365', '4921810', '4936740', '4937390', '4955051', '4993934', '5024644', '5070846', '5076753', '5076821', '5102537', '5117279', '5118757', '5135326', '5202182', '5214755', '5214943', '5248391', '5258365', '5314439', '5345058', '5356489', '5363251', '536656', '5377710', '547692', '825292', '861484', '925895', '94350', '986931']\n",
      "- 2nd correct    5.303%, ['4860099', '4875475', '4969415', '5137153', '5157605', '906681', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   9.091%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4947281', '5135326', '5160584', '633082', '750132', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    23.485%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4884993', '4960424', '4984238', '5039329', '5068771', '5073839', '5137153', '5137157', '5137158', '5171396', '5195826', '5213896', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     7.576%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5335389', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   56.061%, ['4631727', '4661735', '4667626', '4671443', '4677606', '4693039', '4694833', '4696505', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4850346', '4863146', '4899365', '4921810', '4936740', '4937390', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5143186', '5162042', '5202182', '5204781', '5214755', '5214943', '5248391', '5258365', '5268098', '5294335', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '691688', '691694', '710469', '825292', '861484', '906680', '925895', '94350', '986931']\n",
      "- 2nd correct    3.788%, ['4875475', '4969415', '5137154', '5157605', '5214265']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4661735', '4696505', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    25.758%, ['4666231', '4678080', '4710576', '4711578', '4767260', '4772658', '4827287', '4861484', '4875475', '4884993', '4960424', '4969415', '4984238', '5039329', '5068771', '5073839', '5137153', '5137154', '5137158', '5171396', '5195826', '5213896', '5214265', '5237462', '5261461', '5347155', '5431709', '672063', '672064', '906681', '906760', '907836', '907837', '989704']\n",
      "- diff error     8.333%, ['4633603', '4653852', '4773857', '4845088', '4860099', '4896659', '4951739', '5157605', '5335389', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   62.879%, ['4631727', '4650113', '4667626', '4671406', '4671443', '4677606', '4693039', '4693198', '4694833', '4703149', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4850346', '4853692', '4863146', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4993934', '5024644', '5051606', '5070846', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5135326', '5143186', '5160584', '5162042', '5202182', '5204781', '5214755', '5214943', '5248391', '5258365', '5268098', '5294335', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '536656', '5377710', '5406759', '547692', '587794', '633082', '691688', '691694', '750132', '825292', '861484', '906680', '925895', '94350', '956606', '986931']\n",
      "- 2nd correct    0.758%, ['5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   3.788%, ['4772658', '4850346', '4969415', '5102537', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    75.758%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5135326', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5248391', '5258365', '5261461', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '5377710', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    6.818%, ['4650113', '4714481', '4743012', '4875475', '5117279', '5160584', '5214265', '5237462', '633082']\n",
      "- 2nd correct   13.636%, ['4749611', '4823611', '4960424', '5089294', '5118757', '5137154', '5157605', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '906680', '906681', '942357', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   5.303%, ['4743012', '4850346', '5117279', '5160584', '5214265', '633082', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    75.758%, ['4633603', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    5.303%, ['4650113', '4714481', '4772658', '4875475', '4969415', '5102537', '5237462']\n",
      "- 2nd correct   12.879%, ['4631727', '4853692', '4960424', '5076821', '5078640', '5089294', '5118757', '5162042', '5214755', '5268098', '5294335', '5302339', '5355157', '547692', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.758%, ['861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.030%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082']\n",
      "- 2nd correct    9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '906680', '906681', '942357']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.848%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5117279', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    36.364%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '5355157', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     4.545%, ['4816604', '4896659', '4951739', '5214943', '5335389', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    0.758%, ['5102537']\n",
      "- 2nd correct   48.485%, ['4631727', '4653852', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4723905', '4735758', '4749611', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4853692', '4860099', '4863146', '4937390', '4955051', '4955053', '4960424', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137158', '5143186', '5157605', '5162042', '5213896', '5214755', '5248391', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '691688', '691694', '710469', '825292', '906680', '906681', '925895', '956606', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.758%, ['5117279']\n",
      "- both incons    0.000%, []\n",
      "- same error    86.364%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5302339', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.758%, ['861484']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082']\n",
      "- 2nd correct    9.091%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '906680', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   6.061%, ['4650113', '4714481', '4743012', '4850346', '4875475', '4969415', '5160584', '633082']\n",
      "- both incons    0.000%, []\n",
      "- same error    56.061%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4960424', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5076821', '5118757', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214755', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     2.273%, ['5214943', '5355157', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['4772658', '5102537', '5117279', '5214265', '5237462', '861484']\n",
      "- 2nd correct   31.061%, ['4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4723905', '4735758', '4749611', '4810810', '4823439', '4823611', '4827285', '4853692', '4860099', '4947281', '4955053', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5157605', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '691688', '691694', '710469', '750132', '906680', '906681', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   4.545%, ['4650113', '4875475', '4969415', '5160584', '5214265', '633082']\n",
      "- both incons    0.000%, []\n",
      "- same error    81.061%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4960424', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    6.061%, ['4714481', '4743012', '4772658', '4850346', '5102537', '5117279', '5237462', '861484']\n",
      "- 2nd correct    8.333%, ['4671406', '4693198', '4810810', '4823611', '4853692', '4947281', '5135326', '5137154', '5157605', '750132', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-24_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    86.364%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4723905', '4735587', '4735758', '4749611', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5248391', '5258365', '5261461', '5268098', '5294335', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4650113', '4714481', '4743012', '4772658', '4850346', '4875475', '4969415', '5102537', '5117279', '5160584', '5214265', '5237462', '633082', '861484']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   9.848%, ['4850346', '4960424', '5089294', '5118757', '5162042', '5214755', '5268098', '5294335', '547692', '861484', '906680', '906681', '942357']\n",
      "- both incons    0.000%, []\n",
      "- same error    73.485%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5135326', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '5377710', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    7.576%, ['4749611', '4772658', '4823611', '4969415', '5102537', '5137154', '5157605', '536656', '5406759', '956606']\n",
      "- 2nd correct    8.333%, ['4631727', '4743012', '4853692', '5076821', '5078640', '5117279', '5160584', '5214265', '5302339', '5355157', '633082']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   6.818%, ['4960424', '5089294', '5162042', '5214755', '547692', '861484', '906680', '906681', '942357']\n",
      "- both incons    0.000%, []\n",
      "- same error    77.273%, ['4631727', '4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4749611', '4772658', '4823611', '4850346', '4969415', '5102537', '5118757', '5137154', '5157605', '5268098', '5294335', '536656', '5406759', '956606']\n",
      "- 2nd correct    3.788%, ['4951739', '5076821', '5078640', '5302339', '5355157']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  12.879%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5118757', '5157605', '5162042', '5214755', '5406759', '547692', '861484', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    33.333%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5137153', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5347155', '5355157', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     3.788%, ['4816604', '4896659', '4951739', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    4.545%, ['5102537', '5137154', '5268098', '5294335', '536656', '942357']\n",
      "- 2nd correct   45.455%, ['4631727', '4650113', '4653852', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4773948', '4810810', '4823439', '4826957', '4827285', '4827287', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5117279', '5135326', '5137158', '5143186', '5160584', '5213896', '5214265', '5237462', '5248391', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '587794', '633082', '691688', '691694', '710469', '825292', '925895', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   17.424%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5102537', '5118757', '5137154', '5157605', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '906681', '942357', '956606']\n",
      "- 2nd correct    3.788%, ['4661735', '4696505', '5117279', '5302339', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   6.061%, ['4960424', '5089294', '5162042', '5214755', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    77.273%, ['4631727', '4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5117279', '5135326', '5137153', '5137157', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   11.364%, ['4749611', '4772658', '4823611', '4850346', '4969415', '5102537', '5118757', '5137154', '5157605', '5268098', '5294335', '536656', '5406759', '942357', '956606']\n",
      "- 2nd correct    3.788%, ['4951739', '5076821', '5078640', '5302339', '5355157']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.848%, ['4749611', '4823611', '4850346', '4969415', '5089294', '5157605', '5162042', '5268098', '5294335', '5406759', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    53.788%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5076821', '5117279', '5135326', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '5377710', '5431709', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['5214943', '5355157']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    7.576%, ['4772658', '4960424', '5102537', '5118757', '5137154', '5214755', '536656', '547692', '861484', '942357']\n",
      "- 2nd correct   27.273%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4810810', '4823439', '4827285', '4853692', '4860099', '4875475', '4947281', '4955053', '5051606', '5078640', '5079918', '5081990', '5137153', '5143186', '5160584', '5204781', '5302339', '5315510', '587794', '633082', '691688', '691694', '710469', '750132', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.788%, ['4823611', '4969415', '5137154', '5157605', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    73.485%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5117279', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '5377710', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   13.636%, ['4749611', '4772658', '4850346', '4960424', '5089294', '5102537', '5118757', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    9.091%, ['4650113', '4671406', '4693198', '4810810', '4853692', '4875475', '4947281', '5135326', '5160584', '5214265', '633082', '750132']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    79.545%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4767260', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5117279', '5135326', '5137153', '5137158', '5143186', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '5377710', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   17.424%, ['4749611', '4772658', '4823611', '4850346', '4960424', '4969415', '5089294', '5102537', '5118757', '5137154', '5157605', '5162042', '5214755', '5268098', '5294335', '536656', '5406759', '547692', '861484', '906680', '906681', '942357', '956606']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.848%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- both incons    0.000%, []\n",
      "- same error    80.303%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.758%, ['5081990']\n",
      "- 1st correct    8.333%, ['4631727', '4743012', '4850346', '4853692', '5117279', '5118757', '5160584', '5214265', '5268098', '5294335', '633082']\n",
      "- 2nd correct    0.758%, ['4951739']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  15.152%, ['4631727', '4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5117279', '5118757', '5160584', '5162042', '5214265', '5214755', '5302339', '547692', '633082', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    34.848%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5347155', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     3.788%, ['4816604', '4896659', '4951739', '5214943', '5335389']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.030%, ['5268098', '5294335', '5355157', '942357']\n",
      "- 2nd correct   43.182%, ['4650113', '4653852', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4749611', '4772658', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4969415', '5024644', '5051606', '5070846', '5073839', '5079918', '5081990', '5135326', '5137158', '5143186', '5157605', '5213896', '5237462', '5248391', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '587794', '691688', '691694', '710469', '825292', '925895', '956606', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   1.515%, ['5117279', '5302339']\n",
      "- both incons    0.000%, []\n",
      "- same error    78.788%, ['4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   16.667%, ['4631727', '4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5118757', '5160584', '5162042', '5214265', '5214755', '5268098', '5294335', '5355157', '547692', '633082', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    2.273%, ['4661735', '4696505', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.091%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    80.303%, ['4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.758%, ['4896659']\n",
      "- music error    0.758%, ['5081990']\n",
      "- 1st correct    9.091%, ['4631727', '4743012', '4850346', '4853692', '5117279', '5118757', '5160584', '5214265', '5268098', '5294335', '633082', '942357']\n",
      "- 2nd correct    0.758%, ['4951739']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   9.848%, ['4743012', '4850346', '4853692', '5078640', '5089294', '5160584', '5162042', '5268098', '5294335', '5302339', '633082', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    53.788%, ['4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5102537', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    8.333%, ['4631727', '4960424', '5076821', '5117279', '5118757', '5214265', '5214755', '5355157', '547692', '861484', '942357']\n",
      "- 2nd correct   27.273%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4749611', '4810810', '4823439', '4823611', '4827285', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5079918', '5081990', '5137153', '5143186', '5157605', '5204781', '5315510', '5406759', '587794', '691688', '691694', '710469', '750132', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.030%, ['4853692', '5160584', '5214265', '633082']\n",
      "- both incons    0.000%, []\n",
      "- same error    71.212%, ['4633603', '4653852', '4661735', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   15.152%, ['4631727', '4743012', '4850346', '4960424', '5076821', '5078640', '5089294', '5117279', '5118757', '5162042', '5214755', '5268098', '5294335', '5302339', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    9.848%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '750132', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    78.030%, ['4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.758%, ['5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   18.182%, ['4631727', '4743012', '4850346', '4853692', '4960424', '5076821', '5078640', '5089294', '5117279', '5118757', '5160584', '5162042', '5214265', '5214755', '5268098', '5294335', '5302339', '5355157', '547692', '633082', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   8.333%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.121%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4896659', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     2.273%, ['4816604', '5214943', '5335389']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct    2.273%, ['4951739', '5355157', '942357']\n",
      "- 2nd correct   50.000%, ['4631727', '4650113', '4653852', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4969415', '5024644', '5051606', '5070846', '5073839', '5079918', '5081990', '5117279', '5118757', '5135326', '5137158', '5143186', '5157605', '5160584', '5213896', '5214265', '5237462', '5248391', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '587794', '633082', '691688', '691694', '710469', '825292', '925895', '956606', '986931']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.758%, ['5302339']\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5117279', '710469']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    89.394%, ['4631727', '4633603', '4650113', '4653852', '4661735', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5081990', '5102537', '5117279', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '710469', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    1.515%, ['4896659', '5081990']\n",
      "- 1st correct    0.758%, ['942357']\n",
      "- 2nd correct    0.000%, []\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   4.545%, ['5078640', '5089294', '5162042', '5302339', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    55.303%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5102537', '5117279', '5118757', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5214943']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    6.061%, ['4951739', '4960424', '5076821', '5214755', '5355157', '547692', '861484', '942357']\n",
      "- 2nd correct   32.576%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5079918', '5081990', '5137153', '5143186', '5157605', '5160584', '5204781', '5268098', '5294335', '5315510', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    75.000%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5117279', '5118757', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '906760', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct   12.879%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-2_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    84.848%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5117279', '5118757', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   10.606%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681', '942357']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   3.030%, ['4661735', '5117279', '5302339', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    36.364%, ['4633603', '4666231', '4671443', '4678080', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '5355157', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     4.545%, ['4816604', '4896659', '4951739', '5214943', '5335389', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   55.303%, ['4631727', '4650113', '4653852', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4960424', '4969415', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5118757', '5135326', '5137158', '5143186', '5157605', '5160584', '5162042', '5213896', '5214265', '5214755', '5237462', '5248391', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '633082', '691688', '691694', '825292', '861484', '906680', '906681', '925895', '956606', '986931']\n",
      "- 2nd correct    0.758%, ['4696505']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   8.333%, ['4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '547692', '861484', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    37.121%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4896659', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137154', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     3.030%, ['4816604', '5214943', '5335389', '942357']\n",
      "- music error    0.758%, ['4896659']\n",
      "- 1st correct   50.000%, ['4631727', '4650113', '4653852', '4661735', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4969415', '5024644', '5051606', '5070846', '5073839', '5079918', '5081990', '5117279', '5118757', '5135326', '5137158', '5143186', '5157605', '5160584', '5213896', '5214265', '5237462', '5248391', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '587794', '633082', '691688', '691694', '710469', '825292', '925895', '956606', '986931']\n",
      "- 2nd correct    1.515%, ['4951739', '5355157']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct  31.818%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5143186', '5157605', '5160584', '5162042', '5302339', '5315510', '5406759', '587794', '633082', '691688', '691694', '710469', '906680', '906681', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    32.576%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137154', '5137157', '5171396', '5195826', '5202182', '5214943', '5258365', '5261461', '5347155', '536656', '5377710', '5431709', '672063', '672064', '907836', '907837', '942357', '94350', '989704']\n",
      "- diff error     3.788%, ['4816604', '4896659', '4951739', '5335389', '5355157']\n",
      "- music error    1.515%, ['5214943', '942357']\n",
      "- 1st correct   26.515%, ['4631727', '4653852', '4667626', '4703149', '4710576', '4772658', '4773948', '4826957', '4827287', '4863146', '4937390', '4955051', '4960424', '5024644', '5070846', '5073839', '5076821', '5117279', '5118757', '5135326', '5137158', '5213896', '5214265', '5214755', '5237462', '5248391', '5314439', '5345058', '5356489', '5363251', '547692', '825292', '861484', '925895', '986931']\n",
      "- 2nd correct    5.303%, ['4947281', '5137153', '5204781', '5268098', '5294335', '750132', '906760']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  10.606%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4969415', '5135326', '5157605', '5160584', '5214265', '633082', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    34.848%, ['4633603', '4666231', '4671443', '4678080', '4696505', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137157', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '5355157', '536656', '5377710', '5431709', '672063', '672064', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     4.545%, ['4816604', '4896659', '4951739', '5214943', '5335389', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   47.727%, ['4631727', '4653852', '4661735', '4667626', '4677606', '4693039', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4823439', '4826957', '4827285', '4827287', '4850346', '4860099', '4863146', '4937390', '4955051', '4955053', '4960424', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5137158', '5143186', '5162042', '5213896', '5214755', '5237462', '5248391', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '691688', '691694', '710469', '825292', '861484', '906680', '906681', '925895', '986931']\n",
      "- 2nd correct    2.273%, ['4947281', '5137154', '750132']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   1.515%, ['4661735', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    35.606%, ['4633603', '4666231', '4671443', '4678080', '4711578', '4735587', '4767260', '4773857', '4800274', '4800275', '4826952', '4845088', '4861484', '4884993', '4899365', '4921810', '4936740', '4947281', '4984238', '4993934', '5039329', '5068771', '5076753', '5102537', '5137153', '5137154', '5171396', '5195826', '5202182', '5204781', '5258365', '5261461', '5268098', '5294335', '5347155', '5355157', '536656', '5377710', '5431709', '672063', '672064', '750132', '906760', '907836', '907837', '94350', '989704']\n",
      "- diff error     4.545%, ['4816604', '4896659', '4951739', '5214943', '5335389', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   56.818%, ['4631727', '4650113', '4653852', '4667626', '4671406', '4677606', '4693039', '4693198', '4694833', '4703149', '4710576', '4714481', '4723905', '4735758', '4743012', '4749611', '4772658', '4773948', '4810810', '4823439', '4823611', '4826957', '4827285', '4827287', '4850346', '4853692', '4860099', '4863146', '4875475', '4937390', '4955051', '4955053', '4960424', '4969415', '5024644', '5051606', '5070846', '5073839', '5076821', '5078640', '5079918', '5081990', '5089294', '5117279', '5118757', '5135326', '5137158', '5143186', '5157605', '5160584', '5162042', '5213896', '5214265', '5214755', '5237462', '5248391', '5302339', '5314439', '5315510', '5345058', '5356489', '5363251', '5406759', '547692', '587794', '633082', '691688', '691694', '825292', '861484', '906680', '906681', '925895', '956606', '986931']\n",
      "- 2nd correct    1.515%, ['4696505', '5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.758%, ['5302339']\n",
      "- both incons    0.000%, []\n",
      "- same error    85.606%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5118757', '5135326', '5137153', '5137154', '5137157', '5137158', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.030%, ['4661735', '4696505', '5117279', '710469']\n",
      "- 2nd correct    9.091%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5355157', '547692', '861484', '906680', '906681']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   2.273%, ['4661735', '5302339', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    58.333%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4960424', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5076821', '5102537', '5118757', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     3.030%, ['5214943', '5355157', '861484', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    1.515%, ['4696505', '5117279']\n",
      "- 2nd correct   34.848%, ['4650113', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5157605', '5160584', '5162042', '5204781', '5268098', '5294335', '5315510', '5406759', '587794', '633082', '691688', '691694', '750132', '906680', '906681', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    83.333%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4960424', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5118757', '5137153', '5137157', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    3.788%, ['4661735', '4696505', '5117279', '5302339', '710469']\n",
      "- 2nd correct   12.879%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   2.273%, ['4661735', '4696505', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    95.455%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4947281', '4951739', '4955051', '4955053', '4960424', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5118757', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5160584', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214755', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct    1.515%, ['5117279', '5302339']\n",
      "- 2nd correct    0.758%, ['5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1:\n",
      "- both correct   4.545%, ['5078640', '5089294', '5162042', '5302339', '906680', '906681']\n",
      "- both incons    0.000%, []\n",
      "- same error    55.303%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5102537', '5117279', '5118757', '5135326', '5137154', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     2.273%, ['4896659', '5214943', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    5.303%, ['4951739', '4960424', '5076821', '5214755', '5355157', '547692', '861484']\n",
      "- 2nd correct   32.576%, ['4650113', '4661735', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5079918', '5081990', '5137153', '5143186', '5157605', '5160584', '5204781', '5268098', '5294335', '5315510', '5406759', '587794', '633082', '691688', '691694', '710469', '750132', '906760', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    75.758%, ['4631727', '4633603', '4653852', '4661735', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4696505', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4860099', '4861484', '4863146', '4884993', '4899365', '4921810', '4936740', '4937390', '4955051', '4955053', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5117279', '5118757', '5137153', '5137157', '5137158', '5143186', '5171396', '5195826', '5202182', '5204781', '5213896', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '672063', '672064', '691688', '691694', '710469', '825292', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681']\n",
      "- 2nd correct   12.879%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-4_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    85.606%, ['4631727', '4633603', '4650113', '4653852', '4666231', '4667626', '4671406', '4671443', '4677606', '4678080', '4693039', '4693198', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4810810', '4816604', '4823439', '4823611', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4853692', '4860099', '4861484', '4863146', '4875475', '4884993', '4899365', '4921810', '4936740', '4937390', '4947281', '4955051', '4955053', '4969415', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5079918', '5102537', '5117279', '5118757', '5135326', '5137153', '5137154', '5137158', '5143186', '5157605', '5160584', '5171396', '5195826', '5202182', '5204781', '5213896', '5214265', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5314439', '5315510', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '587794', '633082', '672063', '672064', '691688', '691694', '750132', '825292', '906760', '907836', '907837', '925895', '942357', '94350', '956606', '986931', '989704']\n",
      "- diff error     1.515%, ['4896659', '5081990']\n",
      "- music error    0.000%, []\n",
      "- 1st correct    9.848%, ['4951739', '4960424', '5076821', '5078640', '5089294', '5162042', '5214755', '5302339', '5355157', '547692', '861484', '906680', '906681']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3:\n",
      "- both correct  10.606%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4947281', '4969415', '5157605', '5160584', '633082', '750132', '956606']\n",
      "- both incons    0.000%, []\n",
      "- same error    57.576%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4696505', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4960424', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5076821', '5102537', '5117279', '5118757', '5137157', '5137158', '5171396', '5195826', '5202182', '5213896', '5214755', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     3.030%, ['5214943', '5355157', '861484', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   26.515%, ['4661735', '4677606', '4693039', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4823439', '4827285', '4850346', '4860099', '4955053', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '691688', '691694', '710469', '906680', '906681', '906760']\n",
      "- 2nd correct    2.273%, ['5135326', '5137154', '5214265']\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.1\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   1.515%, ['4661735', '710469']\n",
      "- both incons    0.000%, []\n",
      "- same error    58.333%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4678080', '4703149', '4710576', '4711578', '4735587', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4826952', '4826957', '4827287', '4845088', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4960424', '4984238', '4993934', '5024644', '5039329', '5068771', '5070846', '5073839', '5076753', '5076821', '5102537', '5117279', '5118757', '5135326', '5137154', '5137158', '5171396', '5195826', '5202182', '5213896', '5214265', '5214755', '5237462', '5248391', '5258365', '5261461', '5314439', '5335389', '5345058', '5347155', '5356489', '5363251', '536656', '5377710', '5431709', '547692', '672063', '672064', '825292', '907836', '907837', '925895', '94350', '986931', '989704']\n",
      "- diff error     3.030%, ['5214943', '5355157', '861484', '942357']\n",
      "- music error    0.000%, []\n",
      "- 1st correct   35.606%, ['4650113', '4671406', '4677606', '4693039', '4693198', '4694833', '4714481', '4723905', '4735758', '4743012', '4749611', '4810810', '4823439', '4823611', '4827285', '4850346', '4853692', '4860099', '4875475', '4947281', '4955053', '4969415', '5051606', '5078640', '5079918', '5081990', '5089294', '5137153', '5143186', '5157605', '5160584', '5162042', '5204781', '5268098', '5294335', '5302339', '5315510', '5406759', '587794', '633082', '691688', '691694', '750132', '906680', '906681', '906760', '956606']\n",
      "- 2nd correct    1.515%, ['4696505', '5137157']\n",
      "---------------------------------------------------------------------------------\n",
      "comparing vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.3\n",
      "with      vgg_like_in-40__256__1_out-256_filters-8_pool_shape-2__2_max-True_filter_shapes-1__5__1__3_dropout-0.5:\n",
      "- both correct   0.000%, []\n",
      "- both incons    0.000%, []\n",
      "- same error    84.091%, ['4631727', '4633603', '4653852', '4666231', '4667626', '4671443', '4677606', '4678080', '4693039', '4694833', '4703149', '4710576', '4711578', '4714481', '4723905', '4735587', '4735758', '4743012', '4749611', '4767260', '4772658', '4773857', '4773948', '4800274', '4800275', '4816604', '4823439', '4826952', '4826957', '4827285', '4827287', '4845088', '4850346', '4860099', '4861484', '4863146', '4884993', '4896659', '4899365', '4921810', '4936740', '4937390', '4951739', '4955051', '4955053', '4960424', '4984238', '4993934', '5024644', '5039329', '5051606', '5068771', '5070846', '5073839', '5076753', '5076821', '5078640', '5079918', '5081990', '5089294', '5102537', '5117279', '5118757', '5137153', '5137158', '5143186', '5162042', '5171396', '5195826', '5202182', '5204781', '5213896', '5214755', '5214943', '5237462', '5248391', '5258365', '5261461', '5268098', '5294335', '5302339', '5314439', '5315510', '5335389', '5345058', '5347155', '5355157', '5356489', '5363251', '536656', '5377710', '5406759', '5431709', '547692', '587794', '672063', '672064', '691688', '691694', '825292', '861484', '906680', '906681', '906760', '907836', '907837', '925895', '942357', '94350', '986931', '989704']\n",
      "- diff error     0.000%, []\n",
      "- music error    0.000%, []\n",
      "- 1st correct   12.879%, ['4650113', '4671406', '4693198', '4810810', '4823611', '4853692', '4875475', '4947281', '4969415', '5135326', '5137154', '5157605', '5160584', '5214265', '633082', '750132', '956606']\n",
      "- 2nd correct    3.030%, ['4661735', '4696505', '5137157', '710469']\n",
      "---------------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_predict('train.tsv', 'val.tsv', 'test.tsv', \n",
    "  'giantsteps-tempo-dataset/audio/tempo_features.joblib', './jobs', './models')    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, AveragePooling2D, GlobalAveragePooling2D, Activation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = Input(shape=(4,4,1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = Conv2D(4, (1,1), padding='same')(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
